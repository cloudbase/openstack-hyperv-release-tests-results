++ trueorfalse False
+++ set +o
+++ grep xtrace
++ local 'xtrace=set -o xtrace'
++ set +o xtrace
+ OFFLINE=False
++ trueorfalse False
+++ set +o
+++ grep xtrace
++ local 'xtrace=set -o xtrace'
++ set +o xtrace
+ ERROR_ON_CLONE=False
++ trueorfalse True
+++ set +o
+++ grep xtrace
++ local 'xtrace=set -o xtrace'
++ set +o xtrace
+ ENABLE_DEBUG_LOG_LEVEL=True
+ FLOATING_RANGE=172.24.4.0/24
+ FIXED_RANGE=10.0.0.0/24
+ FIXED_NETWORK_SIZE=256
++ get_default_host_ip 10.0.0.0/24 172.24.4.0/24 '' 10.14.0.26
++ local fixed_range=10.0.0.0/24
++ local floating_range=172.24.4.0/24
++ local host_ip_iface=
++ local host_ip=10.14.0.26
+++ ip route
+++ sed -n '/^default/{ s/.*dev \(\w\+\)\s\+.*/\1/; p; }'
+++ head -1
++ host_ip_iface=eth0
++ '[' -z 10.14.0.26 -o 10.14.0.26 == dhcp ']'
++ echo 10.14.0.26
+ HOST_IP=10.14.0.26
+ '[' 10.14.0.26 == '' ']'
+ SERVICE_HOST=10.14.0.26
++ trueorfalse False
+++ set +o
+++ grep xtrace
++ local 'xtrace=set -o xtrace'
++ set +o xtrace
+ SYSLOG=False
+ SYSLOG_HOST=10.14.0.26
+ SYSLOG_PORT=516
++ trueorfalse True False
+++ set +o
+++ grep xtrace
++ local 'xtrace=set -o xtrace'
++ set +o xtrace
+ LOG_COLOR=False
+ SSL_BUNDLE_FILE=/opt/stack/data/ca-bundle.pem
+ rm -f /opt/stack/data/ca-bundle.pem
+ source /home/cloudbase/devstack/lib/database
+++ set +o
+++ grep xtrace
++ XTRACE='set -o xtrace'
++ set +o xtrace
+ source /home/cloudbase/devstack/lib/rpc_backend
+++ set +o
+++ grep xtrace
++ XTRACE='set -o xtrace'
++ set +o xtrace
+ check_rpc_backend
+ local c svc
+ local rpc_needed=1
++ grep -rl iniset_rpc_backend /home/cloudbase/devstack/lib/
++ awk -F/ '{print $NF}'
+ rpc_candidates='nova
glance
ironic
ceilometer
rpc_backend
sahara
cinder
neutron
heat'
+ for c in '${rpc_candidates}'
+ is_service_enabled nova
++ set +o
++ grep xtrace
+ local 'xtrace=set -o xtrace'
+ set +o xtrace
+ return 0
+ rpc_needed=0
+ break
+ local rpc_backend_cnt=0
+ for svc in qpid zeromq rabbit
+ is_service_enabled qpid
++ set +o
++ grep xtrace
+ local 'xtrace=set -o xtrace'
+ set +o xtrace
+ return 1
+ true
+ for svc in qpid zeromq rabbit
+ is_service_enabled zeromq
++ set +o
++ grep xtrace
+ local 'xtrace=set -o xtrace'
+ set +o xtrace
+ return 1
+ true
+ for svc in qpid zeromq rabbit
+ is_service_enabled rabbit
++ set +o
++ grep xtrace
+ local 'xtrace=set -o xtrace'
+ set +o xtrace
+ return 0
+ ((  rpc_backend_cnt++  ))
+ true
+ '[' 1 -gt 1 ']'
+ '[' 1 == 0 ']'
+ is_service_enabled qpid
++ set +o
++ grep xtrace
+ local 'xtrace=set -o xtrace'
+ set +o xtrace
+ return 1
++ trueorfalse False
+++ set +o
+++ grep xtrace
++ local 'xtrace=set -o xtrace'
++ set +o xtrace
+ USE_SSL=False
+ SSL_ENABLED_SERVICES=key,nova,cinder,glance,s-proxy,neutron
+ is_service_enabled tls-proxy
++ set +o
++ grep xtrace
+ local 'xtrace=set -o xtrace'
+ set +o xtrace
+ return 1
+ source /home/cloudbase/devstack/lib/apache
+++ set +o
+++ grep xtrace
++ XTRACE='set -o xtrace'
++ set +o xtrace
+ source /home/cloudbase/devstack/lib/tls
++ is_service_enabled tls-proxy
+++ set +o
+++ grep xtrace
++ local 'xtrace=set -o xtrace'
++ set +o xtrace
++ return 1
+++ hostname -f
++ DEVSTACK_HOSTNAME=localhost
++ DEVSTACK_CERT_NAME=devstack-cert
++ DEVSTACK_CERT=/opt/stack/data/devstack-cert.pem
++ ROOT_CA_DIR=/opt/stack/data/CA/root-ca
++ INT_CA_DIR=/opt/stack/data/CA/int-ca
++ ORG_NAME=OpenStack
++ ORG_UNIT_NAME=DevStack
++ STUD_PROTO=--tls
++ STUD_CIPHERS='TLSv1+HIGH:!DES:!aNULL:!eNULL:@STRENGTH'
++ OPENSSL=/usr/bin/openssl
+ source /home/cloudbase/devstack/lib/infra
+++ set +o
+++ grep xtrace
++ XTRACE='set -o xtrace'
++ set +o xtrace
+ source /home/cloudbase/devstack/lib/oslo
+++ set +o
+++ grep xtrace
++ XTRACE='set -o xtrace'
++ set +o xtrace
+ source /home/cloudbase/devstack/lib/stackforge
+++ set +o
+++ grep xtrace
++ XTRACE='set -o xtrace'
++ set +o xtrace
+ source /home/cloudbase/devstack/lib/horizon
+++ set +o
+++ grep xtrace
++ XTRACE='set -o xtrace'
++ set +o xtrace
+ source /home/cloudbase/devstack/lib/keystone
+++ set +o
+++ grep xtrace
++ XTRACE='set -o xtrace'
++ set +o xtrace
+ source /home/cloudbase/devstack/lib/glance
+++ set +o
+++ grep xtrace
++ XTRACE='set -o xtrace'
++ set +o xtrace
+ source /home/cloudbase/devstack/lib/nova
+++ set +o
+++ grep xtrace
++ XTRACE='set -o xtrace'
++ set +o xtrace
+ source /home/cloudbase/devstack/lib/cinder
+++ set +o
+++ grep xtrace
++ XTRACE='set -o xtrace'
++ set +o xtrace
+ source /home/cloudbase/devstack/lib/swift
+++ set +o
+++ grep xtrace
++ XTRACE='set -o xtrace'
++ set +o xtrace
+ source /home/cloudbase/devstack/lib/ceilometer
+++ set +o
+++ grep xtrace
++ XTRACE='set -o xtrace'
++ set +o xtrace
+ source /home/cloudbase/devstack/lib/heat
+++ set +o
+++ grep xtrace
++ XTRACE='set -o xtrace'
++ set +o xtrace
+ source /home/cloudbase/devstack/lib/neutron
++ NETWORK_GATEWAY=10.0.0.1
++ PUBLIC_NETWORK_GATEWAY=172.24.4.1
++ PRIVATE_SUBNET_NAME=private-subnet
++ PUBLIC_SUBNET_NAME=public-subnet
++ is_ssl_enabled_service neutron
++ local services=neutron
++ local service=
++ '[' False == False ']'
++ return 1
++ is_service_enabled tls-proxy
+++ set +o
+++ grep xtrace
++ local 'xtrace=set -o xtrace'
++ set +o xtrace
++ return 1
++ GITDIR["python-neutronclient"]=/opt/stack/python-neutronclient
++ NEUTRON_DIR=/opt/stack/neutron
++ NEUTRON_AUTH_CACHE_DIR=/var/cache/neutron
++ [[ -d /opt/stack/neutron/bin/neutron-server ]]
+++ get_python_exec_prefix
+++ is_fedora
+++ [[ -z Ubuntu ]]
+++ '[' Ubuntu = Fedora ']'
+++ '[' Ubuntu = 'Red Hat' ']'
+++ '[' Ubuntu = CentOS ']'
+++ '[' Ubuntu = OracleServer ']'
+++ is_suse
+++ [[ -z Ubuntu ]]
+++ '[' Ubuntu = openSUSE ']'
+++ '[' Ubuntu = 'SUSE LINUX' ']'
+++ echo /usr/local/bin
++ NEUTRON_BIN_DIR=/usr/local/bin
++ NEUTRON_CONF_DIR=/etc/neutron
++ NEUTRON_CONF=/etc/neutron/neutron.conf
++ export NEUTRON_TEST_CONFIG_FILE=/etc/neutron/debug.ini
++ NEUTRON_TEST_CONFIG_FILE=/etc/neutron/debug.ini
++ AGENT_DHCP_BINARY=/usr/local/bin/neutron-dhcp-agent
++ AGENT_L3_BINARY=/usr/local/bin/neutron-l3-agent
++ AGENT_META_BINARY=/usr/local/bin/neutron-metadata-agent
++ Q_DHCP_CONF_FILE=/etc/neutron/dhcp_agent.ini
++ Q_L3_CONF_FILE=/etc/neutron/l3_agent.ini
++ Q_FWAAS_CONF_FILE=/etc/neutron/fwaas_driver.ini
++ Q_VPN_CONF_FILE=/etc/neutron/vpn_agent.ini
++ Q_META_CONF_FILE=/etc/neutron/metadata_agent.ini
++ Q_DB_NAME=neutron
++ Q_PLUGIN=ml2
++ Q_PORT=9696
++ Q_PORT_INT=19696
++ Q_HOST=10.14.0.26
++ Q_PROTOCOL=http
++ Q_ADMIN_USERNAME=neutron
++ Q_AUTH_STRATEGY=keystone
++ Q_USE_NAMESPACE=True
++ Q_OVS_USE_VETH=False
++ Q_USE_ROOTWRAP=True
++ Q_META_DATA_IP=10.14.0.26
++ Q_ALLOW_OVERLAPPING_IP=True
++ Q_USE_DEBUG_COMMAND=False
++ Q_ROUTER_NAME=router1
++ NOVA_VIF_DRIVER=nova.virt.libvirt.vif.LibvirtGenericVIFDriver
++ Q_NOTIFY_NOVA_PORT_STATUS_CHANGES=True
++ Q_NOTIFY_NOVA_PORT_DATA_CHANGES=True
++ VIF_PLUGGING_IS_FATAL=True
++ VIF_PLUGGING_TIMEOUT=300
++ PROVIDER_SUBNET_NAME=provider_net
++ Q_USE_PROVIDERNET_FOR_PUBLIC=False
++ PUBLIC_PHYSICAL_NETWORK=public
++ Q_USE_PUBLIC_VETH=False
++ Q_PUBLIC_VETH_EX=veth-pub-ex
++ Q_PUBLIC_VETH_INT=veth-pub-int
++ Q_L3_ENABLED=False
++ Q_L3_ROUTER_PER_TENANT=False
++ declare -a Q_PLUGIN_EXTRA_CONF_FILES
++ declare -a Q_VPN_EXTRA_CONF_FILES
++ Q_RR_CONF_FILE=/etc/neutron/rootwrap.conf
++ [[ True == \F\a\l\s\e ]]
+++ get_rootwrap_location neutron
+++ local module=neutron
++++ get_python_exec_prefix
++++ is_fedora
++++ [[ -z Ubuntu ]]
++++ '[' Ubuntu = Fedora ']'
++++ '[' Ubuntu = 'Red Hat' ']'
++++ '[' Ubuntu = CentOS ']'
++++ '[' Ubuntu = OracleServer ']'
++++ is_suse
++++ [[ -z Ubuntu ]]
++++ '[' Ubuntu = openSUSE ']'
++++ '[' Ubuntu = 'SUSE LINUX' ']'
++++ echo /usr/local/bin
+++ echo /usr/local/bin/neutron-rootwrap
++ NEUTRON_ROOTWRAP=/usr/local/bin/neutron-rootwrap
++ Q_RR_COMMAND='sudo /usr/local/bin/neutron-rootwrap /etc/neutron/rootwrap.conf'
++ Q_DVR_MODE=legacy
++ [[ legacy != \l\e\g\a\c\y ]]
++ ENABLE_TENANT_TUNNELS=True
++ TENANT_TUNNEL_RANGES=1:1000
++ ENABLE_TENANT_VLANS=True
++ TENANT_VLAN_RANGE=500:2000
++ PHYSICAL_NETWORK=physnet1
++ OVS_PHYSICAL_BRIDGE=br-eth1
++ LB_PHYSICAL_INTERFACE=
++ TUNNEL_ENDPOINT_IP=10.14.0.26
++ OVS_ENABLE_TUNNELING=False
++ source /home/cloudbase/devstack/lib/neutron_plugins/ml2
++++ set +o
++++ grep xtrace
+++ ML2_XTRACE='set -o xtrace'
+++ set +o xtrace
++ source /home/cloudbase/devstack/lib/neutron_plugins/services/loadbalancer
++++ set +o
++++ grep xtrace
+++ LB_XTRACE='set -o xtrace'
+++ set +o xtrace
++ source /home/cloudbase/devstack/lib/neutron_plugins/services/metering
++++ set +o
++++ grep xtrace
+++ METER_XTRACE='set -o xtrace'
+++ set +o xtrace
++ source /home/cloudbase/devstack/lib/neutron_plugins/services/vpn
++++ set +o
++++ grep xtrace
+++ VPN_XTRACE='set -o xtrace'
+++ set +o xtrace
++ source /home/cloudbase/devstack/lib/neutron_plugins/services/firewall
++++ set +o
++++ grep xtrace
+++ FW_XTRACE='set -o xtrace'
+++ set +o xtrace
++ has_neutron_plugin_security_group
++ return 0
++ Q_USE_SECGROUP=True
++ TEMPEST_SERVICES+=,neutron
+++ set +o
+++ grep xtrace
++ XTRACE='set -o xtrace'
++ set +o xtrace
+ source /home/cloudbase/devstack/lib/baremetal
+++ set +o
+++ grep xtrace
++ XTRACE='set -o xtrace'
++ set +o xtrace
+ source /home/cloudbase/devstack/lib/ldap
+++ set +o
+++ grep xtrace
++ XTRACE='set -o xtrace'
++ set +o xtrace
+ source /home/cloudbase/devstack/lib/dstat
+++ set +o
+++ grep xtrace
++ XTRACE='set -o xtrace'
++ set +o xtrace
+ [[ -d /home/cloudbase/devstack/extras.d ]]
+ for i in '$TOP_DIR/extras.d/*.sh'
+ [[ -r /home/cloudbase/devstack/extras.d/40-dib.sh ]]
+ source /home/cloudbase/devstack/extras.d/40-dib.sh source
++ is_service_enabled dib
+++ set +o
+++ grep xtrace
++ local 'xtrace=set -o xtrace'
++ set +o xtrace
++ return 1
+ for i in '$TOP_DIR/extras.d/*.sh'
+ [[ -r /home/cloudbase/devstack/extras.d/50-ironic.sh ]]
+ source /home/cloudbase/devstack/extras.d/50-ironic.sh source
++ is_service_enabled ir-api ir-cond
+++ set +o
+++ grep xtrace
++ local 'xtrace=set -o xtrace'
++ set +o xtrace
++ return 1
+ for i in '$TOP_DIR/extras.d/*.sh'
+ [[ -r /home/cloudbase/devstack/extras.d/60-ceph.sh ]]
+ source /home/cloudbase/devstack/extras.d/60-ceph.sh source
++ is_service_enabled ceph
+++ set +o
+++ grep xtrace
++ local 'xtrace=set -o xtrace'
++ set +o xtrace
++ return 1
+ for i in '$TOP_DIR/extras.d/*.sh'
+ [[ -r /home/cloudbase/devstack/extras.d/70-gantt.sh ]]
+ source /home/cloudbase/devstack/extras.d/70-gantt.sh source
++ is_service_enabled n-sch
+++ set +o
+++ grep xtrace
++ local 'xtrace=set -o xtrace'
++ set +o xtrace
++ return 0
++ disable_service gantt
++ local tmpsvcs=,g-api,g-reg,key,n-api,n-crt,n-obj,n-cond,n-sch,n-xvnc,n-cauth,c-sch,c-api,c-vol,h-eng,h-api,h-api-cfn,h-api-cw,rabbit,tempest,mysql,neutron,q-svc,q-agt,q-dhcp,q-l3,q-meta,q-lbaas,q-fwaas,q-metering,q-vpn,c-bak,s-proxy,s-object,s-container,s-account,heat,ceilometer-acentral,ceilometer-collector,ceilometer-api,
++ local service
++ for service in '$@'
++ is_service_enabled gantt
+++ set +o
+++ grep xtrace
++ local 'xtrace=set -o xtrace'
++ set +o xtrace
++ return 1
+++ _cleanup_service_list ,g-api,g-reg,key,n-api,n-crt,n-obj,n-cond,n-sch,n-xvnc,n-cauth,c-sch,c-api,c-vol,h-eng,h-api,h-api-cfn,h-api-cw,rabbit,tempest,mysql,neutron,q-svc,q-agt,q-dhcp,q-l3,q-meta,q-lbaas,q-fwaas,q-metering,q-vpn,c-bak,s-proxy,s-object,s-container,s-account,heat,ceilometer-acentral,ceilometer-collector,ceilometer-api,
+++ echo ,g-api,g-reg,key,n-api,n-crt,n-obj,n-cond,n-sch,n-xvnc,n-cauth,c-sch,c-api,c-vol,h-eng,h-api,h-api-cfn,h-api-cw,rabbit,tempest,mysql,neutron,q-svc,q-agt,q-dhcp,q-l3,q-meta,q-lbaas,q-fwaas,q-metering,q-vpn,c-bak,s-proxy,s-object,s-container,s-account,heat,ceilometer-acentral,ceilometer-collector,ceilometer-api,
+++ sed -e '
        s/,,/,/g;
        s/^,//;
        s/,$//
    '
++ ENABLED_SERVICES=g-api,g-reg,key,n-api,n-crt,n-obj,n-cond,n-sch,n-xvnc,n-cauth,c-sch,c-api,c-vol,h-eng,h-api,h-api-cfn,h-api-cw,rabbit,tempest,mysql,neutron,q-svc,q-agt,q-dhcp,q-l3,q-meta,q-lbaas,q-fwaas,q-metering,q-vpn,c-bak,s-proxy,s-object,s-container,s-account,heat,ceilometer-acentral,ceilometer-collector,ceilometer-api
++ is_service_enabled gantt
+++ set +o
+++ grep xtrace
++ local 'xtrace=set -o xtrace'
++ set +o xtrace
++ return 1
+ for i in '$TOP_DIR/extras.d/*.sh'
+ [[ -r /home/cloudbase/devstack/extras.d/70-sahara.sh ]]
+ source /home/cloudbase/devstack/extras.d/70-sahara.sh source
++ is_service_enabled sahara
+++ set +o
+++ grep xtrace
++ local 'xtrace=set -o xtrace'
++ set +o xtrace
++ return 1
+ for i in '$TOP_DIR/extras.d/*.sh'
+ [[ -r /home/cloudbase/devstack/extras.d/70-trove.sh ]]
+ source /home/cloudbase/devstack/extras.d/70-trove.sh source
++ is_service_enabled trove
+++ set +o
+++ grep xtrace
++ local 'xtrace=set -o xtrace'
++ set +o xtrace
++ return 1
+ for i in '$TOP_DIR/extras.d/*.sh'
+ [[ -r /home/cloudbase/devstack/extras.d/70-zaqar.sh ]]
+ source /home/cloudbase/devstack/extras.d/70-zaqar.sh source
++ is_service_enabled zaqar-server
+++ set +o
+++ grep xtrace
++ local 'xtrace=set -o xtrace'
++ set +o xtrace
++ return 1
+ for i in '$TOP_DIR/extras.d/*.sh'
+ [[ -r /home/cloudbase/devstack/extras.d/80-opendaylight.sh ]]
+ source /home/cloudbase/devstack/extras.d/80-opendaylight.sh source
++ is_service_enabled odl-server odl-compute
+++ set +o
+++ grep xtrace
++ local 'xtrace=set -o xtrace'
++ set +o xtrace
++ return 1
++ is_service_enabled odl-server
+++ set +o
+++ grep xtrace
++ local 'xtrace=set -o xtrace'
++ set +o xtrace
++ return 1
++ is_service_enabled odl-compute
+++ set +o
+++ grep xtrace
++ local 'xtrace=set -o xtrace'
++ set +o xtrace
++ return 1
+ for i in '$TOP_DIR/extras.d/*.sh'
+ [[ -r /home/cloudbase/devstack/extras.d/80-tempest.sh ]]
+ source /home/cloudbase/devstack/extras.d/80-tempest.sh source
++ is_service_enabled tempest
+++ set +o
+++ grep xtrace
++ local 'xtrace=set -o xtrace'
++ set +o xtrace
++ return 0
++ [[ source == \s\o\u\r\c\e ]]
++ source /home/cloudbase/devstack/lib/tempest
++++ set +o
++++ grep xtrace
+++ XTRACE='set -o xtrace'
+++ set +o xtrace
++ [[ source == \u\n\s\t\a\c\k ]]
++ [[ source == \c\l\e\a\n ]]
+ initialize_database_backends
+ for backend in '$DATABASE_BACKENDS'
+ is_service_enabled mysql
++ set +o
++ grep xtrace
+ local 'xtrace=set -o xtrace'
+ set +o xtrace
+ return 0
+ DATABASE_TYPE=mysql
+ for backend in '$DATABASE_BACKENDS'
+ is_service_enabled postgresql
++ set +o
++ grep xtrace
+ local 'xtrace=set -o xtrace'
+ set +o xtrace
+ return 1
+ '[' -z mysql ']'
+ MYSQL_HOST=127.0.0.1
+ MYSQL_USER=root
+ DATABASE_HOST=127.0.0.1
+ DATABASE_USER=root
+ '[' -n '' ']'
+ read_password DATABASE_PASSWORD 'ENTER A PASSWORD TO USE FOR THE DATABASE.'
++ set +o
++ grep xtrace
+ XTRACE='set -o xtrace'
+ set +o xtrace
++ get_database_type
++ [[ -n '' ]]
++ echo mysql
+ BASE_SQL_CONN=mysql://root:Passw0rd@127.0.0.1
+ return 0
+ echo 'Using mysql database backend'
+ is_service_enabled rabbit
++ set +o
++ grep xtrace
+ local 'xtrace=set -o xtrace'
+ set +o xtrace
+ return 0
+ RABBIT_HOST=10.14.0.26
+ read_password RABBIT_PASSWORD 'ENTER A PASSWORD TO USE FOR RABBIT.'
++ set +o
++ grep xtrace
+ XTRACE='set -o xtrace'
+ set +o xtrace
+ is_service_enabled key
++ set +o
++ grep xtrace
+ local 'xtrace=set -o xtrace'
+ set +o xtrace
+ return 0
+ read_password SERVICE_TOKEN 'ENTER A SERVICE_TOKEN TO USE FOR THE SERVICE ADMIN TOKEN.'
++ set +o
++ grep xtrace
+ XTRACE='set -o xtrace'
+ set +o xtrace
+ read_password SERVICE_PASSWORD 'ENTER A SERVICE_PASSWORD TO USE FOR THE SERVICE AUTHENTICATION.'
++ set +o
++ grep xtrace
+ XTRACE='set -o xtrace'
+ set +o xtrace
+ read_password ADMIN_PASSWORD 'ENTER A PASSWORD TO USE FOR HORIZON AND KEYSTONE (20 CHARS OR LESS).'
++ set +o
++ grep xtrace
+ XTRACE='set -o xtrace'
+ set +o xtrace
+ is_service_enabled ldap
++ set +o
++ grep xtrace
+ local 'xtrace=set -o xtrace'
+ set +o xtrace
+ return 1
+ is_service_enabled s-proxy
++ set +o
++ grep xtrace
+ local 'xtrace=set -o xtrace'
+ set +o xtrace
+ return 0
+ read_password SWIFT_HASH 'ENTER A RANDOM SWIFT HASH.'
++ set +o
++ grep xtrace
+ XTRACE='set -o xtrace'
+ set +o xtrace
+ [[ -z '' ]]
+ [[ False == \T\r\u\e ]]
+ echo_summary 'Installing package prerequisites'
+ [[ -t 3 ]]
+ echo -e Installing package prerequisites
+ source /home/cloudbase/devstack/tools/install_prereqs.sh
++ [[ -n '' ]]
++ [[ -z /home/cloudbase/devstack ]]
++ PREREQ_RERUN_MARKER=/home/cloudbase/devstack/.prereqs
++ PREREQ_RERUN_HOURS=2
++ PREREQ_RERUN_SECONDS=7200
+++ date +%s
++ NOW=1418394538
+++ head -1 /home/cloudbase/devstack/.prereqs
++ LAST_RUN=1418390879
++ DELTA=3659
++ [[ 3659 -lt 7200 ]]
++ [[ -z '' ]]
++ echo 'Re-run time has not expired (3541 seconds remaining) '
++ echo 'and FORCE_PREREQ not set; exiting...'
++ return 0
+ [[ False != \T\r\u\e ]]
+ PYPI_ALTERNATIVE_URL=
+ /home/cloudbase/devstack/tools/install_pip.sh
+++ dirname /home/cloudbase/devstack/tools/install_pip.sh
++ cd /home/cloudbase/devstack/tools
++ pwd
+ TOOLS_DIR=/home/cloudbase/devstack/tools
++ cd /home/cloudbase/devstack/tools/..
++ pwd
+ TOP_DIR=/home/cloudbase/devstack
+ cd /home/cloudbase/devstack
+ source /home/cloudbase/devstack/functions
++++ dirname /home/cloudbase/devstack/functions
+++ cd /home/cloudbase/devstack
+++ pwd
++ FUNC_DIR=/home/cloudbase/devstack
++ source /home/cloudbase/devstack/functions-common
++++ set +o
++++ grep xtrace
+++ XTRACE='set -o xtrace'
+++ set +o xtrace
+++ set +o
+++ grep xtrace
++ XTRACE='set -o xtrace'
++ set +o xtrace
+ FILES=/home/cloudbase/devstack/files
+ PIP_GET_PIP_URL=https://bootstrap.pypa.io/get-pip.py
++ basename https://bootstrap.pypa.io/get-pip.py
+ LOCAL_PIP=/home/cloudbase/devstack/files/get-pip.py
+ GetDistro
+ GetOSVersion
++ which sw_vers
+ [[ -x '' ]]
++ which lsb_release
+ [[ -x /usr/bin/lsb_release ]]
++ lsb_release -i -s
+ os_VENDOR=Ubuntu
++ lsb_release -r -s
+ os_RELEASE=14.04
+ os_UPDATE=
+ os_PACKAGE=rpm
+ [[ Debian,Ubuntu,LinuxMint =~ Ubuntu ]]
+ os_PACKAGE=deb
++ lsb_release -c -s
+ os_CODENAME=trusty
+ export os_VENDOR os_RELEASE os_UPDATE os_PACKAGE os_CODENAME
+ [[ Ubuntu =~ (Ubuntu) ]]
+ DISTRO=trusty
+ export DISTRO
+ echo 'Distro: trusty'
+ get_versions
++ which pip
+ PIP=/usr/local/bin/pip
+ [[ -n /usr/local/bin/pip ]]
++ /usr/local/bin/pip --version
++ awk '{ print $2}'
+ PIP_VERSION=1.5.6
+ echo 'pip: 1.5.6'
+ uninstall_package python-pip
+ is_ubuntu
+ [[ -z deb ]]
+ '[' deb = deb ']'
+ apt_get purge python-pip
++ set +o
++ grep xtrace
+ local 'xtrace=set -o xtrace'
+ set +o xtrace
+ sudo DEBIAN_FRONTEND=noninteractive http_proxy= https_proxy= no_proxy= apt-get --option Dpkg::Options::=--force-confold --assume-yes purge python-pip
+ install_get_pip
+ [[ ! -r /home/cloudbase/devstack/files/get-pip.py ]]
+ sudo -E python /home/cloudbase/devstack/files/get-pip.py
+ [[ -n '' ]]
+ pip_install -U setuptools
++ set +o
++ grep xtrace
+ local 'xtrace=set -o xtrace'
+ set +o xtrace
+ sudo PIP_DOWNLOAD_CACHE=/var/cache/pip http_proxy= https_proxy= no_proxy= /usr/local/bin/pip install -U setuptools
+ [[ '' == \T\r\u\e ]]
+ get_versions
++ which pip
+ PIP=/usr/local/bin/pip
+ [[ -n /usr/local/bin/pip ]]
++ /usr/local/bin/pip --version
++ awk '{ print $2}'
+ PIP_VERSION=1.5.6
+ echo 'pip: 1.5.6'
+ source /home/cloudbase/devstack/tools/fixup_stuff.sh
++ [[ -z /home/cloudbase/devstack ]]
++ keystone_ports=35357,35358
+++ sysctl net.ipv4.ip_local_reserved_ports
+++ awk -F= '{print $2;}'
+++ sed 's/^ //'
++ reserved_ports=35357-35358
++ [[ -z 35357-35358 ]]
++ sudo sysctl -w net.ipv4.ip_local_reserved_ports=35357,35358,35357-35358
++ pip_install 'prettytable>0.7'
+++ set +o
+++ grep xtrace
++ local 'xtrace=set -o xtrace'
++ set +o xtrace
++ sudo PIP_DOWNLOAD_CACHE=/var/cache/pip http_proxy= https_proxy= no_proxy= /usr/local/bin/pip install 'prettytable>0.7'
++ [[ False == \T\r\u\e ]]
+++ get_package_path prettytable
+++ local package=prettytable
++++ python -c 'import os; import prettytable; print(os.path.split(os.path.realpath(prettytable.__file__))[0])'
+++ echo /usr/local/lib/python2.7/dist-packages
++ PACKAGE_DIR=/usr/local/lib/python2.7/dist-packages
+++ echo /usr/local/lib/python2.7/dist-packages/prettytable-0.7.2.egg-info
++ dir=/usr/local/lib/python2.7/dist-packages/prettytable-0.7.2.egg-info
++ [[ -d /usr/local/lib/python2.7/dist-packages/prettytable-0.7.2.egg-info ]]
++ sudo chmod +r /usr/local/lib/python2.7/dist-packages/prettytable-0.7.2.egg-info/PKG-INFO /usr/local/lib/python2.7/dist-packages/prettytable-0.7.2.egg-info/SOURCES.txt /usr/local/lib/python2.7/dist-packages/prettytable-0.7.2.egg-info/dependency_links.txt /usr/local/lib/python2.7/dist-packages/prettytable-0.7.2.egg-info/installed-files.txt /usr/local/lib/python2.7/dist-packages/prettytable-0.7.2.egg-info/top_level.txt
++ pip_install httplib2
+++ set +o
+++ grep xtrace
++ local 'xtrace=set -o xtrace'
++ set +o xtrace
++ sudo PIP_DOWNLOAD_CACHE=/var/cache/pip http_proxy= https_proxy= no_proxy= /usr/local/bin/pip install httplib2
++ [[ False == \T\r\u\e ]]
+++ get_package_path httplib2
+++ local package=httplib2
++++ python -c 'import os; import httplib2; print(os.path.split(os.path.realpath(httplib2.__file__))[0])'
+++ echo /usr/local/lib/python2.7/dist-packages/httplib2
++ PACKAGE_DIR=/usr/local/lib/python2.7/dist-packages/httplib2
+++ echo '/usr/local/lib/python2.7/dist-packages/httplib2-0.8*'
++ dir='/usr/local/lib/python2.7/dist-packages/httplib2-0.8*'
++ [[ -d /usr/local/lib/python2.7/dist-packages/httplib2-0.8* ]]
++ is_fedora
++ [[ -z Ubuntu ]]
++ '[' Ubuntu = Fedora ']'
++ '[' Ubuntu = 'Red Hat' ']'
++ '[' Ubuntu = CentOS ']'
++ '[' Ubuntu = OracleServer ']'
++ [[ trusty =~ (rhel6) ]]
+ [[ -d /home/cloudbase/devstack/extras.d ]]
+ for i in '$TOP_DIR/extras.d/*.sh'
+ [[ -r /home/cloudbase/devstack/extras.d/40-dib.sh ]]
+ source /home/cloudbase/devstack/extras.d/40-dib.sh stack pre-install
++ is_service_enabled dib
+++ set +o
+++ grep xtrace
++ local 'xtrace=set -o xtrace'
++ set +o xtrace
++ return 1
+ for i in '$TOP_DIR/extras.d/*.sh'
+ [[ -r /home/cloudbase/devstack/extras.d/50-ironic.sh ]]
+ source /home/cloudbase/devstack/extras.d/50-ironic.sh stack pre-install
++ is_service_enabled ir-api ir-cond
+++ set +o
+++ grep xtrace
++ local 'xtrace=set -o xtrace'
++ set +o xtrace
++ return 1
+ for i in '$TOP_DIR/extras.d/*.sh'
+ [[ -r /home/cloudbase/devstack/extras.d/60-ceph.sh ]]
+ source /home/cloudbase/devstack/extras.d/60-ceph.sh stack pre-install
++ is_service_enabled ceph
+++ set +o
+++ grep xtrace
++ local 'xtrace=set -o xtrace'
++ set +o xtrace
++ return 1
+ for i in '$TOP_DIR/extras.d/*.sh'
+ [[ -r /home/cloudbase/devstack/extras.d/70-gantt.sh ]]
+ source /home/cloudbase/devstack/extras.d/70-gantt.sh stack pre-install
++ is_service_enabled n-sch
+++ set +o
+++ grep xtrace
++ local 'xtrace=set -o xtrace'
++ set +o xtrace
++ return 0
++ disable_service gantt
++ local tmpsvcs=,g-api,g-reg,key,n-api,n-crt,n-obj,n-cond,n-sch,n-xvnc,n-cauth,c-sch,c-api,c-vol,h-eng,h-api,h-api-cfn,h-api-cw,rabbit,tempest,mysql,neutron,q-svc,q-agt,q-dhcp,q-l3,q-meta,q-lbaas,q-fwaas,q-metering,q-vpn,c-bak,s-proxy,s-object,s-container,s-account,heat,ceilometer-acentral,ceilometer-collector,ceilometer-api,
++ local service
++ for service in '$@'
++ is_service_enabled gantt
+++ set +o
+++ grep xtrace
++ local 'xtrace=set -o xtrace'
++ set +o xtrace
++ return 1
+++ _cleanup_service_list ,g-api,g-reg,key,n-api,n-crt,n-obj,n-cond,n-sch,n-xvnc,n-cauth,c-sch,c-api,c-vol,h-eng,h-api,h-api-cfn,h-api-cw,rabbit,tempest,mysql,neutron,q-svc,q-agt,q-dhcp,q-l3,q-meta,q-lbaas,q-fwaas,q-metering,q-vpn,c-bak,s-proxy,s-object,s-container,s-account,heat,ceilometer-acentral,ceilometer-collector,ceilometer-api,
+++ echo ,g-api,g-reg,key,n-api,n-crt,n-obj,n-cond,n-sch,n-xvnc,n-cauth,c-sch,c-api,c-vol,h-eng,h-api,h-api-cfn,h-api-cw,rabbit,tempest,mysql,neutron,q-svc,q-agt,q-dhcp,q-l3,q-meta,q-lbaas,q-fwaas,q-metering,q-vpn,c-bak,s-proxy,s-object,s-container,s-account,heat,ceilometer-acentral,ceilometer-collector,ceilometer-api,
+++ sed -e '
        s/,,/,/g;
        s/^,//;
        s/,$//
    '
++ ENABLED_SERVICES=g-api,g-reg,key,n-api,n-crt,n-obj,n-cond,n-sch,n-xvnc,n-cauth,c-sch,c-api,c-vol,h-eng,h-api,h-api-cfn,h-api-cw,rabbit,tempest,mysql,neutron,q-svc,q-agt,q-dhcp,q-l3,q-meta,q-lbaas,q-fwaas,q-metering,q-vpn,c-bak,s-proxy,s-object,s-container,s-account,heat,ceilometer-acentral,ceilometer-collector,ceilometer-api
++ is_service_enabled gantt
+++ set +o
+++ grep xtrace
++ local 'xtrace=set -o xtrace'
++ set +o xtrace
++ return 1
+ for i in '$TOP_DIR/extras.d/*.sh'
+ [[ -r /home/cloudbase/devstack/extras.d/70-sahara.sh ]]
+ source /home/cloudbase/devstack/extras.d/70-sahara.sh stack pre-install
++ is_service_enabled sahara
+++ set +o
+++ grep xtrace
++ local 'xtrace=set -o xtrace'
++ set +o xtrace
++ return 1
+ for i in '$TOP_DIR/extras.d/*.sh'
+ [[ -r /home/cloudbase/devstack/extras.d/70-trove.sh ]]
+ source /home/cloudbase/devstack/extras.d/70-trove.sh stack pre-install
++ is_service_enabled trove
+++ set +o
+++ grep xtrace
++ local 'xtrace=set -o xtrace'
++ set +o xtrace
++ return 1
+ for i in '$TOP_DIR/extras.d/*.sh'
+ [[ -r /home/cloudbase/devstack/extras.d/70-zaqar.sh ]]
+ source /home/cloudbase/devstack/extras.d/70-zaqar.sh stack pre-install
++ is_service_enabled zaqar-server
+++ set +o
+++ grep xtrace
++ local 'xtrace=set -o xtrace'
++ set +o xtrace
++ return 1
+ for i in '$TOP_DIR/extras.d/*.sh'
+ [[ -r /home/cloudbase/devstack/extras.d/80-opendaylight.sh ]]
+ source /home/cloudbase/devstack/extras.d/80-opendaylight.sh stack pre-install
++ is_service_enabled odl-server odl-compute
+++ set +o
+++ grep xtrace
++ local 'xtrace=set -o xtrace'
++ set +o xtrace
++ return 1
++ is_service_enabled odl-server
+++ set +o
+++ grep xtrace
++ local 'xtrace=set -o xtrace'
++ set +o xtrace
++ return 1
++ is_service_enabled odl-compute
+++ set +o
+++ grep xtrace
++ local 'xtrace=set -o xtrace'
++ set +o xtrace
++ return 1
+ for i in '$TOP_DIR/extras.d/*.sh'
+ [[ -r /home/cloudbase/devstack/extras.d/80-tempest.sh ]]
+ source /home/cloudbase/devstack/extras.d/80-tempest.sh stack pre-install
++ is_service_enabled tempest
+++ set +o
+++ grep xtrace
++ local 'xtrace=set -o xtrace'
++ set +o xtrace
++ return 0
++ [[ stack == \s\o\u\r\c\e ]]
++ [[ stack == \s\t\a\c\k ]]
++ [[ pre-install == \i\n\s\t\a\l\l ]]
++ [[ stack == \s\t\a\c\k ]]
++ [[ pre-install == \p\o\s\t\-\c\o\n\f\i\g ]]
++ [[ stack == \s\t\a\c\k ]]
++ [[ pre-install == \e\x\t\r\a ]]
++ [[ stack == \s\t\a\c\k ]]
++ [[ pre-install == \p\o\s\t\-\e\x\t\r\a ]]
++ [[ stack == \u\n\s\t\a\c\k ]]
++ [[ stack == \c\l\e\a\n ]]
+ install_rpc_backend
+ '[' '' == AMQP1 ']'
+ is_service_enabled rabbit
++ set +o
++ grep xtrace
+ local 'xtrace=set -o xtrace'
+ set +o xtrace
+ return 0
+ install_package rabbitmq-server
+ update_package_repo
+ [[ '' = \T\r\u\e ]]
+ is_ubuntu
+ [[ -z deb ]]
+ '[' deb = deb ']'
++ set +o
++ grep xtrace
+ local 'xtrace=set -o xtrace'
+ set +o xtrace
+ real_install_package rabbitmq-server
+ is_ubuntu
+ [[ -z deb ]]
+ '[' deb = deb ']'
+ apt_get install rabbitmq-server
++ set +o
++ grep xtrace
+ local 'xtrace=set -o xtrace'
+ set +o xtrace
+ sudo DEBIAN_FRONTEND=noninteractive http_proxy= https_proxy= no_proxy= apt-get --option Dpkg::Options::=--force-confold --assume-yes install rabbitmq-server
+ real_install_package rabbitmq-server
+ is_ubuntu
+ [[ -z deb ]]
+ '[' deb = deb ']'
+ apt_get install rabbitmq-server
++ set +o
++ grep xtrace
+ local 'xtrace=set -o xtrace'
+ set +o xtrace
+ sudo DEBIAN_FRONTEND=noninteractive http_proxy= https_proxy= no_proxy= apt-get --option Dpkg::Options::=--force-confold --assume-yes install rabbitmq-server
+ is_service_enabled qpid
++ set +o
++ grep xtrace
+ local 'xtrace=set -o xtrace'
+ set +o xtrace
+ return 1
+ '[' -n '' ']'
+ is_service_enabled mysql postgresql
++ set +o
++ grep xtrace
+ local 'xtrace=set -o xtrace'
+ set +o xtrace
+ return 0
+ install_database
+ install_database_mysql
+ is_ubuntu
+ [[ -z deb ]]
+ '[' deb = deb ']'
+ cat
+ sudo debconf-set-selections
+ [[ ! -e /home/cloudbase/.my.cnf ]]
+ is_ubuntu
+ [[ -z deb ]]
+ '[' deb = deb ']'
+ [[ trusty =~ (rhel7) ]]
+ install_package mysql-server
+ update_package_repo
+ [[ '' = \T\r\u\e ]]
+ is_ubuntu
+ [[ -z deb ]]
+ '[' deb = deb ']'
++ set +o
++ grep xtrace
+ local 'xtrace=set -o xtrace'
+ set +o xtrace
+ real_install_package mysql-server
+ is_ubuntu
+ [[ -z deb ]]
+ '[' deb = deb ']'
+ apt_get install mysql-server
++ set +o
++ grep xtrace
+ local 'xtrace=set -o xtrace'
+ set +o xtrace
+ sudo DEBIAN_FRONTEND=noninteractive http_proxy= https_proxy= no_proxy= apt-get --option Dpkg::Options::=--force-confold --assume-yes install mysql-server
+ real_install_package mysql-server
+ is_ubuntu
+ [[ -z deb ]]
+ '[' deb = deb ']'
+ apt_get install mysql-server
++ set +o
++ grep xtrace
+ local 'xtrace=set -o xtrace'
+ set +o xtrace
+ sudo DEBIAN_FRONTEND=noninteractive http_proxy= https_proxy= no_proxy= apt-get --option Dpkg::Options::=--force-confold --assume-yes install mysql-server
+ is_service_enabled neutron
++ set +o
++ grep xtrace
+ local 'xtrace=set -o xtrace'
+ set +o xtrace
+ return 0
+ install_neutron_agent_packages
+ is_service_enabled q-l3
++ set +o
++ grep xtrace
+ local 'xtrace=set -o xtrace'
+ set +o xtrace
+ return 0
+ install_package radvd
+ update_package_repo
+ [[ '' = \T\r\u\e ]]
+ is_ubuntu
+ [[ -z deb ]]
+ '[' deb = deb ']'
++ set +o
++ grep xtrace
+ local 'xtrace=set -o xtrace'
+ set +o xtrace
+ real_install_package radvd
+ is_ubuntu
+ [[ -z deb ]]
+ '[' deb = deb ']'
+ apt_get install radvd
++ set +o
++ grep xtrace
+ local 'xtrace=set -o xtrace'
+ set +o xtrace
+ sudo DEBIAN_FRONTEND=noninteractive http_proxy= https_proxy= no_proxy= apt-get --option Dpkg::Options::=--force-confold --assume-yes install radvd
+ real_install_package radvd
+ is_ubuntu
+ [[ -z deb ]]
+ '[' deb = deb ']'
+ apt_get install radvd
++ set +o
++ grep xtrace
+ local 'xtrace=set -o xtrace'
+ set +o xtrace
+ sudo DEBIAN_FRONTEND=noninteractive http_proxy= https_proxy= no_proxy= apt-get --option Dpkg::Options::=--force-confold --assume-yes install radvd
+ is_service_enabled q-agt q-dhcp q-l3
++ set +o
++ grep xtrace
+ local 'xtrace=set -o xtrace'
+ set +o xtrace
+ return 0
+ neutron_plugin_install_agent_packages
+ _neutron_ovs_base_install_agent_packages
++ get_packages openvswitch
+++ set +o
+++ grep xtrace
++ local 'xtrace=set -o xtrace'
++ set +o xtrace
+ install_package fakeroot make openvswitch-switch
+ update_package_repo
+ [[ '' = \T\r\u\e ]]
+ is_ubuntu
+ [[ -z deb ]]
+ '[' deb = deb ']'
++ set +o
++ grep xtrace
+ local 'xtrace=set -o xtrace'
+ set +o xtrace
+ real_install_package fakeroot make openvswitch-switch
+ is_ubuntu
+ [[ -z deb ]]
+ '[' deb = deb ']'
+ apt_get install fakeroot make openvswitch-switch
++ set +o
++ grep xtrace
+ local 'xtrace=set -o xtrace'
+ set +o xtrace
+ sudo DEBIAN_FRONTEND=noninteractive http_proxy= https_proxy= no_proxy= apt-get --option Dpkg::Options::=--force-confold --assume-yes install fakeroot make openvswitch-switch
+ real_install_package fakeroot make openvswitch-switch
+ is_ubuntu
+ [[ -z deb ]]
+ '[' deb = deb ']'
+ apt_get install fakeroot make openvswitch-switch
++ set +o
++ grep xtrace
+ local 'xtrace=set -o xtrace'
+ set +o xtrace
+ sudo DEBIAN_FRONTEND=noninteractive http_proxy= https_proxy= no_proxy= apt-get --option Dpkg::Options::=--force-confold --assume-yes install fakeroot make openvswitch-switch
+ is_ubuntu
+ [[ -z deb ]]
+ '[' deb = deb ']'
+ _neutron_ovs_base_install_ubuntu_dkms
++ uname -r
+ local kernel_version=3.13.0-39-generic
++ echo 3.13.0-39-generic
++ cut -d. -f1-2
+ local kernel_major_minor=3.13
++ vercmp_numbers 3.13 3.13
++ typeset v1=3.13 v2=3.13 sep
++ typeset -a ver1 ver2
++ IFS=.
++ read -ra ver1
++ IFS=.
++ read -ra ver2
++ _vercmp_r 2 3 13 3 13
++ typeset sep
++ ver1=()
++ ver2=()
++ typeset -a ver1 ver2
++ sep=2
++ shift
++ ver1=("${@:1:sep}")
++ ver2=("${@:sep+1}")
++ (( ver1 > ver2 ))
++ (( ver2 > ver1 ))
++ (( sep <= 1 ))
++ _vercmp_r 1 13 13
++ typeset sep
++ ver1=()
++ ver2=()
++ typeset -a ver1 ver2
++ sep=1
++ shift
++ ver1=("${@:1:sep}")
++ ver2=("${@:sep+1}")
++ (( ver1 > ver2 ))
++ (( ver2 > ver1 ))
++ (( sep <= 1 ))
++ echo 0
++ return 0
+ '[' 0 -lt 0 ']'
+ restart_service openvswitch-switch
+ is_ubuntu
+ [[ -z deb ]]
+ '[' deb = deb ']'
+ sudo /usr/sbin/service openvswitch-switch restart
+ is_service_enabled q-lbaas
++ set +o
++ grep xtrace
+ local 'xtrace=set -o xtrace'
+ set +o xtrace
+ return 0
+ neutron_agent_lbaas_install_agent_packages
+ is_ubuntu
+ [[ -z deb ]]
+ '[' deb = deb ']'
+ install_package haproxy
+ update_package_repo
+ [[ '' = \T\r\u\e ]]
+ is_ubuntu
+ [[ -z deb ]]
+ '[' deb = deb ']'
++ set +o
++ grep xtrace
+ local 'xtrace=set -o xtrace'
+ set +o xtrace
+ real_install_package haproxy
+ is_ubuntu
+ [[ -z deb ]]
+ '[' deb = deb ']'
+ apt_get install haproxy
++ set +o
++ grep xtrace
+ local 'xtrace=set -o xtrace'
+ set +o xtrace
+ sudo DEBIAN_FRONTEND=noninteractive http_proxy= https_proxy= no_proxy= apt-get --option Dpkg::Options::=--force-confold --assume-yes install haproxy
+ real_install_package haproxy
+ is_ubuntu
+ [[ -z deb ]]
+ '[' deb = deb ']'
+ apt_get install haproxy
++ set +o
++ grep xtrace
+ local 'xtrace=set -o xtrace'
+ set +o xtrace
+ sudo DEBIAN_FRONTEND=noninteractive http_proxy= https_proxy= no_proxy= apt-get --option Dpkg::Options::=--force-confold --assume-yes install haproxy
+ TRACK_DEPENDS=False
+ [[ False = True ]]
+ echo_summary 'Installing OpenStack project source'
+ [[ -t 3 ]]
+ echo -e Installing OpenStack project source
+ install_infra
+ git_clone git://git.openstack.org/openstack/requirements.git /opt/stack/requirements stable/juno
+ local git_remote=git://git.openstack.org/openstack/requirements.git
+ local git_dest=/opt/stack/requirements
+ local git_ref=stable/juno
++ pwd
+ local orig_dir=/home/cloudbase/devstack
++ trueorfalse False
+++ set +o
+++ grep xtrace
++ local 'xtrace=set -o xtrace'
++ set +o xtrace
+ RECLONE=False
+ [[ False = \T\r\u\e ]]
+ echo stable/juno
+ egrep -q '^refs'
+ [[ ! -d /opt/stack/requirements ]]
+ [[ False = \T\r\u\e ]]
+ cd /opt/stack/requirements
+ git show --oneline
+ head -1
+ cd /home/cloudbase/devstack
+ use_library_from_git pbr
+ local name=pbr
+ local enabled=1
+ [[ ,, =~ ,pbr, ]]
+ return 1
+ pip_install pbr
++ set +o
++ grep xtrace
+ local 'xtrace=set -o xtrace'
+ set +o xtrace
+ sudo PIP_DOWNLOAD_CACHE=/var/cache/pip http_proxy= https_proxy= no_proxy= /usr/local/bin/pip install pbr
+ [[ False == \T\r\u\e ]]
+ install_oslo
+ _do_install_oslo_lib cliff
+ local name=cliff
+ use_library_from_git cliff
+ local name=cliff
+ local enabled=1
+ [[ ,, =~ ,cliff, ]]
+ return 1
+ _do_install_oslo_lib oslo.i18n
+ local name=oslo.i18n
+ use_library_from_git oslo.i18n
+ local name=oslo.i18n
+ local enabled=1
+ [[ ,, =~ ,oslo.i18n, ]]
+ return 1
+ _do_install_oslo_lib oslo.utils
+ local name=oslo.utils
+ use_library_from_git oslo.utils
+ local name=oslo.utils
+ local enabled=1
+ [[ ,, =~ ,oslo.utils, ]]
+ return 1
+ _do_install_oslo_lib oslo.serialization
+ local name=oslo.serialization
+ use_library_from_git oslo.serialization
+ local name=oslo.serialization
+ local enabled=1
+ [[ ,, =~ ,oslo.serialization, ]]
+ return 1
+ _do_install_oslo_lib oslo.config
+ local name=oslo.config
+ use_library_from_git oslo.config
+ local name=oslo.config
+ local enabled=1
+ [[ ,, =~ ,oslo.config, ]]
+ return 1
+ _do_install_oslo_lib oslo.concurrency
+ local name=oslo.concurrency
+ use_library_from_git oslo.concurrency
+ local name=oslo.concurrency
+ local enabled=1
+ [[ ,, =~ ,oslo.concurrency, ]]
+ return 1
+ _do_install_oslo_lib oslo.log
+ local name=oslo.log
+ use_library_from_git oslo.log
+ local name=oslo.log
+ local enabled=1
+ [[ ,, =~ ,oslo.log, ]]
+ return 1
+ _do_install_oslo_lib oslo.middleware
+ local name=oslo.middleware
+ use_library_from_git oslo.middleware
+ local name=oslo.middleware
+ local enabled=1
+ [[ ,, =~ ,oslo.middleware, ]]
+ return 1
+ _do_install_oslo_lib oslo.messaging
+ local name=oslo.messaging
+ use_library_from_git oslo.messaging
+ local name=oslo.messaging
+ local enabled=1
+ [[ ,, =~ ,oslo.messaging, ]]
+ return 1
+ _do_install_oslo_lib oslo.rootwrap
+ local name=oslo.rootwrap
+ use_library_from_git oslo.rootwrap
+ local name=oslo.rootwrap
+ local enabled=1
+ [[ ,, =~ ,oslo.rootwrap, ]]
+ return 1
+ _do_install_oslo_lib oslo.db
+ local name=oslo.db
+ use_library_from_git oslo.db
+ local name=oslo.db
+ local enabled=1
+ [[ ,, =~ ,oslo.db, ]]
+ return 1
+ _do_install_oslo_lib oslo.vmware
+ local name=oslo.vmware
+ use_library_from_git oslo.vmware
+ local name=oslo.vmware
+ local enabled=1
+ [[ ,, =~ ,oslo.vmware, ]]
+ return 1
+ _do_install_oslo_lib pycadf
+ local name=pycadf
+ use_library_from_git pycadf
+ local name=pycadf
+ local enabled=1
+ [[ ,, =~ ,pycadf, ]]
+ return 1
+ _do_install_oslo_lib stevedore
+ local name=stevedore
+ use_library_from_git stevedore
+ local name=stevedore
+ local enabled=1
+ [[ ,, =~ ,stevedore, ]]
+ return 1
+ _do_install_oslo_lib taskflow
+ local name=taskflow
+ use_library_from_git taskflow
+ local name=taskflow
+ local enabled=1
+ [[ ,, =~ ,taskflow, ]]
+ return 1
+ is_service_enabled stackforge_libs
++ set +o
++ grep xtrace
+ local 'xtrace=set -o xtrace'
+ set +o xtrace
+ return 1
+ install_keystoneclient
+ use_library_from_git python-keystoneclient
+ local name=python-keystoneclient
+ local enabled=1
+ [[ ,, =~ ,python-keystoneclient, ]]
+ return 1
+ install_glanceclient
+ use_library_from_git python-glanceclient
+ local name=python-glanceclient
+ local enabled=1
+ [[ ,, =~ ,python-glanceclient, ]]
+ return 1
+ install_cinderclient
+ use_library_from_git python-cinderclient
+ local name=python-cinderclient
+ local enabled=1
+ [[ ,, =~ ,python-cinderclient, ]]
+ return 1
+ install_novaclient
+ use_library_from_git python-novaclient
+ local name=python-novaclient
+ local enabled=1
+ [[ ,, =~ ,python-novaclient, ]]
+ return 1
+ is_service_enabled swift glance horizon
++ set +o
++ grep xtrace
+ local 'xtrace=set -o xtrace'
+ set +o xtrace
+ return 0
+ install_swiftclient
+ use_library_from_git python-swiftclient
+ local name=python-swiftclient
+ local enabled=1
+ [[ ,, =~ ,python-swiftclient, ]]
+ return 1
+ is_service_enabled neutron nova horizon
++ set +o
++ grep xtrace
+ local 'xtrace=set -o xtrace'
+ set +o xtrace
+ return 0
+ install_neutronclient
+ use_library_from_git python-neutronclient
+ local name=python-neutronclient
+ local enabled=1
+ [[ ,, =~ ,python-neutronclient, ]]
+ return 1
+ is_service_enabled heat horizon
++ set +o
++ grep xtrace
+ local 'xtrace=set -o xtrace'
+ set +o xtrace
+ return 0
+ install_heatclient
+ use_library_from_git python-heatclient
+ local name=python-heatclient
+ local enabled=1
+ [[ ,, =~ ,python-heatclient, ]]
+ return 1
+ install_keystonemiddleware
+ use_library_from_git keystonemiddleware
+ local name=keystonemiddleware
+ local enabled=1
+ [[ ,, =~ ,keystonemiddleware, ]]
+ return 1
+ use_library_from_git python-openstackclient
+ local name=python-openstackclient
+ local enabled=1
+ [[ ,, =~ ,python-openstackclient, ]]
+ return 1
+ pip_install python-openstackclient
++ set +o
++ grep xtrace
+ local 'xtrace=set -o xtrace'
+ set +o xtrace
+ sudo PIP_DOWNLOAD_CACHE=/var/cache/pip http_proxy= https_proxy= no_proxy= /usr/local/bin/pip install python-openstackclient
+ [[ False == \T\r\u\e ]]
+ is_service_enabled key
++ set +o
++ grep xtrace
+ local 'xtrace=set -o xtrace'
+ set +o xtrace
+ return 0
+ '[' 10.14.0.26 == 10.14.0.26 ']'
+ install_keystone
+ is_service_enabled ldap
++ set +o
++ grep xtrace
+ local 'xtrace=set -o xtrace'
+ set +o xtrace
+ return 1
+ [[ sql = \m\e\m\c\a\c\h\e ]]
+ git_clone git://git.openstack.org/openstack/keystone.git /opt/stack/keystone stable/juno
+ local git_remote=git://git.openstack.org/openstack/keystone.git
+ local git_dest=/opt/stack/keystone
+ local git_ref=stable/juno
++ pwd
+ local orig_dir=/home/cloudbase/devstack
++ trueorfalse False False
+++ set +o
+++ grep xtrace
++ local 'xtrace=set -o xtrace'
++ set +o xtrace
+ RECLONE=False
+ [[ False = \T\r\u\e ]]
+ echo stable/juno
+ egrep -q '^refs'
+ [[ ! -d /opt/stack/keystone ]]
+ [[ False = \T\r\u\e ]]
+ cd /opt/stack/keystone
+ git show --oneline
+ head -1
+ cd /home/cloudbase/devstack
+ setup_develop /opt/stack/keystone
+ local project_dir=/opt/stack/keystone
+ setup_package_with_req_sync /opt/stack/keystone -e
+ local project_dir=/opt/stack/keystone
+ local flags=-e
++ cd /opt/stack/keystone
++ git diff --exit-code
+ local update_requirements=
+ [[ '' != \c\h\a\n\g\e\d ]]
+ cd /opt/stack/requirements
+ python update.py /opt/stack/keystone
+ setup_package /opt/stack/keystone -e
+ local project_dir=/opt/stack/keystone
+ local flags=-e
+ pip_install -e /opt/stack/keystone
++ set +o
++ grep xtrace
+ local 'xtrace=set -o xtrace'
+ set +o xtrace
+ sudo PIP_DOWNLOAD_CACHE=/var/cache/pip http_proxy= https_proxy= no_proxy= /usr/local/bin/pip install -e /opt/stack/keystone
+ [[ False == \T\r\u\e ]]
+ [[ -e == \-\e ]]
+ safe_chown -R cloudbase /opt/stack/keystone/keystone.egg-info
+ _safe_permission_operation chown -R cloudbase /opt/stack/keystone/keystone.egg-info
++ set +o
++ grep xtrace
+ local 'xtrace=set -o xtrace'
+ set +o xtrace
+ sudo chown -R cloudbase /opt/stack/keystone/keystone.egg-info
+ '[' True = True ']'
+ [[ '' != \c\h\a\n\g\e\d ]]
+ cd /opt/stack/keystone
+ git reset --hard
+ '[' True == True ']'
+ install_apache_wsgi
+ is_ubuntu
+ [[ -z deb ]]
+ '[' deb = deb ']'
+ install_package apache2 libapache2-mod-wsgi
+ update_package_repo
+ [[ '' = \T\r\u\e ]]
+ is_ubuntu
+ [[ -z deb ]]
+ '[' deb = deb ']'
++ set +o
++ grep xtrace
+ local 'xtrace=set -o xtrace'
+ set +o xtrace
+ real_install_package apache2 libapache2-mod-wsgi
+ is_ubuntu
+ [[ -z deb ]]
+ '[' deb = deb ']'
+ apt_get install apache2 libapache2-mod-wsgi
++ set +o
++ grep xtrace
+ local 'xtrace=set -o xtrace'
+ set +o xtrace
+ sudo DEBIAN_FRONTEND=noninteractive http_proxy= https_proxy= no_proxy= apt-get --option Dpkg::Options::=--force-confold --assume-yes install apache2 libapache2-mod-wsgi
+ real_install_package apache2 libapache2-mod-wsgi
+ is_ubuntu
+ [[ -z deb ]]
+ '[' deb = deb ']'
+ apt_get install apache2 libapache2-mod-wsgi
++ set +o
++ grep xtrace
+ local 'xtrace=set -o xtrace'
+ set +o xtrace
+ sudo DEBIAN_FRONTEND=noninteractive http_proxy= https_proxy= no_proxy= apt-get --option Dpkg::Options::=--force-confold --assume-yes install apache2 libapache2-mod-wsgi
+ sudo a2enmod wsgi
+ sudo a2enmod version
ERROR: Module version does not exist!
+ true
+ is_ssl_enabled_service key
+ local services=key
+ local service=
+ '[' False == False ']'
+ return 1
+ configure_keystone
+ [[ ! -d /etc/keystone ]]
+ sudo chown cloudbase /etc/keystone
+ [[ /etc/keystone != \/\o\p\t\/\s\t\a\c\k\/\k\e\y\s\t\o\n\e\/\e\t\c ]]
+ cp -p /opt/stack/keystone/etc/keystone.conf.sample /etc/keystone/keystone.conf
+ chmod 600 /etc/keystone/keystone.conf
+ cp -p /opt/stack/keystone/etc/policy.json /etc/keystone
+ [[ -f /opt/stack/keystone/etc/keystone-paste.ini ]]
+ cp -p /opt/stack/keystone/etc/keystone-paste.ini /etc/keystone/keystone-paste.ini
+ [[ -f /etc/keystone/keystone-paste.ini ]]
+ iniset /etc/keystone/keystone.conf paste_deploy config_file /etc/keystone/keystone-paste.ini
++ set +o
++ grep xtrace
+ local 'xtrace=set -o xtrace'
+ set +o xtrace
+ configure_keystone_extensions
+ local extension_value
+ local api_v3
+ local extension
+ local api_v3_extension
+ is_service_enabled ldap
++ set +o
++ grep xtrace
+ local 'xtrace=set -o xtrace'
+ set +o xtrace
+ return 1
+ [[ kvs,ldap,pam,sql =~ sql ]]
+ iniset /etc/keystone/keystone.conf identity driver keystone.identity.backends.sql.Identity
++ set +o
++ grep xtrace
+ local 'xtrace=set -o xtrace'
+ set +o xtrace
+ [[ kvs,ldap,sql =~ sql ]]
+ iniset /etc/keystone/keystone.conf assignment driver keystone.assignment.backends.sql.Assignment
++ set +o
++ grep xtrace
+ local 'xtrace=set -o xtrace'
+ set +o xtrace
+ is_service_enabled rabbit
++ set +o
++ grep xtrace
+ local 'xtrace=set -o xtrace'
+ set +o xtrace
+ return 0
+ iniset /etc/keystone/keystone.conf DEFAULT rabbit_password Passw0rd
++ set +o
++ grep xtrace
+ local 'xtrace=set -o xtrace'
+ set +o xtrace
+ iniset /etc/keystone/keystone.conf DEFAULT rabbit_host 10.14.0.26
++ set +o
++ grep xtrace
+ local 'xtrace=set -o xtrace'
+ set +o xtrace
+ is_service_enabled tls-proxy
++ set +o
++ grep xtrace
+ local 'xtrace=set -o xtrace'
+ set +o xtrace
+ return 1
+ iniset /etc/keystone/keystone.conf DEFAULT public_endpoint 'http://10.14.0.26:%(public_port)s/'
++ set +o
++ grep xtrace
+ local 'xtrace=set -o xtrace'
+ set +o xtrace
+ iniset /etc/keystone/keystone.conf DEFAULT admin_endpoint 'http://10.14.0.26:%(admin_port)s/'
++ set +o
++ grep xtrace
+ local 'xtrace=set -o xtrace'
+ set +o xtrace
+ iniset /etc/keystone/keystone.conf DEFAULT admin_bind_host 10.14.0.26
++ set +o
++ grep xtrace
+ local 'xtrace=set -o xtrace'
+ set +o xtrace
+ is_ssl_enabled_service key
+ local services=key
+ local service=
+ '[' False == False ']'
+ return 1
+ is_service_enabled tls-proxy
++ set +o
++ grep xtrace
+ local 'xtrace=set -o xtrace'
+ set +o xtrace
+ return 1
+ iniset /etc/keystone/keystone.conf DEFAULT admin_token Passw0rd
++ set +o
++ grep xtrace
+ local 'xtrace=set -o xtrace'
+ set +o xtrace
+ [[ '' != '' ]]
++ database_connection_url keystone
++ local db=keystone
++ database_connection_url_mysql keystone
++ local db=keystone
++ echo 'mysql://root:Passw0rd@127.0.0.1/keystone?charset=utf8'
+ iniset /etc/keystone/keystone.conf database connection 'mysql://root:Passw0rd@127.0.0.1/keystone?charset=utf8'
++ set +o
++ grep xtrace
+ local 'xtrace=set -o xtrace'
+ set +o xtrace
+ iniset /etc/keystone/keystone.conf ec2 driver keystone.contrib.ec2.backends.sql.Ec2
++ set +o
++ grep xtrace
+ local 'xtrace=set -o xtrace'
+ set +o xtrace
+ [[ sql = \s\q\l ]]
+ iniset /etc/keystone/keystone.conf token driver keystone.token.persistence.backends.sql.Token
++ set +o
++ grep xtrace
+ local 'xtrace=set -o xtrace'
+ set +o xtrace
+ [[ sql = \s\q\l ]]
+ iniset /etc/keystone/keystone.conf catalog driver keystone.catalog.backends.sql.Catalog
++ set +o
++ grep xtrace
+ local 'xtrace=set -o xtrace'
+ set +o xtrace
+ inicomment /etc/keystone/keystone.conf catalog template_file
++ set +o
++ grep xtrace
+ local 'xtrace=set -o xtrace'
+ set +o xtrace
+ '[' False '!=' False ']'
+ '[' False == True ']'
+ '[' True == True ']'
+ iniset /etc/keystone/keystone.conf DEFAULT debug True
++ set +o
++ grep xtrace
+ local 'xtrace=set -o xtrace'
+ set +o xtrace
+ iniset /etc/keystone/keystone.conf DEFAULT logging_context_format_string '%(process)d %(levelname)s %(name)s [%(request_id)s %(user_identity)s] %(instance)s%(message)s'
++ set +o
++ grep xtrace
+ local 'xtrace=set -o xtrace'
+ set +o xtrace
+ iniset /etc/keystone/keystone.conf DEFAULT logging_default_format_string '%(process)d %(levelname)s %(name)s [-] %(instance)s%(message)s'
++ set +o
++ grep xtrace
+ local 'xtrace=set -o xtrace'
+ set +o xtrace
+ iniset /etc/keystone/keystone.conf DEFAULT logging_debug_format_suffix '%(funcName)s %(pathname)s:%(lineno)d'
++ set +o
++ grep xtrace
+ local 'xtrace=set -o xtrace'
+ set +o xtrace
+ iniset /etc/keystone/keystone.conf DEFAULT logging_exception_prefix '%(process)d TRACE %(name)s %(instance)s'
++ set +o
++ grep xtrace
+ local 'xtrace=set -o xtrace'
+ set +o xtrace
+ _config_keystone_apache_wsgi
+ sudo mkdir -p /var/www/keystone
++ apache_site_config_for keystone
++ local site=keystone
++ is_ubuntu
++ [[ -z deb ]]
++ '[' deb = deb ']'
+++ get_apache_version
+++ is_ubuntu
+++ [[ -z deb ]]
+++ '[' deb = deb ']'
++++ sudo /usr/sbin/apache2ctl -v
++++ cut -f2 -d/
++++ awk '/Server version/ {print $3}'
+++ local version_str=2.4.7
+++ [[ 2.4.7 =~ ^2\.2\. ]]
+++ [[ 2.4.7 =~ ^2\.4\. ]]
+++ echo 2.4
++ local apache_version=2.4
++ [[ 2.4 == \2\.\2 ]]
++ echo /etc/apache2/sites-available/keystone.conf
+ local keystone_apache_conf=/etc/apache2/sites-available/keystone.conf
+ local keystone_ssl=
+ local keystone_certfile=
+ local keystone_keyfile=
+ local keystone_service_port=5000
+ local keystone_auth_port=35357
+ is_ssl_enabled_service key
+ local services=key
+ local service=
+ '[' False == False ']'
+ return 1
+ is_service_enabled tls-proxy
++ set +o
++ grep xtrace
+ local 'xtrace=set -o xtrace'
+ set +o xtrace
+ return 1
+ sudo cp /opt/stack/keystone/httpd/keystone.py /var/www/keystone/main
+ sudo cp /opt/stack/keystone/httpd/keystone.py /var/www/keystone/admin
+ sudo cp /home/cloudbase/devstack/files/apache-keystone.template /etc/apache2/sites-available/keystone.conf
+ sudo sed -e '
        s|%PUBLICPORT%|5000|g;
        s|%ADMINPORT%|35357|g;
        s|%APACHE_NAME%|apache2|g;
        s|%PUBLICWSGI%|/var/www/keystone/main|g;
        s|%ADMINWSGI%|/var/www/keystone/admin|g;
        s|%SSLENGINE%||g;
        s|%SSLCERTFILE%||g;
        s|%SSLKEYFILE%||g;
        s|%USER%|cloudbase|g
    ' -i /etc/apache2/sites-available/keystone.conf
+ iniset /etc/keystone/keystone.conf DEFAULT max_token_size 16384
++ set +o
++ grep xtrace
+ local 'xtrace=set -o xtrace'
+ set +o xtrace
+ iniset /etc/keystone/keystone.conf DEFAULT admin_workers 2
++ set +o
++ grep xtrace
+ local 'xtrace=set -o xtrace'
+ set +o xtrace
+ [[ -n '' ]]
+ is_service_enabled s-proxy
++ set +o
++ grep xtrace
+ local 'xtrace=set -o xtrace'
+ set +o xtrace
+ return 0
+ install_swift
+ git_clone git://git.openstack.org/openstack/swift.git /opt/stack/swift stable/juno
+ local git_remote=git://git.openstack.org/openstack/swift.git
+ local git_dest=/opt/stack/swift
+ local git_ref=stable/juno
++ pwd
+ local orig_dir=/home/cloudbase/devstack
++ trueorfalse False False
+++ set +o
+++ grep xtrace
++ local 'xtrace=set -o xtrace'
++ set +o xtrace
+ RECLONE=False
+ [[ False = \T\r\u\e ]]
+ echo stable/juno
+ egrep -q '^refs'
+ [[ ! -d /opt/stack/swift ]]
+ [[ False = \T\r\u\e ]]
+ cd /opt/stack/swift
+ git show --oneline
+ head -1
+ cd /home/cloudbase/devstack
+ setup_develop /opt/stack/swift
+ local project_dir=/opt/stack/swift
+ setup_package_with_req_sync /opt/stack/swift -e
+ local project_dir=/opt/stack/swift
+ local flags=-e
++ cd /opt/stack/swift
++ git diff --exit-code
+ local update_requirements=
+ [[ '' != \c\h\a\n\g\e\d ]]
+ cd /opt/stack/requirements
+ python update.py /opt/stack/swift
+ setup_package /opt/stack/swift -e
+ local project_dir=/opt/stack/swift
+ local flags=-e
+ pip_install -e /opt/stack/swift
++ set +o
++ grep xtrace
+ local 'xtrace=set -o xtrace'
+ set +o xtrace
+ sudo PIP_DOWNLOAD_CACHE=/var/cache/pip http_proxy= https_proxy= no_proxy= /usr/local/bin/pip install -e /opt/stack/swift
+ [[ False == \T\r\u\e ]]
+ [[ -e == \-\e ]]
+ safe_chown -R cloudbase /opt/stack/swift/swift.egg-info
+ _safe_permission_operation chown -R cloudbase /opt/stack/swift/swift.egg-info
++ set +o
++ grep xtrace
+ local 'xtrace=set -o xtrace'
+ set +o xtrace
+ sudo chown -R cloudbase /opt/stack/swift/swift.egg-info
+ '[' True = True ']'
+ [[ '' != \c\h\a\n\g\e\d ]]
+ cd /opt/stack/swift
+ git reset --hard
+ '[' False == True ']'
+ configure_swift
+ local swift_pipeline=crossdomain
+ local node_number
+ local swift_node_config
+ local swift_log_dir
+ swift-init --run-dir=/opt/stack/data/swift/run all stop
+ true
+ sudo mkdir -p /etc/swift/object-server /etc/swift/container-server /etc/swift/account-server
+ sudo chown -R cloudbase: /etc/swift
+ [[ /etc/swift != \/\e\t\c\/\s\w\i\f\t ]]
+ sed -e '
        s/%GROUP%//;
        s/%USER%/cloudbase/;
        s,%SWIFT_DATA_DIR%,/opt/stack/data/swift,;
    ' /home/cloudbase/devstack/files/swift/rsyncd.conf
+ sudo tee /etc/rsyncd.conf
+ is_ubuntu
+ [[ -z deb ]]
+ '[' deb = deb ']'
+ sudo sed -i '/^RSYNC_ENABLE=false/ { s/false/true/ }' /etc/default/rsync
+ SWIFT_CONFIG_PROXY_SERVER=/etc/swift/proxy-server.conf
+ cp /opt/stack/swift/etc/proxy-server.conf-sample /etc/swift/proxy-server.conf
+ local csyncfile=/etc/swift/container-sync-realms.conf
+ cp /opt/stack/swift/etc/container-sync-realms.conf-sample /etc/swift/container-sync-realms.conf
+ iniset /etc/swift/container-sync-realms.conf realm1 key realm1key
++ set +o
++ grep xtrace
+ local 'xtrace=set -o xtrace'
+ set +o xtrace
+ iniset /etc/swift/container-sync-realms.conf realm1 cluster_name1 http://10.14.0.26:8080/v1/
++ set +o
++ grep xtrace
+ local 'xtrace=set -o xtrace'
+ set +o xtrace
+ iniuncomment /etc/swift/proxy-server.conf DEFAULT user
++ set +o
++ grep xtrace
+ local 'xtrace=set -o xtrace'
+ set +o xtrace
+ iniset /etc/swift/proxy-server.conf DEFAULT user cloudbase
++ set +o
++ grep xtrace
+ local 'xtrace=set -o xtrace'
+ set +o xtrace
+ iniuncomment /etc/swift/proxy-server.conf DEFAULT swift_dir
++ set +o
++ grep xtrace
+ local 'xtrace=set -o xtrace'
+ set +o xtrace
+ iniset /etc/swift/proxy-server.conf DEFAULT swift_dir /etc/swift
++ set +o
++ grep xtrace
+ local 'xtrace=set -o xtrace'
+ set +o xtrace
+ iniuncomment /etc/swift/proxy-server.conf DEFAULT workers
++ set +o
++ grep xtrace
+ local 'xtrace=set -o xtrace'
+ set +o xtrace
+ iniset /etc/swift/proxy-server.conf DEFAULT workers 1
++ set +o
++ grep xtrace
+ local 'xtrace=set -o xtrace'
+ set +o xtrace
+ iniuncomment /etc/swift/proxy-server.conf DEFAULT log_level
++ set +o
++ grep xtrace
+ local 'xtrace=set -o xtrace'
+ set +o xtrace
+ iniset /etc/swift/proxy-server.conf DEFAULT log_level DEBUG
++ set +o
++ grep xtrace
+ local 'xtrace=set -o xtrace'
+ set +o xtrace
+ iniuncomment /etc/swift/proxy-server.conf DEFAULT bind_port
++ set +o
++ grep xtrace
+ local 'xtrace=set -o xtrace'
+ set +o xtrace
+ is_service_enabled tls-proxy
++ set +o
++ grep xtrace
+ local 'xtrace=set -o xtrace'
+ set +o xtrace
+ return 1
+ iniset /etc/swift/proxy-server.conf DEFAULT bind_port 8080
++ set +o
++ grep xtrace
+ local 'xtrace=set -o xtrace'
+ set +o xtrace
+ is_ssl_enabled_service s-proxy
+ local services=s-proxy
+ local service=
+ '[' False == False ']'
+ return 1
+ iniset /etc/swift/proxy-server.conf app:proxy-server node_timeout 120
++ set +o
++ grep xtrace
+ local 'xtrace=set -o xtrace'
+ set +o xtrace
+ iniset /etc/swift/proxy-server.conf app:proxy-server conn_timeout 20
++ set +o
++ grep xtrace
+ local 'xtrace=set -o xtrace'
+ set +o xtrace
+ is_service_enabled ceilometer
++ set +o
++ grep xtrace
+ local 'xtrace=set -o xtrace'
+ set +o xtrace
+ return 0
+ iniset /etc/swift/proxy-server.conf filter:ceilometer 'set log_level' WARN
++ set +o
++ grep xtrace
+ local 'xtrace=set -o xtrace'
+ set +o xtrace
+ iniset /etc/swift/proxy-server.conf filter:ceilometer use egg:ceilometer#swift
++ set +o
++ grep xtrace
+ local 'xtrace=set -o xtrace'
+ set +o xtrace
+ SWIFT_EXTRAS_MIDDLEWARE_LAST=' ceilometer'
+ iniset /etc/swift/proxy-server.conf filter:proxy-logging reveal_sensitive_prefix 12
++ set +o
++ grep xtrace
+ local 'xtrace=set -o xtrace'
+ set +o xtrace
+ is_service_enabled swift3
++ set +o
++ grep xtrace
+ local 'xtrace=set -o xtrace'
+ set +o xtrace
+ return 1
+ is_service_enabled key
++ set +o
++ grep xtrace
+ local 'xtrace=set -o xtrace'
+ set +o xtrace
+ return 0
+ swift_pipeline+=' authtoken keystoneauth'
+ swift_pipeline+=' tempauth '
+ sed -i '/^pipeline/ { s/tempauth/crossdomain authtoken keystoneauth tempauth  formpost staticweb/ ;}' /etc/swift/proxy-server.conf
+ sed -i '/^pipeline/ { s/proxy-server/ ceilometer proxy-server/ ; }' /etc/swift/proxy-server.conf
+ iniuncomment /etc/swift/proxy-server.conf filter:tempauth account_autocreate
++ set +o
++ grep xtrace
+ local 'xtrace=set -o xtrace'
+ set +o xtrace
+ iniset /etc/swift/proxy-server.conf app:proxy-server account_autocreate true
++ set +o
++ grep xtrace
+ local 'xtrace=set -o xtrace'
+ set +o xtrace
+ iniuncomment /etc/swift/proxy-server.conf filter:tempauth reseller_prefix
++ set +o
++ grep xtrace
+ local 'xtrace=set -o xtrace'
+ set +o xtrace
+ iniset /etc/swift/proxy-server.conf filter:tempauth reseller_prefix TEMPAUTH
++ set +o
++ grep xtrace
+ local 'xtrace=set -o xtrace'
+ set +o xtrace
+ iniset /etc/swift/proxy-server.conf filter:crossdomain use egg:swift#crossdomain
++ set +o
++ grep xtrace
+ local 'xtrace=set -o xtrace'
+ set +o xtrace
+ sed -i '/^# \[filter:authtoken\]/,/^# \[filter:keystoneauth\]$/ s/^#[ \t]*//' /etc/swift/proxy-server.conf
+ configure_auth_token_middleware /etc/swift/proxy-server.conf swift /var/cache/swift filter:authtoken
+ local conf_file=/etc/swift/proxy-server.conf
+ local admin_user=swift
+ local signing_dir=/var/cache/swift
+ local section=filter:authtoken
+ iniset /etc/swift/proxy-server.conf filter:authtoken auth_host 10.14.0.26
++ set +o
++ grep xtrace
+ local 'xtrace=set -o xtrace'
+ set +o xtrace
+ iniset /etc/swift/proxy-server.conf filter:authtoken auth_port 35357
++ set +o
++ grep xtrace
+ local 'xtrace=set -o xtrace'
+ set +o xtrace
+ iniset /etc/swift/proxy-server.conf filter:authtoken auth_protocol http
++ set +o
++ grep xtrace
+ local 'xtrace=set -o xtrace'
+ set +o xtrace
+ iniset /etc/swift/proxy-server.conf filter:authtoken identity_uri http://10.14.0.26:35357
++ set +o
++ grep xtrace
+ local 'xtrace=set -o xtrace'
+ set +o xtrace
+ iniset /etc/swift/proxy-server.conf filter:authtoken cafile /opt/stack/data/ca-bundle.pem
++ set +o
++ grep xtrace
+ local 'xtrace=set -o xtrace'
+ set +o xtrace
+ configure_API_version /etc/swift/proxy-server.conf 2.0 filter:authtoken
+ local conf_file=/etc/swift/proxy-server.conf
+ local api_version=2.0
+ local section=filter:authtoken
+ iniset /etc/swift/proxy-server.conf filter:authtoken auth_uri http://10.14.0.26:5000/v2.0
++ set +o
++ grep xtrace
+ local 'xtrace=set -o xtrace'
+ set +o xtrace
+ iniset /etc/swift/proxy-server.conf filter:authtoken admin_tenant_name service
++ set +o
++ grep xtrace
+ local 'xtrace=set -o xtrace'
+ set +o xtrace
+ iniset /etc/swift/proxy-server.conf filter:authtoken admin_user swift
++ set +o
++ grep xtrace
+ local 'xtrace=set -o xtrace'
+ set +o xtrace
+ iniset /etc/swift/proxy-server.conf filter:authtoken admin_password Passw0rd
++ set +o
++ grep xtrace
+ local 'xtrace=set -o xtrace'
+ set +o xtrace
+ iniset /etc/swift/proxy-server.conf filter:authtoken signing_dir /var/cache/swift
++ set +o
++ grep xtrace
+ local 'xtrace=set -o xtrace'
+ set +o xtrace
+ [[ -n '' ]]
+ iniset /etc/swift/proxy-server.conf filter:authtoken log_name swift
++ set +o
++ grep xtrace
+ local 'xtrace=set -o xtrace'
+ set +o xtrace
+ iniuncomment /etc/swift/proxy-server.conf filter:keystoneauth use
++ set +o
++ grep xtrace
+ local 'xtrace=set -o xtrace'
+ set +o xtrace
+ iniuncomment /etc/swift/proxy-server.conf filter:keystoneauth operator_roles
++ set +o
++ grep xtrace
+ local 'xtrace=set -o xtrace'
+ set +o xtrace
+ iniset /etc/swift/proxy-server.conf filter:keystoneauth operator_roles 'Member, admin'
++ set +o
++ grep xtrace
+ local 'xtrace=set -o xtrace'
+ set +o xtrace
+ is_service_enabled swift3
++ set +o
++ grep xtrace
+ local 'xtrace=set -o xtrace'
+ set +o xtrace
+ return 1
+ cp /opt/stack/swift/etc/swift.conf-sample /etc/swift/swift.conf
+ iniset /etc/swift/swift.conf swift-hash swift_hash_path_suffix 66a3d6b56c1f479c8b4e70ab5d2014f6
++ set +o
++ grep xtrace
+ local 'xtrace=set -o xtrace'
+ set +o xtrace
+ iniset /etc/swift/swift.conf swift-constraints max_header_size 16384
++ set +o
++ grep xtrace
+ local 'xtrace=set -o xtrace'
+ set +o xtrace
+ local node_number
+ for node_number in '${SWIFT_REPLICAS_SEQ}'
+ local swift_node_config=/etc/swift/object-server/1.conf
+ cp /opt/stack/swift/etc/object-server.conf-sample /etc/swift/object-server/1.conf
+ generate_swift_config_services /etc/swift/object-server/1.conf 1 6013 object
+ local swift_node_config=/etc/swift/object-server/1.conf
+ local node_id=1
+ local bind_port=6013
+ local server_type=object
+ log_facility=0
+ local node_path=/opt/stack/data/swift/1
+ iniuncomment /etc/swift/object-server/1.conf DEFAULT user
++ set +o
++ grep xtrace
+ local 'xtrace=set -o xtrace'
+ set +o xtrace
+ iniset /etc/swift/object-server/1.conf DEFAULT user cloudbase
++ set +o
++ grep xtrace
+ local 'xtrace=set -o xtrace'
+ set +o xtrace
+ iniuncomment /etc/swift/object-server/1.conf DEFAULT bind_port
++ set +o
++ grep xtrace
+ local 'xtrace=set -o xtrace'
+ set +o xtrace
+ iniset /etc/swift/object-server/1.conf DEFAULT bind_port 6013
++ set +o
++ grep xtrace
+ local 'xtrace=set -o xtrace'
+ set +o xtrace
+ iniuncomment /etc/swift/object-server/1.conf DEFAULT swift_dir
++ set +o
++ grep xtrace
+ local 'xtrace=set -o xtrace'
+ set +o xtrace
+ iniset /etc/swift/object-server/1.conf DEFAULT swift_dir /etc/swift
++ set +o
++ grep xtrace
+ local 'xtrace=set -o xtrace'
+ set +o xtrace
+ iniuncomment /etc/swift/object-server/1.conf DEFAULT devices
++ set +o
++ grep xtrace
+ local 'xtrace=set -o xtrace'
+ set +o xtrace
+ iniset /etc/swift/object-server/1.conf DEFAULT devices /opt/stack/data/swift/1
++ set +o
++ grep xtrace
+ local 'xtrace=set -o xtrace'
+ set +o xtrace
+ iniuncomment /etc/swift/object-server/1.conf DEFAULT log_facility
++ set +o
++ grep xtrace
+ local 'xtrace=set -o xtrace'
+ set +o xtrace
+ iniset /etc/swift/object-server/1.conf DEFAULT log_facility LOG_LOCAL0
++ set +o
++ grep xtrace
+ local 'xtrace=set -o xtrace'
+ set +o xtrace
+ iniuncomment /etc/swift/object-server/1.conf DEFAULT workers
++ set +o
++ grep xtrace
+ local 'xtrace=set -o xtrace'
+ set +o xtrace
+ iniset /etc/swift/object-server/1.conf DEFAULT workers 2
++ set +o
++ grep xtrace
+ local 'xtrace=set -o xtrace'
+ set +o xtrace
+ iniuncomment /etc/swift/object-server/1.conf DEFAULT disable_fallocate
++ set +o
++ grep xtrace
+ local 'xtrace=set -o xtrace'
+ set +o xtrace
+ iniset /etc/swift/object-server/1.conf DEFAULT disable_fallocate true
++ set +o
++ grep xtrace
+ local 'xtrace=set -o xtrace'
+ set +o xtrace
+ iniuncomment /etc/swift/object-server/1.conf DEFAULT mount_check
++ set +o
++ grep xtrace
+ local 'xtrace=set -o xtrace'
+ set +o xtrace
+ iniset /etc/swift/object-server/1.conf DEFAULT mount_check false
++ set +o
++ grep xtrace
+ local 'xtrace=set -o xtrace'
+ set +o xtrace
+ iniuncomment /etc/swift/object-server/1.conf object-replicator vm_test_mode
++ set +o
++ grep xtrace
+ local 'xtrace=set -o xtrace'
+ set +o xtrace
+ iniset /etc/swift/object-server/1.conf object-replicator vm_test_mode yes
++ set +o
++ grep xtrace
+ local 'xtrace=set -o xtrace'
+ set +o xtrace
+ sed -i -e 's,#[ ]*recon_cache_path .*,recon_cache_path = /opt/stack/data/swift/cache,' /etc/swift/object-server/1.conf
+ iniset /etc/swift/object-server/1.conf filter:recon recon_cache_path /opt/stack/data/swift/cache
++ set +o
++ grep xtrace
+ local 'xtrace=set -o xtrace'
+ set +o xtrace
+ swift_node_config=/etc/swift/container-server/1.conf
+ cp /opt/stack/swift/etc/container-server.conf-sample /etc/swift/container-server/1.conf
+ generate_swift_config_services /etc/swift/container-server/1.conf 1 6011 container
+ local swift_node_config=/etc/swift/container-server/1.conf
+ local node_id=1
+ local bind_port=6011
+ local server_type=container
+ log_facility=0
+ local node_path=/opt/stack/data/swift/1
+ iniuncomment /etc/swift/container-server/1.conf DEFAULT user
++ set +o
++ grep xtrace
+ local 'xtrace=set -o xtrace'
+ set +o xtrace
+ iniset /etc/swift/container-server/1.conf DEFAULT user cloudbase
++ set +o
++ grep xtrace
+ local 'xtrace=set -o xtrace'
+ set +o xtrace
+ iniuncomment /etc/swift/container-server/1.conf DEFAULT bind_port
++ set +o
++ grep xtrace
+ local 'xtrace=set -o xtrace'
+ set +o xtrace
+ iniset /etc/swift/container-server/1.conf DEFAULT bind_port 6011
++ set +o
++ grep xtrace
+ local 'xtrace=set -o xtrace'
+ set +o xtrace
+ iniuncomment /etc/swift/container-server/1.conf DEFAULT swift_dir
++ set +o
++ grep xtrace
+ local 'xtrace=set -o xtrace'
+ set +o xtrace
+ iniset /etc/swift/container-server/1.conf DEFAULT swift_dir /etc/swift
++ set +o
++ grep xtrace
+ local 'xtrace=set -o xtrace'
+ set +o xtrace
+ iniuncomment /etc/swift/container-server/1.conf DEFAULT devices
++ set +o
++ grep xtrace
+ local 'xtrace=set -o xtrace'
+ set +o xtrace
+ iniset /etc/swift/container-server/1.conf DEFAULT devices /opt/stack/data/swift/1
++ set +o
++ grep xtrace
+ local 'xtrace=set -o xtrace'
+ set +o xtrace
+ iniuncomment /etc/swift/container-server/1.conf DEFAULT log_facility
++ set +o
++ grep xtrace
+ local 'xtrace=set -o xtrace'
+ set +o xtrace
+ iniset /etc/swift/container-server/1.conf DEFAULT log_facility LOG_LOCAL0
++ set +o
++ grep xtrace
+ local 'xtrace=set -o xtrace'
+ set +o xtrace
+ iniuncomment /etc/swift/container-server/1.conf DEFAULT workers
++ set +o
++ grep xtrace
+ local 'xtrace=set -o xtrace'
+ set +o xtrace
+ iniset /etc/swift/container-server/1.conf DEFAULT workers 2
++ set +o
++ grep xtrace
+ local 'xtrace=set -o xtrace'
+ set +o xtrace
+ iniuncomment /etc/swift/container-server/1.conf DEFAULT disable_fallocate
++ set +o
++ grep xtrace
+ local 'xtrace=set -o xtrace'
+ set +o xtrace
+ iniset /etc/swift/container-server/1.conf DEFAULT disable_fallocate true
++ set +o
++ grep xtrace
+ local 'xtrace=set -o xtrace'
+ set +o xtrace
+ iniuncomment /etc/swift/container-server/1.conf DEFAULT mount_check
++ set +o
++ grep xtrace
+ local 'xtrace=set -o xtrace'
+ set +o xtrace
+ iniset /etc/swift/container-server/1.conf DEFAULT mount_check false
++ set +o
++ grep xtrace
+ local 'xtrace=set -o xtrace'
+ set +o xtrace
+ iniuncomment /etc/swift/container-server/1.conf container-replicator vm_test_mode
++ set +o
++ grep xtrace
+ local 'xtrace=set -o xtrace'
+ set +o xtrace
+ iniset /etc/swift/container-server/1.conf container-replicator vm_test_mode yes
++ set +o
++ grep xtrace
+ local 'xtrace=set -o xtrace'
+ set +o xtrace
+ sed -i -e 's,#[ ]*recon_cache_path .*,recon_cache_path = /opt/stack/data/swift/cache,' /etc/swift/container-server/1.conf
+ iniuncomment /etc/swift/container-server/1.conf app:container-server allow_versions
++ set +o
++ grep xtrace
+ local 'xtrace=set -o xtrace'
+ set +o xtrace
+ iniset /etc/swift/container-server/1.conf app:container-server allow_versions true
++ set +o
++ grep xtrace
+ local 'xtrace=set -o xtrace'
+ set +o xtrace
+ swift_node_config=/etc/swift/account-server/1.conf
+ cp /opt/stack/swift/etc/account-server.conf-sample /etc/swift/account-server/1.conf
+ generate_swift_config_services /etc/swift/account-server/1.conf 1 6012 account
+ local swift_node_config=/etc/swift/account-server/1.conf
+ local node_id=1
+ local bind_port=6012
+ local server_type=account
+ log_facility=0
+ local node_path=/opt/stack/data/swift/1
+ iniuncomment /etc/swift/account-server/1.conf DEFAULT user
++ set +o
++ grep xtrace
+ local 'xtrace=set -o xtrace'
+ set +o xtrace
+ iniset /etc/swift/account-server/1.conf DEFAULT user cloudbase
++ set +o
++ grep xtrace
+ local 'xtrace=set -o xtrace'
+ set +o xtrace
+ iniuncomment /etc/swift/account-server/1.conf DEFAULT bind_port
++ set +o
++ grep xtrace
+ local 'xtrace=set -o xtrace'
+ set +o xtrace
+ iniset /etc/swift/account-server/1.conf DEFAULT bind_port 6012
++ set +o
++ grep xtrace
+ local 'xtrace=set -o xtrace'
+ set +o xtrace
+ iniuncomment /etc/swift/account-server/1.conf DEFAULT swift_dir
++ set +o
++ grep xtrace
+ local 'xtrace=set -o xtrace'
+ set +o xtrace
+ iniset /etc/swift/account-server/1.conf DEFAULT swift_dir /etc/swift
++ set +o
++ grep xtrace
+ local 'xtrace=set -o xtrace'
+ set +o xtrace
+ iniuncomment /etc/swift/account-server/1.conf DEFAULT devices
++ set +o
++ grep xtrace
+ local 'xtrace=set -o xtrace'
+ set +o xtrace
+ iniset /etc/swift/account-server/1.conf DEFAULT devices /opt/stack/data/swift/1
++ set +o
++ grep xtrace
+ local 'xtrace=set -o xtrace'
+ set +o xtrace
+ iniuncomment /etc/swift/account-server/1.conf DEFAULT log_facility
++ set +o
++ grep xtrace
+ local 'xtrace=set -o xtrace'
+ set +o xtrace
+ iniset /etc/swift/account-server/1.conf DEFAULT log_facility LOG_LOCAL0
++ set +o
++ grep xtrace
+ local 'xtrace=set -o xtrace'
+ set +o xtrace
+ iniuncomment /etc/swift/account-server/1.conf DEFAULT workers
++ set +o
++ grep xtrace
+ local 'xtrace=set -o xtrace'
+ set +o xtrace
+ iniset /etc/swift/account-server/1.conf DEFAULT workers 2
++ set +o
++ grep xtrace
+ local 'xtrace=set -o xtrace'
+ set +o xtrace
+ iniuncomment /etc/swift/account-server/1.conf DEFAULT disable_fallocate
++ set +o
++ grep xtrace
+ local 'xtrace=set -o xtrace'
+ set +o xtrace
+ iniset /etc/swift/account-server/1.conf DEFAULT disable_fallocate true
++ set +o
++ grep xtrace
+ local 'xtrace=set -o xtrace'
+ set +o xtrace
+ iniuncomment /etc/swift/account-server/1.conf DEFAULT mount_check
++ set +o
++ grep xtrace
+ local 'xtrace=set -o xtrace'
+ set +o xtrace
+ iniset /etc/swift/account-server/1.conf DEFAULT mount_check false
++ set +o
++ grep xtrace
+ local 'xtrace=set -o xtrace'
+ set +o xtrace
+ iniuncomment /etc/swift/account-server/1.conf account-replicator vm_test_mode
++ set +o
++ grep xtrace
+ local 'xtrace=set -o xtrace'
+ set +o xtrace
+ iniset /etc/swift/account-server/1.conf account-replicator vm_test_mode yes
++ set +o
++ grep xtrace
+ local 'xtrace=set -o xtrace'
+ set +o xtrace
+ sed -i -e 's,#[ ]*recon_cache_path .*,recon_cache_path = /opt/stack/data/swift/cache,' /etc/swift/account-server/1.conf
+ iniset /etc/swift/proxy-server.conf filter:tempauth user_swifttenanttest1_swiftusertest1 'testing .admin'
++ set +o
++ grep xtrace
+ local 'xtrace=set -o xtrace'
+ set +o xtrace
+ iniset /etc/swift/proxy-server.conf filter:tempauth user_swifttenanttest2_swiftusertest2 'testing2 .admin'
++ set +o
++ grep xtrace
+ local 'xtrace=set -o xtrace'
+ set +o xtrace
+ iniset /etc/swift/proxy-server.conf filter:tempauth user_swifttenanttest1_swiftusertest3 'testing3 .admin'
++ set +o
++ grep xtrace
+ local 'xtrace=set -o xtrace'
+ set +o xtrace
+ testfile=/etc/swift/test.conf
+ cp /opt/stack/swift/test/sample.conf /etc/swift/test.conf
+ iniset /etc/swift/test.conf func_test account swifttenanttest1
++ set +o
++ grep xtrace
+ local 'xtrace=set -o xtrace'
+ set +o xtrace
+ iniset /etc/swift/test.conf func_test username swiftusertest1
++ set +o
++ grep xtrace
+ local 'xtrace=set -o xtrace'
+ set +o xtrace
+ iniset /etc/swift/test.conf func_test username3 swiftusertest3
++ set +o
++ grep xtrace
+ local 'xtrace=set -o xtrace'
+ set +o xtrace
+ iniset /etc/swift/test.conf func_test account2 swifttenanttest2
++ set +o
++ grep xtrace
+ local 'xtrace=set -o xtrace'
+ set +o xtrace
+ iniset /etc/swift/test.conf func_test username2 swiftusertest2
++ set +o
++ grep xtrace
+ local 'xtrace=set -o xtrace'
+ set +o xtrace
+ is_service_enabled key
++ set +o
++ grep xtrace
+ local 'xtrace=set -o xtrace'
+ set +o xtrace
+ return 0
+ iniuncomment /etc/swift/test.conf func_test auth_version
++ set +o
++ grep xtrace
+ local 'xtrace=set -o xtrace'
+ set +o xtrace
+ iniset /etc/swift/test.conf func_test auth_host 10.14.0.26
++ set +o
++ grep xtrace
+ local 'xtrace=set -o xtrace'
+ set +o xtrace
+ iniset /etc/swift/test.conf func_test auth_port 35357
++ set +o
++ grep xtrace
+ local 'xtrace=set -o xtrace'
+ set +o xtrace
+ iniset /etc/swift/test.conf func_test auth_prefix /v2.0/
++ set +o
++ grep xtrace
+ local 'xtrace=set -o xtrace'
+ set +o xtrace
+ local swift_log_dir=/opt/stack/data/swift/logs
+ rm -rf /opt/stack/data/swift/logs
+ mkdir -p /opt/stack/data/swift/logs/hourly
+ sudo chown -R cloudbase:adm /opt/stack/data/swift/logs
+ [[ False != \F\a\l\s\e ]]
+ '[' False == True ']'
+ is_service_enabled swift3
++ set +o
++ grep xtrace
+ local 'xtrace=set -o xtrace'
+ set +o xtrace
+ return 1
+ is_service_enabled g-api n-api
++ set +o
++ grep xtrace
+ local 'xtrace=set -o xtrace'
+ set +o xtrace
+ return 0
+ install_glance
+ use_library_from_git glance_store
+ local name=glance_store
+ local enabled=1
+ [[ ,, =~ ,glance_store, ]]
+ return 1
+ git_clone git://git.openstack.org/openstack/glance.git /opt/stack/glance stable/juno
+ local git_remote=git://git.openstack.org/openstack/glance.git
+ local git_dest=/opt/stack/glance
+ local git_ref=stable/juno
++ pwd
+ local orig_dir=/home/cloudbase/devstack
++ trueorfalse False False
+++ set +o
+++ grep xtrace
++ local 'xtrace=set -o xtrace'
++ set +o xtrace
+ RECLONE=False
+ [[ False = \T\r\u\e ]]
+ echo stable/juno
+ egrep -q '^refs'
+ [[ ! -d /opt/stack/glance ]]
+ [[ False = \T\r\u\e ]]
+ cd /opt/stack/glance
+ git show --oneline
+ head -1
+ cd /home/cloudbase/devstack
+ setup_develop /opt/stack/glance
+ local project_dir=/opt/stack/glance
+ setup_package_with_req_sync /opt/stack/glance -e
+ local project_dir=/opt/stack/glance
+ local flags=-e
++ cd /opt/stack/glance
++ git diff --exit-code
+ local update_requirements=
+ [[ '' != \c\h\a\n\g\e\d ]]
+ cd /opt/stack/requirements
+ python update.py /opt/stack/glance
+ setup_package /opt/stack/glance -e
+ local project_dir=/opt/stack/glance
+ local flags=-e
+ pip_install -e /opt/stack/glance
++ set +o
++ grep xtrace
+ local 'xtrace=set -o xtrace'
+ set +o xtrace
+ sudo PIP_DOWNLOAD_CACHE=/var/cache/pip http_proxy= https_proxy= no_proxy= /usr/local/bin/pip install -e /opt/stack/glance
+ [[ False == \T\r\u\e ]]
+ [[ -e == \-\e ]]
+ safe_chown -R cloudbase /opt/stack/glance/glance.egg-info
+ _safe_permission_operation chown -R cloudbase /opt/stack/glance/glance.egg-info
++ set +o
++ grep xtrace
+ local 'xtrace=set -o xtrace'
+ set +o xtrace
+ sudo chown -R cloudbase /opt/stack/glance/glance.egg-info
+ '[' True = True ']'
+ [[ '' != \c\h\a\n\g\e\d ]]
+ cd /opt/stack/glance
+ git reset --hard
+ configure_glance
+ [[ ! -d /etc/glance ]]
+ sudo chown cloudbase /etc/glance
+ [[ ! -d /etc/glance/metadefs ]]
+ sudo chown cloudbase /etc/glance/metadefs
+ cp /opt/stack/glance/etc/glance-registry.conf /etc/glance/glance-registry.conf
+ iniset /etc/glance/glance-registry.conf DEFAULT debug True
++ set +o
++ grep xtrace
+ local 'xtrace=set -o xtrace'
+ set +o xtrace
+ inicomment /etc/glance/glance-registry.conf DEFAULT log_file
++ set +o
++ grep xtrace
+ local 'xtrace=set -o xtrace'
+ set +o xtrace
++ database_connection_url glance
++ local db=glance
++ database_connection_url_mysql glance
++ local db=glance
++ echo 'mysql://root:Passw0rd@127.0.0.1/glance?charset=utf8'
+ local 'dburl=mysql://root:Passw0rd@127.0.0.1/glance?charset=utf8'
+ iniset /etc/glance/glance-registry.conf DEFAULT sql_connection 'mysql://root:Passw0rd@127.0.0.1/glance?charset=utf8'
++ set +o
++ grep xtrace
+ local 'xtrace=set -o xtrace'
+ set +o xtrace
+ iniset /etc/glance/glance-registry.conf DEFAULT use_syslog False
++ set +o
++ grep xtrace
+ local 'xtrace=set -o xtrace'
+ set +o xtrace
+ iniset /etc/glance/glance-registry.conf paste_deploy flavor keystone
++ set +o
++ grep xtrace
+ local 'xtrace=set -o xtrace'
+ set +o xtrace
+ configure_auth_token_middleware /etc/glance/glance-registry.conf glance /var/cache/glance/registry
+ local conf_file=/etc/glance/glance-registry.conf
+ local admin_user=glance
+ local signing_dir=/var/cache/glance/registry
+ local section=keystone_authtoken
+ iniset /etc/glance/glance-registry.conf keystone_authtoken auth_host 10.14.0.26
++ set +o
++ grep xtrace
+ local 'xtrace=set -o xtrace'
+ set +o xtrace
+ iniset /etc/glance/glance-registry.conf keystone_authtoken auth_port 35357
++ set +o
++ grep xtrace
+ local 'xtrace=set -o xtrace'
+ set +o xtrace
+ iniset /etc/glance/glance-registry.conf keystone_authtoken auth_protocol http
++ set +o
++ grep xtrace
+ local 'xtrace=set -o xtrace'
+ set +o xtrace
+ iniset /etc/glance/glance-registry.conf keystone_authtoken identity_uri http://10.14.0.26:35357
++ set +o
++ grep xtrace
+ local 'xtrace=set -o xtrace'
+ set +o xtrace
+ iniset /etc/glance/glance-registry.conf keystone_authtoken cafile /opt/stack/data/ca-bundle.pem
++ set +o
++ grep xtrace
+ local 'xtrace=set -o xtrace'
+ set +o xtrace
+ configure_API_version /etc/glance/glance-registry.conf 2.0 keystone_authtoken
+ local conf_file=/etc/glance/glance-registry.conf
+ local api_version=2.0
+ local section=keystone_authtoken
+ iniset /etc/glance/glance-registry.conf keystone_authtoken auth_uri http://10.14.0.26:5000/v2.0
++ set +o
++ grep xtrace
+ local 'xtrace=set -o xtrace'
+ set +o xtrace
+ iniset /etc/glance/glance-registry.conf keystone_authtoken admin_tenant_name service
++ set +o
++ grep xtrace
+ local 'xtrace=set -o xtrace'
+ set +o xtrace
+ iniset /etc/glance/glance-registry.conf keystone_authtoken admin_user glance
++ set +o
++ grep xtrace
+ local 'xtrace=set -o xtrace'
+ set +o xtrace
+ iniset /etc/glance/glance-registry.conf keystone_authtoken admin_password Passw0rd
++ set +o
++ grep xtrace
+ local 'xtrace=set -o xtrace'
+ set +o xtrace
+ iniset /etc/glance/glance-registry.conf keystone_authtoken signing_dir /var/cache/glance/registry
++ set +o
++ grep xtrace
+ local 'xtrace=set -o xtrace'
+ set +o xtrace
+ [[ -n '' ]]
+ is_service_enabled qpid
++ set +o
++ grep xtrace
+ local 'xtrace=set -o xtrace'
+ set +o xtrace
+ return 1
+ '[' -n 10.14.0.26 ']'
+ '[' -n Passw0rd ']'
+ iniset /etc/glance/glance-registry.conf DEFAULT notification_driver messaging
++ set +o
++ grep xtrace
+ local 'xtrace=set -o xtrace'
+ set +o xtrace
+ iniset_rpc_backend glance /etc/glance/glance-registry.conf DEFAULT
+ local package=glance
+ local file=/etc/glance/glance-registry.conf
+ local section=DEFAULT
+ is_service_enabled zeromq
++ set +o
++ grep xtrace
+ local 'xtrace=set -o xtrace'
+ set +o xtrace
+ return 1
+ is_service_enabled qpid
++ set +o
++ grep xtrace
+ local 'xtrace=set -o xtrace'
+ set +o xtrace
+ return 1
+ '[' -n '' ']'
+ is_service_enabled rabbit
++ set +o
++ grep xtrace
+ local 'xtrace=set -o xtrace'
+ set +o xtrace
+ return 0
+ iniset /etc/glance/glance-registry.conf DEFAULT rpc_backend glance.openstack.common.rpc.impl_kombu
++ set +o
++ grep xtrace
+ local 'xtrace=set -o xtrace'
+ set +o xtrace
+ iniset /etc/glance/glance-registry.conf DEFAULT rabbit_hosts 10.14.0.26
++ set +o
++ grep xtrace
+ local 'xtrace=set -o xtrace'
+ set +o xtrace
+ iniset /etc/glance/glance-registry.conf DEFAULT rabbit_password Passw0rd
++ set +o
++ grep xtrace
+ local 'xtrace=set -o xtrace'
+ set +o xtrace
+ cp /opt/stack/glance/etc/glance-api.conf /etc/glance/glance-api.conf
+ iniset /etc/glance/glance-api.conf DEFAULT debug True
++ set +o
++ grep xtrace
+ local 'xtrace=set -o xtrace'
+ set +o xtrace
+ inicomment /etc/glance/glance-api.conf DEFAULT log_file
++ set +o
++ grep xtrace
+ local 'xtrace=set -o xtrace'
+ set +o xtrace
+ iniset /etc/glance/glance-api.conf DEFAULT sql_connection 'mysql://root:Passw0rd@127.0.0.1/glance?charset=utf8'
++ set +o
++ grep xtrace
+ local 'xtrace=set -o xtrace'
+ set +o xtrace
+ iniset /etc/glance/glance-api.conf DEFAULT use_syslog False
++ set +o
++ grep xtrace
+ local 'xtrace=set -o xtrace'
+ set +o xtrace
+ iniset /etc/glance/glance-api.conf DEFAULT image_cache_dir /opt/stack/data/glance/cache/
++ set +o
++ grep xtrace
+ local 'xtrace=set -o xtrace'
+ set +o xtrace
+ iniset /etc/glance/glance-api.conf paste_deploy flavor keystone+cachemanagement
++ set +o
++ grep xtrace
+ local 'xtrace=set -o xtrace'
+ set +o xtrace
+ configure_auth_token_middleware /etc/glance/glance-api.conf glance /var/cache/glance/api
+ local conf_file=/etc/glance/glance-api.conf
+ local admin_user=glance
+ local signing_dir=/var/cache/glance/api
+ local section=keystone_authtoken
+ iniset /etc/glance/glance-api.conf keystone_authtoken auth_host 10.14.0.26
++ set +o
++ grep xtrace
+ local 'xtrace=set -o xtrace'
+ set +o xtrace
+ iniset /etc/glance/glance-api.conf keystone_authtoken auth_port 35357
++ set +o
++ grep xtrace
+ local 'xtrace=set -o xtrace'
+ set +o xtrace
+ iniset /etc/glance/glance-api.conf keystone_authtoken auth_protocol http
++ set +o
++ grep xtrace
+ local 'xtrace=set -o xtrace'
+ set +o xtrace
+ iniset /etc/glance/glance-api.conf keystone_authtoken identity_uri http://10.14.0.26:35357
++ set +o
++ grep xtrace
+ local 'xtrace=set -o xtrace'
+ set +o xtrace
+ iniset /etc/glance/glance-api.conf keystone_authtoken cafile /opt/stack/data/ca-bundle.pem
++ set +o
++ grep xtrace
+ local 'xtrace=set -o xtrace'
+ set +o xtrace
+ configure_API_version /etc/glance/glance-api.conf 2.0 keystone_authtoken
+ local conf_file=/etc/glance/glance-api.conf
+ local api_version=2.0
+ local section=keystone_authtoken
+ iniset /etc/glance/glance-api.conf keystone_authtoken auth_uri http://10.14.0.26:5000/v2.0
++ set +o
++ grep xtrace
+ local 'xtrace=set -o xtrace'
+ set +o xtrace
+ iniset /etc/glance/glance-api.conf keystone_authtoken admin_tenant_name service
++ set +o
++ grep xtrace
+ local 'xtrace=set -o xtrace'
+ set +o xtrace
+ iniset /etc/glance/glance-api.conf keystone_authtoken admin_user glance
++ set +o
++ grep xtrace
+ local 'xtrace=set -o xtrace'
+ set +o xtrace
+ iniset /etc/glance/glance-api.conf keystone_authtoken admin_password Passw0rd
++ set +o
++ grep xtrace
+ local 'xtrace=set -o xtrace'
+ set +o xtrace
+ iniset /etc/glance/glance-api.conf keystone_authtoken signing_dir /var/cache/glance/api
++ set +o
++ grep xtrace
+ local 'xtrace=set -o xtrace'
+ set +o xtrace
+ [[ -n '' ]]
+ is_service_enabled qpid
++ set +o
++ grep xtrace
+ local 'xtrace=set -o xtrace'
+ set +o xtrace
+ return 1
+ '[' -n 10.14.0.26 ']'
+ '[' -n Passw0rd ']'
+ iniset /etc/glance/glance-api.conf DEFAULT notification_driver messaging
++ set +o
++ grep xtrace
+ local 'xtrace=set -o xtrace'
+ set +o xtrace
+ iniset_rpc_backend glance /etc/glance/glance-api.conf DEFAULT
+ local package=glance
+ local file=/etc/glance/glance-api.conf
+ local section=DEFAULT
+ is_service_enabled zeromq
++ set +o
++ grep xtrace
+ local 'xtrace=set -o xtrace'
+ set +o xtrace
+ return 1
+ is_service_enabled qpid
++ set +o
++ grep xtrace
+ local 'xtrace=set -o xtrace'
+ set +o xtrace
+ return 1
+ '[' -n '' ']'
+ is_service_enabled rabbit
++ set +o
++ grep xtrace
+ local 'xtrace=set -o xtrace'
+ set +o xtrace
+ return 0
+ iniset /etc/glance/glance-api.conf DEFAULT rpc_backend glance.openstack.common.rpc.impl_kombu
++ set +o
++ grep xtrace
+ local 'xtrace=set -o xtrace'
+ set +o xtrace
+ iniset /etc/glance/glance-api.conf DEFAULT rabbit_hosts 10.14.0.26
++ set +o
++ grep xtrace
+ local 'xtrace=set -o xtrace'
+ set +o xtrace
+ iniset /etc/glance/glance-api.conf DEFAULT rabbit_password Passw0rd
++ set +o
++ grep xtrace
+ local 'xtrace=set -o xtrace'
+ set +o xtrace
+ '[' libvirt = xenserver ']'
+ iniset /etc/glance/glance-api.conf DEFAULT filesystem_store_datadir /opt/stack/data/glance/images/
++ set +o
++ grep xtrace
+ local 'xtrace=set -o xtrace'
+ set +o xtrace
+ iniset /etc/glance/glance-api.conf glance_store filesystem_store_datadir /opt/stack/data/glance/images/
++ set +o
++ grep xtrace
+ local 'xtrace=set -o xtrace'
+ set +o xtrace
+ iniset /etc/glance/glance-api.conf DEFAULT workers 2
++ set +o
++ grep xtrace
+ local 'xtrace=set -o xtrace'
+ set +o xtrace
+ is_service_enabled s-proxy
++ set +o
++ grep xtrace
+ local 'xtrace=set -o xtrace'
+ set +o xtrace
+ return 0
+ iniset /etc/glance/glance-api.conf DEFAULT default_store swift
++ set +o
++ grep xtrace
+ local 'xtrace=set -o xtrace'
+ set +o xtrace
+ iniset /etc/glance/glance-api.conf DEFAULT swift_store_auth_address http://10.14.0.26:5000/v2.0/
++ set +o
++ grep xtrace
+ local 'xtrace=set -o xtrace'
+ set +o xtrace
+ iniset /etc/glance/glance-api.conf DEFAULT swift_store_user service:glance-swift
++ set +o
++ grep xtrace
+ local 'xtrace=set -o xtrace'
+ set +o xtrace
+ iniset /etc/glance/glance-api.conf DEFAULT swift_store_key Passw0rd
++ set +o
++ grep xtrace
+ local 'xtrace=set -o xtrace'
+ set +o xtrace
+ iniset /etc/glance/glance-api.conf DEFAULT swift_store_create_container_on_put True
++ set +o
++ grep xtrace
+ local 'xtrace=set -o xtrace'
+ set +o xtrace
+ iniset /etc/glance/glance-api.conf DEFAULT known_stores 'glance.store.filesystem.Store, glance.store.http.Store, glance.store.swift.Store'
++ set +o
++ grep xtrace
+ local 'xtrace=set -o xtrace'
+ set +o xtrace
+ iniset /etc/glance/glance-api.conf glance_store default_store swift
++ set +o
++ grep xtrace
+ local 'xtrace=set -o xtrace'
+ set +o xtrace
+ iniset /etc/glance/glance-api.conf glance_store swift_store_auth_address http://10.14.0.26:5000/v2.0/
++ set +o
++ grep xtrace
+ local 'xtrace=set -o xtrace'
+ set +o xtrace
+ iniset /etc/glance/glance-api.conf glance_store swift_store_user service:glance-swift
++ set +o
++ grep xtrace
+ local 'xtrace=set -o xtrace'
+ set +o xtrace
+ iniset /etc/glance/glance-api.conf glance_store swift_store_key Passw0rd
++ set +o
++ grep xtrace
+ local 'xtrace=set -o xtrace'
+ set +o xtrace
+ iniset /etc/glance/glance-api.conf glance_store swift_store_create_container_on_put True
++ set +o
++ grep xtrace
+ local 'xtrace=set -o xtrace'
+ set +o xtrace
+ iniset /etc/glance/glance-api.conf glance_store stores 'file, http, swift'
++ set +o
++ grep xtrace
+ local 'xtrace=set -o xtrace'
+ set +o xtrace
+ is_service_enabled tls-proxy
++ set +o
++ grep xtrace
+ local 'xtrace=set -o xtrace'
+ set +o xtrace
+ return 1
+ is_ssl_enabled_service glance
+ local services=glance
+ local service=
+ '[' False == False ']'
+ return 1
+ is_ssl_enabled_service glance
+ local services=glance
+ local service=
+ '[' False == False ']'
+ return 1
+ is_service_enabled tls-proxy
++ set +o
++ grep xtrace
+ local 'xtrace=set -o xtrace'
+ set +o xtrace
+ return 1
+ cp -p /opt/stack/glance/etc/glance-registry-paste.ini /etc/glance/glance-registry-paste.ini
+ cp -p /opt/stack/glance/etc/glance-api-paste.ini /etc/glance/glance-api-paste.ini
+ cp /opt/stack/glance/etc/glance-cache.conf /etc/glance/glance-cache.conf
+ iniset /etc/glance/glance-cache.conf DEFAULT debug True
++ set +o
++ grep xtrace
+ local 'xtrace=set -o xtrace'
+ set +o xtrace
+ inicomment /etc/glance/glance-cache.conf DEFAULT log_file
++ set +o
++ grep xtrace
+ local 'xtrace=set -o xtrace'
+ set +o xtrace
+ iniset /etc/glance/glance-cache.conf DEFAULT use_syslog False
++ set +o
++ grep xtrace
+ local 'xtrace=set -o xtrace'
+ set +o xtrace
+ iniset /etc/glance/glance-cache.conf DEFAULT image_cache_dir /opt/stack/data/glance/cache/
++ set +o
++ grep xtrace
+ local 'xtrace=set -o xtrace'
+ set +o xtrace
+ iniuncomment /etc/glance/glance-cache.conf DEFAULT auth_url
++ set +o
++ grep xtrace
+ local 'xtrace=set -o xtrace'
+ set +o xtrace
+ iniset /etc/glance/glance-cache.conf DEFAULT auth_url http://10.14.0.26:35357/v2.0
++ set +o
++ grep xtrace
+ local 'xtrace=set -o xtrace'
+ set +o xtrace
+ iniuncomment /etc/glance/glance-cache.conf DEFAULT auth_tenant_name
++ set +o
++ grep xtrace
+ local 'xtrace=set -o xtrace'
+ set +o xtrace
+ iniset /etc/glance/glance-cache.conf DEFAULT admin_tenant_name service
++ set +o
++ grep xtrace
+ local 'xtrace=set -o xtrace'
+ set +o xtrace
+ iniuncomment /etc/glance/glance-cache.conf DEFAULT auth_user
++ set +o
++ grep xtrace
+ local 'xtrace=set -o xtrace'
+ set +o xtrace
+ iniset /etc/glance/glance-cache.conf DEFAULT admin_user glance
++ set +o
++ grep xtrace
+ local 'xtrace=set -o xtrace'
+ set +o xtrace
+ iniuncomment /etc/glance/glance-cache.conf DEFAULT auth_password
++ set +o
++ grep xtrace
+ local 'xtrace=set -o xtrace'
+ set +o xtrace
+ iniset /etc/glance/glance-cache.conf DEFAULT admin_password Passw0rd
++ set +o
++ grep xtrace
+ local 'xtrace=set -o xtrace'
+ set +o xtrace
+ iniset /etc/glance/glance-cache.conf DEFAULT filesystem_store_datadir /opt/stack/data/glance/images/
++ set +o
++ grep xtrace
+ local 'xtrace=set -o xtrace'
+ set +o xtrace
+ iniset /etc/glance/glance-cache.conf glance_store filesystem_store_datadir /opt/stack/data/glance/images/
++ set +o
++ grep xtrace
+ local 'xtrace=set -o xtrace'
+ set +o xtrace
+ cp -p /opt/stack/glance/etc/policy.json /etc/glance/policy.json
+ cp -p /opt/stack/glance/etc/schema-image.json /etc/glance/schema-image.json
+ cp -p /opt/stack/glance/etc/metadefs/compute-aggr-disk-filter.json /opt/stack/glance/etc/metadefs/compute-aggr-iops-filter.json /opt/stack/glance/etc/metadefs/compute-aggr-num-instances.json /opt/stack/glance/etc/metadefs/compute-guest-shutdown.json /opt/stack/glance/etc/metadefs/compute-host-capabilities.json /opt/stack/glance/etc/metadefs/compute-hypervisor.json /opt/stack/glance/etc/metadefs/compute-instance-data.json /opt/stack/glance/etc/metadefs/compute-libvirt.json /opt/stack/glance/etc/metadefs/compute-quota.json /opt/stack/glance/etc/metadefs/compute-randomgen.json /opt/stack/glance/etc/metadefs/compute-trust.json /opt/stack/glance/etc/metadefs/compute-vcputopology.json /opt/stack/glance/etc/metadefs/compute-vmware.json /opt/stack/glance/etc/metadefs/compute-watchdog.json /opt/stack/glance/etc/metadefs/compute-xenapi.json /opt/stack/glance/etc/metadefs/glance-common-image-props.json /etc/glance/metadefs
+ is_ssl_enabled_service cinder
+ local services=cinder
+ local service=
+ '[' False == False ']'
+ return 1
+ is_service_enabled tls-proxy
++ set +o
++ grep xtrace
+ local 'xtrace=set -o xtrace'
+ set +o xtrace
+ return 1
+ is_service_enabled cinder
++ set +o
++ grep xtrace
+ local 'xtrace=set -o xtrace'
+ set +o xtrace
+ return 0
+ install_cinder
+ git_clone git://git.openstack.org/openstack/cinder.git /opt/stack/cinder stable/juno
+ local git_remote=git://git.openstack.org/openstack/cinder.git
+ local git_dest=/opt/stack/cinder
+ local git_ref=stable/juno
++ pwd
+ local orig_dir=/home/cloudbase/devstack
++ trueorfalse False False
+++ set +o
+++ grep xtrace
++ local 'xtrace=set -o xtrace'
++ set +o xtrace
+ RECLONE=False
+ [[ False = \T\r\u\e ]]
+ echo stable/juno
+ egrep -q '^refs'
+ [[ ! -d /opt/stack/cinder ]]
+ [[ False = \T\r\u\e ]]
+ cd /opt/stack/cinder
+ git show --oneline
+ head -1
+ cd /home/cloudbase/devstack
+ setup_develop /opt/stack/cinder
+ local project_dir=/opt/stack/cinder
+ setup_package_with_req_sync /opt/stack/cinder -e
+ local project_dir=/opt/stack/cinder
+ local flags=-e
++ cd /opt/stack/cinder
++ git diff --exit-code
+ local update_requirements=
+ [[ '' != \c\h\a\n\g\e\d ]]
+ cd /opt/stack/requirements
+ python update.py /opt/stack/cinder
+ setup_package /opt/stack/cinder -e
+ local project_dir=/opt/stack/cinder
+ local flags=-e
+ pip_install -e /opt/stack/cinder
++ set +o
++ grep xtrace
+ local 'xtrace=set -o xtrace'
+ set +o xtrace
+ sudo PIP_DOWNLOAD_CACHE=/var/cache/pip http_proxy= https_proxy= no_proxy= /usr/local/bin/pip install -e /opt/stack/cinder
+ [[ False == \T\r\u\e ]]
+ [[ -e == \-\e ]]
+ safe_chown -R cloudbase /opt/stack/cinder/cinder.egg-info
+ _safe_permission_operation chown -R cloudbase /opt/stack/cinder/cinder.egg-info
++ set +o
++ grep xtrace
+ local 'xtrace=set -o xtrace'
+ set +o xtrace
+ sudo chown -R cloudbase /opt/stack/cinder/cinder.egg-info
+ '[' True = True ']'
+ [[ '' != \c\h\a\n\g\e\d ]]
+ cd /opt/stack/cinder
+ git reset --hard
+ configure_cinder
+ [[ ! -d /etc/cinder ]]
+ sudo chown cloudbase /etc/cinder
+ cp -p /opt/stack/cinder/etc/cinder/policy.json /etc/cinder
+ configure_cinder_rootwrap
++ get_rootwrap_location cinder
++ local module=cinder
+++ get_python_exec_prefix
+++ is_fedora
+++ [[ -z Ubuntu ]]
+++ '[' Ubuntu = Fedora ']'
+++ '[' Ubuntu = 'Red Hat' ']'
+++ '[' Ubuntu = CentOS ']'
+++ '[' Ubuntu = OracleServer ']'
+++ is_suse
+++ [[ -z Ubuntu ]]
+++ '[' Ubuntu = openSUSE ']'
+++ '[' Ubuntu = 'SUSE LINUX' ']'
+++ echo /usr/local/bin
++ echo /usr/local/bin/cinder-rootwrap
+ local cinder_rootwrap=/usr/local/bin/cinder-rootwrap
+ [[ -d /etc/cinder/rootwrap.d ]]
+ sudo rm -rf /etc/cinder/rootwrap.d
+ sudo mkdir -m 755 /etc/cinder/rootwrap.d
+ sudo cp /opt/stack/cinder/etc/cinder/rootwrap.d/volume.filters /etc/cinder/rootwrap.d
+ sudo chown -R root:root /etc/cinder/rootwrap.d
+ sudo chmod 644 /etc/cinder/rootwrap.d/volume.filters
+ sudo cp /opt/stack/cinder/etc/cinder/rootwrap.conf /etc/cinder/
+ sudo sed -e 's:^filters_path=.*$:filters_path=/etc/cinder/rootwrap.d:' -i /etc/cinder/rootwrap.conf
+ sudo chown root:root /etc/cinder/rootwrap.conf
+ sudo chmod 0644 /etc/cinder/rootwrap.conf
+ ROOTWRAP_CSUDOER_CMD='/usr/local/bin/cinder-rootwrap /etc/cinder/rootwrap.conf *'
++ mktemp
+ local tempfile=/tmp/tmp.1c27pIaZOw
+ echo 'cloudbase ALL=(root) NOPASSWD: /usr/local/bin/cinder-rootwrap /etc/cinder/rootwrap.conf *'
+ chmod 0440 /tmp/tmp.1c27pIaZOw
+ sudo chown root:root /tmp/tmp.1c27pIaZOw
+ sudo mv /tmp/tmp.1c27pIaZOw /etc/sudoers.d/cinder-rootwrap
+ cp /opt/stack/cinder/etc/cinder/api-paste.ini /etc/cinder/api-paste.ini
+ inicomment /etc/cinder/api-paste.ini filter:authtoken auth_host
++ set +o
++ grep xtrace
+ local 'xtrace=set -o xtrace'
+ set +o xtrace
+ inicomment /etc/cinder/api-paste.ini filter:authtoken auth_port
++ set +o
++ grep xtrace
+ local 'xtrace=set -o xtrace'
+ set +o xtrace
+ inicomment /etc/cinder/api-paste.ini filter:authtoken auth_protocol
++ set +o
++ grep xtrace
+ local 'xtrace=set -o xtrace'
+ set +o xtrace
+ inicomment /etc/cinder/api-paste.ini filter:authtoken cafile
++ set +o
++ grep xtrace
+ local 'xtrace=set -o xtrace'
+ set +o xtrace
+ inicomment /etc/cinder/api-paste.ini filter:authtoken admin_tenant_name
++ set +o
++ grep xtrace
+ local 'xtrace=set -o xtrace'
+ set +o xtrace
+ inicomment /etc/cinder/api-paste.ini filter:authtoken admin_user
++ set +o
++ grep xtrace
+ local 'xtrace=set -o xtrace'
+ set +o xtrace
+ inicomment /etc/cinder/api-paste.ini filter:authtoken admin_password
++ set +o
++ grep xtrace
+ local 'xtrace=set -o xtrace'
+ set +o xtrace
+ inicomment /etc/cinder/api-paste.ini filter:authtoken signing_dir
++ set +o
++ grep xtrace
+ local 'xtrace=set -o xtrace'
+ set +o xtrace
+ configure_auth_token_middleware /etc/cinder/cinder.conf cinder /var/cache/cinder
+ local conf_file=/etc/cinder/cinder.conf
+ local admin_user=cinder
+ local signing_dir=/var/cache/cinder
+ local section=keystone_authtoken
+ iniset /etc/cinder/cinder.conf keystone_authtoken auth_host 10.14.0.26
++ set +o
++ grep xtrace
+ local 'xtrace=set -o xtrace'
+ set +o xtrace
+ iniset /etc/cinder/cinder.conf keystone_authtoken auth_port 35357
++ set +o
++ grep xtrace
+ local 'xtrace=set -o xtrace'
+ set +o xtrace
+ iniset /etc/cinder/cinder.conf keystone_authtoken auth_protocol http
++ set +o
++ grep xtrace
+ local 'xtrace=set -o xtrace'
+ set +o xtrace
+ iniset /etc/cinder/cinder.conf keystone_authtoken identity_uri http://10.14.0.26:35357
++ set +o
++ grep xtrace
+ local 'xtrace=set -o xtrace'
+ set +o xtrace
+ iniset /etc/cinder/cinder.conf keystone_authtoken cafile /opt/stack/data/ca-bundle.pem
++ set +o
++ grep xtrace
+ local 'xtrace=set -o xtrace'
+ set +o xtrace
+ configure_API_version /etc/cinder/cinder.conf 2.0 keystone_authtoken
+ local conf_file=/etc/cinder/cinder.conf
+ local api_version=2.0
+ local section=keystone_authtoken
+ iniset /etc/cinder/cinder.conf keystone_authtoken auth_uri http://10.14.0.26:5000/v2.0
++ set +o
++ grep xtrace
+ local 'xtrace=set -o xtrace'
+ set +o xtrace
+ iniset /etc/cinder/cinder.conf keystone_authtoken admin_tenant_name service
++ set +o
++ grep xtrace
+ local 'xtrace=set -o xtrace'
+ set +o xtrace
+ iniset /etc/cinder/cinder.conf keystone_authtoken admin_user cinder
++ set +o
++ grep xtrace
+ local 'xtrace=set -o xtrace'
+ set +o xtrace
+ iniset /etc/cinder/cinder.conf keystone_authtoken admin_password Passw0rd
++ set +o
++ grep xtrace
+ local 'xtrace=set -o xtrace'
+ set +o xtrace
+ iniset /etc/cinder/cinder.conf keystone_authtoken signing_dir /var/cache/cinder
++ set +o
++ grep xtrace
+ local 'xtrace=set -o xtrace'
+ set +o xtrace
+ [[ -n '' ]]
+ iniset /etc/cinder/cinder.conf DEFAULT auth_strategy keystone
++ set +o
++ grep xtrace
+ local 'xtrace=set -o xtrace'
+ set +o xtrace
+ iniset /etc/cinder/cinder.conf DEFAULT debug True
++ set +o
++ grep xtrace
+ local 'xtrace=set -o xtrace'
+ set +o xtrace
+ iniset /etc/cinder/cinder.conf DEFAULT verbose True
++ set +o
++ grep xtrace
+ local 'xtrace=set -o xtrace'
+ set +o xtrace
+ iniset /etc/cinder/cinder.conf DEFAULT my_ip 10.14.0.26
++ set +o
++ grep xtrace
+ local 'xtrace=set -o xtrace'
+ set +o xtrace
+ iniset /etc/cinder/cinder.conf DEFAULT iscsi_helper tgtadm
++ set +o
++ grep xtrace
+ local 'xtrace=set -o xtrace'
+ set +o xtrace
++ database_connection_url cinder
++ local db=cinder
++ database_connection_url_mysql cinder
++ local db=cinder
++ echo 'mysql://root:Passw0rd@127.0.0.1/cinder?charset=utf8'
+ iniset /etc/cinder/cinder.conf DEFAULT sql_connection 'mysql://root:Passw0rd@127.0.0.1/cinder?charset=utf8'
++ set +o
++ grep xtrace
+ local 'xtrace=set -o xtrace'
+ set +o xtrace
+ iniset /etc/cinder/cinder.conf DEFAULT api_paste_config /etc/cinder/api-paste.ini
++ set +o
++ grep xtrace
+ local 'xtrace=set -o xtrace'
+ set +o xtrace
+ iniset /etc/cinder/cinder.conf DEFAULT rootwrap_config /etc/cinder/rootwrap.conf
++ set +o
++ grep xtrace
+ local 'xtrace=set -o xtrace'
+ set +o xtrace
+ iniset /etc/cinder/cinder.conf DEFAULT osapi_volume_extension cinder.api.contrib.standard_extensions
++ set +o
++ grep xtrace
+ local 'xtrace=set -o xtrace'
+ set +o xtrace
+ iniset /etc/cinder/cinder.conf DEFAULT state_path /opt/stack/data/cinder
++ set +o
++ grep xtrace
+ local 'xtrace=set -o xtrace'
+ set +o xtrace
+ iniset /etc/cinder/cinder.conf DEFAULT lock_path /opt/stack/data/cinder
++ set +o
++ grep xtrace
+ local 'xtrace=set -o xtrace'
+ set +o xtrace
+ iniset /etc/cinder/cinder.conf DEFAULT periodic_interval 60
++ set +o
++ grep xtrace
+ local 'xtrace=set -o xtrace'
+ set +o xtrace
+ iniset /etc/cinder/cinder.conf DEFAULT enable_v1_api true
++ set +o
++ grep xtrace
+ local 'xtrace=set -o xtrace'
+ set +o xtrace
+ is_service_enabled c-vol
++ set +o
++ grep xtrace
+ local 'xtrace=set -o xtrace'
+ set +o xtrace
+ return 0
+ [[ -n lvm:lvmdriver-1 ]]
+ local enabled_backends=
+ local default_name=
+ local be be_name be_type
+ for be in '${CINDER_ENABLED_BACKENDS//,/ }'
+ be_type=lvm
+ be_name=lvmdriver-1
+ type configure_cinder_backend_lvm
+ configure_cinder_backend_lvm lvmdriver-1
+ local be_name=lvmdriver-1
++ get_volume_group_name lvmdriver-1
++ local be_name=lvmdriver-1
++ local volume_group_name=stack-volumes
++ [[ -z '' ]]
++ volume_group_name+=-lvmdriver-1
++ echo stack-volumes-lvmdriver-1
+ local volume_group_name=stack-volumes-lvmdriver-1
+ iniset /etc/cinder/cinder.conf lvmdriver-1 volume_backend_name lvmdriver-1
++ set +o
++ grep xtrace
+ local 'xtrace=set -o xtrace'
+ set +o xtrace
+ iniset /etc/cinder/cinder.conf lvmdriver-1 volume_driver cinder.volume.drivers.lvm.LVMISCSIDriver
++ set +o
++ grep xtrace
+ local 'xtrace=set -o xtrace'
+ set +o xtrace
+ iniset /etc/cinder/cinder.conf lvmdriver-1 volume_group stack-volumes-lvmdriver-1
++ set +o
++ grep xtrace
+ local 'xtrace=set -o xtrace'
+ set +o xtrace
+ [[ False == \F\a\l\s\e ]]
+ iniset /etc/cinder/cinder.conf lvmdriver-1 volume_clear none
++ set +o
++ grep xtrace
+ local 'xtrace=set -o xtrace'
+ set +o xtrace
+ [[ -z '' ]]
+ default_name=lvmdriver-1
+ enabled_backends+=lvmdriver-1,
+ iniset /etc/cinder/cinder.conf DEFAULT enabled_backends lvmdriver-1
++ set +o
++ grep xtrace
+ local 'xtrace=set -o xtrace'
+ set +o xtrace
+ [[ -n lvmdriver-1 ]]
+ iniset /etc/cinder/cinder.conf DEFAULT default_volume_type lvmdriver-1
++ set +o
++ grep xtrace
+ local 'xtrace=set -o xtrace'
+ set +o xtrace
+ is_service_enabled swift
++ set +o
++ grep xtrace
+ local 'xtrace=set -o xtrace'
+ set +o xtrace
+ return 0
+ iniset /etc/cinder/cinder.conf DEFAULT backup_swift_url http://10.14.0.26:8080/v1/AUTH_
++ set +o
++ grep xtrace
+ local 'xtrace=set -o xtrace'
+ set +o xtrace
+ is_service_enabled ceilometer
++ set +o
++ grep xtrace
+ local 'xtrace=set -o xtrace'
+ set +o xtrace
+ return 0
+ iniset /etc/cinder/cinder.conf DEFAULT notification_driver messaging
++ set +o
++ grep xtrace
+ local 'xtrace=set -o xtrace'
+ set +o xtrace
+ is_service_enabled tls-proxy
++ set +o
++ grep xtrace
+ local 'xtrace=set -o xtrace'
+ set +o xtrace
+ return 1
+ '[' False '!=' False ']'
+ iniset_rpc_backend cinder /etc/cinder/cinder.conf DEFAULT
+ local package=cinder
+ local file=/etc/cinder/cinder.conf
+ local section=DEFAULT
+ is_service_enabled zeromq
++ set +o
++ grep xtrace
+ local 'xtrace=set -o xtrace'
+ set +o xtrace
+ return 1
+ is_service_enabled qpid
++ set +o
++ grep xtrace
+ local 'xtrace=set -o xtrace'
+ set +o xtrace
+ return 1
+ '[' -n '' ']'
+ is_service_enabled rabbit
++ set +o
++ grep xtrace
+ local 'xtrace=set -o xtrace'
+ set +o xtrace
+ return 0
+ iniset /etc/cinder/cinder.conf DEFAULT rpc_backend cinder.openstack.common.rpc.impl_kombu
++ set +o
++ grep xtrace
+ local 'xtrace=set -o xtrace'
+ set +o xtrace
+ iniset /etc/cinder/cinder.conf DEFAULT rabbit_hosts 10.14.0.26
++ set +o
++ grep xtrace
+ local 'xtrace=set -o xtrace'
+ set +o xtrace
+ iniset /etc/cinder/cinder.conf DEFAULT rabbit_password Passw0rd
++ set +o
++ grep xtrace
+ local 'xtrace=set -o xtrace'
+ set +o xtrace
+ [[ False == \F\a\l\s\e ]]
+ iniset /etc/cinder/cinder.conf DEFAULT secure_delete False
++ set +o
++ grep xtrace
+ local 'xtrace=set -o xtrace'
+ set +o xtrace
+ iniset /etc/cinder/cinder.conf DEFAULT volume_clear none
++ set +o
++ grep xtrace
+ local 'xtrace=set -o xtrace'
+ set +o xtrace
+ '[' False == True ']'
+ [[ -r /home/cloudbase/devstack/lib/cinder_plugins/default ]]
+ [[ -n is_fedora ]]
+ [[ trusty =~ (rhel6) ]]
+ iniset /etc/cinder/cinder.conf DEFAULT osapi_volume_workers 2
++ set +o
++ grep xtrace
+ local 'xtrace=set -o xtrace'
+ set +o xtrace
+ iniset /etc/cinder/cinder.conf DEFAULT glance_api_servers http://10.14.0.26:9292
++ set +o
++ grep xtrace
+ local 'xtrace=set -o xtrace'
+ set +o xtrace
+ is_ssl_enabled_service glance
+ local services=glance
+ local service=
+ '[' False == False ']'
+ return 1
+ is_service_enabled tls-proxy
++ set +o
++ grep xtrace
+ local 'xtrace=set -o xtrace'
+ set +o xtrace
+ return 1
+ is_ssl_enabled_service cinder
+ local services=cinder
+ local service=
+ '[' False == False ']'
+ return 1
+ is_service_enabled neutron
++ set +o
++ grep xtrace
+ local 'xtrace=set -o xtrace'
+ set +o xtrace
+ return 0
+ install_neutron
+ git_clone git://git.openstack.org/openstack/neutron.git /opt/stack/neutron stable/juno
+ local git_remote=git://git.openstack.org/openstack/neutron.git
+ local git_dest=/opt/stack/neutron
+ local git_ref=stable/juno
++ pwd
+ local orig_dir=/home/cloudbase/devstack
++ trueorfalse False False
+++ set +o
+++ grep xtrace
++ local 'xtrace=set -o xtrace'
++ set +o xtrace
+ RECLONE=False
+ [[ False = \T\r\u\e ]]
+ echo stable/juno
+ egrep -q '^refs'
+ [[ ! -d /opt/stack/neutron ]]
+ [[ False = \T\r\u\e ]]
+ cd /opt/stack/neutron
+ git show --oneline
+ head -1
+ cd /home/cloudbase/devstack
+ setup_develop /opt/stack/neutron
+ local project_dir=/opt/stack/neutron
+ setup_package_with_req_sync /opt/stack/neutron -e
+ local project_dir=/opt/stack/neutron
+ local flags=-e
++ cd /opt/stack/neutron
++ git diff --exit-code
+ local update_requirements=
+ [[ '' != \c\h\a\n\g\e\d ]]
+ cd /opt/stack/requirements
+ python update.py /opt/stack/neutron
+ setup_package /opt/stack/neutron -e
+ local project_dir=/opt/stack/neutron
+ local flags=-e
+ pip_install -e /opt/stack/neutron
++ set +o
++ grep xtrace
+ local 'xtrace=set -o xtrace'
+ set +o xtrace
+ sudo PIP_DOWNLOAD_CACHE=/var/cache/pip http_proxy= https_proxy= no_proxy= /usr/local/bin/pip install -e /opt/stack/neutron
+ [[ False == \T\r\u\e ]]
+ [[ -e == \-\e ]]
+ safe_chown -R cloudbase /opt/stack/neutron/neutron.egg-info
+ _safe_permission_operation chown -R cloudbase /opt/stack/neutron/neutron.egg-info
++ set +o
++ grep xtrace
+ local 'xtrace=set -o xtrace'
+ set +o xtrace
+ sudo chown -R cloudbase /opt/stack/neutron/neutron.egg-info
+ '[' True = True ']'
+ [[ '' != \c\h\a\n\g\e\d ]]
+ cd /opt/stack/neutron
+ git reset --hard
+ install_neutron_third_party
+ _neutron_third_party_do install
+ is_service_enabled nova
++ set +o
++ grep xtrace
+ local 'xtrace=set -o xtrace'
+ set +o xtrace
+ return 0
+ install_nova
+ is_service_enabled n-cpu
++ set +o
++ grep xtrace
+ local 'xtrace=set -o xtrace'
+ set +o xtrace
+ return 1
+ is_service_enabled n-novnc
++ set +o
++ grep xtrace
+ local 'xtrace=set -o xtrace'
+ set +o xtrace
+ return 1
+ is_service_enabled n-spice
++ set +o
++ grep xtrace
+ local 'xtrace=set -o xtrace'
+ set +o xtrace
+ return 1
+ git_clone git://git.openstack.org/openstack/nova.git /opt/stack/nova stable/juno
+ local git_remote=git://git.openstack.org/openstack/nova.git
+ local git_dest=/opt/stack/nova
+ local git_ref=stable/juno
++ pwd
+ local orig_dir=/home/cloudbase/devstack
++ trueorfalse False False
+++ set +o
+++ grep xtrace
++ local 'xtrace=set -o xtrace'
++ set +o xtrace
+ RECLONE=False
+ [[ False = \T\r\u\e ]]
+ echo stable/juno
+ egrep -q '^refs'
+ [[ ! -d /opt/stack/nova ]]
+ [[ False = \T\r\u\e ]]
+ cd /opt/stack/nova
+ git show --oneline
+ head -1
+ cd /home/cloudbase/devstack
+ setup_develop /opt/stack/nova
+ local project_dir=/opt/stack/nova
+ setup_package_with_req_sync /opt/stack/nova -e
+ local project_dir=/opt/stack/nova
+ local flags=-e
++ cd /opt/stack/nova
++ git diff --exit-code
+ local update_requirements=
+ [[ '' != \c\h\a\n\g\e\d ]]
+ cd /opt/stack/requirements
+ python update.py /opt/stack/nova
+ setup_package /opt/stack/nova -e
+ local project_dir=/opt/stack/nova
+ local flags=-e
+ pip_install -e /opt/stack/nova
++ set +o
++ grep xtrace
+ local 'xtrace=set -o xtrace'
+ set +o xtrace
+ sudo PIP_DOWNLOAD_CACHE=/var/cache/pip http_proxy= https_proxy= no_proxy= /usr/local/bin/pip install -e /opt/stack/nova
+ [[ False == \T\r\u\e ]]
+ [[ -e == \-\e ]]
+ safe_chown -R cloudbase /opt/stack/nova/nova.egg-info
+ _safe_permission_operation chown -R cloudbase /opt/stack/nova/nova.egg-info
++ set +o
++ grep xtrace
+ local 'xtrace=set -o xtrace'
+ set +o xtrace
+ sudo chown -R cloudbase /opt/stack/nova/nova.egg-info
+ '[' True = True ']'
+ [[ '' != \c\h\a\n\g\e\d ]]
+ cd /opt/stack/nova
+ git reset --hard
+ sudo install -D -m 0644 -o cloudbase /opt/stack/nova/tools/nova-manage.bash_completion /etc/bash_completion.d/nova-manage.bash_completion
+ cleanup_nova
+ is_service_enabled n-cpu
++ set +o
++ grep xtrace
+ local 'xtrace=set -o xtrace'
+ set +o xtrace
+ return 1
+ sudo rm -rf /opt/stack/data/nova /var/cache/nova
+ configure_nova
+ [[ ! -d /etc/nova ]]
+ sudo chown cloudbase /etc/nova
+ cp -p /opt/stack/nova/etc/nova/policy.json /etc/nova
+ configure_nova_rootwrap
+ [[ -d /etc/nova/rootwrap.d ]]
+ sudo rm -rf /etc/nova/rootwrap.d
+ sudo mkdir -m 755 /etc/nova/rootwrap.d
+ sudo cp /opt/stack/nova/etc/nova/rootwrap.d/api-metadata.filters /opt/stack/nova/etc/nova/rootwrap.d/baremetal-compute-ipmi.filters /opt/stack/nova/etc/nova/rootwrap.d/baremetal-deploy-helper.filters /opt/stack/nova/etc/nova/rootwrap.d/compute.filters /opt/stack/nova/etc/nova/rootwrap.d/network.filters /etc/nova/rootwrap.d
+ sudo chown -R root:root /etc/nova/rootwrap.d
+ sudo chmod 644 /etc/nova/rootwrap.d/api-metadata.filters /etc/nova/rootwrap.d/baremetal-compute-ipmi.filters /etc/nova/rootwrap.d/baremetal-deploy-helper.filters /etc/nova/rootwrap.d/compute.filters /etc/nova/rootwrap.d/network.filters
+ sudo cp /opt/stack/nova/etc/nova/rootwrap.conf /etc/nova/
+ sudo sed -e 's:^filters_path=.*$:filters_path=/etc/nova/rootwrap.d:' -i /etc/nova/rootwrap.conf
+ sudo chown root:root /etc/nova/rootwrap.conf
+ sudo chmod 0644 /etc/nova/rootwrap.conf
+ local 'rootwrap_sudoer_cmd=/usr/local/bin/nova-rootwrap /etc/nova/rootwrap.conf *'
++ mktemp
+ local tempfile=/tmp/tmp.Tapeajn05i
+ echo 'cloudbase ALL=(root) NOPASSWD: /usr/local/bin/nova-rootwrap /etc/nova/rootwrap.conf *'
+ chmod 0440 /tmp/tmp.Tapeajn05i
+ sudo chown root:root /tmp/tmp.Tapeajn05i
+ sudo mv /tmp/tmp.Tapeajn05i /etc/sudoers.d/nova-rootwrap
+ is_service_enabled n-api
++ set +o
++ grep xtrace
+ local 'xtrace=set -o xtrace'
+ set +o xtrace
+ return 0
+ rm -f /opt/stack/nova/bin/nova-api-paste.ini
+ cp /opt/stack/nova/etc/nova/api-paste.ini /etc/nova
+ is_service_enabled n-cpu
++ set +o
++ grep xtrace
+ local 'xtrace=set -o xtrace'
+ set +o xtrace
+ return 1
+ create_nova_conf
+ rm -f /opt/stack/nova/bin/nova.conf
+ rm -f /etc/nova/nova.conf
+ iniset /etc/nova/nova.conf DEFAULT verbose True
++ set +o
++ grep xtrace
+ local 'xtrace=set -o xtrace'
+ set +o xtrace
+ iniset /etc/nova/nova.conf DEFAULT debug True
++ set +o
++ grep xtrace
+ local 'xtrace=set -o xtrace'
+ set +o xtrace
+ iniset /etc/nova/nova.conf DEFAULT allow_resize_to_same_host True
++ set +o
++ grep xtrace
+ local 'xtrace=set -o xtrace'
+ set +o xtrace
+ iniset /etc/nova/nova.conf DEFAULT allow_migrate_to_same_host True
++ set +o
++ grep xtrace
+ local 'xtrace=set -o xtrace'
+ set +o xtrace
+ iniset /etc/nova/nova.conf DEFAULT api_paste_config /etc/nova/api-paste.ini
++ set +o
++ grep xtrace
+ local 'xtrace=set -o xtrace'
+ set +o xtrace
+ iniset /etc/nova/nova.conf DEFAULT rootwrap_config /etc/nova/rootwrap.conf
++ set +o
++ grep xtrace
+ local 'xtrace=set -o xtrace'
+ set +o xtrace
+ iniset /etc/nova/nova.conf DEFAULT scheduler_driver nova.scheduler.filter_scheduler.FilterScheduler
++ set +o
++ grep xtrace
+ local 'xtrace=set -o xtrace'
+ set +o xtrace
+ iniset /etc/nova/nova.conf DEFAULT dhcpbridge_flagfile /etc/nova/nova.conf
++ set +o
++ grep xtrace
+ local 'xtrace=set -o xtrace'
+ set +o xtrace
+ iniset /etc/nova/nova.conf DEFAULT force_dhcp_release True
++ set +o
++ grep xtrace
+ local 'xtrace=set -o xtrace'
+ set +o xtrace
+ iniset /etc/nova/nova.conf DEFAULT default_floating_pool public
++ set +o
++ grep xtrace
+ local 'xtrace=set -o xtrace'
+ set +o xtrace
+ iniset /etc/nova/nova.conf DEFAULT s3_host 10.14.0.26
++ set +o
++ grep xtrace
+ local 'xtrace=set -o xtrace'
+ set +o xtrace
+ iniset /etc/nova/nova.conf DEFAULT s3_port 3333
++ set +o
++ grep xtrace
+ local 'xtrace=set -o xtrace'
+ set +o xtrace
+ iniset /etc/nova/nova.conf DEFAULT my_ip 10.14.0.26
++ set +o
++ grep xtrace
+ local 'xtrace=set -o xtrace'
+ set +o xtrace
++ database_connection_url nova
++ local db=nova
++ database_connection_url_mysql nova
++ local db=nova
++ echo 'mysql://root:Passw0rd@127.0.0.1/nova?charset=utf8'
+ iniset /etc/nova/nova.conf DEFAULT sql_connection 'mysql://root:Passw0rd@127.0.0.1/nova?charset=utf8'
++ set +o
++ grep xtrace
+ local 'xtrace=set -o xtrace'
+ set +o xtrace
+ iniset /etc/nova/nova.conf DEFAULT instance_name_template instance-%08x
++ set +o
++ grep xtrace
+ local 'xtrace=set -o xtrace'
+ set +o xtrace
+ iniset /etc/nova/nova.conf osapi_v3 enabled True
++ set +o
++ grep xtrace
+ local 'xtrace=set -o xtrace'
+ set +o xtrace
+ is_fedora
+ [[ -z Ubuntu ]]
+ '[' Ubuntu = Fedora ']'
+ '[' Ubuntu = 'Red Hat' ']'
+ '[' Ubuntu = CentOS ']'
+ '[' Ubuntu = OracleServer ']'
+ is_suse
+ [[ -z Ubuntu ]]
+ '[' Ubuntu = openSUSE ']'
+ '[' Ubuntu = 'SUSE LINUX' ']'
+ is_service_enabled n-api
++ set +o
++ grep xtrace
+ local 'xtrace=set -o xtrace'
+ set +o xtrace
+ return 0
+ is_service_enabled n-api-meta
++ set +o
++ grep xtrace
+ local 'xtrace=set -o xtrace'
+ set +o xtrace
+ return 1
+ iniset /etc/nova/nova.conf DEFAULT enabled_apis ec2,osapi_compute,metadata
++ set +o
++ grep xtrace
+ local 'xtrace=set -o xtrace'
+ set +o xtrace
+ is_service_enabled tls-proxy
++ set +o
++ grep xtrace
+ local 'xtrace=set -o xtrace'
+ set +o xtrace
+ return 1
+ configure_auth_token_middleware /etc/nova/nova.conf nova /var/cache/nova
+ local conf_file=/etc/nova/nova.conf
+ local admin_user=nova
+ local signing_dir=/var/cache/nova
+ local section=keystone_authtoken
+ iniset /etc/nova/nova.conf keystone_authtoken auth_host 10.14.0.26
++ set +o
++ grep xtrace
+ local 'xtrace=set -o xtrace'
+ set +o xtrace
+ iniset /etc/nova/nova.conf keystone_authtoken auth_port 35357
++ set +o
++ grep xtrace
+ local 'xtrace=set -o xtrace'
+ set +o xtrace
+ iniset /etc/nova/nova.conf keystone_authtoken auth_protocol http
++ set +o
++ grep xtrace
+ local 'xtrace=set -o xtrace'
+ set +o xtrace
+ iniset /etc/nova/nova.conf keystone_authtoken identity_uri http://10.14.0.26:35357
++ set +o
++ grep xtrace
+ local 'xtrace=set -o xtrace'
+ set +o xtrace
+ iniset /etc/nova/nova.conf keystone_authtoken cafile /opt/stack/data/ca-bundle.pem
++ set +o
++ grep xtrace
+ local 'xtrace=set -o xtrace'
+ set +o xtrace
+ configure_API_version /etc/nova/nova.conf 2.0 keystone_authtoken
+ local conf_file=/etc/nova/nova.conf
+ local api_version=2.0
+ local section=keystone_authtoken
+ iniset /etc/nova/nova.conf keystone_authtoken auth_uri http://10.14.0.26:5000/v2.0
++ set +o
++ grep xtrace
+ local 'xtrace=set -o xtrace'
+ set +o xtrace
+ iniset /etc/nova/nova.conf keystone_authtoken admin_tenant_name service
++ set +o
++ grep xtrace
+ local 'xtrace=set -o xtrace'
+ set +o xtrace
+ iniset /etc/nova/nova.conf keystone_authtoken admin_user nova
++ set +o
++ grep xtrace
+ local 'xtrace=set -o xtrace'
+ set +o xtrace
+ iniset /etc/nova/nova.conf keystone_authtoken admin_password Passw0rd
++ set +o
++ grep xtrace
+ local 'xtrace=set -o xtrace'
+ set +o xtrace
+ iniset /etc/nova/nova.conf keystone_authtoken signing_dir /var/cache/nova
++ set +o
++ grep xtrace
+ local 'xtrace=set -o xtrace'
+ set +o xtrace
+ [[ -n '' ]]
+ is_service_enabled cinder
++ set +o
++ grep xtrace
+ local 'xtrace=set -o xtrace'
+ set +o xtrace
+ return 0
+ is_ssl_enabled_service cinder
+ local services=cinder
+ local service=
+ '[' False == False ']'
+ return 1
+ is_service_enabled tls-proxy
++ set +o
++ grep xtrace
+ local 'xtrace=set -o xtrace'
+ set +o xtrace
+ return 1
+ '[' -n /opt/stack/data/nova ']'
+ iniset /etc/nova/nova.conf DEFAULT state_path /opt/stack/data/nova
++ set +o
++ grep xtrace
+ local 'xtrace=set -o xtrace'
+ set +o xtrace
+ iniset /etc/nova/nova.conf DEFAULT lock_path /opt/stack/data/nova
++ set +o
++ grep xtrace
+ local 'xtrace=set -o xtrace'
+ set +o xtrace
+ '[' -n /opt/stack/data/nova/instances ']'
+ iniset /etc/nova/nova.conf DEFAULT instances_path /opt/stack/data/nova/instances
++ set +o
++ grep xtrace
+ local 'xtrace=set -o xtrace'
+ set +o xtrace
+ '[' False '!=' False ']'
+ '[' False '!=' False ']'
+ '[' always '!=' False ']'
+ iniset /etc/nova/nova.conf DEFAULT force_config_drive always
++ set +o
++ grep xtrace
+ local 'xtrace=set -o xtrace'
+ set +o xtrace
+ '[' False == True ']'
+ iniset /etc/nova/nova.conf DEFAULT logging_context_format_string '%(asctime)s.%(msecs)03d %(levelname)s %(name)s [%(request_id)s %(user_name)s %(project_name)s] %(instance)s%(message)s'
++ set +o
++ grep xtrace
+ local 'xtrace=set -o xtrace'
+ set +o xtrace
+ is_service_enabled ceilometer
++ set +o
++ grep xtrace
+ local 'xtrace=set -o xtrace'
+ set +o xtrace
+ return 0
+ iniset /etc/nova/nova.conf DEFAULT instance_usage_audit True
++ set +o
++ grep xtrace
+ local 'xtrace=set -o xtrace'
+ set +o xtrace
+ iniset /etc/nova/nova.conf DEFAULT instance_usage_audit_period hour
++ set +o
++ grep xtrace
+ local 'xtrace=set -o xtrace'
+ set +o xtrace
+ iniset /etc/nova/nova.conf DEFAULT notify_on_state_change vm_and_task_state
++ set +o
++ grep xtrace
+ local 'xtrace=set -o xtrace'
+ set +o xtrace
+ iniset /etc/nova/nova.conf DEFAULT notification_driver messaging
++ set +o
++ grep xtrace
+ local 'xtrace=set -o xtrace'
+ set +o xtrace
+ is_service_enabled n-cpu
++ set +o
++ grep xtrace
+ local 'xtrace=set -o xtrace'
+ set +o xtrace
+ return 1
+ is_service_enabled n-novnc
++ set +o
++ grep xtrace
+ local 'xtrace=set -o xtrace'
+ set +o xtrace
+ return 1
+ is_service_enabled n-xvnc
++ set +o
++ grep xtrace
+ local 'xtrace=set -o xtrace'
+ set +o xtrace
+ return 0
+ VNCSERVER_LISTEN=127.0.0.1
+ VNCSERVER_PROXYCLIENT_ADDRESS=127.0.0.1
+ iniset /etc/nova/nova.conf DEFAULT vnc_enabled true
++ set +o
++ grep xtrace
+ local 'xtrace=set -o xtrace'
+ set +o xtrace
+ iniset /etc/nova/nova.conf DEFAULT vncserver_listen 127.0.0.1
++ set +o
++ grep xtrace
+ local 'xtrace=set -o xtrace'
+ set +o xtrace
+ iniset /etc/nova/nova.conf DEFAULT vncserver_proxyclient_address 127.0.0.1
++ set +o
++ grep xtrace
+ local 'xtrace=set -o xtrace'
+ set +o xtrace
+ is_service_enabled n-spice
++ set +o
++ grep xtrace
+ local 'xtrace=set -o xtrace'
+ set +o xtrace
+ return 1
+ iniset /etc/nova/nova.conf spice enabled false
++ set +o
++ grep xtrace
+ local 'xtrace=set -o xtrace'
+ set +o xtrace
+ iniset /etc/nova/nova.conf DEFAULT ec2_dmz_host 10.14.0.26
++ set +o
++ grep xtrace
+ local 'xtrace=set -o xtrace'
+ set +o xtrace
+ iniset /etc/nova/nova.conf DEFAULT keystone_ec2_url http://10.14.0.26:5000/v2.0/ec2tokens
++ set +o
++ grep xtrace
+ local 'xtrace=set -o xtrace'
+ set +o xtrace
+ iniset_rpc_backend nova /etc/nova/nova.conf DEFAULT
+ local package=nova
+ local file=/etc/nova/nova.conf
+ local section=DEFAULT
+ is_service_enabled zeromq
++ set +o
++ grep xtrace
+ local 'xtrace=set -o xtrace'
+ set +o xtrace
+ return 1
+ is_service_enabled qpid
++ set +o
++ grep xtrace
+ local 'xtrace=set -o xtrace'
+ set +o xtrace
+ return 1
+ '[' -n '' ']'
+ is_service_enabled rabbit
++ set +o
++ grep xtrace
+ local 'xtrace=set -o xtrace'
+ set +o xtrace
+ return 0
+ iniset /etc/nova/nova.conf DEFAULT rpc_backend nova.openstack.common.rpc.impl_kombu
++ set +o
++ grep xtrace
+ local 'xtrace=set -o xtrace'
+ set +o xtrace
+ iniset /etc/nova/nova.conf DEFAULT rabbit_hosts 10.14.0.26
++ set +o
++ grep xtrace
+ local 'xtrace=set -o xtrace'
+ set +o xtrace
+ iniset /etc/nova/nova.conf DEFAULT rabbit_password Passw0rd
++ set +o
++ grep xtrace
+ local 'xtrace=set -o xtrace'
+ set +o xtrace
+ iniset /etc/nova/nova.conf glance api_servers http://10.14.0.26:9292
++ set +o
++ grep xtrace
+ local 'xtrace=set -o xtrace'
+ set +o xtrace
+ iniset /etc/nova/nova.conf DEFAULT osapi_compute_workers 2
++ set +o
++ grep xtrace
+ local 'xtrace=set -o xtrace'
+ set +o xtrace
+ iniset /etc/nova/nova.conf DEFAULT ec2_workers 2
++ set +o
++ grep xtrace
+ local 'xtrace=set -o xtrace'
+ set +o xtrace
+ iniset /etc/nova/nova.conf DEFAULT metadata_workers 2
++ set +o
++ grep xtrace
+ local 'xtrace=set -o xtrace'
+ set +o xtrace
+ is_ssl_enabled_service glance
+ local services=glance
+ local service=
+ '[' False == False ']'
+ return 1
+ is_service_enabled tls-proxy
++ set +o
++ grep xtrace
+ local 'xtrace=set -o xtrace'
+ set +o xtrace
+ return 1
+ is_ssl_enabled_service nova
+ local services=nova
+ local service=
+ '[' False == False ']'
+ return 1
+ is_service_enabled tls-proxy
++ set +o
++ grep xtrace
+ local 'xtrace=set -o xtrace'
+ set +o xtrace
+ return 1
+ is_service_enabled n-cpu
++ set +o
++ grep xtrace
+ local 'xtrace=set -o xtrace'
+ set +o xtrace
+ return 1
+ is_service_enabled horizon
++ set +o
++ grep xtrace
+ local 'xtrace=set -o xtrace'
+ set +o xtrace
+ return 1
+ is_service_enabled ceilometer
++ set +o
++ grep xtrace
+ local 'xtrace=set -o xtrace'
+ set +o xtrace
+ return 0
+ install_ceilometerclient
+ use_library_from_git python-ceilometerclient
+ local name=python-ceilometerclient
+ local enabled=1
+ [[ ,, =~ ,python-ceilometerclient, ]]
+ return 1
+ install_ceilometer
+ git_clone git://git.openstack.org/openstack/ceilometer.git /opt/stack/ceilometer stable/juno
+ local git_remote=git://git.openstack.org/openstack/ceilometer.git
+ local git_dest=/opt/stack/ceilometer
+ local git_ref=stable/juno
++ pwd
+ local orig_dir=/home/cloudbase/devstack
++ trueorfalse False False
+++ set +o
+++ grep xtrace
++ local 'xtrace=set -o xtrace'
++ set +o xtrace
+ RECLONE=False
+ [[ False = \T\r\u\e ]]
+ echo stable/juno
+ egrep -q '^refs'
+ [[ ! -d /opt/stack/ceilometer ]]
+ [[ False = \T\r\u\e ]]
+ cd /opt/stack/ceilometer
+ git show --oneline
+ head -1
+ cd /home/cloudbase/devstack
+ setup_develop /opt/stack/ceilometer
+ local project_dir=/opt/stack/ceilometer
+ setup_package_with_req_sync /opt/stack/ceilometer -e
+ local project_dir=/opt/stack/ceilometer
+ local flags=-e
++ cd /opt/stack/ceilometer
++ git diff --exit-code
+ local update_requirements=
+ [[ '' != \c\h\a\n\g\e\d ]]
+ cd /opt/stack/requirements
+ python update.py /opt/stack/ceilometer
+ setup_package /opt/stack/ceilometer -e
+ local project_dir=/opt/stack/ceilometer
+ local flags=-e
+ pip_install -e /opt/stack/ceilometer
++ set +o
++ grep xtrace
+ local 'xtrace=set -o xtrace'
+ set +o xtrace
+ sudo PIP_DOWNLOAD_CACHE=/var/cache/pip http_proxy= https_proxy= no_proxy= /usr/local/bin/pip install -e /opt/stack/ceilometer
+ [[ False == \T\r\u\e ]]
+ [[ -e == \-\e ]]
+ safe_chown -R cloudbase /opt/stack/ceilometer/ceilometer.egg-info
+ _safe_permission_operation chown -R cloudbase /opt/stack/ceilometer/ceilometer.egg-info
++ set +o
++ grep xtrace
+ local 'xtrace=set -o xtrace'
+ set +o xtrace
+ sudo chown -R cloudbase /opt/stack/ceilometer/ceilometer.egg-info
+ '[' True = True ']'
+ [[ '' != \c\h\a\n\g\e\d ]]
+ cd /opt/stack/ceilometer
+ git reset --hard
+ echo_summary 'Configuring Ceilometer'
+ [[ -t 3 ]]
+ echo -e Configuring Ceilometer
+ configure_ceilometer
+ '[' '!' -d /etc/ceilometer ']'
+ sudo chown cloudbase /etc/ceilometer
+ '[' '!' -d /var/log/ceilometer-api ']'
+ sudo chown cloudbase /var/log/ceilometer-api
+ iniset_rpc_backend ceilometer /etc/ceilometer/ceilometer.conf DEFAULT
+ local package=ceilometer
+ local file=/etc/ceilometer/ceilometer.conf
+ local section=DEFAULT
+ is_service_enabled zeromq
++ set +o
++ grep xtrace
+ local 'xtrace=set -o xtrace'
+ set +o xtrace
+ return 1
+ is_service_enabled qpid
++ set +o
++ grep xtrace
+ local 'xtrace=set -o xtrace'
+ set +o xtrace
+ return 1
+ '[' -n '' ']'
+ is_service_enabled rabbit
++ set +o
++ grep xtrace
+ local 'xtrace=set -o xtrace'
+ set +o xtrace
+ return 0
+ iniset /etc/ceilometer/ceilometer.conf DEFAULT rpc_backend ceilometer.openstack.common.rpc.impl_kombu
++ set +o
++ grep xtrace
+ local 'xtrace=set -o xtrace'
+ set +o xtrace
+ iniset /etc/ceilometer/ceilometer.conf DEFAULT rabbit_hosts 10.14.0.26
++ set +o
++ grep xtrace
+ local 'xtrace=set -o xtrace'
+ set +o xtrace
+ iniset /etc/ceilometer/ceilometer.conf DEFAULT rabbit_password Passw0rd
++ set +o
++ grep xtrace
+ local 'xtrace=set -o xtrace'
+ set +o xtrace
+ iniset /etc/ceilometer/ceilometer.conf DEFAULT notification_topics notifications
++ set +o
++ grep xtrace
+ local 'xtrace=set -o xtrace'
+ set +o xtrace
+ iniset /etc/ceilometer/ceilometer.conf DEFAULT verbose True
++ set +o
++ grep xtrace
+ local 'xtrace=set -o xtrace'
+ set +o xtrace
+ iniset /etc/ceilometer/ceilometer.conf DEFAULT debug True
++ set +o
++ grep xtrace
+ local 'xtrace=set -o xtrace'
+ set +o xtrace
+ cp /opt/stack/ceilometer/etc/ceilometer/policy.json /etc/ceilometer
+ iniset /etc/ceilometer/ceilometer.conf DEFAULT policy_file /etc/ceilometer/policy.json
++ set +o
++ grep xtrace
+ local 'xtrace=set -o xtrace'
+ set +o xtrace
+ cp /opt/stack/ceilometer/etc/ceilometer/pipeline.yaml /etc/ceilometer
+ cp /opt/stack/ceilometer/etc/ceilometer/api_paste.ini /etc/ceilometer
+ cp /opt/stack/ceilometer/etc/ceilometer/event_definitions.yaml /etc/ceilometer
+ '[' '' ']'
+ iniset /etc/ceilometer/ceilometer.conf service_credentials os_username ceilometer
++ set +o
++ grep xtrace
+ local 'xtrace=set -o xtrace'
+ set +o xtrace
+ iniset /etc/ceilometer/ceilometer.conf service_credentials os_password Passw0rd
++ set +o
++ grep xtrace
+ local 'xtrace=set -o xtrace'
+ set +o xtrace
+ iniset /etc/ceilometer/ceilometer.conf service_credentials os_tenant_name service
++ set +o
++ grep xtrace
+ local 'xtrace=set -o xtrace'
+ set +o xtrace
+ configure_auth_token_middleware /etc/ceilometer/ceilometer.conf ceilometer /var/cache/ceilometer
+ local conf_file=/etc/ceilometer/ceilometer.conf
+ local admin_user=ceilometer
+ local signing_dir=/var/cache/ceilometer
+ local section=keystone_authtoken
+ iniset /etc/ceilometer/ceilometer.conf keystone_authtoken auth_host 10.14.0.26
++ set +o
++ grep xtrace
+ local 'xtrace=set -o xtrace'
+ set +o xtrace
+ iniset /etc/ceilometer/ceilometer.conf keystone_authtoken auth_port 35357
++ set +o
++ grep xtrace
+ local 'xtrace=set -o xtrace'
+ set +o xtrace
+ iniset /etc/ceilometer/ceilometer.conf keystone_authtoken auth_protocol http
++ set +o
++ grep xtrace
+ local 'xtrace=set -o xtrace'
+ set +o xtrace
+ iniset /etc/ceilometer/ceilometer.conf keystone_authtoken identity_uri http://10.14.0.26:35357
++ set +o
++ grep xtrace
+ local 'xtrace=set -o xtrace'
+ set +o xtrace
+ iniset /etc/ceilometer/ceilometer.conf keystone_authtoken cafile /opt/stack/data/ca-bundle.pem
++ set +o
++ grep xtrace
+ local 'xtrace=set -o xtrace'
+ set +o xtrace
+ configure_API_version /etc/ceilometer/ceilometer.conf 2.0 keystone_authtoken
+ local conf_file=/etc/ceilometer/ceilometer.conf
+ local api_version=2.0
+ local section=keystone_authtoken
+ iniset /etc/ceilometer/ceilometer.conf keystone_authtoken auth_uri http://10.14.0.26:5000/v2.0
++ set +o
++ grep xtrace
+ local 'xtrace=set -o xtrace'
+ set +o xtrace
+ iniset /etc/ceilometer/ceilometer.conf keystone_authtoken admin_tenant_name service
++ set +o
++ grep xtrace
+ local 'xtrace=set -o xtrace'
+ set +o xtrace
+ iniset /etc/ceilometer/ceilometer.conf keystone_authtoken admin_user ceilometer
++ set +o
++ grep xtrace
+ local 'xtrace=set -o xtrace'
+ set +o xtrace
+ iniset /etc/ceilometer/ceilometer.conf keystone_authtoken admin_password Passw0rd
++ set +o
++ grep xtrace
+ local 'xtrace=set -o xtrace'
+ set +o xtrace
+ iniset /etc/ceilometer/ceilometer.conf keystone_authtoken signing_dir /var/cache/ceilometer
++ set +o
++ grep xtrace
+ local 'xtrace=set -o xtrace'
+ set +o xtrace
+ [[ -n '' ]]
+ '[' mongodb = mysql ']'
+ '[' mongodb = postgresql ']'
+ iniset /etc/ceilometer/ceilometer.conf database connection mongodb://localhost:27017/ceilometer
++ set +o
++ grep xtrace
+ local 'xtrace=set -o xtrace'
+ set +o xtrace
+ configure_mongodb
+ local packages=mongodb-server
+ is_fedora
+ [[ -z Ubuntu ]]
+ '[' Ubuntu = Fedora ']'
+ '[' Ubuntu = 'Red Hat' ']'
+ '[' Ubuntu = CentOS ']'
+ '[' Ubuntu = OracleServer ']'
+ packages='mongodb-server python-pymongo'
+ install_package mongodb-server python-pymongo
+ update_package_repo
+ [[ '' = \T\r\u\e ]]
+ is_ubuntu
+ [[ -z deb ]]
+ '[' deb = deb ']'
++ set +o
++ grep xtrace
+ local 'xtrace=set -o xtrace'
+ set +o xtrace
+ real_install_package mongodb-server python-pymongo
+ is_ubuntu
+ [[ -z deb ]]
+ '[' deb = deb ']'
+ apt_get install mongodb-server python-pymongo
++ set +o
++ grep xtrace
+ local 'xtrace=set -o xtrace'
+ set +o xtrace
+ sudo DEBIAN_FRONTEND=noninteractive http_proxy= https_proxy= no_proxy= apt-get --option Dpkg::Options::=--force-confold --assume-yes install mongodb-server python-pymongo
+ real_install_package mongodb-server python-pymongo
+ is_ubuntu
+ [[ -z deb ]]
+ '[' deb = deb ']'
+ apt_get install mongodb-server python-pymongo
++ set +o
++ grep xtrace
+ local 'xtrace=set -o xtrace'
+ set +o xtrace
+ sudo DEBIAN_FRONTEND=noninteractive http_proxy= https_proxy= no_proxy= apt-get --option Dpkg::Options::=--force-confold --assume-yes install mongodb-server python-pymongo
+ is_fedora
+ [[ -z Ubuntu ]]
+ '[' Ubuntu = Fedora ']'
+ '[' Ubuntu = 'Red Hat' ']'
+ '[' Ubuntu = CentOS ']'
+ '[' Ubuntu = OracleServer ']'
+ sleep 5
+ cleanup_ceilometer
+ '[' mongodb '!=' mysql ']'
+ '[' mongodb '!=' postgresql ']'
+ mongo ceilometer --eval 'db.dropDatabase();'
+ '[' False == True ']'
+ [[ libvirt = \v\s\p\h\e\r\e ]]
+ '[' False == True ']'
+ is_service_enabled heat
++ set +o
++ grep xtrace
+ local 'xtrace=set -o xtrace'
+ set +o xtrace
+ return 0
+ install_heat
+ git_clone git://git.openstack.org/openstack/heat.git /opt/stack/heat stable/juno
+ local git_remote=git://git.openstack.org/openstack/heat.git
+ local git_dest=/opt/stack/heat
+ local git_ref=stable/juno
++ pwd
+ local orig_dir=/home/cloudbase/devstack
++ trueorfalse False False
+++ set +o
+++ grep xtrace
++ local 'xtrace=set -o xtrace'
++ set +o xtrace
+ RECLONE=False
+ [[ False = \T\r\u\e ]]
+ echo stable/juno
+ egrep -q '^refs'
+ [[ ! -d /opt/stack/heat ]]
+ [[ False = \T\r\u\e ]]
+ cd /opt/stack/heat
+ git show --oneline
+ head -1
+ cd /home/cloudbase/devstack
+ install_heat_other
+ git_clone git://git.openstack.org/openstack/heat-cfntools.git /opt/stack/heat-cfntools master
+ local git_remote=git://git.openstack.org/openstack/heat-cfntools.git
+ local git_dest=/opt/stack/heat-cfntools
+ local git_ref=master
++ pwd
+ local orig_dir=/home/cloudbase/devstack
++ trueorfalse False False
+++ set +o
+++ grep xtrace
++ local 'xtrace=set -o xtrace'
++ set +o xtrace
+ RECLONE=False
+ [[ False = \T\r\u\e ]]
+ echo master
+ egrep -q '^refs'
+ [[ ! -d /opt/stack/heat-cfntools ]]
+ [[ False = \T\r\u\e ]]
+ cd /opt/stack/heat-cfntools
+ git show --oneline
+ head -1
+ cd /home/cloudbase/devstack
+ git_clone git://git.openstack.org/openstack/heat-templates.git /opt/stack/heat-templates master
+ local git_remote=git://git.openstack.org/openstack/heat-templates.git
+ local git_dest=/opt/stack/heat-templates
+ local git_ref=master
++ pwd
+ local orig_dir=/home/cloudbase/devstack
++ trueorfalse False False
+++ set +o
+++ grep xtrace
++ local 'xtrace=set -o xtrace'
++ set +o xtrace
+ RECLONE=False
+ [[ False = \T\r\u\e ]]
+ echo master
+ egrep -q '^refs'
+ [[ ! -d /opt/stack/heat-templates ]]
+ [[ False = \T\r\u\e ]]
+ cd /opt/stack/heat-templates
+ git show --oneline
+ head -1
+ cd /home/cloudbase/devstack
+ cleanup_heat
+ sudo rm -rf /var/cache/heat
+ sudo rm -rf /etc/heat/environment.d
+ sudo rm -rf /etc/heat/templates
+ configure_heat
+ setup_develop /opt/stack/heat
+ local project_dir=/opt/stack/heat
+ setup_package_with_req_sync /opt/stack/heat -e
+ local project_dir=/opt/stack/heat
+ local flags=-e
++ cd /opt/stack/heat
++ git diff --exit-code
+ local update_requirements=
+ [[ '' != \c\h\a\n\g\e\d ]]
+ cd /opt/stack/requirements
+ python update.py /opt/stack/heat
+ setup_package /opt/stack/heat -e
+ local project_dir=/opt/stack/heat
+ local flags=-e
+ pip_install -e /opt/stack/heat
++ set +o
++ grep xtrace
+ local 'xtrace=set -o xtrace'
+ set +o xtrace
+ sudo PIP_DOWNLOAD_CACHE=/var/cache/pip http_proxy= https_proxy= no_proxy= /usr/local/bin/pip install -e /opt/stack/heat
+ [[ False == \T\r\u\e ]]
+ [[ -e == \-\e ]]
+ safe_chown -R cloudbase /opt/stack/heat/heat.egg-info
+ _safe_permission_operation chown -R cloudbase /opt/stack/heat/heat.egg-info
++ set +o
++ grep xtrace
+ local 'xtrace=set -o xtrace'
+ set +o xtrace
+ sudo chown -R cloudbase /opt/stack/heat/heat.egg-info
+ '[' True = True ']'
+ [[ '' != \c\h\a\n\g\e\d ]]
+ cd /opt/stack/heat
+ git reset --hard
+ [[ False = \T\r\u\e ]]
+ [[ ! -d /etc/heat ]]
+ sudo chown cloudbase /etc/heat
+ rm -f '/etc/heat/heat-*.conf'
+ HEAT_API_CFN_HOST=10.14.0.26
+ HEAT_API_CFN_PORT=8000
+ HEAT_ENGINE_HOST=10.14.0.26
+ HEAT_ENGINE_PORT=8001
+ HEAT_API_CW_HOST=10.14.0.26
+ HEAT_API_CW_PORT=8003
+ HEAT_API_PASTE_FILE=/etc/heat/api-paste.ini
+ HEAT_POLICY_FILE=/etc/heat/policy.json
+ cp /opt/stack/heat/etc/heat/api-paste.ini /etc/heat/api-paste.ini
+ cp /opt/stack/heat/etc/heat/policy.json /etc/heat/policy.json
+ cp /opt/stack/heat/etc/heat/heat.conf.sample /etc/heat/heat.conf
+ iniset_rpc_backend heat /etc/heat/heat.conf DEFAULT
+ local package=heat
+ local file=/etc/heat/heat.conf
+ local section=DEFAULT
+ is_service_enabled zeromq
++ set +o
++ grep xtrace
+ local 'xtrace=set -o xtrace'
+ set +o xtrace
+ return 1
+ is_service_enabled qpid
++ set +o
++ grep xtrace
+ local 'xtrace=set -o xtrace'
+ set +o xtrace
+ return 1
+ '[' -n '' ']'
+ is_service_enabled rabbit
++ set +o
++ grep xtrace
+ local 'xtrace=set -o xtrace'
+ set +o xtrace
+ return 0
+ iniset /etc/heat/heat.conf DEFAULT rpc_backend heat.openstack.common.rpc.impl_kombu
++ set +o
++ grep xtrace
+ local 'xtrace=set -o xtrace'
+ set +o xtrace
+ iniset /etc/heat/heat.conf DEFAULT rabbit_hosts 10.14.0.26
++ set +o
++ grep xtrace
+ local 'xtrace=set -o xtrace'
+ set +o xtrace
+ iniset /etc/heat/heat.conf DEFAULT rabbit_password Passw0rd
++ set +o
++ grep xtrace
+ local 'xtrace=set -o xtrace'
+ set +o xtrace
+ iniset /etc/heat/heat.conf DEFAULT heat_metadata_server_url http://10.14.0.26:8000
++ set +o
++ grep xtrace
+ local 'xtrace=set -o xtrace'
+ set +o xtrace
+ iniset /etc/heat/heat.conf DEFAULT heat_waitcondition_server_url http://10.14.0.26:8000/v1/waitcondition
++ set +o
++ grep xtrace
+ local 'xtrace=set -o xtrace'
+ set +o xtrace
+ iniset /etc/heat/heat.conf DEFAULT heat_watch_server_url http://10.14.0.26:8003
++ set +o
++ grep xtrace
+ local 'xtrace=set -o xtrace'
+ set +o xtrace
++ database_connection_url heat
++ local db=heat
++ database_connection_url_mysql heat
++ local db=heat
++ echo 'mysql://root:Passw0rd@127.0.0.1/heat?charset=utf8'
+ iniset /etc/heat/heat.conf database connection 'mysql://root:Passw0rd@127.0.0.1/heat?charset=utf8'
++ set +o
++ grep xtrace
+ local 'xtrace=set -o xtrace'
+ set +o xtrace
++ generate_hex_string 16
++ local size=16
++ hexdump -n 16 -v -e '/1 "%02x"' /dev/urandom
+ iniset /etc/heat/heat.conf DEFAULT auth_encryption_key 20ef32ade925777d0bf9baf541adb259
++ set +o
++ grep xtrace
+ local 'xtrace=set -o xtrace'
+ set +o xtrace
+ iniset /etc/heat/heat.conf DEFAULT region_name_for_services RegionOne
++ set +o
++ grep xtrace
+ local 'xtrace=set -o xtrace'
+ set +o xtrace
+ iniset /etc/heat/heat.conf DEFAULT debug True
++ set +o
++ grep xtrace
+ local 'xtrace=set -o xtrace'
+ set +o xtrace
+ iniset /etc/heat/heat.conf DEFAULT use_syslog False
++ set +o
++ grep xtrace
+ local 'xtrace=set -o xtrace'
+ set +o xtrace
+ '[' False == True ']'
+ configure_auth_token_middleware /etc/heat/heat.conf heat /var/cache/heat
+ local conf_file=/etc/heat/heat.conf
+ local admin_user=heat
+ local signing_dir=/var/cache/heat
+ local section=keystone_authtoken
+ iniset /etc/heat/heat.conf keystone_authtoken auth_host 10.14.0.26
++ set +o
++ grep xtrace
+ local 'xtrace=set -o xtrace'
+ set +o xtrace
+ iniset /etc/heat/heat.conf keystone_authtoken auth_port 35357
++ set +o
++ grep xtrace
+ local 'xtrace=set -o xtrace'
+ set +o xtrace
+ iniset /etc/heat/heat.conf keystone_authtoken auth_protocol http
++ set +o
++ grep xtrace
+ local 'xtrace=set -o xtrace'
+ set +o xtrace
+ iniset /etc/heat/heat.conf keystone_authtoken identity_uri http://10.14.0.26:35357
++ set +o
++ grep xtrace
+ local 'xtrace=set -o xtrace'
+ set +o xtrace
+ iniset /etc/heat/heat.conf keystone_authtoken cafile /opt/stack/data/ca-bundle.pem
++ set +o
++ grep xtrace
+ local 'xtrace=set -o xtrace'
+ set +o xtrace
+ configure_API_version /etc/heat/heat.conf 2.0 keystone_authtoken
+ local conf_file=/etc/heat/heat.conf
+ local api_version=2.0
+ local section=keystone_authtoken
+ iniset /etc/heat/heat.conf keystone_authtoken auth_uri http://10.14.0.26:5000/v2.0
++ set +o
++ grep xtrace
+ local 'xtrace=set -o xtrace'
+ set +o xtrace
+ iniset /etc/heat/heat.conf keystone_authtoken admin_tenant_name service
++ set +o
++ grep xtrace
+ local 'xtrace=set -o xtrace'
+ set +o xtrace
+ iniset /etc/heat/heat.conf keystone_authtoken admin_user heat
++ set +o
++ grep xtrace
+ local 'xtrace=set -o xtrace'
+ set +o xtrace
+ iniset /etc/heat/heat.conf keystone_authtoken admin_password Passw0rd
++ set +o
++ grep xtrace
+ local 'xtrace=set -o xtrace'
+ set +o xtrace
+ iniset /etc/heat/heat.conf keystone_authtoken signing_dir /var/cache/heat
++ set +o
++ grep xtrace
+ local 'xtrace=set -o xtrace'
+ set +o xtrace
+ [[ -n '' ]]
+ is_ssl_enabled_service key
+ local services=key
+ local service=
+ '[' False == False ']'
+ return 1
+ iniset /etc/heat/heat.conf ec2authtoken auth_uri http://10.14.0.26:5000/v2.0
++ set +o
++ grep xtrace
+ local 'xtrace=set -o xtrace'
+ set +o xtrace
+ [[ False = \T\r\u\e ]]
+ iniset /etc/heat/heat.conf heat_api bind_port 8004
++ set +o
++ grep xtrace
+ local 'xtrace=set -o xtrace'
+ set +o xtrace
+ iniset /etc/heat/heat.conf heat_api_cfn bind_port 8000
++ set +o
++ grep xtrace
+ local 'xtrace=set -o xtrace'
+ set +o xtrace
+ iniset /etc/heat/heat.conf heat_api_cloudwatch bind_port 8003
++ set +o
++ grep xtrace
+ local 'xtrace=set -o xtrace'
+ set +o xtrace
+ is_ssl_enabled_service key
+ local services=key
+ local service=
+ '[' False == False ']'
+ return 1
+ is_service_enabled tls-proxy
++ set +o
++ grep xtrace
+ local 'xtrace=set -o xtrace'
+ set +o xtrace
+ return 1
+ is_ssl_enabled_service nova
+ local services=nova
+ local service=
+ '[' False == False ']'
+ return 1
+ is_service_enabled tls-proxy
++ set +o
++ grep xtrace
+ local 'xtrace=set -o xtrace'
+ set +o xtrace
+ return 1
+ is_ssl_enabled_service cinder
+ local services=cinder
+ local service=
+ '[' False == False ']'
+ return 1
+ is_service_enabled tls-proxy
++ set +o
++ grep xtrace
+ local 'xtrace=set -o xtrace'
+ set +o xtrace
+ return 1
+ sudo mkdir -p /etc/heat/environment.d
+ sudo chown cloudbase /etc/heat/environment.d
+ cp /opt/stack/heat/etc/heat/environment.d/default.yaml /etc/heat/environment.d/
+ sudo mkdir -p /etc/heat/templates
+ sudo chown cloudbase /etc/heat/templates
+ cp /opt/stack/heat/etc/heat/templates/AWS_CloudWatch_Alarm.yaml /opt/stack/heat/etc/heat/templates/AWS_RDS_DBInstance.yaml /etc/heat/templates/
+ is_service_enabled tls-proxy
++ set +o
++ grep xtrace
+ local 'xtrace=set -o xtrace'
+ set +o xtrace
+ return 1
+ '[' False == True ']'
+ [[ -d /home/cloudbase/devstack/extras.d ]]
+ for i in '$TOP_DIR/extras.d/*.sh'
+ [[ -r /home/cloudbase/devstack/extras.d/40-dib.sh ]]
+ source /home/cloudbase/devstack/extras.d/40-dib.sh stack install
++ is_service_enabled dib
+++ set +o
+++ grep xtrace
++ local 'xtrace=set -o xtrace'
++ set +o xtrace
++ return 1
+ for i in '$TOP_DIR/extras.d/*.sh'
+ [[ -r /home/cloudbase/devstack/extras.d/50-ironic.sh ]]
+ source /home/cloudbase/devstack/extras.d/50-ironic.sh stack install
++ is_service_enabled ir-api ir-cond
+++ set +o
+++ grep xtrace
++ local 'xtrace=set -o xtrace'
++ set +o xtrace
++ return 1
+ for i in '$TOP_DIR/extras.d/*.sh'
+ [[ -r /home/cloudbase/devstack/extras.d/60-ceph.sh ]]
+ source /home/cloudbase/devstack/extras.d/60-ceph.sh stack install
++ is_service_enabled ceph
+++ set +o
+++ grep xtrace
++ local 'xtrace=set -o xtrace'
++ set +o xtrace
++ return 1
+ for i in '$TOP_DIR/extras.d/*.sh'
+ [[ -r /home/cloudbase/devstack/extras.d/70-gantt.sh ]]
+ source /home/cloudbase/devstack/extras.d/70-gantt.sh stack install
++ is_service_enabled n-sch
+++ set +o
+++ grep xtrace
++ local 'xtrace=set -o xtrace'
++ set +o xtrace
++ return 0
++ disable_service gantt
++ local tmpsvcs=,g-api,g-reg,key,n-api,n-crt,n-obj,n-cond,n-sch,n-xvnc,n-cauth,c-sch,c-api,c-vol,h-eng,h-api,h-api-cfn,h-api-cw,rabbit,tempest,mysql,neutron,q-svc,q-agt,q-dhcp,q-l3,q-meta,q-lbaas,q-fwaas,q-metering,q-vpn,c-bak,s-proxy,s-object,s-container,s-account,heat,ceilometer-acentral,ceilometer-collector,ceilometer-api,
++ local service
++ for service in '$@'
++ is_service_enabled gantt
+++ set +o
+++ grep xtrace
++ local 'xtrace=set -o xtrace'
++ set +o xtrace
++ return 1
+++ _cleanup_service_list ,g-api,g-reg,key,n-api,n-crt,n-obj,n-cond,n-sch,n-xvnc,n-cauth,c-sch,c-api,c-vol,h-eng,h-api,h-api-cfn,h-api-cw,rabbit,tempest,mysql,neutron,q-svc,q-agt,q-dhcp,q-l3,q-meta,q-lbaas,q-fwaas,q-metering,q-vpn,c-bak,s-proxy,s-object,s-container,s-account,heat,ceilometer-acentral,ceilometer-collector,ceilometer-api,
+++ echo ,g-api,g-reg,key,n-api,n-crt,n-obj,n-cond,n-sch,n-xvnc,n-cauth,c-sch,c-api,c-vol,h-eng,h-api,h-api-cfn,h-api-cw,rabbit,tempest,mysql,neutron,q-svc,q-agt,q-dhcp,q-l3,q-meta,q-lbaas,q-fwaas,q-metering,q-vpn,c-bak,s-proxy,s-object,s-container,s-account,heat,ceilometer-acentral,ceilometer-collector,ceilometer-api,
+++ sed -e '
        s/,,/,/g;
        s/^,//;
        s/,$//
    '
++ ENABLED_SERVICES=g-api,g-reg,key,n-api,n-crt,n-obj,n-cond,n-sch,n-xvnc,n-cauth,c-sch,c-api,c-vol,h-eng,h-api,h-api-cfn,h-api-cw,rabbit,tempest,mysql,neutron,q-svc,q-agt,q-dhcp,q-l3,q-meta,q-lbaas,q-fwaas,q-metering,q-vpn,c-bak,s-proxy,s-object,s-container,s-account,heat,ceilometer-acentral,ceilometer-collector,ceilometer-api
++ is_service_enabled gantt
+++ set +o
+++ grep xtrace
++ local 'xtrace=set -o xtrace'
++ set +o xtrace
++ return 1
+ for i in '$TOP_DIR/extras.d/*.sh'
+ [[ -r /home/cloudbase/devstack/extras.d/70-sahara.sh ]]
+ source /home/cloudbase/devstack/extras.d/70-sahara.sh stack install
++ is_service_enabled sahara
+++ set +o
+++ grep xtrace
++ local 'xtrace=set -o xtrace'
++ set +o xtrace
++ return 1
+ for i in '$TOP_DIR/extras.d/*.sh'
+ [[ -r /home/cloudbase/devstack/extras.d/70-trove.sh ]]
+ source /home/cloudbase/devstack/extras.d/70-trove.sh stack install
++ is_service_enabled trove
+++ set +o
+++ grep xtrace
++ local 'xtrace=set -o xtrace'
++ set +o xtrace
++ return 1
+ for i in '$TOP_DIR/extras.d/*.sh'
+ [[ -r /home/cloudbase/devstack/extras.d/70-zaqar.sh ]]
+ source /home/cloudbase/devstack/extras.d/70-zaqar.sh stack install
++ is_service_enabled zaqar-server
+++ set +o
+++ grep xtrace
++ local 'xtrace=set -o xtrace'
++ set +o xtrace
++ return 1
+ for i in '$TOP_DIR/extras.d/*.sh'
+ [[ -r /home/cloudbase/devstack/extras.d/80-opendaylight.sh ]]
+ source /home/cloudbase/devstack/extras.d/80-opendaylight.sh stack install
++ is_service_enabled odl-server odl-compute
+++ set +o
+++ grep xtrace
++ local 'xtrace=set -o xtrace'
++ set +o xtrace
++ return 1
++ is_service_enabled odl-server
+++ set +o
+++ grep xtrace
++ local 'xtrace=set -o xtrace'
++ set +o xtrace
++ return 1
++ is_service_enabled odl-compute
+++ set +o
+++ grep xtrace
++ local 'xtrace=set -o xtrace'
++ set +o xtrace
++ return 1
+ for i in '$TOP_DIR/extras.d/*.sh'
+ [[ -r /home/cloudbase/devstack/extras.d/80-tempest.sh ]]
+ source /home/cloudbase/devstack/extras.d/80-tempest.sh stack install
++ is_service_enabled tempest
+++ set +o
+++ grep xtrace
++ local 'xtrace=set -o xtrace'
++ set +o xtrace
++ return 0
++ [[ stack == \s\o\u\r\c\e ]]
++ [[ stack == \s\t\a\c\k ]]
++ [[ install == \i\n\s\t\a\l\l ]]
++ echo_summary 'Installing Tempest'
++ [[ -t 3 ]]
++ echo -e Installing Tempest
++ install_tempest
++ install_tempest_lib
++ use_library_from_git tempest-lib
++ local name=tempest-lib
++ local enabled=1
++ [[ ,, =~ ,tempest-lib, ]]
++ return 1
++ git_clone git://git.openstack.org/openstack/tempest.git /opt/stack/tempest master
++ local git_remote=git://git.openstack.org/openstack/tempest.git
++ local git_dest=/opt/stack/tempest
++ local git_ref=master
+++ pwd
++ local orig_dir=/home/cloudbase/devstack
+++ trueorfalse False False
++++ set +o
++++ grep xtrace
+++ local 'xtrace=set -o xtrace'
+++ set +o xtrace
++ RECLONE=False
++ [[ False = \T\r\u\e ]]
++ echo master
++ egrep -q '^refs'
++ [[ ! -d /opt/stack/tempest ]]
++ [[ False = \T\r\u\e ]]
++ cd /opt/stack/tempest
++ git show --oneline
++ head -1
++ cd /home/cloudbase/devstack
++ pip_install tox
+++ set +o
+++ grep xtrace
++ local 'xtrace=set -o xtrace'
++ set +o xtrace
++ sudo PIP_DOWNLOAD_CACHE=/var/cache/pip http_proxy= https_proxy= no_proxy= /usr/local/bin/pip install tox
++ [[ False == \T\r\u\e ]]
++ [[ stack == \u\n\s\t\a\c\k ]]
++ [[ stack == \c\l\e\a\n ]]
+ [[ False = True ]]
+ [[ False != \F\a\l\s\e ]]
+ restart_rpc_backend
+ is_service_enabled rabbit
++ set +o
++ grep xtrace
+ local 'xtrace=set -o xtrace'
+ set +o xtrace
+ return 0
+ echo_summary 'Starting RabbitMQ'
+ [[ -t 3 ]]
+ echo -e Starting RabbitMQ
+ local i
++ seq 10
+ for i in '`seq 10`'
+ is_fedora
+ [[ -z Ubuntu ]]
+ '[' Ubuntu = Fedora ']'
+ '[' Ubuntu = 'Red Hat' ']'
+ '[' Ubuntu = CentOS ']'
+ '[' Ubuntu = OracleServer ']'
+ is_suse
+ [[ -z Ubuntu ]]
+ '[' Ubuntu = openSUSE ']'
+ '[' Ubuntu = 'SUSE LINUX' ']'
+ sudo rabbitmqctl change_password guest Passw0rd
ls: cannot access /etc/rabbitmq/rabbitmq.conf.d: No such file or directory
+ break
+ is_service_enabled n-cell
++ set +o
++ grep xtrace
+ local 'xtrace=set -o xtrace'
+ set +o xtrace
+ return 1
+ '[' -f /opt/stack/data/ca-bundle.pem ']'
+ is_service_enabled mysql postgresql
++ set +o
++ grep xtrace
+ local 'xtrace=set -o xtrace'
+ set +o xtrace
+ return 0
+ configure_database
+ configure_database_mysql
+ local my_conf mysql slow_log
+ echo_summary 'Configuring and starting MySQL'
+ [[ -t 3 ]]
+ echo -e Configuring and starting MySQL
+ is_ubuntu
+ [[ -z deb ]]
+ '[' deb = deb ']'
+ my_conf=/etc/mysql/my.cnf
+ mysql=mysql
+ is_fedora
+ [[ -z Ubuntu ]]
+ '[' Ubuntu = Fedora ']'
+ '[' Ubuntu = 'Red Hat' ']'
+ '[' Ubuntu = CentOS ']'
+ '[' Ubuntu = OracleServer ']'
+ is_suse
+ [[ -z Ubuntu ]]
+ '[' Ubuntu = openSUSE ']'
+ '[' Ubuntu = 'SUSE LINUX' ']'
+ is_ubuntu
+ [[ -z deb ]]
+ '[' deb = deb ']'
+ sudo mysql -uroot -pPassw0rd -h127.0.0.1 -e 'GRANT ALL PRIVILEGES ON *.* TO '\''root'\''@'\''%'\'' identified by '\''Passw0rd'\'';'
+ sudo bash -c 'source /home/cloudbase/devstack/functions &&         iniset /etc/mysql/my.cnf mysqld bind-address 0.0.0.0 &&         iniset /etc/mysql/my.cnf mysqld sql_mode STRICT_ALL_TABLES &&         iniset /etc/mysql/my.cnf mysqld default-storage-engine InnoDB'
+ [[ True == \T\r\u\e ]]
+ echo_summary 'Enabling MySQL query logging'
+ [[ -t 3 ]]
+ echo -e Enabling MySQL query logging
+ is_fedora
+ [[ -z Ubuntu ]]
+ '[' Ubuntu = Fedora ']'
+ '[' Ubuntu = 'Red Hat' ']'
+ '[' Ubuntu = CentOS ']'
+ '[' Ubuntu = OracleServer ']'
+ slow_log=/var/log/mysql/mysql-slow.log
+ sudo sed -e /log.slow.queries/d -e /long.query.time/d -e /log.queries.not.using.indexes/d -i /etc/mysql/my.cnf
+ sudo bash -c 'source /home/cloudbase/devstack/functions &&             iniset /etc/mysql/my.cnf mysqld slow-query-log 1 &&             iniset /etc/mysql/my.cnf mysqld slow-query-log-file /var/log/mysql/mysql-slow.log &&             iniset /etc/mysql/my.cnf mysqld long-query-time 0 &&             iniset /etc/mysql/my.cnf mysqld log-queries-not-using-indexes 1'
+ restart_service mysql
+ is_ubuntu
+ [[ -z deb ]]
+ '[' deb = deb ']'
+ sudo /usr/sbin/service mysql restart
++ trueorfalse True True
+++ set +o
+++ grep xtrace
++ local 'xtrace=set -o xtrace'
++ set +o xtrace
+ USE_SCREEN=True
+ [[ True == \T\r\u\e ]]
+ screen -d -m -S stack -t shell -s /bin/bash
+ sleep 1
+ '[' -z '' ']'
+ SCREEN_HARDSTATUS='%{= .} %-Lw%{= .}%> %n%f %t*%{= .}%+Lw%< %-=%{g}(%{d}%H/%l%{g})'
+ screen -r stack -X hardstatus alwayslastline '%{= .} %-Lw%{= .}%> %n%f %t*%{= .}%+Lw%< %-=%{g}(%{d}%H/%l%{g})'
+ screen -r stack -X setenv PROMPT_COMMAND /bin/true
+ SCREENRC=/home/cloudbase/devstack/stack-screenrc
+ [[ -e /home/cloudbase/devstack/stack-screenrc ]]
+ rm -f /home/cloudbase/devstack/stack-screenrc
+ init_service_check
+ SCREEN_NAME=stack
+ SERVICE_DIR=/opt/stack/status
+ [[ ! -d /opt/stack/status/stack ]]
+ rm -f /opt/stack/status/stack/ceilometer-api.failure /opt/stack/status/stack/h-api-cfn.failure /opt/stack/status/stack/h-api-cw.failure /opt/stack/status/stack/h-api.failure
+ start_dstat
+ DSTAT_OPTS='-tcmndrylp --top-cpu-adv'
+ [[ -n /home/cloudbase/jenkins/workspace/openstack-hyperv-release-tests/reports/2014_12_12_13_16_55_547646598/HyperV2012_VHD_v1/logs/devstack ]]
+ screen_it dstat 'cd /home/cloudbase/devstack; dstat -tcmndrylp --top-cpu-adv | tee /home/cloudbase/jenkins/workspace/openstack-hyperv-release-tests/reports/2014_12_12_13_16_55_547646598/HyperV2012_VHD_v1/logs/devstack/dstat.txt'
+ is_service_enabled dstat
++ set +o
++ grep xtrace
+ local 'xtrace=set -o xtrace'
+ set +o xtrace
+ return 1
+ is_service_enabled key
++ set +o
++ grep xtrace
+ local 'xtrace=set -o xtrace'
+ set +o xtrace
+ return 0
+ echo_summary 'Starting Keystone'
+ [[ -t 3 ]]
+ echo -e Starting Keystone
+ '[' 10.14.0.26 == 10.14.0.26 ']'
+ init_keystone
+ is_service_enabled ldap
++ set +o
++ grep xtrace
+ local 'xtrace=set -o xtrace'
+ set +o xtrace
+ return 1
+ recreate_database keystone utf8
+ local db=keystone
+ local charset=utf8
+ recreate_database_mysql keystone utf8
+ local db=keystone
+ local charset=utf8
+ mysql -uroot -pPassw0rd -h127.0.0.1 -e 'DROP DATABASE IF EXISTS keystone;'
+ mysql -uroot -pPassw0rd -h127.0.0.1 -e 'CREATE DATABASE keystone CHARACTER SET utf8;'
+ /opt/stack/keystone/bin/keystone-manage db_sync
13385 DEBUG oslo.db.sqlalchemy.session [-] MySQL server mode set to STRICT_TRANS_TABLES,STRICT_ALL_TABLES,NO_ZERO_IN_DATE,NO_ZERO_DATE,ERROR_FOR_DIVISION_BY_ZERO,TRADITIONAL,NO_AUTO_CREATE_USER,NO_ENGINE_SUBSTITUTION _init_events /usr/local/lib/python2.7/dist-packages/oslo/db/sqlalchemy/session.py:474
13385 DEBUG migrate.versioning.repository [-] Loading repository /opt/stack/keystone/keystone/common/sql/migrate_repo... __init__ /usr/local/lib/python2.7/dist-packages/migrate/versioning/repository.py:76
13385 DEBUG migrate.versioning.script.base [-] Loading script /opt/stack/keystone/keystone/common/sql/migrate_repo/versions/034_havana.py... __init__ /usr/local/lib/python2.7/dist-packages/migrate/versioning/script/base.py:27
13385 DEBUG migrate.versioning.script.base [-] Script /opt/stack/keystone/keystone/common/sql/migrate_repo/versions/034_havana.py loaded successfully __init__ /usr/local/lib/python2.7/dist-packages/migrate/versioning/script/base.py:30
13385 DEBUG migrate.versioning.script.base [-] Loading script /opt/stack/keystone/keystone/common/sql/migrate_repo/versions/035_add_compound_revoked_token_index.py... __init__ /usr/local/lib/python2.7/dist-packages/migrate/versioning/script/base.py:27
13385 DEBUG migrate.versioning.script.base [-] Script /opt/stack/keystone/keystone/common/sql/migrate_repo/versions/035_add_compound_revoked_token_index.py loaded successfully __init__ /usr/local/lib/python2.7/dist-packages/migrate/versioning/script/base.py:30
13385 DEBUG migrate.versioning.script.base [-] Loading script /opt/stack/keystone/keystone/common/sql/migrate_repo/versions/036_token_drop_valid_index.py... __init__ /usr/local/lib/python2.7/dist-packages/migrate/versioning/script/base.py:27
13385 DEBUG migrate.versioning.script.base [-] Script /opt/stack/keystone/keystone/common/sql/migrate_repo/versions/036_token_drop_valid_index.py loaded successfully __init__ /usr/local/lib/python2.7/dist-packages/migrate/versioning/script/base.py:30
13385 DEBUG migrate.versioning.script.base [-] Loading script /opt/stack/keystone/keystone/common/sql/migrate_repo/versions/037_add_region_table.py... __init__ /usr/local/lib/python2.7/dist-packages/migrate/versioning/script/base.py:27
13385 DEBUG migrate.versioning.script.base [-] Script /opt/stack/keystone/keystone/common/sql/migrate_repo/versions/037_add_region_table.py loaded successfully __init__ /usr/local/lib/python2.7/dist-packages/migrate/versioning/script/base.py:30
13385 DEBUG migrate.versioning.script.base [-] Loading script /opt/stack/keystone/keystone/common/sql/migrate_repo/versions/038_add_assignment_table.py... __init__ /usr/local/lib/python2.7/dist-packages/migrate/versioning/script/base.py:27
13385 DEBUG migrate.versioning.script.base [-] Script /opt/stack/keystone/keystone/common/sql/migrate_repo/versions/038_add_assignment_table.py loaded successfully __init__ /usr/local/lib/python2.7/dist-packages/migrate/versioning/script/base.py:30
13385 DEBUG migrate.versioning.script.base [-] Loading script /opt/stack/keystone/keystone/common/sql/migrate_repo/versions/039_grant_to_assignment.py... __init__ /usr/local/lib/python2.7/dist-packages/migrate/versioning/script/base.py:27
13385 DEBUG migrate.versioning.script.base [-] Script /opt/stack/keystone/keystone/common/sql/migrate_repo/versions/039_grant_to_assignment.py loaded successfully __init__ /usr/local/lib/python2.7/dist-packages/migrate/versioning/script/base.py:30
13385 DEBUG migrate.versioning.script.base [-] Loading script /opt/stack/keystone/keystone/common/sql/migrate_repo/versions/040_drop_grant_tables.py... __init__ /usr/local/lib/python2.7/dist-packages/migrate/versioning/script/base.py:27
13385 DEBUG migrate.versioning.script.base [-] Script /opt/stack/keystone/keystone/common/sql/migrate_repo/versions/040_drop_grant_tables.py loaded successfully __init__ /usr/local/lib/python2.7/dist-packages/migrate/versioning/script/base.py:30
13385 DEBUG migrate.versioning.script.base [-] Loading script /opt/stack/keystone/keystone/common/sql/migrate_repo/versions/041_add_remaining_uses_count_to_trusts.py... __init__ /usr/local/lib/python2.7/dist-packages/migrate/versioning/script/base.py:27
13385 DEBUG migrate.versioning.script.base [-] Script /opt/stack/keystone/keystone/common/sql/migrate_repo/versions/041_add_remaining_uses_count_to_trusts.py loaded successfully __init__ /usr/local/lib/python2.7/dist-packages/migrate/versioning/script/base.py:30
13385 DEBUG migrate.versioning.script.base [-] Loading script /opt/stack/keystone/keystone/common/sql/migrate_repo/versions/042_endpoint_enabled.py... __init__ /usr/local/lib/python2.7/dist-packages/migrate/versioning/script/base.py:27
13385 DEBUG migrate.versioning.script.base [-] Script /opt/stack/keystone/keystone/common/sql/migrate_repo/versions/042_endpoint_enabled.py loaded successfully __init__ /usr/local/lib/python2.7/dist-packages/migrate/versioning/script/base.py:30
13385 DEBUG migrate.versioning.script.base [-] Loading script /opt/stack/keystone/keystone/common/sql/migrate_repo/versions/043_fixup_region_description.py... __init__ /usr/local/lib/python2.7/dist-packages/migrate/versioning/script/base.py:27
13385 DEBUG migrate.versioning.script.base [-] Script /opt/stack/keystone/keystone/common/sql/migrate_repo/versions/043_fixup_region_description.py loaded successfully __init__ /usr/local/lib/python2.7/dist-packages/migrate/versioning/script/base.py:30
13385 DEBUG migrate.versioning.script.base [-] Loading script /opt/stack/keystone/keystone/common/sql/migrate_repo/versions/044_service_enabled.py... __init__ /usr/local/lib/python2.7/dist-packages/migrate/versioning/script/base.py:27
13385 DEBUG migrate.versioning.script.base [-] Script /opt/stack/keystone/keystone/common/sql/migrate_repo/versions/044_service_enabled.py loaded successfully __init__ /usr/local/lib/python2.7/dist-packages/migrate/versioning/script/base.py:30
13385 DEBUG migrate.versioning.script.base [-] Loading script /opt/stack/keystone/keystone/common/sql/migrate_repo/versions/045_placeholder.py... __init__ /usr/local/lib/python2.7/dist-packages/migrate/versioning/script/base.py:27
13385 DEBUG migrate.versioning.script.base [-] Script /opt/stack/keystone/keystone/common/sql/migrate_repo/versions/045_placeholder.py loaded successfully __init__ /usr/local/lib/python2.7/dist-packages/migrate/versioning/script/base.py:30
13385 DEBUG migrate.versioning.script.base [-] Loading script /opt/stack/keystone/keystone/common/sql/migrate_repo/versions/046_placeholder.py... __init__ /usr/local/lib/python2.7/dist-packages/migrate/versioning/script/base.py:27
13385 DEBUG migrate.versioning.script.base [-] Script /opt/stack/keystone/keystone/common/sql/migrate_repo/versions/046_placeholder.py loaded successfully __init__ /usr/local/lib/python2.7/dist-packages/migrate/versioning/script/base.py:30
13385 DEBUG migrate.versioning.script.base [-] Loading script /opt/stack/keystone/keystone/common/sql/migrate_repo/versions/047_placeholder.py... __init__ /usr/local/lib/python2.7/dist-packages/migrate/versioning/script/base.py:27
13385 DEBUG migrate.versioning.script.base [-] Script /opt/stack/keystone/keystone/common/sql/migrate_repo/versions/047_placeholder.py loaded successfully __init__ /usr/local/lib/python2.7/dist-packages/migrate/versioning/script/base.py:30
13385 DEBUG migrate.versioning.script.base [-] Loading script /opt/stack/keystone/keystone/common/sql/migrate_repo/versions/048_placeholder.py... __init__ /usr/local/lib/python2.7/dist-packages/migrate/versioning/script/base.py:27
13385 DEBUG migrate.versioning.script.base [-] Script /opt/stack/keystone/keystone/common/sql/migrate_repo/versions/048_placeholder.py loaded successfully __init__ /usr/local/lib/python2.7/dist-packages/migrate/versioning/script/base.py:30
13385 DEBUG migrate.versioning.script.base [-] Loading script /opt/stack/keystone/keystone/common/sql/migrate_repo/versions/049_placeholder.py... __init__ /usr/local/lib/python2.7/dist-packages/migrate/versioning/script/base.py:27
13385 DEBUG migrate.versioning.script.base [-] Script /opt/stack/keystone/keystone/common/sql/migrate_repo/versions/049_placeholder.py loaded successfully __init__ /usr/local/lib/python2.7/dist-packages/migrate/versioning/script/base.py:30
13385 DEBUG migrate.versioning.script.base [-] Loading script /opt/stack/keystone/keystone/common/sql/migrate_repo/versions/050_fk_consistent_indexes.py... __init__ /usr/local/lib/python2.7/dist-packages/migrate/versioning/script/base.py:27
13385 DEBUG migrate.versioning.script.base [-] Script /opt/stack/keystone/keystone/common/sql/migrate_repo/versions/050_fk_consistent_indexes.py loaded successfully __init__ /usr/local/lib/python2.7/dist-packages/migrate/versioning/script/base.py:30
13385 DEBUG migrate.versioning.script.base [-] Loading script /opt/stack/keystone/keystone/common/sql/migrate_repo/versions/051_add_id_mapping.py... __init__ /usr/local/lib/python2.7/dist-packages/migrate/versioning/script/base.py:27
13385 DEBUG migrate.versioning.script.base [-] Script /opt/stack/keystone/keystone/common/sql/migrate_repo/versions/051_add_id_mapping.py loaded successfully __init__ /usr/local/lib/python2.7/dist-packages/migrate/versioning/script/base.py:30
13385 DEBUG migrate.versioning.script.base [-] Loading script /opt/stack/keystone/keystone/common/sql/migrate_repo/versions/052_add_auth_url_to_region.py... __init__ /usr/local/lib/python2.7/dist-packages/migrate/versioning/script/base.py:27
13385 DEBUG migrate.versioning.script.base [-] Script /opt/stack/keystone/keystone/common/sql/migrate_repo/versions/052_add_auth_url_to_region.py loaded successfully __init__ /usr/local/lib/python2.7/dist-packages/migrate/versioning/script/base.py:30
13385 DEBUG migrate.versioning.script.base [-] Loading script /opt/stack/keystone/keystone/common/sql/migrate_repo/versions/053_endpoint_to_region_association.py... __init__ /usr/local/lib/python2.7/dist-packages/migrate/versioning/script/base.py:27
13385 DEBUG migrate.versioning.script.base [-] Script /opt/stack/keystone/keystone/common/sql/migrate_repo/versions/053_endpoint_to_region_association.py loaded successfully __init__ /usr/local/lib/python2.7/dist-packages/migrate/versioning/script/base.py:30
13385 DEBUG migrate.versioning.script.base [-] Loading script /opt/stack/keystone/keystone/common/sql/migrate_repo/versions/054_add_actor_id_index.py... __init__ /usr/local/lib/python2.7/dist-packages/migrate/versioning/script/base.py:27
13385 DEBUG migrate.versioning.script.base [-] Script /opt/stack/keystone/keystone/common/sql/migrate_repo/versions/054_add_actor_id_index.py loaded successfully __init__ /usr/local/lib/python2.7/dist-packages/migrate/versioning/script/base.py:30
13385 DEBUG migrate.versioning.script.base [-] Loading script /opt/stack/keystone/keystone/common/sql/migrate_repo/versions/055_add_indexes_to_token_table.py... __init__ /usr/local/lib/python2.7/dist-packages/migrate/versioning/script/base.py:27
13385 DEBUG migrate.versioning.script.base [-] Script /opt/stack/keystone/keystone/common/sql/migrate_repo/versions/055_add_indexes_to_token_table.py loaded successfully __init__ /usr/local/lib/python2.7/dist-packages/migrate/versioning/script/base.py:30
13385 DEBUG migrate.versioning.repository [-] Repository /opt/stack/keystone/keystone/common/sql/migrate_repo loaded successfully __init__ /usr/local/lib/python2.7/dist-packages/migrate/versioning/repository.py:82
13385 DEBUG migrate.versioning.repository [-] Config: OrderedDict([('db_settings', OrderedDict([('__name__', 'db_settings'), ('repository_id', 'keystone'), ('version_table', 'migrate_version'), ('required_dbs', '[]'), ('use_timestamp_numbering', 'False')]))]) __init__ /usr/local/lib/python2.7/dist-packages/migrate/versioning/repository.py:83
13385 DEBUG migrate.versioning.repository [-] Loading repository /opt/stack/keystone/keystone/common/sql/migrate_repo... __init__ /usr/local/lib/python2.7/dist-packages/migrate/versioning/repository.py:76
13385 DEBUG migrate.versioning.script.base [-] Loading script /opt/stack/keystone/keystone/common/sql/migrate_repo/versions/034_havana.py... __init__ /usr/local/lib/python2.7/dist-packages/migrate/versioning/script/base.py:27
13385 DEBUG migrate.versioning.script.base [-] Script /opt/stack/keystone/keystone/common/sql/migrate_repo/versions/034_havana.py loaded successfully __init__ /usr/local/lib/python2.7/dist-packages/migrate/versioning/script/base.py:30
13385 DEBUG migrate.versioning.script.base [-] Loading script /opt/stack/keystone/keystone/common/sql/migrate_repo/versions/035_add_compound_revoked_token_index.py... __init__ /usr/local/lib/python2.7/dist-packages/migrate/versioning/script/base.py:27
13385 DEBUG migrate.versioning.script.base [-] Script /opt/stack/keystone/keystone/common/sql/migrate_repo/versions/035_add_compound_revoked_token_index.py loaded successfully __init__ /usr/local/lib/python2.7/dist-packages/migrate/versioning/script/base.py:30
13385 DEBUG migrate.versioning.script.base [-] Loading script /opt/stack/keystone/keystone/common/sql/migrate_repo/versions/036_token_drop_valid_index.py... __init__ /usr/local/lib/python2.7/dist-packages/migrate/versioning/script/base.py:27
13385 DEBUG migrate.versioning.script.base [-] Script /opt/stack/keystone/keystone/common/sql/migrate_repo/versions/036_token_drop_valid_index.py loaded successfully __init__ /usr/local/lib/python2.7/dist-packages/migrate/versioning/script/base.py:30
13385 DEBUG migrate.versioning.script.base [-] Loading script /opt/stack/keystone/keystone/common/sql/migrate_repo/versions/037_add_region_table.py... __init__ /usr/local/lib/python2.7/dist-packages/migrate/versioning/script/base.py:27
13385 DEBUG migrate.versioning.script.base [-] Script /opt/stack/keystone/keystone/common/sql/migrate_repo/versions/037_add_region_table.py loaded successfully __init__ /usr/local/lib/python2.7/dist-packages/migrate/versioning/script/base.py:30
13385 DEBUG migrate.versioning.script.base [-] Loading script /opt/stack/keystone/keystone/common/sql/migrate_repo/versions/038_add_assignment_table.py... __init__ /usr/local/lib/python2.7/dist-packages/migrate/versioning/script/base.py:27
13385 DEBUG migrate.versioning.script.base [-] Script /opt/stack/keystone/keystone/common/sql/migrate_repo/versions/038_add_assignment_table.py loaded successfully __init__ /usr/local/lib/python2.7/dist-packages/migrate/versioning/script/base.py:30
13385 DEBUG migrate.versioning.script.base [-] Loading script /opt/stack/keystone/keystone/common/sql/migrate_repo/versions/039_grant_to_assignment.py... __init__ /usr/local/lib/python2.7/dist-packages/migrate/versioning/script/base.py:27
13385 DEBUG migrate.versioning.script.base [-] Script /opt/stack/keystone/keystone/common/sql/migrate_repo/versions/039_grant_to_assignment.py loaded successfully __init__ /usr/local/lib/python2.7/dist-packages/migrate/versioning/script/base.py:30
13385 DEBUG migrate.versioning.script.base [-] Loading script /opt/stack/keystone/keystone/common/sql/migrate_repo/versions/040_drop_grant_tables.py... __init__ /usr/local/lib/python2.7/dist-packages/migrate/versioning/script/base.py:27
13385 DEBUG migrate.versioning.script.base [-] Script /opt/stack/keystone/keystone/common/sql/migrate_repo/versions/040_drop_grant_tables.py loaded successfully __init__ /usr/local/lib/python2.7/dist-packages/migrate/versioning/script/base.py:30
13385 DEBUG migrate.versioning.script.base [-] Loading script /opt/stack/keystone/keystone/common/sql/migrate_repo/versions/041_add_remaining_uses_count_to_trusts.py... __init__ /usr/local/lib/python2.7/dist-packages/migrate/versioning/script/base.py:27
13385 DEBUG migrate.versioning.script.base [-] Script /opt/stack/keystone/keystone/common/sql/migrate_repo/versions/041_add_remaining_uses_count_to_trusts.py loaded successfully __init__ /usr/local/lib/python2.7/dist-packages/migrate/versioning/script/base.py:30
13385 DEBUG migrate.versioning.script.base [-] Loading script /opt/stack/keystone/keystone/common/sql/migrate_repo/versions/042_endpoint_enabled.py... __init__ /usr/local/lib/python2.7/dist-packages/migrate/versioning/script/base.py:27
13385 DEBUG migrate.versioning.script.base [-] Script /opt/stack/keystone/keystone/common/sql/migrate_repo/versions/042_endpoint_enabled.py loaded successfully __init__ /usr/local/lib/python2.7/dist-packages/migrate/versioning/script/base.py:30
13385 DEBUG migrate.versioning.script.base [-] Loading script /opt/stack/keystone/keystone/common/sql/migrate_repo/versions/043_fixup_region_description.py... __init__ /usr/local/lib/python2.7/dist-packages/migrate/versioning/script/base.py:27
13385 DEBUG migrate.versioning.script.base [-] Script /opt/stack/keystone/keystone/common/sql/migrate_repo/versions/043_fixup_region_description.py loaded successfully __init__ /usr/local/lib/python2.7/dist-packages/migrate/versioning/script/base.py:30
13385 DEBUG migrate.versioning.script.base [-] Loading script /opt/stack/keystone/keystone/common/sql/migrate_repo/versions/044_service_enabled.py... __init__ /usr/local/lib/python2.7/dist-packages/migrate/versioning/script/base.py:27
13385 DEBUG migrate.versioning.script.base [-] Script /opt/stack/keystone/keystone/common/sql/migrate_repo/versions/044_service_enabled.py loaded successfully __init__ /usr/local/lib/python2.7/dist-packages/migrate/versioning/script/base.py:30
13385 DEBUG migrate.versioning.script.base [-] Loading script /opt/stack/keystone/keystone/common/sql/migrate_repo/versions/045_placeholder.py... __init__ /usr/local/lib/python2.7/dist-packages/migrate/versioning/script/base.py:27
13385 DEBUG migrate.versioning.script.base [-] Script /opt/stack/keystone/keystone/common/sql/migrate_repo/versions/045_placeholder.py loaded successfully __init__ /usr/local/lib/python2.7/dist-packages/migrate/versioning/script/base.py:30
13385 DEBUG migrate.versioning.script.base [-] Loading script /opt/stack/keystone/keystone/common/sql/migrate_repo/versions/046_placeholder.py... __init__ /usr/local/lib/python2.7/dist-packages/migrate/versioning/script/base.py:27
13385 DEBUG migrate.versioning.script.base [-] Script /opt/stack/keystone/keystone/common/sql/migrate_repo/versions/046_placeholder.py loaded successfully __init__ /usr/local/lib/python2.7/dist-packages/migrate/versioning/script/base.py:30
13385 DEBUG migrate.versioning.script.base [-] Loading script /opt/stack/keystone/keystone/common/sql/migrate_repo/versions/047_placeholder.py... __init__ /usr/local/lib/python2.7/dist-packages/migrate/versioning/script/base.py:27
13385 DEBUG migrate.versioning.script.base [-] Script /opt/stack/keystone/keystone/common/sql/migrate_repo/versions/047_placeholder.py loaded successfully __init__ /usr/local/lib/python2.7/dist-packages/migrate/versioning/script/base.py:30
13385 DEBUG migrate.versioning.script.base [-] Loading script /opt/stack/keystone/keystone/common/sql/migrate_repo/versions/048_placeholder.py... __init__ /usr/local/lib/python2.7/dist-packages/migrate/versioning/script/base.py:27
13385 DEBUG migrate.versioning.script.base [-] Script /opt/stack/keystone/keystone/common/sql/migrate_repo/versions/048_placeholder.py loaded successfully __init__ /usr/local/lib/python2.7/dist-packages/migrate/versioning/script/base.py:30
13385 DEBUG migrate.versioning.script.base [-] Loading script /opt/stack/keystone/keystone/common/sql/migrate_repo/versions/049_placeholder.py... __init__ /usr/local/lib/python2.7/dist-packages/migrate/versioning/script/base.py:27
13385 DEBUG migrate.versioning.script.base [-] Script /opt/stack/keystone/keystone/common/sql/migrate_repo/versions/049_placeholder.py loaded successfully __init__ /usr/local/lib/python2.7/dist-packages/migrate/versioning/script/base.py:30
13385 DEBUG migrate.versioning.script.base [-] Loading script /opt/stack/keystone/keystone/common/sql/migrate_repo/versions/050_fk_consistent_indexes.py... __init__ /usr/local/lib/python2.7/dist-packages/migrate/versioning/script/base.py:27
13385 DEBUG migrate.versioning.script.base [-] Script /opt/stack/keystone/keystone/common/sql/migrate_repo/versions/050_fk_consistent_indexes.py loaded successfully __init__ /usr/local/lib/python2.7/dist-packages/migrate/versioning/script/base.py:30
13385 DEBUG migrate.versioning.script.base [-] Loading script /opt/stack/keystone/keystone/common/sql/migrate_repo/versions/051_add_id_mapping.py... __init__ /usr/local/lib/python2.7/dist-packages/migrate/versioning/script/base.py:27
13385 DEBUG migrate.versioning.script.base [-] Script /opt/stack/keystone/keystone/common/sql/migrate_repo/versions/051_add_id_mapping.py loaded successfully __init__ /usr/local/lib/python2.7/dist-packages/migrate/versioning/script/base.py:30
13385 DEBUG migrate.versioning.script.base [-] Loading script /opt/stack/keystone/keystone/common/sql/migrate_repo/versions/052_add_auth_url_to_region.py... __init__ /usr/local/lib/python2.7/dist-packages/migrate/versioning/script/base.py:27
13385 DEBUG migrate.versioning.script.base [-] Script /opt/stack/keystone/keystone/common/sql/migrate_repo/versions/052_add_auth_url_to_region.py loaded successfully __init__ /usr/local/lib/python2.7/dist-packages/migrate/versioning/script/base.py:30
13385 DEBUG migrate.versioning.script.base [-] Loading script /opt/stack/keystone/keystone/common/sql/migrate_repo/versions/053_endpoint_to_region_association.py... __init__ /usr/local/lib/python2.7/dist-packages/migrate/versioning/script/base.py:27
13385 DEBUG migrate.versioning.script.base [-] Script /opt/stack/keystone/keystone/common/sql/migrate_repo/versions/053_endpoint_to_region_association.py loaded successfully __init__ /usr/local/lib/python2.7/dist-packages/migrate/versioning/script/base.py:30
13385 DEBUG migrate.versioning.script.base [-] Loading script /opt/stack/keystone/keystone/common/sql/migrate_repo/versions/054_add_actor_id_index.py... __init__ /usr/local/lib/python2.7/dist-packages/migrate/versioning/script/base.py:27
13385 DEBUG migrate.versioning.script.base [-] Script /opt/stack/keystone/keystone/common/sql/migrate_repo/versions/054_add_actor_id_index.py loaded successfully __init__ /usr/local/lib/python2.7/dist-packages/migrate/versioning/script/base.py:30
13385 DEBUG migrate.versioning.script.base [-] Loading script /opt/stack/keystone/keystone/common/sql/migrate_repo/versions/055_add_indexes_to_token_table.py... __init__ /usr/local/lib/python2.7/dist-packages/migrate/versioning/script/base.py:27
13385 DEBUG migrate.versioning.script.base [-] Script /opt/stack/keystone/keystone/common/sql/migrate_repo/versions/055_add_indexes_to_token_table.py loaded successfully __init__ /usr/local/lib/python2.7/dist-packages/migrate/versioning/script/base.py:30
13385 DEBUG migrate.versioning.repository [-] Repository /opt/stack/keystone/keystone/common/sql/migrate_repo loaded successfully __init__ /usr/local/lib/python2.7/dist-packages/migrate/versioning/repository.py:82
13385 DEBUG migrate.versioning.repository [-] Config: OrderedDict([('db_settings', OrderedDict([('__name__', 'db_settings'), ('repository_id', 'keystone'), ('version_table', 'migrate_version'), ('required_dbs', '[]'), ('use_timestamp_numbering', 'False')]))]) __init__ /usr/local/lib/python2.7/dist-packages/migrate/versioning/repository.py:83
13385 DEBUG migrate.versioning.repository [-] Loading repository /opt/stack/keystone/keystone/common/sql/migrate_repo... __init__ /usr/local/lib/python2.7/dist-packages/migrate/versioning/repository.py:76
13385 DEBUG migrate.versioning.script.base [-] Loading script /opt/stack/keystone/keystone/common/sql/migrate_repo/versions/034_havana.py... __init__ /usr/local/lib/python2.7/dist-packages/migrate/versioning/script/base.py:27
13385 DEBUG migrate.versioning.script.base [-] Script /opt/stack/keystone/keystone/common/sql/migrate_repo/versions/034_havana.py loaded successfully __init__ /usr/local/lib/python2.7/dist-packages/migrate/versioning/script/base.py:30
13385 DEBUG migrate.versioning.script.base [-] Loading script /opt/stack/keystone/keystone/common/sql/migrate_repo/versions/035_add_compound_revoked_token_index.py... __init__ /usr/local/lib/python2.7/dist-packages/migrate/versioning/script/base.py:27
13385 DEBUG migrate.versioning.script.base [-] Script /opt/stack/keystone/keystone/common/sql/migrate_repo/versions/035_add_compound_revoked_token_index.py loaded successfully __init__ /usr/local/lib/python2.7/dist-packages/migrate/versioning/script/base.py:30
13385 DEBUG migrate.versioning.script.base [-] Loading script /opt/stack/keystone/keystone/common/sql/migrate_repo/versions/036_token_drop_valid_index.py... __init__ /usr/local/lib/python2.7/dist-packages/migrate/versioning/script/base.py:27
13385 DEBUG migrate.versioning.script.base [-] Script /opt/stack/keystone/keystone/common/sql/migrate_repo/versions/036_token_drop_valid_index.py loaded successfully __init__ /usr/local/lib/python2.7/dist-packages/migrate/versioning/script/base.py:30
13385 DEBUG migrate.versioning.script.base [-] Loading script /opt/stack/keystone/keystone/common/sql/migrate_repo/versions/037_add_region_table.py... __init__ /usr/local/lib/python2.7/dist-packages/migrate/versioning/script/base.py:27
13385 DEBUG migrate.versioning.script.base [-] Script /opt/stack/keystone/keystone/common/sql/migrate_repo/versions/037_add_region_table.py loaded successfully __init__ /usr/local/lib/python2.7/dist-packages/migrate/versioning/script/base.py:30
13385 DEBUG migrate.versioning.script.base [-] Loading script /opt/stack/keystone/keystone/common/sql/migrate_repo/versions/038_add_assignment_table.py... __init__ /usr/local/lib/python2.7/dist-packages/migrate/versioning/script/base.py:27
13385 DEBUG migrate.versioning.script.base [-] Script /opt/stack/keystone/keystone/common/sql/migrate_repo/versions/038_add_assignment_table.py loaded successfully __init__ /usr/local/lib/python2.7/dist-packages/migrate/versioning/script/base.py:30
13385 DEBUG migrate.versioning.script.base [-] Loading script /opt/stack/keystone/keystone/common/sql/migrate_repo/versions/039_grant_to_assignment.py... __init__ /usr/local/lib/python2.7/dist-packages/migrate/versioning/script/base.py:27
13385 DEBUG migrate.versioning.script.base [-] Script /opt/stack/keystone/keystone/common/sql/migrate_repo/versions/039_grant_to_assignment.py loaded successfully __init__ /usr/local/lib/python2.7/dist-packages/migrate/versioning/script/base.py:30
13385 DEBUG migrate.versioning.script.base [-] Loading script /opt/stack/keystone/keystone/common/sql/migrate_repo/versions/040_drop_grant_tables.py... __init__ /usr/local/lib/python2.7/dist-packages/migrate/versioning/script/base.py:27
13385 DEBUG migrate.versioning.script.base [-] Script /opt/stack/keystone/keystone/common/sql/migrate_repo/versions/040_drop_grant_tables.py loaded successfully __init__ /usr/local/lib/python2.7/dist-packages/migrate/versioning/script/base.py:30
13385 DEBUG migrate.versioning.script.base [-] Loading script /opt/stack/keystone/keystone/common/sql/migrate_repo/versions/041_add_remaining_uses_count_to_trusts.py... __init__ /usr/local/lib/python2.7/dist-packages/migrate/versioning/script/base.py:27
13385 DEBUG migrate.versioning.script.base [-] Script /opt/stack/keystone/keystone/common/sql/migrate_repo/versions/041_add_remaining_uses_count_to_trusts.py loaded successfully __init__ /usr/local/lib/python2.7/dist-packages/migrate/versioning/script/base.py:30
13385 DEBUG migrate.versioning.script.base [-] Loading script /opt/stack/keystone/keystone/common/sql/migrate_repo/versions/042_endpoint_enabled.py... __init__ /usr/local/lib/python2.7/dist-packages/migrate/versioning/script/base.py:27
13385 DEBUG migrate.versioning.script.base [-] Script /opt/stack/keystone/keystone/common/sql/migrate_repo/versions/042_endpoint_enabled.py loaded successfully __init__ /usr/local/lib/python2.7/dist-packages/migrate/versioning/script/base.py:30
13385 DEBUG migrate.versioning.script.base [-] Loading script /opt/stack/keystone/keystone/common/sql/migrate_repo/versions/043_fixup_region_description.py... __init__ /usr/local/lib/python2.7/dist-packages/migrate/versioning/script/base.py:27
13385 DEBUG migrate.versioning.script.base [-] Script /opt/stack/keystone/keystone/common/sql/migrate_repo/versions/043_fixup_region_description.py loaded successfully __init__ /usr/local/lib/python2.7/dist-packages/migrate/versioning/script/base.py:30
13385 DEBUG migrate.versioning.script.base [-] Loading script /opt/stack/keystone/keystone/common/sql/migrate_repo/versions/044_service_enabled.py... __init__ /usr/local/lib/python2.7/dist-packages/migrate/versioning/script/base.py:27
13385 DEBUG migrate.versioning.script.base [-] Script /opt/stack/keystone/keystone/common/sql/migrate_repo/versions/044_service_enabled.py loaded successfully __init__ /usr/local/lib/python2.7/dist-packages/migrate/versioning/script/base.py:30
13385 DEBUG migrate.versioning.script.base [-] Loading script /opt/stack/keystone/keystone/common/sql/migrate_repo/versions/045_placeholder.py... __init__ /usr/local/lib/python2.7/dist-packages/migrate/versioning/script/base.py:27
13385 DEBUG migrate.versioning.script.base [-] Script /opt/stack/keystone/keystone/common/sql/migrate_repo/versions/045_placeholder.py loaded successfully __init__ /usr/local/lib/python2.7/dist-packages/migrate/versioning/script/base.py:30
13385 DEBUG migrate.versioning.script.base [-] Loading script /opt/stack/keystone/keystone/common/sql/migrate_repo/versions/046_placeholder.py... __init__ /usr/local/lib/python2.7/dist-packages/migrate/versioning/script/base.py:27
13385 DEBUG migrate.versioning.script.base [-] Script /opt/stack/keystone/keystone/common/sql/migrate_repo/versions/046_placeholder.py loaded successfully __init__ /usr/local/lib/python2.7/dist-packages/migrate/versioning/script/base.py:30
13385 DEBUG migrate.versioning.script.base [-] Loading script /opt/stack/keystone/keystone/common/sql/migrate_repo/versions/047_placeholder.py... __init__ /usr/local/lib/python2.7/dist-packages/migrate/versioning/script/base.py:27
13385 DEBUG migrate.versioning.script.base [-] Script /opt/stack/keystone/keystone/common/sql/migrate_repo/versions/047_placeholder.py loaded successfully __init__ /usr/local/lib/python2.7/dist-packages/migrate/versioning/script/base.py:30
13385 DEBUG migrate.versioning.script.base [-] Loading script /opt/stack/keystone/keystone/common/sql/migrate_repo/versions/048_placeholder.py... __init__ /usr/local/lib/python2.7/dist-packages/migrate/versioning/script/base.py:27
13385 DEBUG migrate.versioning.script.base [-] Script /opt/stack/keystone/keystone/common/sql/migrate_repo/versions/048_placeholder.py loaded successfully __init__ /usr/local/lib/python2.7/dist-packages/migrate/versioning/script/base.py:30
13385 DEBUG migrate.versioning.script.base [-] Loading script /opt/stack/keystone/keystone/common/sql/migrate_repo/versions/049_placeholder.py... __init__ /usr/local/lib/python2.7/dist-packages/migrate/versioning/script/base.py:27
13385 DEBUG migrate.versioning.script.base [-] Script /opt/stack/keystone/keystone/common/sql/migrate_repo/versions/049_placeholder.py loaded successfully __init__ /usr/local/lib/python2.7/dist-packages/migrate/versioning/script/base.py:30
13385 DEBUG migrate.versioning.script.base [-] Loading script /opt/stack/keystone/keystone/common/sql/migrate_repo/versions/050_fk_consistent_indexes.py... __init__ /usr/local/lib/python2.7/dist-packages/migrate/versioning/script/base.py:27
13385 DEBUG migrate.versioning.script.base [-] Script /opt/stack/keystone/keystone/common/sql/migrate_repo/versions/050_fk_consistent_indexes.py loaded successfully __init__ /usr/local/lib/python2.7/dist-packages/migrate/versioning/script/base.py:30
13385 DEBUG migrate.versioning.script.base [-] Loading script /opt/stack/keystone/keystone/common/sql/migrate_repo/versions/051_add_id_mapping.py... __init__ /usr/local/lib/python2.7/dist-packages/migrate/versioning/script/base.py:27
13385 DEBUG migrate.versioning.script.base [-] Script /opt/stack/keystone/keystone/common/sql/migrate_repo/versions/051_add_id_mapping.py loaded successfully __init__ /usr/local/lib/python2.7/dist-packages/migrate/versioning/script/base.py:30
13385 DEBUG migrate.versioning.script.base [-] Loading script /opt/stack/keystone/keystone/common/sql/migrate_repo/versions/052_add_auth_url_to_region.py... __init__ /usr/local/lib/python2.7/dist-packages/migrate/versioning/script/base.py:27
13385 DEBUG migrate.versioning.script.base [-] Script /opt/stack/keystone/keystone/common/sql/migrate_repo/versions/052_add_auth_url_to_region.py loaded successfully __init__ /usr/local/lib/python2.7/dist-packages/migrate/versioning/script/base.py:30
13385 DEBUG migrate.versioning.script.base [-] Loading script /opt/stack/keystone/keystone/common/sql/migrate_repo/versions/053_endpoint_to_region_association.py... __init__ /usr/local/lib/python2.7/dist-packages/migrate/versioning/script/base.py:27
13385 DEBUG migrate.versioning.script.base [-] Script /opt/stack/keystone/keystone/common/sql/migrate_repo/versions/053_endpoint_to_region_association.py loaded successfully __init__ /usr/local/lib/python2.7/dist-packages/migrate/versioning/script/base.py:30
13385 DEBUG migrate.versioning.script.base [-] Loading script /opt/stack/keystone/keystone/common/sql/migrate_repo/versions/054_add_actor_id_index.py... __init__ /usr/local/lib/python2.7/dist-packages/migrate/versioning/script/base.py:27
13385 DEBUG migrate.versioning.script.base [-] Script /opt/stack/keystone/keystone/common/sql/migrate_repo/versions/054_add_actor_id_index.py loaded successfully __init__ /usr/local/lib/python2.7/dist-packages/migrate/versioning/script/base.py:30
13385 DEBUG migrate.versioning.script.base [-] Loading script /opt/stack/keystone/keystone/common/sql/migrate_repo/versions/055_add_indexes_to_token_table.py... __init__ /usr/local/lib/python2.7/dist-packages/migrate/versioning/script/base.py:27
13385 DEBUG migrate.versioning.script.base [-] Script /opt/stack/keystone/keystone/common/sql/migrate_repo/versions/055_add_indexes_to_token_table.py loaded successfully __init__ /usr/local/lib/python2.7/dist-packages/migrate/versioning/script/base.py:30
13385 DEBUG migrate.versioning.repository [-] Repository /opt/stack/keystone/keystone/common/sql/migrate_repo loaded successfully __init__ /usr/local/lib/python2.7/dist-packages/migrate/versioning/repository.py:82
13385 DEBUG migrate.versioning.repository [-] Config: OrderedDict([('db_settings', OrderedDict([('__name__', 'db_settings'), ('repository_id', 'keystone'), ('version_table', 'migrate_version'), ('required_dbs', '[]'), ('use_timestamp_numbering', 'False')]))]) __init__ /usr/local/lib/python2.7/dist-packages/migrate/versioning/repository.py:83
13385 INFO migrate.versioning.api [-] 33 -> 34... 
13385 INFO migrate.versioning.api [-] done
13385 INFO migrate.versioning.api [-] 34 -> 35... 
13385 INFO migrate.versioning.api [-] done
13385 INFO migrate.versioning.api [-] 35 -> 36... 
13385 INFO migrate.versioning.api [-] done
13385 INFO migrate.versioning.api [-] 36 -> 37... 
13385 INFO migrate.versioning.api [-] done
13385 INFO migrate.versioning.api [-] 37 -> 38... 
13385 INFO migrate.versioning.api [-] done
13385 INFO migrate.versioning.api [-] 38 -> 39... 
13385 INFO migrate.versioning.api [-] done
13385 INFO migrate.versioning.api [-] 39 -> 40... 
13385 INFO migrate.versioning.api [-] done
13385 INFO migrate.versioning.api [-] 40 -> 41... 
13385 INFO migrate.versioning.api [-] done
13385 INFO migrate.versioning.api [-] 41 -> 42... 
13385 INFO migrate.versioning.api [-] done
13385 INFO migrate.versioning.api [-] 42 -> 43... 
13385 INFO migrate.versioning.api [-] done
13385 INFO migrate.versioning.api [-] 43 -> 44... 
13385 INFO migrate.versioning.api [-] done
13385 INFO migrate.versioning.api [-] 44 -> 45... 
13385 INFO migrate.versioning.api [-] done
13385 INFO migrate.versioning.api [-] 45 -> 46... 
13385 INFO migrate.versioning.api [-] done
13385 INFO migrate.versioning.api [-] 46 -> 47... 
13385 INFO migrate.versioning.api [-] done
13385 INFO migrate.versioning.api [-] 47 -> 48... 
13385 INFO migrate.versioning.api [-] done
13385 INFO migrate.versioning.api [-] 48 -> 49... 
13385 INFO migrate.versioning.api [-] done
13385 INFO migrate.versioning.api [-] 49 -> 50... 
13385 INFO migrate.versioning.api [-] done
13385 INFO migrate.versioning.api [-] 50 -> 51... 
13385 INFO migrate.versioning.api [-] done
13385 INFO migrate.versioning.api [-] 51 -> 52... 
13385 INFO migrate.versioning.api [-] done
13385 INFO migrate.versioning.api [-] 52 -> 53... 
13385 INFO migrate.versioning.api [-] done
13385 INFO migrate.versioning.api [-] 53 -> 54... 
13385 INFO migrate.versioning.api [-] done
13385 INFO migrate.versioning.api [-] 54 -> 55... 
13385 INFO migrate.versioning.api [-] done
13385 DEBUG migrate.versioning.repository [-] Loading repository /opt/stack/keystone/keystone/contrib/revoke/migrate_repo... __init__ /usr/local/lib/python2.7/dist-packages/migrate/versioning/repository.py:76
13385 DEBUG migrate.versioning.script.base [-] Loading script /opt/stack/keystone/keystone/contrib/revoke/migrate_repo/versions/001_revoke_table.py... __init__ /usr/local/lib/python2.7/dist-packages/migrate/versioning/script/base.py:27
13385 DEBUG migrate.versioning.script.base [-] Script /opt/stack/keystone/keystone/contrib/revoke/migrate_repo/versions/001_revoke_table.py loaded successfully __init__ /usr/local/lib/python2.7/dist-packages/migrate/versioning/script/base.py:30
13385 DEBUG migrate.versioning.script.base [-] Loading script /opt/stack/keystone/keystone/contrib/revoke/migrate_repo/versions/002_add_audit_id_and_chain_to_revoke_table.py... __init__ /usr/local/lib/python2.7/dist-packages/migrate/versioning/script/base.py:27
13385 DEBUG migrate.versioning.script.base [-] Script /opt/stack/keystone/keystone/contrib/revoke/migrate_repo/versions/002_add_audit_id_and_chain_to_revoke_table.py loaded successfully __init__ /usr/local/lib/python2.7/dist-packages/migrate/versioning/script/base.py:30
13385 DEBUG migrate.versioning.repository [-] Repository /opt/stack/keystone/keystone/contrib/revoke/migrate_repo loaded successfully __init__ /usr/local/lib/python2.7/dist-packages/migrate/versioning/repository.py:82
13385 DEBUG migrate.versioning.repository [-] Config: OrderedDict([('db_settings', OrderedDict([('__name__', 'db_settings'), ('repository_id', 'revoke'), ('version_table', 'migrate_version'), ('required_dbs', '[]'), ('use_timestamp_numbering', 'False')]))]) __init__ /usr/local/lib/python2.7/dist-packages/migrate/versioning/repository.py:83
13385 DEBUG migrate.versioning.repository [-] Loading repository /opt/stack/keystone/keystone/contrib/revoke/migrate_repo... __init__ /usr/local/lib/python2.7/dist-packages/migrate/versioning/repository.py:76
13385 DEBUG migrate.versioning.script.base [-] Loading script /opt/stack/keystone/keystone/contrib/revoke/migrate_repo/versions/001_revoke_table.py... __init__ /usr/local/lib/python2.7/dist-packages/migrate/versioning/script/base.py:27
13385 DEBUG migrate.versioning.script.base [-] Script /opt/stack/keystone/keystone/contrib/revoke/migrate_repo/versions/001_revoke_table.py loaded successfully __init__ /usr/local/lib/python2.7/dist-packages/migrate/versioning/script/base.py:30
13385 DEBUG migrate.versioning.script.base [-] Loading script /opt/stack/keystone/keystone/contrib/revoke/migrate_repo/versions/002_add_audit_id_and_chain_to_revoke_table.py... __init__ /usr/local/lib/python2.7/dist-packages/migrate/versioning/script/base.py:27
13385 DEBUG migrate.versioning.script.base [-] Script /opt/stack/keystone/keystone/contrib/revoke/migrate_repo/versions/002_add_audit_id_and_chain_to_revoke_table.py loaded successfully __init__ /usr/local/lib/python2.7/dist-packages/migrate/versioning/script/base.py:30
13385 DEBUG migrate.versioning.repository [-] Repository /opt/stack/keystone/keystone/contrib/revoke/migrate_repo loaded successfully __init__ /usr/local/lib/python2.7/dist-packages/migrate/versioning/repository.py:82
13385 DEBUG migrate.versioning.repository [-] Config: OrderedDict([('db_settings', OrderedDict([('__name__', 'db_settings'), ('repository_id', 'revoke'), ('version_table', 'migrate_version'), ('required_dbs', '[]'), ('use_timestamp_numbering', 'False')]))]) __init__ /usr/local/lib/python2.7/dist-packages/migrate/versioning/repository.py:83
13385 DEBUG migrate.versioning.repository [-] Loading repository /opt/stack/keystone/keystone/contrib/revoke/migrate_repo... __init__ /usr/local/lib/python2.7/dist-packages/migrate/versioning/repository.py:76
13385 DEBUG migrate.versioning.script.base [-] Loading script /opt/stack/keystone/keystone/contrib/revoke/migrate_repo/versions/001_revoke_table.py... __init__ /usr/local/lib/python2.7/dist-packages/migrate/versioning/script/base.py:27
13385 DEBUG migrate.versioning.script.base [-] Script /opt/stack/keystone/keystone/contrib/revoke/migrate_repo/versions/001_revoke_table.py loaded successfully __init__ /usr/local/lib/python2.7/dist-packages/migrate/versioning/script/base.py:30
13385 DEBUG migrate.versioning.script.base [-] Loading script /opt/stack/keystone/keystone/contrib/revoke/migrate_repo/versions/002_add_audit_id_and_chain_to_revoke_table.py... __init__ /usr/local/lib/python2.7/dist-packages/migrate/versioning/script/base.py:27
13385 DEBUG migrate.versioning.script.base [-] Script /opt/stack/keystone/keystone/contrib/revoke/migrate_repo/versions/002_add_audit_id_and_chain_to_revoke_table.py loaded successfully __init__ /usr/local/lib/python2.7/dist-packages/migrate/versioning/script/base.py:30
13385 DEBUG migrate.versioning.repository [-] Repository /opt/stack/keystone/keystone/contrib/revoke/migrate_repo loaded successfully __init__ /usr/local/lib/python2.7/dist-packages/migrate/versioning/repository.py:82
13385 DEBUG migrate.versioning.repository [-] Config: OrderedDict([('db_settings', OrderedDict([('__name__', 'db_settings'), ('repository_id', 'revoke'), ('version_table', 'migrate_version'), ('required_dbs', '[]'), ('use_timestamp_numbering', 'False')]))]) __init__ /usr/local/lib/python2.7/dist-packages/migrate/versioning/repository.py:83
13385 INFO migrate.versioning.api [-] 0 -> 1... 
13385 INFO migrate.versioning.api [-] done
13385 INFO migrate.versioning.api [-] 1 -> 2... 
13385 INFO migrate.versioning.api [-] done
+ local extension_value
+ [[ '' != \u\u\i\d ]]
+ rm -rf /etc/keystone/ssl
+ /opt/stack/keystone/bin/keystone-manage pki_setup
13394 WARNING keystone.cli [-] keystone-manage pki_setup is not recommended for production use.
13394 DEBUG keystone.common.openssl [-] make_dirs path='/etc/keystone/ssl/certs' mode=0755 user=None group=None make_dirs /opt/stack/keystone/keystone/common/utils.py:520
13394 DEBUG keystone.common.openssl [-] set_permissions: path='/etc/keystone/ssl/certs' mode=0755 user=None(None) group=None(None) set_permissions /opt/stack/keystone/keystone/common/utils.py:466
13394 DEBUG keystone.common.openssl [-] set_permissions: path='/etc/keystone/ssl/certs/openssl.conf' mode=0640 user=None(None) group=None(None) set_permissions /opt/stack/keystone/keystone/common/utils.py:466
13394 DEBUG keystone.common.openssl [-] set_permissions: path='/etc/keystone/ssl/certs/index.txt' mode=0640 user=None(None) group=None(None) set_permissions /opt/stack/keystone/keystone/common/utils.py:466
13394 DEBUG keystone.common.openssl [-] set_permissions: path='/etc/keystone/ssl/certs/serial' mode=0640 user=None(None) group=None(None) set_permissions /opt/stack/keystone/keystone/common/utils.py:466
13394 DEBUG keystone.common.openssl [-] make_dirs path='/etc/keystone/ssl/private' mode=0750 user=None group=None make_dirs /opt/stack/keystone/keystone/common/utils.py:520
13394 DEBUG keystone.common.openssl [-] set_permissions: path='/etc/keystone/ssl/private' mode=0750 user=None(None) group=None(None) set_permissions /opt/stack/keystone/keystone/common/utils.py:466
13394 INFO keystone.common.openssl [-] Running command - openssl genrsa -out /etc/keystone/ssl/private/cakey.pem 2048
13394 DEBUG keystone.common.openssl [-] set_permissions: path='/etc/keystone/ssl/private/cakey.pem' mode=0640 user=None(None) group=None(None) set_permissions /opt/stack/keystone/keystone/common/utils.py:466
13394 DEBUG keystone.common.openssl [-] make_dirs path='/etc/keystone/ssl/certs' mode=0755 user=None group=None make_dirs /opt/stack/keystone/keystone/common/utils.py:520
13394 DEBUG keystone.common.openssl [-] set_permissions: path='/etc/keystone/ssl/certs' mode=0755 user=None(None) group=None(None) set_permissions /opt/stack/keystone/keystone/common/utils.py:466
13394 INFO keystone.common.openssl [-] Running command - openssl req -new -x509 -extensions v3_ca -key /etc/keystone/ssl/private/cakey.pem -out /etc/keystone/ssl/certs/ca.pem -days 3650 -config /etc/keystone/ssl/certs/openssl.conf -subj /C=US/ST=Unset/L=Unset/O=Unset/CN=www.example.com
13394 DEBUG keystone.common.openssl [-] set_permissions: path='/etc/keystone/ssl/certs/ca.pem' mode=0644 user=None(None) group=None(None) set_permissions /opt/stack/keystone/keystone/common/utils.py:466
13394 DEBUG keystone.common.openssl [-] make_dirs path='/etc/keystone/ssl/private' mode=0750 user=None group=None make_dirs /opt/stack/keystone/keystone/common/utils.py:520
13394 DEBUG keystone.common.openssl [-] set_permissions: path='/etc/keystone/ssl/private' mode=0750 user=None(None) group=None(None) set_permissions /opt/stack/keystone/keystone/common/utils.py:466
13394 INFO keystone.common.openssl [-] Running command - openssl genrsa -out /etc/keystone/ssl/private/signing_key.pem 2048
13394 DEBUG keystone.common.openssl [-] set_permissions: path='/etc/keystone/ssl/private/signing_key.pem' mode=0640 user=None(None) group=None(None) set_permissions /opt/stack/keystone/keystone/common/utils.py:466
13394 DEBUG keystone.common.openssl [-] make_dirs path='/etc/keystone/ssl/certs' mode=0755 user=None group=None make_dirs /opt/stack/keystone/keystone/common/utils.py:520
13394 DEBUG keystone.common.openssl [-] set_permissions: path='/etc/keystone/ssl/certs' mode=0755 user=None(None) group=None(None) set_permissions /opt/stack/keystone/keystone/common/utils.py:466
13394 INFO keystone.common.openssl [-] Running command - openssl req -key /etc/keystone/ssl/private/signing_key.pem -new -out /etc/keystone/ssl/certs/req.pem -config /etc/keystone/ssl/certs/openssl.conf -subj /C=US/ST=Unset/L=Unset/O=Unset/CN=www.example.com
13394 INFO keystone.common.openssl [-] Running command - openssl ca -batch -out /etc/keystone/ssl/certs/signing_cert.pem -config /etc/keystone/ssl/certs/openssl.conf -days 3650d -cert /etc/keystone/ssl/certs/ca.pem -keyfile /etc/keystone/ssl/private/cakey.pem -infiles /etc/keystone/ssl/certs/req.pem
+ sudo mkdir -p /var/cache/keystone
+ sudo chown cloudbase /var/cache/keystone
+ rm -f '/var/cache/keystone/*'
+ start_keystone
+ local service_port=5000
+ local auth_protocol=http
+ is_service_enabled tls-proxy
++ set +o
++ grep xtrace
+ local 'xtrace=set -o xtrace'
+ set +o xtrace
+ return 1
+ '[' True == True ']'
+ enable_apache_site keystone
+ local site=keystone
+ is_ubuntu
+ [[ -z deb ]]
+ '[' deb = deb ']'
+ sudo a2ensite keystone
+ restart_apache_server
+ stop_service apache2
+ is_ubuntu
+ [[ -z deb ]]
+ '[' deb = deb ']'
+ sudo /usr/sbin/service apache2 stop
+ sleep 3
+ start_service apache2
+ is_ubuntu
+ [[ -z deb ]]
+ '[' deb = deb ']'
+ sudo /usr/sbin/service apache2 start
AH00558: apache2: Could not reliably determine the server's fully qualified domain name, using 127.0.0.1. Set the 'ServerName' directive globally to suppress this message
+ tail_log key /var/log/apache2/keystone.log
+ local service=key
+ local logfile=/var/log/apache2/keystone.log
++ trueorfalse True True
+++ set +o
+++ grep xtrace
++ local 'xtrace=set -o xtrace'
++ set +o xtrace
+ USE_SCREEN=True
+ [[ True = \T\r\u\e ]]
+ screen_service key 'sudo tail -f /var/log/apache2/keystone.log'
+ local service=key
+ local 'command=sudo tail -f /var/log/apache2/keystone.log'
+ local group=
+ SCREEN_NAME=stack
+ SERVICE_DIR=/opt/stack/status
++ trueorfalse True True
+++ set +o
+++ grep xtrace
++ local 'xtrace=set -o xtrace'
++ set +o xtrace
+ USE_SCREEN=True
+ is_service_enabled key
++ set +o
++ grep xtrace
+ local 'xtrace=set -o xtrace'
+ set +o xtrace
+ return 0
+ screen_rc key 'sudo tail -f /var/log/apache2/keystone.log'
+ SCREEN_NAME=stack
+ SCREENRC=/home/cloudbase/devstack/stack-screenrc
+ [[ ! -e /home/cloudbase/devstack/stack-screenrc ]]
+ echo 'sessionname stack'
+ echo 'hardstatus alwayslastline '\''%{= .} %-Lw%{= .}%> %n%f %t*%{= .}%+Lw%< %-=%{g}(%{d}%H/%l%{g})'\'''
+ echo 'setenv PROMPT_COMMAND /bin/true'
+ echo 'screen -t shell bash'
+ grep key /home/cloudbase/devstack/stack-screenrc
++ echo -ne '\015'
+ NL=$'\r'
+ echo 'screen -t key bash'
+ echo 'stuff "sudo tail -f /var/log/apache2/keystone.log"'
+ [[ -n /home/cloudbase/jenkins/workspace/openstack-hyperv-release-tests/reports/2014_12_12_13_16_55_547646598/HyperV2012_VHD_v1/logs/devstack ]]
+ echo 'logfile /home/cloudbase/jenkins/workspace/openstack-hyperv-release-tests/reports/2014_12_12_13_16_55_547646598/HyperV2012_VHD_v1/logs/devstack/screen-key.2014-12-12-162857.log'
+ echo 'log on'
+ screen -S stack -X screen -t key
+ [[ -n /home/cloudbase/jenkins/workspace/openstack-hyperv-release-tests/reports/2014_12_12_13_16_55_547646598/HyperV2012_VHD_v1/logs/devstack ]]
+ screen -S stack -p key -X logfile /home/cloudbase/jenkins/workspace/openstack-hyperv-release-tests/reports/2014_12_12_13_16_55_547646598/HyperV2012_VHD_v1/logs/devstack/screen-key.2014-12-12-162857.log
+ screen -S stack -p key -X log on
+ ln -sf /home/cloudbase/jenkins/workspace/openstack-hyperv-release-tests/reports/2014_12_12_13_16_55_547646598/HyperV2012_VHD_v1/logs/devstack/screen-key.2014-12-12-162857.log /home/cloudbase/jenkins/workspace/openstack-hyperv-release-tests/reports/2014_12_12_13_16_55_547646598/HyperV2012_VHD_v1/logs/devstack/screen-key.log
+ sleep 3
++ echo -ne '\015'
+ NL=$'\r'
+ [[ -n '' ]]
+ screen -S stack -p key -X stuff 'sudo tail -f /var/log/apache2/keystone.log & echo $! >/opt/stack/status/stack/key.pid; fg || echo "key failed to start" | tee "/opt/stack/status/stack/key.failure"'
+ tail_log key-access /var/log/apache2/keystone_access.log
+ local service=key-access
+ local logfile=/var/log/apache2/keystone_access.log
++ trueorfalse True True
+++ set +o
+++ grep xtrace
++ local 'xtrace=set -o xtrace'
++ set +o xtrace
+ USE_SCREEN=True
+ [[ True = \T\r\u\e ]]
+ screen_service key-access 'sudo tail -f /var/log/apache2/keystone_access.log'
+ local service=key-access
+ local 'command=sudo tail -f /var/log/apache2/keystone_access.log'
+ local group=
+ SCREEN_NAME=stack
+ SERVICE_DIR=/opt/stack/status
++ trueorfalse True True
+++ set +o
+++ grep xtrace
++ local 'xtrace=set -o xtrace'
++ set +o xtrace
+ USE_SCREEN=True
+ is_service_enabled key-access
++ set +o
++ grep xtrace
+ local 'xtrace=set -o xtrace'
+ set +o xtrace
+ return 0
+ screen_rc key-access 'sudo tail -f /var/log/apache2/keystone_access.log'
+ SCREEN_NAME=stack
+ SCREENRC=/home/cloudbase/devstack/stack-screenrc
+ [[ ! -e /home/cloudbase/devstack/stack-screenrc ]]
+ grep key-access /home/cloudbase/devstack/stack-screenrc
++ echo -ne '\015'
+ NL=$'\r'
+ echo 'screen -t key-access bash'
+ echo 'stuff "sudo tail -f /var/log/apache2/keystone_access.log"'
+ [[ -n /home/cloudbase/jenkins/workspace/openstack-hyperv-release-tests/reports/2014_12_12_13_16_55_547646598/HyperV2012_VHD_v1/logs/devstack ]]
+ echo 'logfile /home/cloudbase/jenkins/workspace/openstack-hyperv-release-tests/reports/2014_12_12_13_16_55_547646598/HyperV2012_VHD_v1/logs/devstack/screen-key-access.2014-12-12-162857.log'
+ echo 'log on'
+ screen -S stack -X screen -t key-access
+ [[ -n /home/cloudbase/jenkins/workspace/openstack-hyperv-release-tests/reports/2014_12_12_13_16_55_547646598/HyperV2012_VHD_v1/logs/devstack ]]
+ screen -S stack -p key-access -X logfile /home/cloudbase/jenkins/workspace/openstack-hyperv-release-tests/reports/2014_12_12_13_16_55_547646598/HyperV2012_VHD_v1/logs/devstack/screen-key-access.2014-12-12-162857.log
+ screen -S stack -p key-access -X log on
+ ln -sf /home/cloudbase/jenkins/workspace/openstack-hyperv-release-tests/reports/2014_12_12_13_16_55_547646598/HyperV2012_VHD_v1/logs/devstack/screen-key-access.2014-12-12-162857.log /home/cloudbase/jenkins/workspace/openstack-hyperv-release-tests/reports/2014_12_12_13_16_55_547646598/HyperV2012_VHD_v1/logs/devstack/screen-key-access.log
+ sleep 3
++ echo -ne '\015'
+ NL=$'\r'
+ [[ -n '' ]]
+ screen -S stack -p key-access -X stuff 'sudo tail -f /var/log/apache2/keystone_access.log & echo $! >/opt/stack/status/stack/key-access.pid; fg || echo "key-access failed to start" | tee "/opt/stack/status/stack/key-access.failure"'
+ echo 'Waiting for keystone to start...'
+ timeout 60 sh -c 'while ! curl --noproxy '\''*'\'' -k -s http://10.14.0.26:5000/v2.0/ >/dev/null; do sleep 1; done'
+ is_service_enabled tls-proxy
++ set +o
++ grep xtrace
+ local 'xtrace=set -o xtrace'
+ set +o xtrace
+ return 1
+ SERVICE_ENDPOINT=http://10.14.0.26:35357/v2.0
+ is_service_enabled tls-proxy
++ set +o
++ grep xtrace
+ local 'xtrace=set -o xtrace'
+ set +o xtrace
+ return 1
+ export OS_TOKEN=Passw0rd
+ OS_TOKEN=Passw0rd
+ export OS_URL=http://10.14.0.26:35357/v2.0
+ OS_URL=http://10.14.0.26:35357/v2.0
+ create_keystone_accounts
++ get_or_create_project admin
+++ openstack project show admin -f value -c id
+++ openstack project create admin -f value -c id
++ local project_id=c8a8f2c1f6ed4781a8bb278ddd58d962
++ echo c8a8f2c1f6ed4781a8bb278ddd58d962
+ local admin_tenant=c8a8f2c1f6ed4781a8bb278ddd58d962
++ get_or_create_user admin Passw0rd c8a8f2c1f6ed4781a8bb278ddd58d962
++ [[ ! -z '' ]]
++ local email=
+++ openstack user show admin -f value -c id
+++ openstack user create admin --password Passw0rd --project c8a8f2c1f6ed4781a8bb278ddd58d962 -f value -c id
++ local user_id=aeee7d926a3747c88a454c79ed8b306a
++ echo aeee7d926a3747c88a454c79ed8b306a
+ local admin_user=aeee7d926a3747c88a454c79ed8b306a
++ get_or_create_role admin
+++ openstack role show admin -f value -c id
+++ openstack role create admin -f value -c id
++ local role_id=a73e26b53d1d4f81992b1698c5a69300
++ echo a73e26b53d1d4f81992b1698c5a69300
+ local admin_role=a73e26b53d1d4f81992b1698c5a69300
+ get_or_add_user_role a73e26b53d1d4f81992b1698c5a69300 aeee7d926a3747c88a454c79ed8b306a c8a8f2c1f6ed4781a8bb278ddd58d962
++ openstack user role list aeee7d926a3747c88a454c79ed8b306a --project c8a8f2c1f6ed4781a8bb278ddd58d962 --column ID --column Name
++ grep ' a73e26b53d1d4f81992b1698c5a69300 '
++ get_field 1
++ local data field
++ read data
+ local user_role_id=
+ [[ -z '' ]]
++ openstack role add a73e26b53d1d4f81992b1698c5a69300 --user aeee7d926a3747c88a454c79ed8b306a --project c8a8f2c1f6ed4781a8bb278ddd58d962
++ get_field 2
++ local data field
++ read data
++ grep ' id '
++ '[' 2 -lt 0 ']'
++ field='$3'
++ echo '| id    | a73e26b53d1d4f81992b1698c5a69300 |'
++ awk '-F[ \t]*\\|[ \t]*' '{print $3}'
++ read data
+ user_role_id=a73e26b53d1d4f81992b1698c5a69300
+ echo a73e26b53d1d4f81992b1698c5a69300
+ get_or_create_project service
++ openstack project show service -f value -c id
++ openstack project create service -f value -c id
+ local project_id=8d6b5a09210d46e69aaf5d0d3693fb5d
+ echo 8d6b5a09210d46e69aaf5d0d3693fb5d
+ get_or_create_role service
++ openstack role show service -f value -c id
++ openstack role create service -f value -c id
+ local role_id=ffcad3cc0ea44a6b9463782b9dfb531b
+ echo ffcad3cc0ea44a6b9463782b9dfb531b
+ get_or_create_role ResellerAdmin
++ openstack role show ResellerAdmin -f value -c id
++ openstack role create ResellerAdmin -f value -c id
+ local role_id=80c294908f4643f295eca766f96ae048
+ echo 80c294908f4643f295eca766f96ae048
++ get_or_create_role Member
+++ openstack role show Member -f value -c id
+++ openstack role create Member -f value -c id
++ local role_id=cf9bfac7a7b64c35b930c4c6f98a3673
++ echo cf9bfac7a7b64c35b930c4c6f98a3673
+ local member_role=cf9bfac7a7b64c35b930c4c6f98a3673
++ get_or_create_role anotherrole
+++ openstack role show anotherrole -f value -c id
+++ openstack role create anotherrole -f value -c id
++ local role_id=8a3fc10d70964b229935633527998f0f
++ echo 8a3fc10d70964b229935633527998f0f
+ local another_role=8a3fc10d70964b229935633527998f0f
++ get_or_create_project invisible_to_admin
+++ openstack project show invisible_to_admin -f value -c id
+++ openstack project create invisible_to_admin -f value -c id
++ local project_id=5b03c07bc8344c2fb08533c23ea165a2
++ echo 5b03c07bc8344c2fb08533c23ea165a2
+ local invis_tenant=5b03c07bc8344c2fb08533c23ea165a2
++ get_or_create_project demo
+++ openstack project show demo -f value -c id
+++ openstack project create demo -f value -c id
++ local project_id=e925366f53424cdeb40943a8495711df
++ echo e925366f53424cdeb40943a8495711df
+ local demo_tenant=e925366f53424cdeb40943a8495711df
++ get_or_create_user demo Passw0rd e925366f53424cdeb40943a8495711df demo@example.com
++ [[ ! -z demo@example.com ]]
++ local email=--email=demo@example.com
+++ openstack user show demo -f value -c id
+++ openstack user create demo --password Passw0rd --project e925366f53424cdeb40943a8495711df --email=demo@example.com -f value -c id
++ local user_id=02b7ace5c16240b9851a6bce8b1379c7
++ echo 02b7ace5c16240b9851a6bce8b1379c7
+ local demo_user=02b7ace5c16240b9851a6bce8b1379c7
+ get_or_add_user_role cf9bfac7a7b64c35b930c4c6f98a3673 02b7ace5c16240b9851a6bce8b1379c7 e925366f53424cdeb40943a8495711df
++ openstack user role list 02b7ace5c16240b9851a6bce8b1379c7 --project e925366f53424cdeb40943a8495711df --column ID --column Name
++ grep ' cf9bfac7a7b64c35b930c4c6f98a3673 '
++ get_field 1
++ local data field
++ read data
+ local user_role_id=
+ [[ -z '' ]]
++ openstack role add cf9bfac7a7b64c35b930c4c6f98a3673 --user 02b7ace5c16240b9851a6bce8b1379c7 --project e925366f53424cdeb40943a8495711df
++ grep ' id '
++ get_field 2
++ local data field
++ read data
++ '[' 2 -lt 0 ']'
++ field='$3'
++ echo '| id    | cf9bfac7a7b64c35b930c4c6f98a3673 |'
++ awk '-F[ \t]*\\|[ \t]*' '{print $3}'
++ read data
+ user_role_id=cf9bfac7a7b64c35b930c4c6f98a3673
+ echo cf9bfac7a7b64c35b930c4c6f98a3673
+ get_or_add_user_role a73e26b53d1d4f81992b1698c5a69300 aeee7d926a3747c88a454c79ed8b306a e925366f53424cdeb40943a8495711df
++ openstack user role list aeee7d926a3747c88a454c79ed8b306a --project e925366f53424cdeb40943a8495711df --column ID --column Name
++ grep ' a73e26b53d1d4f81992b1698c5a69300 '
++ get_field 1
++ local data field
++ read data
+ local user_role_id=
+ [[ -z '' ]]
++ openstack role add a73e26b53d1d4f81992b1698c5a69300 --user aeee7d926a3747c88a454c79ed8b306a --project e925366f53424cdeb40943a8495711df
++ get_field 2
++ local data field
++ read data
++ '[' 2 -lt 0 ']'
++ field='$3'
++ echo '| id    | a73e26b53d1d4f81992b1698c5a69300 |'
++ awk '-F[ \t]*\\|[ \t]*' '{print $3}'
++ read data
+ user_role_id=a73e26b53d1d4f81992b1698c5a69300
+ echo a73e26b53d1d4f81992b1698c5a69300
+ get_or_add_user_role 8a3fc10d70964b229935633527998f0f 02b7ace5c16240b9851a6bce8b1379c7 e925366f53424cdeb40943a8495711df
++ openstack user role list 02b7ace5c16240b9851a6bce8b1379c7 --project e925366f53424cdeb40943a8495711df --column ID --column Name
++ grep ' 8a3fc10d70964b229935633527998f0f '
++ get_field 1
++ local data field
++ read data
+ local user_role_id=
+ [[ -z '' ]]
++ openstack role add 8a3fc10d70964b229935633527998f0f --user 02b7ace5c16240b9851a6bce8b1379c7 --project e925366f53424cdeb40943a8495711df
++ grep ' id '
++ get_field 2
++ local data field
++ read data
++ '[' 2 -lt 0 ']'
++ field='$3'
++ echo '| id    | 8a3fc10d70964b229935633527998f0f |'
++ awk '-F[ \t]*\\|[ \t]*' '{print $3}'
++ read data
+ user_role_id=8a3fc10d70964b229935633527998f0f
+ echo 8a3fc10d70964b229935633527998f0f
+ get_or_add_user_role cf9bfac7a7b64c35b930c4c6f98a3673 02b7ace5c16240b9851a6bce8b1379c7 5b03c07bc8344c2fb08533c23ea165a2
++ openstack user role list 02b7ace5c16240b9851a6bce8b1379c7 --project 5b03c07bc8344c2fb08533c23ea165a2 --column ID --column Name
++ grep ' cf9bfac7a7b64c35b930c4c6f98a3673 '
++ get_field 1
++ local data field
++ read data
+ local user_role_id=
+ [[ -z '' ]]
++ openstack role add cf9bfac7a7b64c35b930c4c6f98a3673 --user 02b7ace5c16240b9851a6bce8b1379c7 --project 5b03c07bc8344c2fb08533c23ea165a2
++ grep ' id '
++ get_field 2
++ local data field
++ read data
++ '[' 2 -lt 0 ']'
++ field='$3'
++ echo '| id    | cf9bfac7a7b64c35b930c4c6f98a3673 |'
++ awk '-F[ \t]*\\|[ \t]*' '{print $3}'
++ read data
+ user_role_id=cf9bfac7a7b64c35b930c4c6f98a3673
+ echo cf9bfac7a7b64c35b930c4c6f98a3673
+ [[ sql = \s\q\l ]]
++ get_or_create_service keystone identity 'Keystone Identity Service'
+++ openstack service show keystone -f value -c id
+++ openstack service create keystone --type=identity '--description=Keystone Identity Service' -f value -c id
++ local service_id=8cf3c9b4862c493d93feea9ec6f89eff
++ echo 8cf3c9b4862c493d93feea9ec6f89eff
+ KEYSTONE_SERVICE=8cf3c9b4862c493d93feea9ec6f89eff
+ get_or_create_endpoint 8cf3c9b4862c493d93feea9ec6f89eff RegionOne http://10.14.0.26:5000/v2.0 http://10.14.0.26:35357/v2.0 http://10.14.0.26:5000/v2.0
++ openstack endpoint list --column ID --column Region --column 'Service Name'
++ grep ' RegionOne '
++ grep ' 8cf3c9b4862c493d93feea9ec6f89eff '
++ get_field 1
++ local data field
++ read data
+ local endpoint_id=
+ [[ -z '' ]]
++ openstack endpoint create 8cf3c9b4862c493d93feea9ec6f89eff --region RegionOne --publicurl http://10.14.0.26:5000/v2.0 --adminurl http://10.14.0.26:35357/v2.0 --internalurl http://10.14.0.26:5000/v2.0
++ grep ' id '
++ get_field 2
++ local data field
++ read data
++ '[' 2 -lt 0 ']'
++ field='$3'
++ echo '| id           | baaf97e574f44546898a266b1f6eb1ff |'
++ awk '-F[ \t]*\\|[ \t]*' '{print $3}'
++ read data
+ endpoint_id=baaf97e574f44546898a266b1f6eb1ff
+ echo baaf97e574f44546898a266b1f6eb1ff
+ create_nova_accounts
++ openstack project list
++ awk '/ service / { print $2 }'
+ local service_tenant=8d6b5a09210d46e69aaf5d0d3693fb5d
++ openstack role list
++ awk '/ admin / { print $2 }'
+ local admin_role=a73e26b53d1d4f81992b1698c5a69300
+ [[ g-api,g-reg,key,n-api,n-crt,n-obj,n-cond,n-sch,n-xvnc,n-cauth,c-sch,c-api,c-vol,h-eng,h-api,h-api-cfn,h-api-cw,rabbit,tempest,mysql,neutron,q-svc,q-agt,q-dhcp,q-l3,q-meta,q-lbaas,q-fwaas,q-metering,q-vpn,c-bak,s-proxy,s-object,s-container,s-account,heat,ceilometer-acentral,ceilometer-collector,ceilometer-api =~ n-api ]]
++ get_or_create_user nova Passw0rd 8d6b5a09210d46e69aaf5d0d3693fb5d
++ [[ ! -z '' ]]
++ local email=
+++ openstack user show nova -f value -c id
+++ openstack user create nova --password Passw0rd --project 8d6b5a09210d46e69aaf5d0d3693fb5d -f value -c id
++ local user_id=36a2acbad40f45a38606f913d6e9cda5
++ echo 36a2acbad40f45a38606f913d6e9cda5
+ local nova_user=36a2acbad40f45a38606f913d6e9cda5
+ get_or_add_user_role a73e26b53d1d4f81992b1698c5a69300 36a2acbad40f45a38606f913d6e9cda5 8d6b5a09210d46e69aaf5d0d3693fb5d
++ openstack user role list 36a2acbad40f45a38606f913d6e9cda5 --project 8d6b5a09210d46e69aaf5d0d3693fb5d --column ID --column Name
++ grep ' a73e26b53d1d4f81992b1698c5a69300 '
++ get_field 1
++ local data field
++ read data
+ local user_role_id=
+ [[ -z '' ]]
++ openstack role add a73e26b53d1d4f81992b1698c5a69300 --user 36a2acbad40f45a38606f913d6e9cda5 --project 8d6b5a09210d46e69aaf5d0d3693fb5d
++ grep ' id '
++ get_field 2
++ local data field
++ read data
++ '[' 2 -lt 0 ']'
++ field='$3'
++ echo '| id    | a73e26b53d1d4f81992b1698c5a69300 |'
++ awk '-F[ \t]*\\|[ \t]*' '{print $3}'
++ read data
+ user_role_id=a73e26b53d1d4f81992b1698c5a69300
+ echo a73e26b53d1d4f81992b1698c5a69300
+ [[ sql = \s\q\l ]]
++ get_or_create_service nova compute 'Nova Compute Service'
+++ openstack service show nova -f value -c id
+++ openstack service create nova --type=compute '--description=Nova Compute Service' -f value -c id
++ local service_id=73cbd0d9cf094d4091fc3055539beeac
++ echo 73cbd0d9cf094d4091fc3055539beeac
+ local nova_service=73cbd0d9cf094d4091fc3055539beeac
+ get_or_create_endpoint 73cbd0d9cf094d4091fc3055539beeac RegionOne 'http://10.14.0.26:8774/v2/$(tenant_id)s' 'http://10.14.0.26:8774/v2/$(tenant_id)s' 'http://10.14.0.26:8774/v2/$(tenant_id)s'
++ openstack endpoint list --column ID --column Region --column 'Service Name'
++ grep ' RegionOne '
++ grep ' 73cbd0d9cf094d4091fc3055539beeac '
++ get_field 1
++ local data field
++ read data
+ local endpoint_id=
+ [[ -z '' ]]
++ openstack endpoint create 73cbd0d9cf094d4091fc3055539beeac --region RegionOne --publicurl 'http://10.14.0.26:8774/v2/$(tenant_id)s' --adminurl 'http://10.14.0.26:8774/v2/$(tenant_id)s' --internalurl 'http://10.14.0.26:8774/v2/$(tenant_id)s'
++ grep ' id '
++ get_field 2
++ local data field
++ read data
++ '[' 2 -lt 0 ']'
++ field='$3'
++ echo '| id           | a1dfdae8abd44d719e2da551fe3ea0b4        |'
++ awk '-F[ \t]*\\|[ \t]*' '{print $3}'
++ read data
+ endpoint_id=a1dfdae8abd44d719e2da551fe3ea0b4
+ echo a1dfdae8abd44d719e2da551fe3ea0b4
++ get_or_create_service novav21 computev21 'Nova Compute Service V2.1'
+++ openstack service show novav21 -f value -c id
+++ openstack service create novav21 --type=computev21 '--description=Nova Compute Service V2.1' -f value -c id
++ local service_id=a5e4f8d6259f4453a60f64102c96fb66
++ echo a5e4f8d6259f4453a60f64102c96fb66
+ local nova_v21_service=a5e4f8d6259f4453a60f64102c96fb66
+ get_or_create_endpoint a5e4f8d6259f4453a60f64102c96fb66 RegionOne 'http://10.14.0.26:8774/v2.1/$(tenant_id)s' 'http://10.14.0.26:8774/v2.1/$(tenant_id)s' 'http://10.14.0.26:8774/v2.1/$(tenant_id)s'
++ openstack endpoint list --column ID --column Region --column 'Service Name'
++ grep ' RegionOne '
++ get_field 1
++ local data field
++ read data
+ local endpoint_id=
+ [[ -z '' ]]
++ openstack endpoint create a5e4f8d6259f4453a60f64102c96fb66 --region RegionOne --publicurl 'http://10.14.0.26:8774/v2.1/$(tenant_id)s' --adminurl 'http://10.14.0.26:8774/v2.1/$(tenant_id)s' --internalurl 'http://10.14.0.26:8774/v2.1/$(tenant_id)s'
++ grep ' id '
++ get_field 2
++ local data field
++ read data
++ '[' 2 -lt 0 ']'
++ field='$3'
++ echo '| id           | 9d44d0d6136d469d9f91713696a65efe          |'
++ awk '-F[ \t]*\\|[ \t]*' '{print $3}'
++ read data
+ endpoint_id=9d44d0d6136d469d9f91713696a65efe
+ echo 9d44d0d6136d469d9f91713696a65efe
+ is_service_enabled n-api
++ set +o
++ grep xtrace
+ local 'xtrace=set -o xtrace'
+ set +o xtrace
+ return 0
+ is_service_enabled swift
++ set +o
++ grep xtrace
+ local 'xtrace=set -o xtrace'
+ set +o xtrace
+ return 0
+ get_or_add_user_role ResellerAdmin nova service
++ openstack user role list nova --project service --column ID --column Name
++ grep ' ResellerAdmin '
++ get_field 1
++ local data field
++ read data
+ local user_role_id=
+ [[ -z '' ]]
++ openstack role add ResellerAdmin --user nova --project service
++ grep ' id '
++ get_field 2
++ local data field
++ read data
++ '[' 2 -lt 0 ']'
++ field='$3'
++ echo '| id    | 80c294908f4643f295eca766f96ae048 |'
++ awk '-F[ \t]*\\|[ \t]*' '{print $3}'
++ read data
+ user_role_id=80c294908f4643f295eca766f96ae048
+ echo 80c294908f4643f295eca766f96ae048
+ [[ sql = \s\q\l ]]
++ get_or_create_service ec2 ec2 'EC2 Compatibility Layer'
+++ openstack service show ec2 -f value -c id
+++ openstack service create ec2 --type=ec2 '--description=EC2 Compatibility Layer' -f value -c id
++ local service_id=f823cda7b4b949f1b4000c292981b331
++ echo f823cda7b4b949f1b4000c292981b331
+ local ec2_service=f823cda7b4b949f1b4000c292981b331
+ get_or_create_endpoint f823cda7b4b949f1b4000c292981b331 RegionOne http://10.14.0.26:8773/services/Cloud http://10.14.0.26:8773/services/Admin http://10.14.0.26:8773/services/Cloud
++ openstack endpoint list --column ID --column Region --column 'Service Name'
++ grep ' RegionOne '
++ grep ' f823cda7b4b949f1b4000c292981b331 '
++ get_field 1
++ local data field
++ read data
+ local endpoint_id=
+ [[ -z '' ]]
++ openstack endpoint create f823cda7b4b949f1b4000c292981b331 --region RegionOne --publicurl http://10.14.0.26:8773/services/Cloud --adminurl http://10.14.0.26:8773/services/Admin --internalurl http://10.14.0.26:8773/services/Cloud
++ grep ' id '
++ get_field 2
++ local data field
++ read data
++ '[' 2 -lt 0 ']'
++ field='$3'
++ echo '| id           | e0f8fb8c578547299eddce04c7602543      |'
++ awk '-F[ \t]*\\|[ \t]*' '{print $3}'
++ read data
+ endpoint_id=e0f8fb8c578547299eddce04c7602543
+ echo e0f8fb8c578547299eddce04c7602543
+ is_service_enabled n-obj swift3
++ set +o
++ grep xtrace
+ local 'xtrace=set -o xtrace'
+ set +o xtrace
+ return 0
+ [[ sql = \s\q\l ]]
++ get_or_create_service s3 s3 S3
+++ openstack service show s3 -f value -c id
+++ openstack service create s3 --type=s3 --description=S3 -f value -c id
++ local service_id=50f32fecc7064bd2be26e4e496272d6b
++ echo 50f32fecc7064bd2be26e4e496272d6b
+ local s3_service=50f32fecc7064bd2be26e4e496272d6b
+ get_or_create_endpoint 50f32fecc7064bd2be26e4e496272d6b RegionOne http://10.14.0.26:3333 http://10.14.0.26:3333 http://10.14.0.26:3333
++ openstack endpoint list --column ID --column Region --column 'Service Name'
++ grep ' RegionOne '
++ get_field 1
++ local data field
++ read data
++ grep ' 50f32fecc7064bd2be26e4e496272d6b '
+ local endpoint_id=
+ [[ -z '' ]]
++ openstack endpoint create 50f32fecc7064bd2be26e4e496272d6b --region RegionOne --publicurl http://10.14.0.26:3333 --adminurl http://10.14.0.26:3333 --internalurl http://10.14.0.26:3333
++ grep ' id '
++ get_field 2
++ local data field
++ read data
++ '[' 2 -lt 0 ']'
++ field='$3'
++ echo '| id           | 39a1cf98c4734a9bba60beeeb9ca2854 |'
++ awk '-F[ \t]*\\|[ \t]*' '{print $3}'
++ read data
+ endpoint_id=39a1cf98c4734a9bba60beeeb9ca2854
+ echo 39a1cf98c4734a9bba60beeeb9ca2854
+ create_glance_accounts
+ is_service_enabled g-api
++ set +o
++ grep xtrace
+ local 'xtrace=set -o xtrace'
+ set +o xtrace
+ return 0
++ get_or_create_user glance Passw0rd service
++ [[ ! -z '' ]]
++ local email=
+++ openstack user show glance -f value -c id
+++ openstack user create glance --password Passw0rd --project service -f value -c id
++ local user_id=31c079980fc3418ab6ef298647d05a06
++ echo 31c079980fc3418ab6ef298647d05a06
+ local glance_user=31c079980fc3418ab6ef298647d05a06
+ get_or_add_user_role service 31c079980fc3418ab6ef298647d05a06 service
++ openstack user role list 31c079980fc3418ab6ef298647d05a06 --project service --column ID --column Name
++ grep ' service '
++ get_field 1
++ local data field
++ read data
+ local user_role_id=
+ [[ -z '' ]]
++ openstack role add service --user 31c079980fc3418ab6ef298647d05a06 --project service
++ grep ' id '
++ get_field 2
++ local data field
++ read data
++ '[' 2 -lt 0 ']'
++ field='$3'
++ echo '| id    | ffcad3cc0ea44a6b9463782b9dfb531b |'
++ awk '-F[ \t]*\\|[ \t]*' '{print $3}'
++ read data
+ user_role_id=ffcad3cc0ea44a6b9463782b9dfb531b
+ echo ffcad3cc0ea44a6b9463782b9dfb531b
+ is_service_enabled s-proxy
++ set +o
++ grep xtrace
+ local 'xtrace=set -o xtrace'
+ set +o xtrace
+ return 0
++ get_or_create_user glance-swift Passw0rd service glance-swift@example.com
++ [[ ! -z glance-swift@example.com ]]
++ local email=--email=glance-swift@example.com
+++ openstack user show glance-swift -f value -c id
+++ openstack user create glance-swift --password Passw0rd --project service --email=glance-swift@example.com -f value -c id
++ local user_id=3370418864424660b22994edaaa68410
++ echo 3370418864424660b22994edaaa68410
+ local glance_swift_user=3370418864424660b22994edaaa68410
+ get_or_add_user_role ResellerAdmin 3370418864424660b22994edaaa68410 service
++ openstack user role list 3370418864424660b22994edaaa68410 --project service --column ID --column Name
++ grep ' ResellerAdmin '
++ get_field 1
++ local data field
++ read data
+ local user_role_id=
+ [[ -z '' ]]
++ openstack role add ResellerAdmin --user 3370418864424660b22994edaaa68410 --project service
++ grep ' id '
++ get_field 2
++ local data field
++ read data
++ '[' 2 -lt 0 ']'
++ field='$3'
++ echo '| id    | 80c294908f4643f295eca766f96ae048 |'
++ awk '-F[ \t]*\\|[ \t]*' '{print $3}'
++ read data
+ user_role_id=80c294908f4643f295eca766f96ae048
+ echo 80c294908f4643f295eca766f96ae048
+ [[ sql = \s\q\l ]]
++ get_or_create_service glance image 'Glance Image Service'
+++ openstack service show glance -f value -c id
+++ openstack service create glance --type=image '--description=Glance Image Service' -f value -c id
++ local service_id=004fff1a23ce4395a7a6ce8b5419dc66
++ echo 004fff1a23ce4395a7a6ce8b5419dc66
+ local glance_service=004fff1a23ce4395a7a6ce8b5419dc66
+ get_or_create_endpoint 004fff1a23ce4395a7a6ce8b5419dc66 RegionOne http://10.14.0.26:9292 http://10.14.0.26:9292 http://10.14.0.26:9292
++ openstack endpoint list --column ID --column Region --column 'Service Name'
++ grep ' RegionOne '
++ grep ' 004fff1a23ce4395a7a6ce8b5419dc66 '
++ get_field 1
++ local data field
++ read data
+ local endpoint_id=
+ [[ -z '' ]]
++ openstack endpoint create 004fff1a23ce4395a7a6ce8b5419dc66 --region RegionOne --publicurl http://10.14.0.26:9292 --adminurl http://10.14.0.26:9292 --internalurl http://10.14.0.26:9292
++ grep ' id '
++ get_field 2
++ local data field
++ read data
++ '[' 2 -lt 0 ']'
++ field='$3'
++ echo '| id           | 9776e6c4345a45069a96e9f82d0159f7 |'
++ awk '-F[ \t]*\\|[ \t]*' '{print $3}'
++ read data
+ endpoint_id=9776e6c4345a45069a96e9f82d0159f7
+ echo 9776e6c4345a45069a96e9f82d0159f7
+ create_cinder_accounts
++ openstack project list
++ awk '/ service / { print $2 }'
+ local service_tenant=8d6b5a09210d46e69aaf5d0d3693fb5d
++ openstack role list
++ awk '/ admin / { print $2 }'
+ local admin_role=a73e26b53d1d4f81992b1698c5a69300
+ [[ g-api,g-reg,key,n-api,n-crt,n-obj,n-cond,n-sch,n-xvnc,n-cauth,c-sch,c-api,c-vol,h-eng,h-api,h-api-cfn,h-api-cw,rabbit,tempest,mysql,neutron,q-svc,q-agt,q-dhcp,q-l3,q-meta,q-lbaas,q-fwaas,q-metering,q-vpn,c-bak,s-proxy,s-object,s-container,s-account,heat,ceilometer-acentral,ceilometer-collector,ceilometer-api =~ c-api ]]
++ get_or_create_user cinder Passw0rd 8d6b5a09210d46e69aaf5d0d3693fb5d
++ [[ ! -z '' ]]
++ local email=
+++ openstack user show cinder -f value -c id
+++ openstack user create cinder --password Passw0rd --project 8d6b5a09210d46e69aaf5d0d3693fb5d -f value -c id
++ local user_id=f6c0dbc07016485fbaf80a52d9141bb2
++ echo f6c0dbc07016485fbaf80a52d9141bb2
+ local cinder_user=f6c0dbc07016485fbaf80a52d9141bb2
+ get_or_add_user_role a73e26b53d1d4f81992b1698c5a69300 f6c0dbc07016485fbaf80a52d9141bb2 8d6b5a09210d46e69aaf5d0d3693fb5d
++ openstack user role list f6c0dbc07016485fbaf80a52d9141bb2 --project 8d6b5a09210d46e69aaf5d0d3693fb5d --column ID --column Name
++ grep ' a73e26b53d1d4f81992b1698c5a69300 '
++ get_field 1
++ local data field
++ read data
+ local user_role_id=
+ [[ -z '' ]]
++ openstack role add a73e26b53d1d4f81992b1698c5a69300 --user f6c0dbc07016485fbaf80a52d9141bb2 --project 8d6b5a09210d46e69aaf5d0d3693fb5d
++ grep ' id '
++ get_field 2
++ local data field
++ read data
++ '[' 2 -lt 0 ']'
++ field='$3'
++ echo '| id    | a73e26b53d1d4f81992b1698c5a69300 |'
++ awk '-F[ \t]*\\|[ \t]*' '{print $3}'
++ read data
+ user_role_id=a73e26b53d1d4f81992b1698c5a69300
+ echo a73e26b53d1d4f81992b1698c5a69300
+ [[ sql = \s\q\l ]]
++ get_or_create_service cinder volume 'Cinder Volume Service'
+++ openstack service show cinder -f value -c id
+++ openstack service create cinder --type=volume '--description=Cinder Volume Service' -f value -c id
++ local service_id=a8fdcb101cfc4916a9b27fc442682a9d
++ echo a8fdcb101cfc4916a9b27fc442682a9d
+ local cinder_service=a8fdcb101cfc4916a9b27fc442682a9d
+ get_or_create_endpoint a8fdcb101cfc4916a9b27fc442682a9d RegionOne 'http://10.14.0.26:8776/v1/$(tenant_id)s' 'http://10.14.0.26:8776/v1/$(tenant_id)s' 'http://10.14.0.26:8776/v1/$(tenant_id)s'
++ openstack endpoint list --column ID --column Region --column 'Service Name'
++ grep ' RegionOne '
++ grep ' a8fdcb101cfc4916a9b27fc442682a9d '
++ get_field 1
++ local data field
++ read data
+ local endpoint_id=
+ [[ -z '' ]]
++ openstack endpoint create a8fdcb101cfc4916a9b27fc442682a9d --region RegionOne --publicurl 'http://10.14.0.26:8776/v1/$(tenant_id)s' --adminurl 'http://10.14.0.26:8776/v1/$(tenant_id)s' --internalurl 'http://10.14.0.26:8776/v1/$(tenant_id)s'
++ grep ' id '
++ get_field 2
++ local data field
++ read data
++ '[' 2 -lt 0 ']'
++ field='$3'
++ echo '| id           | 19bc03f0a7d348eab664ad22555d6f0a        |'
++ awk '-F[ \t]*\\|[ \t]*' '{print $3}'
++ read data
+ endpoint_id=19bc03f0a7d348eab664ad22555d6f0a
+ echo 19bc03f0a7d348eab664ad22555d6f0a
++ get_or_create_service cinderv2 volumev2 'Cinder Volume Service V2'
+++ openstack service show cinderv2 -f value -c id
+++ openstack service create cinderv2 --type=volumev2 '--description=Cinder Volume Service V2' -f value -c id
++ local service_id=12f6ea0cd0fa4a95a16168c124c473b0
++ echo 12f6ea0cd0fa4a95a16168c124c473b0
+ local cinder_v2_service=12f6ea0cd0fa4a95a16168c124c473b0
+ get_or_create_endpoint 12f6ea0cd0fa4a95a16168c124c473b0 RegionOne 'http://10.14.0.26:8776/v2/$(tenant_id)s' 'http://10.14.0.26:8776/v2/$(tenant_id)s' 'http://10.14.0.26:8776/v2/$(tenant_id)s'
++ openstack endpoint list --column ID --column Region --column 'Service Name'
++ grep ' RegionOne '
++ grep ' 12f6ea0cd0fa4a95a16168c124c473b0 '
++ get_field 1
++ local data field
++ read data
+ local endpoint_id=
+ [[ -z '' ]]
++ openstack endpoint create 12f6ea0cd0fa4a95a16168c124c473b0 --region RegionOne --publicurl 'http://10.14.0.26:8776/v2/$(tenant_id)s' --adminurl 'http://10.14.0.26:8776/v2/$(tenant_id)s' --internalurl 'http://10.14.0.26:8776/v2/$(tenant_id)s'
++ grep ' id '
++ get_field 2
++ local data field
++ read data
++ '[' 2 -lt 0 ']'
++ field='$3'
++ echo '| id           | bb84a10f80424cb0bd14677a86facab0        |'
++ awk '-F[ \t]*\\|[ \t]*' '{print $3}'
++ read data
+ endpoint_id=bb84a10f80424cb0bd14677a86facab0
+ echo bb84a10f80424cb0bd14677a86facab0
+ create_neutron_accounts
++ openstack project list
++ awk '/ service / { print $2 }'
+ local service_tenant=8d6b5a09210d46e69aaf5d0d3693fb5d
++ openstack role list
++ awk '/ service / { print $2 }'
+ local service_role=ffcad3cc0ea44a6b9463782b9dfb531b
+ [[ g-api,g-reg,key,n-api,n-crt,n-obj,n-cond,n-sch,n-xvnc,n-cauth,c-sch,c-api,c-vol,h-eng,h-api,h-api-cfn,h-api-cw,rabbit,tempest,mysql,neutron,q-svc,q-agt,q-dhcp,q-l3,q-meta,q-lbaas,q-fwaas,q-metering,q-vpn,c-bak,s-proxy,s-object,s-container,s-account,heat,ceilometer-acentral,ceilometer-collector,ceilometer-api =~ q-svc ]]
++ get_or_create_user neutron Passw0rd 8d6b5a09210d46e69aaf5d0d3693fb5d
++ [[ ! -z '' ]]
++ local email=
+++ openstack user show neutron -f value -c id
+++ openstack user create neutron --password Passw0rd --project 8d6b5a09210d46e69aaf5d0d3693fb5d -f value -c id
++ local user_id=b4c173671e294952b03b6f7d7079d230
++ echo b4c173671e294952b03b6f7d7079d230
+ local neutron_user=b4c173671e294952b03b6f7d7079d230
+ get_or_add_user_role ffcad3cc0ea44a6b9463782b9dfb531b b4c173671e294952b03b6f7d7079d230 8d6b5a09210d46e69aaf5d0d3693fb5d
++ openstack user role list b4c173671e294952b03b6f7d7079d230 --project 8d6b5a09210d46e69aaf5d0d3693fb5d --column ID --column Name
++ grep ' ffcad3cc0ea44a6b9463782b9dfb531b '
++ get_field 1
++ local data field
++ read data
+ local user_role_id=
+ [[ -z '' ]]
++ openstack role add ffcad3cc0ea44a6b9463782b9dfb531b --user b4c173671e294952b03b6f7d7079d230 --project 8d6b5a09210d46e69aaf5d0d3693fb5d
++ grep ' id '
++ get_field 2
++ local data field
++ read data
++ '[' 2 -lt 0 ']'
++ field='$3'
++ echo '| id    | ffcad3cc0ea44a6b9463782b9dfb531b |'
++ awk '-F[ \t]*\\|[ \t]*' '{print $3}'
++ read data
+ user_role_id=ffcad3cc0ea44a6b9463782b9dfb531b
+ echo ffcad3cc0ea44a6b9463782b9dfb531b
+ [[ sql = \s\q\l ]]
++ get_or_create_service neutron network 'Neutron Service'
+++ openstack service show neutron -f value -c id
+++ openstack service create neutron --type=network '--description=Neutron Service' -f value -c id
++ local service_id=a017880d23694c9282dff47e4c7dfe95
++ echo a017880d23694c9282dff47e4c7dfe95
+ local neutron_service=a017880d23694c9282dff47e4c7dfe95
+ get_or_create_endpoint a017880d23694c9282dff47e4c7dfe95 RegionOne http://10.14.0.26:9696/ http://10.14.0.26:9696/ http://10.14.0.26:9696/
++ openstack endpoint list --column ID --column Region --column 'Service Name'
++ grep ' RegionOne '
++ grep ' a017880d23694c9282dff47e4c7dfe95 '
++ get_field 1
++ local data field
++ read data
+ local endpoint_id=
+ [[ -z '' ]]
++ openstack endpoint create a017880d23694c9282dff47e4c7dfe95 --region RegionOne --publicurl http://10.14.0.26:9696/ --adminurl http://10.14.0.26:9696/ --internalurl http://10.14.0.26:9696/
++ grep ' id '
++ get_field 2
++ local data field
++ read data
++ '[' 2 -lt 0 ']'
++ field='$3'
++ echo '| id           | 2dc25b5ec79b4b6c9fea98b386c0850c |'
++ awk '-F[ \t]*\\|[ \t]*' '{print $3}'
++ read data
+ endpoint_id=2dc25b5ec79b4b6c9fea98b386c0850c
+ echo 2dc25b5ec79b4b6c9fea98b386c0850c
+ is_service_enabled ceilometer
++ set +o
++ grep xtrace
+ local 'xtrace=set -o xtrace'
+ set +o xtrace
+ return 0
+ create_ceilometer_accounts
++ openstack project list
++ awk '/ service / { print $2 }'
+ local service_tenant=8d6b5a09210d46e69aaf5d0d3693fb5d
++ openstack role list
++ awk '/ admin / { print $2 }'
+ local admin_role=a73e26b53d1d4f81992b1698c5a69300
+ [[ g-api,g-reg,key,n-api,n-crt,n-obj,n-cond,n-sch,n-xvnc,n-cauth,c-sch,c-api,c-vol,h-eng,h-api,h-api-cfn,h-api-cw,rabbit,tempest,mysql,neutron,q-svc,q-agt,q-dhcp,q-l3,q-meta,q-lbaas,q-fwaas,q-metering,q-vpn,c-bak,s-proxy,s-object,s-container,s-account,heat,ceilometer-acentral,ceilometer-collector,ceilometer-api =~ ceilometer-api ]]
++ get_or_create_user ceilometer Passw0rd 8d6b5a09210d46e69aaf5d0d3693fb5d
++ [[ ! -z '' ]]
++ local email=
+++ openstack user show ceilometer -f value -c id
+++ openstack user create ceilometer --password Passw0rd --project 8d6b5a09210d46e69aaf5d0d3693fb5d -f value -c id
++ local user_id=44522d0b842d4472b2b50c116fd8ccbe
++ echo 44522d0b842d4472b2b50c116fd8ccbe
+ local ceilometer_user=44522d0b842d4472b2b50c116fd8ccbe
+ get_or_add_user_role a73e26b53d1d4f81992b1698c5a69300 44522d0b842d4472b2b50c116fd8ccbe 8d6b5a09210d46e69aaf5d0d3693fb5d
++ openstack user role list 44522d0b842d4472b2b50c116fd8ccbe --project 8d6b5a09210d46e69aaf5d0d3693fb5d --column ID --column Name
++ grep ' a73e26b53d1d4f81992b1698c5a69300 '
++ get_field 1
++ local data field
++ read data
+ local user_role_id=
+ [[ -z '' ]]
++ openstack role add a73e26b53d1d4f81992b1698c5a69300 --user 44522d0b842d4472b2b50c116fd8ccbe --project 8d6b5a09210d46e69aaf5d0d3693fb5d
++ grep ' id '
++ get_field 2
++ local data field
++ read data
++ '[' 2 -lt 0 ']'
++ field='$3'
++ echo '| id    | a73e26b53d1d4f81992b1698c5a69300 |'
++ awk '-F[ \t]*\\|[ \t]*' '{print $3}'
++ read data
+ user_role_id=a73e26b53d1d4f81992b1698c5a69300
+ echo a73e26b53d1d4f81992b1698c5a69300
+ [[ sql = \s\q\l ]]
++ get_or_create_service ceilometer metering 'OpenStack Telemetry Service'
+++ openstack service show ceilometer -f value -c id
+++ openstack service create ceilometer --type=metering '--description=OpenStack Telemetry Service' -f value -c id
++ local service_id=5b24eee552164c33977000fa1a92fd2b
++ echo 5b24eee552164c33977000fa1a92fd2b
+ local ceilometer_service=5b24eee552164c33977000fa1a92fd2b
+ get_or_create_endpoint 5b24eee552164c33977000fa1a92fd2b RegionOne http://10.14.0.26:8777/ http://10.14.0.26:8777/ http://10.14.0.26:8777/
++ openstack endpoint list --column ID --column Region --column 'Service Name'
++ grep ' RegionOne '
++ grep ' 5b24eee552164c33977000fa1a92fd2b '
++ get_field 1
++ local data field
++ read data
+ local endpoint_id=
+ [[ -z '' ]]
++ openstack endpoint create 5b24eee552164c33977000fa1a92fd2b --region RegionOne --publicurl http://10.14.0.26:8777/ --adminurl http://10.14.0.26:8777/ --internalurl http://10.14.0.26:8777/
++ grep ' id '
++ get_field 2
++ local data field
++ read data
++ '[' 2 -lt 0 ']'
++ field='$3'
++ echo '| id           | e47c4a863b4042b19b3ff76f8e986d69 |'
++ awk '-F[ \t]*\\|[ \t]*' '{print $3}'
++ read data
+ endpoint_id=e47c4a863b4042b19b3ff76f8e986d69
+ echo e47c4a863b4042b19b3ff76f8e986d69
+ is_service_enabled swift
++ set +o
++ grep xtrace
+ local 'xtrace=set -o xtrace'
+ set +o xtrace
+ return 0
+ get_or_add_user_role ResellerAdmin ceilometer service
++ openstack user role list ceilometer --project service --column ID --column Name
++ grep ' ResellerAdmin '
++ get_field 1
++ local data field
++ read data
+ local user_role_id=
+ [[ -z '' ]]
++ openstack role add ResellerAdmin --user ceilometer --project service
++ get_field 2
++ local data field
++ read data
++ grep ' id '
++ '[' 2 -lt 0 ']'
++ field='$3'
++ echo '| id    | 80c294908f4643f295eca766f96ae048 |'
++ awk '-F[ \t]*\\|[ \t]*' '{print $3}'
++ read data
+ user_role_id=80c294908f4643f295eca766f96ae048
+ echo 80c294908f4643f295eca766f96ae048
+ is_service_enabled swift
++ set +o
++ grep xtrace
+ local 'xtrace=set -o xtrace'
+ set +o xtrace
+ return 0
+ create_swift_accounts
+ export swiftusertest1_password=testing
+ swiftusertest1_password=testing
+ export swiftusertest2_password=testing2
+ swiftusertest2_password=testing2
+ export swiftusertest3_password=testing3
+ swiftusertest3_password=testing3
+ KEYSTONE_CATALOG_BACKEND=sql
++ openstack project list
++ awk '/ service / { print $2 }'
+ local service_tenant=8d6b5a09210d46e69aaf5d0d3693fb5d
++ openstack role list
++ awk '/ admin / { print $2 }'
+ local admin_role=a73e26b53d1d4f81992b1698c5a69300
++ openstack role list
++ awk '/ anotherrole / { print $2 }'
+ local another_role=8a3fc10d70964b229935633527998f0f
++ get_or_create_user swift Passw0rd 8d6b5a09210d46e69aaf5d0d3693fb5d
++ [[ ! -z '' ]]
++ local email=
+++ openstack user show swift -f value -c id
+++ openstack user create swift --password Passw0rd --project 8d6b5a09210d46e69aaf5d0d3693fb5d -f value -c id
++ local user_id=29d019a70982456c8a0520f1cc516a62
++ echo 29d019a70982456c8a0520f1cc516a62
+ local swift_user=29d019a70982456c8a0520f1cc516a62
+ get_or_add_user_role a73e26b53d1d4f81992b1698c5a69300 29d019a70982456c8a0520f1cc516a62 8d6b5a09210d46e69aaf5d0d3693fb5d
++ openstack user role list 29d019a70982456c8a0520f1cc516a62 --project 8d6b5a09210d46e69aaf5d0d3693fb5d --column ID --column Name
++ grep ' a73e26b53d1d4f81992b1698c5a69300 '
++ get_field 1
++ local data field
++ read data
+ local user_role_id=
+ [[ -z '' ]]
++ openstack role add a73e26b53d1d4f81992b1698c5a69300 --user 29d019a70982456c8a0520f1cc516a62 --project 8d6b5a09210d46e69aaf5d0d3693fb5d
++ grep ' id '
++ get_field 2
++ local data field
++ read data
++ '[' 2 -lt 0 ']'
++ field='$3'
++ echo '| id    | a73e26b53d1d4f81992b1698c5a69300 |'
++ awk '-F[ \t]*\\|[ \t]*' '{print $3}'
++ read data
+ user_role_id=a73e26b53d1d4f81992b1698c5a69300
+ echo a73e26b53d1d4f81992b1698c5a69300
+ [[ sql = \s\q\l ]]
++ get_or_create_service swift object-store 'Swift Service'
+++ openstack service show swift -f value -c id
+++ openstack service create swift --type=object-store '--description=Swift Service' -f value -c id
++ local service_id=3c4c48fcbba24c6e80870bfd3c4280c9
++ echo 3c4c48fcbba24c6e80870bfd3c4280c9
+ local swift_service=3c4c48fcbba24c6e80870bfd3c4280c9
+ get_or_create_endpoint 3c4c48fcbba24c6e80870bfd3c4280c9 RegionOne 'http://10.14.0.26:8080/v1/AUTH_$(tenant_id)s' http://10.14.0.26:8080 'http://10.14.0.26:8080/v1/AUTH_$(tenant_id)s'
++ openstack endpoint list --column ID --column Region --column 'Service Name'
++ grep ' RegionOne '
++ grep ' 3c4c48fcbba24c6e80870bfd3c4280c9 '
++ get_field 1
++ local data field
++ read data
+ local endpoint_id=
+ [[ -z '' ]]
++ openstack endpoint create 3c4c48fcbba24c6e80870bfd3c4280c9 --region RegionOne --publicurl 'http://10.14.0.26:8080/v1/AUTH_$(tenant_id)s' --adminurl http://10.14.0.26:8080 --internalurl 'http://10.14.0.26:8080/v1/AUTH_$(tenant_id)s'
++ grep ' id '
++ get_field 2
++ local data field
++ read data
++ '[' 2 -lt 0 ']'
++ field='$3'
++ echo '| id           | 8508e2220b2d4c2b829c72ab8ca8cbc1             |'
++ awk '-F[ \t]*\\|[ \t]*' '{print $3}'
++ read data
+ endpoint_id=8508e2220b2d4c2b829c72ab8ca8cbc1
+ echo 8508e2220b2d4c2b829c72ab8ca8cbc1
++ get_or_create_project swifttenanttest1
+++ openstack project show swifttenanttest1 -f value -c id
+++ openstack project create swifttenanttest1 -f value -c id
++ local project_id=edc9fc591c9c4dd8b266572970c8f1cb
++ echo edc9fc591c9c4dd8b266572970c8f1cb
+ local swift_tenant_test1=edc9fc591c9c4dd8b266572970c8f1cb
+ die_if_not_set 595 swift_tenant_test1 'Failure creating swift_tenant_test1'
+ local exitcode=0
++ set +o
++ grep xtrace
+ local 'xtrace=set -o xtrace'
+ set +o xtrace
++ get_or_create_user swiftusertest1 testing edc9fc591c9c4dd8b266572970c8f1cb test@example.com
++ [[ ! -z test@example.com ]]
++ local email=--email=test@example.com
+++ openstack user show swiftusertest1 -f value -c id
+++ openstack user create swiftusertest1 --password testing --project edc9fc591c9c4dd8b266572970c8f1cb --email=test@example.com -f value -c id
++ local user_id=a4b761ab10ca406499e6707a1b82c02b
++ echo a4b761ab10ca406499e6707a1b82c02b
+ SWIFT_USER_TEST1=a4b761ab10ca406499e6707a1b82c02b
+ die_if_not_set 598 SWIFT_USER_TEST1 'Failure creating SWIFT_USER_TEST1'
+ local exitcode=0
++ set +o
++ grep xtrace
+ local 'xtrace=set -o xtrace'
+ set +o xtrace
+ get_or_add_user_role a73e26b53d1d4f81992b1698c5a69300 a4b761ab10ca406499e6707a1b82c02b edc9fc591c9c4dd8b266572970c8f1cb
++ openstack user role list a4b761ab10ca406499e6707a1b82c02b --project edc9fc591c9c4dd8b266572970c8f1cb --column ID --column Name
++ grep ' a73e26b53d1d4f81992b1698c5a69300 '
++ get_field 1
++ local data field
++ read data
+ local user_role_id=
+ [[ -z '' ]]
++ openstack role add a73e26b53d1d4f81992b1698c5a69300 --user a4b761ab10ca406499e6707a1b82c02b --project edc9fc591c9c4dd8b266572970c8f1cb
++ grep ' id '
++ get_field 2
++ local data field
++ read data
++ '[' 2 -lt 0 ']'
++ field='$3'
++ echo '| id    | a73e26b53d1d4f81992b1698c5a69300 |'
++ awk '-F[ \t]*\\|[ \t]*' '{print $3}'
++ read data
+ user_role_id=a73e26b53d1d4f81992b1698c5a69300
+ echo a73e26b53d1d4f81992b1698c5a69300
++ get_or_create_user swiftusertest3 testing3 edc9fc591c9c4dd8b266572970c8f1cb test3@example.com
++ [[ ! -z test3@example.com ]]
++ local email=--email=test3@example.com
+++ openstack user show swiftusertest3 -f value -c id
+++ openstack user create swiftusertest3 --password testing3 --project edc9fc591c9c4dd8b266572970c8f1cb --email=test3@example.com -f value -c id
++ local user_id=ad4329a1a9ba428ba81f64376193cd7f
++ echo ad4329a1a9ba428ba81f64376193cd7f
+ local swift_user_test3=ad4329a1a9ba428ba81f64376193cd7f
+ die_if_not_set 603 swift_user_test3 'Failure creating swift_user_test3'
+ local exitcode=0
++ set +o
++ grep xtrace
+ local 'xtrace=set -o xtrace'
+ set +o xtrace
+ get_or_add_user_role 8a3fc10d70964b229935633527998f0f ad4329a1a9ba428ba81f64376193cd7f edc9fc591c9c4dd8b266572970c8f1cb
++ openstack user role list ad4329a1a9ba428ba81f64376193cd7f --project edc9fc591c9c4dd8b266572970c8f1cb --column ID --column Name
++ grep ' 8a3fc10d70964b229935633527998f0f '
++ get_field 1
++ local data field
++ read data
+ local user_role_id=
+ [[ -z '' ]]
++ openstack role add 8a3fc10d70964b229935633527998f0f --user ad4329a1a9ba428ba81f64376193cd7f --project edc9fc591c9c4dd8b266572970c8f1cb
++ grep ' id '
++ get_field 2
++ local data field
++ read data
++ '[' 2 -lt 0 ']'
++ field='$3'
++ echo '| id    | 8a3fc10d70964b229935633527998f0f |'
++ awk '-F[ \t]*\\|[ \t]*' '{print $3}'
++ read data
+ user_role_id=8a3fc10d70964b229935633527998f0f
+ echo 8a3fc10d70964b229935633527998f0f
++ get_or_create_project swifttenanttest2
+++ openstack project show swifttenanttest2 -f value -c id
+++ openstack project create swifttenanttest2 -f value -c id
++ local project_id=8a013c2d524f4385aafb383ed24a3c99
++ echo 8a013c2d524f4385aafb383ed24a3c99
+ local swift_tenant_test2=8a013c2d524f4385aafb383ed24a3c99
+ die_if_not_set 607 swift_tenant_test2 'Failure creating swift_tenant_test2'
+ local exitcode=0
++ set +o
++ grep xtrace
+ local 'xtrace=set -o xtrace'
+ set +o xtrace
++ get_or_create_user swiftusertest2 testing2 8a013c2d524f4385aafb383ed24a3c99 test2@example.com
++ [[ ! -z test2@example.com ]]
++ local email=--email=test2@example.com
+++ openstack user show swiftusertest2 -f value -c id
+++ openstack user create swiftusertest2 --password testing2 --project 8a013c2d524f4385aafb383ed24a3c99 --email=test2@example.com -f value -c id
++ local user_id=d19f4fd8dc854abbab4d78f055e74c40
++ echo d19f4fd8dc854abbab4d78f055e74c40
+ local swift_user_test2=d19f4fd8dc854abbab4d78f055e74c40
+ die_if_not_set 611 swift_user_test2 'Failure creating swift_user_test2'
+ local exitcode=0
++ set +o
++ grep xtrace
+ local 'xtrace=set -o xtrace'
+ set +o xtrace
+ get_or_add_user_role a73e26b53d1d4f81992b1698c5a69300 d19f4fd8dc854abbab4d78f055e74c40 8a013c2d524f4385aafb383ed24a3c99
++ openstack user role list d19f4fd8dc854abbab4d78f055e74c40 --project 8a013c2d524f4385aafb383ed24a3c99 --column ID --column Name
++ grep ' a73e26b53d1d4f81992b1698c5a69300 '
++ get_field 1
++ local data field
++ read data
+ local user_role_id=
+ [[ -z '' ]]
++ openstack role add a73e26b53d1d4f81992b1698c5a69300 --user d19f4fd8dc854abbab4d78f055e74c40 --project 8a013c2d524f4385aafb383ed24a3c99
++ grep ' id '
++ get_field 2
++ local data field
++ read data
++ '[' 2 -lt 0 ']'
++ field='$3'
++ echo '| id    | a73e26b53d1d4f81992b1698c5a69300 |'
++ awk '-F[ \t]*\\|[ \t]*' '{print $3}'
++ read data
+ user_role_id=a73e26b53d1d4f81992b1698c5a69300
+ echo a73e26b53d1d4f81992b1698c5a69300
+ is_service_enabled heat
++ set +o
++ grep xtrace
+ local 'xtrace=set -o xtrace'
+ set +o xtrace
+ return 0
+ [[ False != \T\r\u\e ]]
+ create_heat_accounts
++ openstack project list
++ awk '/ service / { print $2 }'
+ local service_tenant=8d6b5a09210d46e69aaf5d0d3693fb5d
++ openstack role list
++ awk '/ admin / { print $2 }'
+ local admin_role=a73e26b53d1d4f81992b1698c5a69300
++ get_or_create_user heat Passw0rd 8d6b5a09210d46e69aaf5d0d3693fb5d
++ [[ ! -z '' ]]
++ local email=
+++ openstack user show heat -f value -c id
+++ openstack user create heat --password Passw0rd --project 8d6b5a09210d46e69aaf5d0d3693fb5d -f value -c id
++ local user_id=975df84caee142c3b51e9e95cc672c34
++ echo 975df84caee142c3b51e9e95cc672c34
+ local heat_user=975df84caee142c3b51e9e95cc672c34
+ get_or_add_user_role a73e26b53d1d4f81992b1698c5a69300 975df84caee142c3b51e9e95cc672c34 8d6b5a09210d46e69aaf5d0d3693fb5d
++ openstack user role list 975df84caee142c3b51e9e95cc672c34 --project 8d6b5a09210d46e69aaf5d0d3693fb5d --column ID --column Name
++ grep ' a73e26b53d1d4f81992b1698c5a69300 '
++ get_field 1
++ local data field
++ read data
+ local user_role_id=
+ [[ -z '' ]]
++ openstack role add a73e26b53d1d4f81992b1698c5a69300 --user 975df84caee142c3b51e9e95cc672c34 --project 8d6b5a09210d46e69aaf5d0d3693fb5d
++ grep ' id '
++ get_field 2
++ local data field
++ read data
++ '[' 2 -lt 0 ']'
++ field='$3'
++ echo '| id    | a73e26b53d1d4f81992b1698c5a69300 |'
++ awk '-F[ \t]*\\|[ \t]*' '{print $3}'
++ read data
+ user_role_id=a73e26b53d1d4f81992b1698c5a69300
+ echo a73e26b53d1d4f81992b1698c5a69300
+ [[ sql = \s\q\l ]]
++ get_or_create_service heat orchestration 'Heat Orchestration Service'
+++ openstack service show heat -f value -c id
+++ openstack service create heat --type=orchestration '--description=Heat Orchestration Service' -f value -c id
++ local service_id=0fdfeeefdee5431c8f199c3aa64e740e
++ echo 0fdfeeefdee5431c8f199c3aa64e740e
+ local heat_service=0fdfeeefdee5431c8f199c3aa64e740e
+ get_or_create_endpoint 0fdfeeefdee5431c8f199c3aa64e740e RegionOne 'http://10.14.0.26:8004/v1/$(tenant_id)s' 'http://10.14.0.26:8004/v1/$(tenant_id)s' 'http://10.14.0.26:8004/v1/$(tenant_id)s'
++ openstack endpoint list --column ID --column Region --column 'Service Name'
++ grep ' RegionOne '
++ grep ' 0fdfeeefdee5431c8f199c3aa64e740e '
++ get_field 1
++ local data field
++ read data
+ local endpoint_id=
+ [[ -z '' ]]
++ openstack endpoint create 0fdfeeefdee5431c8f199c3aa64e740e --region RegionOne --publicurl 'http://10.14.0.26:8004/v1/$(tenant_id)s' --adminurl 'http://10.14.0.26:8004/v1/$(tenant_id)s' --internalurl 'http://10.14.0.26:8004/v1/$(tenant_id)s'
++ grep ' id '
++ get_field 2
++ local data field
++ read data
++ '[' 2 -lt 0 ']'
++ field='$3'
++ echo '| id           | e0f4f0e325ad4d9a8fc703a344486587        |'
++ awk '-F[ \t]*\\|[ \t]*' '{print $3}'
++ read data
+ endpoint_id=e0f4f0e325ad4d9a8fc703a344486587
+ echo e0f4f0e325ad4d9a8fc703a344486587
++ get_or_create_service heat-cfn cloudformation 'Heat CloudFormation Service'
+++ openstack service show heat-cfn -f value -c id
+++ openstack service create heat-cfn --type=cloudformation '--description=Heat CloudFormation Service' -f value -c id
++ local service_id=3334bef23f8f49f78a6ce161fee349a4
++ echo 3334bef23f8f49f78a6ce161fee349a4
+ local heat_cfn_service=3334bef23f8f49f78a6ce161fee349a4
+ get_or_create_endpoint 3334bef23f8f49f78a6ce161fee349a4 RegionOne http://10.14.0.26:8000/v1 http://10.14.0.26:8000/v1 http://10.14.0.26:8000/v1
++ openstack endpoint list --column ID --column Region --column 'Service Name'
++ grep ' 3334bef23f8f49f78a6ce161fee349a4 '
++ get_field 1
++ local data field
++ read data
++ grep ' RegionOne '
+ local endpoint_id=
+ [[ -z '' ]]
++ openstack endpoint create 3334bef23f8f49f78a6ce161fee349a4 --region RegionOne --publicurl http://10.14.0.26:8000/v1 --adminurl http://10.14.0.26:8000/v1 --internalurl http://10.14.0.26:8000/v1
++ get_field 2
++ local data field
++ read data
++ grep ' id '
++ '[' 2 -lt 0 ']'
++ field='$3'
++ echo '| id           | aef3b019564f40738357aaec5856272f |'
++ awk '-F[ \t]*\\|[ \t]*' '{print $3}'
++ read data
+ endpoint_id=aef3b019564f40738357aaec5856272f
+ echo aef3b019564f40738357aaec5856272f
+ get_or_create_role heat_stack_user
++ openstack role show heat_stack_user -f value -c id
++ openstack role create heat_stack_user -f value -c id
+ local role_id=ba9792865f804a6cb61eedec6d35b6d0
+ echo ba9792865f804a6cb61eedec6d35b6d0
+ [[ trusts == trusts ]]
++ get_or_create_role heat_stack_owner
+++ openstack role show heat_stack_owner -f value -c id
+++ openstack role create heat_stack_owner -f value -c id
++ local role_id=05652d9d686b4f46abe633408ecb347c
++ echo 05652d9d686b4f46abe633408ecb347c
+ local heat_owner_role=05652d9d686b4f46abe633408ecb347c
+ get_or_add_user_role 05652d9d686b4f46abe633408ecb347c demo demo
++ openstack user role list demo --project demo --column ID --column Name
++ grep ' 05652d9d686b4f46abe633408ecb347c '
++ get_field 1
++ local data field
++ read data
+ local user_role_id=
+ [[ -z '' ]]
++ openstack role add 05652d9d686b4f46abe633408ecb347c --user demo --project demo
++ grep ' id '
++ get_field 2
++ local data field
++ read data
++ '[' 2 -lt 0 ']'
++ field='$3'
++ echo '| id    | 05652d9d686b4f46abe633408ecb347c |'
++ awk '-F[ \t]*\\|[ \t]*' '{print $3}'
++ read data
+ user_role_id=05652d9d686b4f46abe633408ecb347c
+ echo 05652d9d686b4f46abe633408ecb347c
+ get_or_add_user_role 05652d9d686b4f46abe633408ecb347c admin demo
++ openstack user role list admin --project demo --column ID --column Name
++ grep ' 05652d9d686b4f46abe633408ecb347c '
++ get_field 1
++ local data field
++ read data
+ local user_role_id=
+ [[ -z '' ]]
++ openstack role add 05652d9d686b4f46abe633408ecb347c --user admin --project demo
++ grep ' id '
++ get_field 2
++ local data field
++ read data
++ '[' 2 -lt 0 ']'
++ field='$3'
++ echo '| id    | 05652d9d686b4f46abe633408ecb347c |'
++ awk '-F[ \t]*\\|[ \t]*' '{print $3}'
++ read data
+ user_role_id=05652d9d686b4f46abe633408ecb347c
+ echo 05652d9d686b4f46abe633408ecb347c
+ get_or_add_user_role 05652d9d686b4f46abe633408ecb347c admin admin
++ openstack user role list admin --project admin --column ID --column Name
++ get_field 1
++ grep ' 05652d9d686b4f46abe633408ecb347c '
++ local data field
++ read data
+ local user_role_id=
+ [[ -z '' ]]
++ openstack role add 05652d9d686b4f46abe633408ecb347c --user admin --project admin
++ grep ' id '
++ get_field 2
++ local data field
++ read data
++ '[' 2 -lt 0 ']'
++ field='$3'
++ echo '| id    | 05652d9d686b4f46abe633408ecb347c |'
++ awk '-F[ \t]*\\|[ \t]*' '{print $3}'
++ read data
+ user_role_id=05652d9d686b4f46abe633408ecb347c
+ echo 05652d9d686b4f46abe633408ecb347c
+ iniset /etc/heat/heat.conf DEFAULT deferred_auth_method trusts
++ set +o
++ grep xtrace
+ local 'xtrace=set -o xtrace'
+ set +o xtrace
+ [[ True == \T\r\u\e ]]
+ local ks_endpoint_v3=http://10.14.0.26:5000/v3
++ openstack --os-token Passw0rd --os-url=http://10.14.0.26:5000/v3 --os-identity-api-version=3 domain list
++ grep ' heat '
++ get_field 1
++ local data field
++ read data
+ D_ID=
+ [[ -z '' ]]
++ openstack --os-token Passw0rd --os-url=http://10.14.0.26:5000/v3 --os-identity-api-version=3 domain create heat --description 'Owns users and projects created by heat'
++ grep ' id '
++ get_field 2
++ local data field
++ read data
++ '[' 2 -lt 0 ']'
++ field='$3'
++ echo '| id          | 1c53db7adb784012a4275a925031e765        |'
++ awk '-F[ \t]*\\|[ \t]*' '{print $3}'
++ read data
+ D_ID=1c53db7adb784012a4275a925031e765
+ iniset /etc/heat/heat.conf DEFAULT stack_user_domain_id 1c53db7adb784012a4275a925031e765
++ set +o
++ grep xtrace
+ local 'xtrace=set -o xtrace'
+ set +o xtrace
+ openstack --os-token Passw0rd --os-url=http://10.14.0.26:5000/v3 --os-identity-api-version=3 user create --password Passw0rd --domain 1c53db7adb784012a4275a925031e765 heat_domain_admin --description 'Manages users and projects created by heat'
+ openstack --os-token Passw0rd --os-url=http://10.14.0.26:5000/v3 --os-identity-api-version=3 role add --user heat_domain_admin --domain 1c53db7adb784012a4275a925031e765 admin
+ iniset /etc/heat/heat.conf DEFAULT stack_domain_admin heat_domain_admin
++ set +o
++ grep xtrace
+ local 'xtrace=set -o xtrace'
+ set +o xtrace
+ iniset /etc/heat/heat.conf DEFAULT stack_domain_admin_password Passw0rd
++ set +o
++ grep xtrace
+ local 'xtrace=set -o xtrace'
+ set +o xtrace
+ unset OS_TOKEN OS_URL
+ export OS_AUTH_URL=http://10.14.0.26:35357/v2.0
+ OS_AUTH_URL=http://10.14.0.26:35357/v2.0
+ export OS_TENANT_NAME=admin
+ OS_TENANT_NAME=admin
+ export OS_USERNAME=admin
+ OS_USERNAME=admin
+ export OS_PASSWORD=Passw0rd
+ OS_PASSWORD=Passw0rd
+ export OS_REGION_NAME=RegionOne
+ OS_REGION_NAME=RegionOne
+ is_service_enabled horizon
++ set +o
++ grep xtrace
+ local 'xtrace=set -o xtrace'
+ set +o xtrace
+ return 1
+ is_service_enabled g-reg
++ set +o
++ grep xtrace
+ local 'xtrace=set -o xtrace'
+ set +o xtrace
+ return 0
+ echo_summary 'Configuring Glance'
+ [[ -t 3 ]]
+ echo -e Configuring Glance
+ init_glance
+ rm -rf /opt/stack/data/glance/images
+ mkdir -p /opt/stack/data/glance/images
+ rm -rf /opt/stack/data/glance/cache
+ mkdir -p /opt/stack/data/glance/cache
+ recreate_database glance utf8
+ local db=glance
+ local charset=utf8
+ recreate_database_mysql glance utf8
+ local db=glance
+ local charset=utf8
+ mysql -uroot -pPassw0rd -h127.0.0.1 -e 'DROP DATABASE IF EXISTS glance;'
+ mysql -uroot -pPassw0rd -h127.0.0.1 -e 'CREATE DATABASE glance CHARACTER SET utf8;'
+ /usr/local/bin/glance-manage db_sync
2014-12-12 16:31:22.150 15678 DEBUG oslo.db.sqlalchemy.session [-] MySQL server mode set to STRICT_TRANS_TABLES,STRICT_ALL_TABLES,NO_ZERO_IN_DATE,NO_ZERO_DATE,ERROR_FOR_DIVISION_BY_ZERO,TRADITIONAL,NO_AUTO_CREATE_USER,NO_ENGINE_SUBSTITUTION _init_events /usr/local/lib/python2.7/dist-packages/oslo/db/sqlalchemy/session.py:474
2014-12-12 16:31:22.152 15678 DEBUG migrate.versioning.repository [-] Loading repository /opt/stack/glance/glance/db/sqlalchemy/migrate_repo... __init__ /usr/local/lib/python2.7/dist-packages/migrate/versioning/repository.py:76
2014-12-12 16:31:22.153 15678 DEBUG migrate.versioning.script.base [-] Loading script /opt/stack/glance/glance/db/sqlalchemy/migrate_repo/versions/001_add_images_table.py... __init__ /usr/local/lib/python2.7/dist-packages/migrate/versioning/script/base.py:27
2014-12-12 16:31:22.153 15678 DEBUG migrate.versioning.script.base [-] Script /opt/stack/glance/glance/db/sqlalchemy/migrate_repo/versions/001_add_images_table.py loaded successfully __init__ /usr/local/lib/python2.7/dist-packages/migrate/versioning/script/base.py:30
2014-12-12 16:31:22.153 15678 DEBUG migrate.versioning.script.base [-] Loading script /opt/stack/glance/glance/db/sqlalchemy/migrate_repo/versions/002_add_image_properties_table.py... __init__ /usr/local/lib/python2.7/dist-packages/migrate/versioning/script/base.py:27
2014-12-12 16:31:22.153 15678 DEBUG migrate.versioning.script.base [-] Script /opt/stack/glance/glance/db/sqlalchemy/migrate_repo/versions/002_add_image_properties_table.py loaded successfully __init__ /usr/local/lib/python2.7/dist-packages/migrate/versioning/script/base.py:30
2014-12-12 16:31:22.153 15678 DEBUG migrate.versioning.script.base [-] Loading script /opt/stack/glance/glance/db/sqlalchemy/migrate_repo/versions/003_sqlite_downgrade.sql... __init__ /usr/local/lib/python2.7/dist-packages/migrate/versioning/script/base.py:27
2014-12-12 16:31:22.153 15678 DEBUG migrate.versioning.script.base [-] Script /opt/stack/glance/glance/db/sqlalchemy/migrate_repo/versions/003_sqlite_downgrade.sql loaded successfully __init__ /usr/local/lib/python2.7/dist-packages/migrate/versioning/script/base.py:30
2014-12-12 16:31:22.153 15678 DEBUG migrate.versioning.script.base [-] Loading script /opt/stack/glance/glance/db/sqlalchemy/migrate_repo/versions/003_sqlite_upgrade.sql... __init__ /usr/local/lib/python2.7/dist-packages/migrate/versioning/script/base.py:27
2014-12-12 16:31:22.154 15678 DEBUG migrate.versioning.script.base [-] Script /opt/stack/glance/glance/db/sqlalchemy/migrate_repo/versions/003_sqlite_upgrade.sql loaded successfully __init__ /usr/local/lib/python2.7/dist-packages/migrate/versioning/script/base.py:30
2014-12-12 16:31:22.154 15678 DEBUG migrate.versioning.script.base [-] Loading script /opt/stack/glance/glance/db/sqlalchemy/migrate_repo/versions/003_add_disk_format.py... __init__ /usr/local/lib/python2.7/dist-packages/migrate/versioning/script/base.py:27
2014-12-12 16:31:22.154 15678 DEBUG migrate.versioning.script.base [-] Script /opt/stack/glance/glance/db/sqlalchemy/migrate_repo/versions/003_add_disk_format.py loaded successfully __init__ /usr/local/lib/python2.7/dist-packages/migrate/versioning/script/base.py:30
2014-12-12 16:31:22.154 15678 DEBUG migrate.versioning.script.base [-] Loading script /opt/stack/glance/glance/db/sqlalchemy/migrate_repo/versions/004_add_checksum.py... __init__ /usr/local/lib/python2.7/dist-packages/migrate/versioning/script/base.py:27
2014-12-12 16:31:22.154 15678 DEBUG migrate.versioning.script.base [-] Script /opt/stack/glance/glance/db/sqlalchemy/migrate_repo/versions/004_add_checksum.py loaded successfully __init__ /usr/local/lib/python2.7/dist-packages/migrate/versioning/script/base.py:30
2014-12-12 16:31:22.154 15678 DEBUG migrate.versioning.script.base [-] Loading script /opt/stack/glance/glance/db/sqlalchemy/migrate_repo/versions/005_size_big_integer.py... __init__ /usr/local/lib/python2.7/dist-packages/migrate/versioning/script/base.py:27
2014-12-12 16:31:22.154 15678 DEBUG migrate.versioning.script.base [-] Script /opt/stack/glance/glance/db/sqlalchemy/migrate_repo/versions/005_size_big_integer.py loaded successfully __init__ /usr/local/lib/python2.7/dist-packages/migrate/versioning/script/base.py:30
2014-12-12 16:31:22.154 15678 DEBUG migrate.versioning.script.base [-] Loading script /opt/stack/glance/glance/db/sqlalchemy/migrate_repo/versions/006_mysql_upgrade.sql... __init__ /usr/local/lib/python2.7/dist-packages/migrate/versioning/script/base.py:27
2014-12-12 16:31:22.154 15678 DEBUG migrate.versioning.script.base [-] Script /opt/stack/glance/glance/db/sqlalchemy/migrate_repo/versions/006_mysql_upgrade.sql loaded successfully __init__ /usr/local/lib/python2.7/dist-packages/migrate/versioning/script/base.py:30
2014-12-12 16:31:22.154 15678 DEBUG migrate.versioning.script.base [-] Loading script /opt/stack/glance/glance/db/sqlalchemy/migrate_repo/versions/006_sqlite_downgrade.sql... __init__ /usr/local/lib/python2.7/dist-packages/migrate/versioning/script/base.py:27
2014-12-12 16:31:22.154 15678 DEBUG migrate.versioning.script.base [-] Script /opt/stack/glance/glance/db/sqlalchemy/migrate_repo/versions/006_sqlite_downgrade.sql loaded successfully __init__ /usr/local/lib/python2.7/dist-packages/migrate/versioning/script/base.py:30
2014-12-12 16:31:22.154 15678 DEBUG migrate.versioning.script.base [-] Loading script /opt/stack/glance/glance/db/sqlalchemy/migrate_repo/versions/006_key_to_name.py... __init__ /usr/local/lib/python2.7/dist-packages/migrate/versioning/script/base.py:27
2014-12-12 16:31:22.155 15678 DEBUG migrate.versioning.script.base [-] Script /opt/stack/glance/glance/db/sqlalchemy/migrate_repo/versions/006_key_to_name.py loaded successfully __init__ /usr/local/lib/python2.7/dist-packages/migrate/versioning/script/base.py:30
2014-12-12 16:31:22.155 15678 DEBUG migrate.versioning.script.base [-] Loading script /opt/stack/glance/glance/db/sqlalchemy/migrate_repo/versions/006_sqlite_upgrade.sql... __init__ /usr/local/lib/python2.7/dist-packages/migrate/versioning/script/base.py:27
2014-12-12 16:31:22.155 15678 DEBUG migrate.versioning.script.base [-] Script /opt/stack/glance/glance/db/sqlalchemy/migrate_repo/versions/006_sqlite_upgrade.sql loaded successfully __init__ /usr/local/lib/python2.7/dist-packages/migrate/versioning/script/base.py:30
2014-12-12 16:31:22.155 15678 DEBUG migrate.versioning.script.base [-] Loading script /opt/stack/glance/glance/db/sqlalchemy/migrate_repo/versions/006_mysql_downgrade.sql... __init__ /usr/local/lib/python2.7/dist-packages/migrate/versioning/script/base.py:27
2014-12-12 16:31:22.155 15678 DEBUG migrate.versioning.script.base [-] Script /opt/stack/glance/glance/db/sqlalchemy/migrate_repo/versions/006_mysql_downgrade.sql loaded successfully __init__ /usr/local/lib/python2.7/dist-packages/migrate/versioning/script/base.py:30
2014-12-12 16:31:22.155 15678 DEBUG migrate.versioning.script.base [-] Loading script /opt/stack/glance/glance/db/sqlalchemy/migrate_repo/versions/007_add_owner.py... __init__ /usr/local/lib/python2.7/dist-packages/migrate/versioning/script/base.py:27
2014-12-12 16:31:22.155 15678 DEBUG migrate.versioning.script.base [-] Script /opt/stack/glance/glance/db/sqlalchemy/migrate_repo/versions/007_add_owner.py loaded successfully __init__ /usr/local/lib/python2.7/dist-packages/migrate/versioning/script/base.py:30
2014-12-12 16:31:22.155 15678 DEBUG migrate.versioning.script.base [-] Loading script /opt/stack/glance/glance/db/sqlalchemy/migrate_repo/versions/008_add_image_members_table.py... __init__ /usr/local/lib/python2.7/dist-packages/migrate/versioning/script/base.py:27
2014-12-12 16:31:22.155 15678 DEBUG migrate.versioning.script.base [-] Script /opt/stack/glance/glance/db/sqlalchemy/migrate_repo/versions/008_add_image_members_table.py loaded successfully __init__ /usr/local/lib/python2.7/dist-packages/migrate/versioning/script/base.py:30
2014-12-12 16:31:22.155 15678 DEBUG migrate.versioning.script.base [-] Loading script /opt/stack/glance/glance/db/sqlalchemy/migrate_repo/versions/009_add_mindisk_and_minram.py... __init__ /usr/local/lib/python2.7/dist-packages/migrate/versioning/script/base.py:27
2014-12-12 16:31:22.155 15678 DEBUG migrate.versioning.script.base [-] Script /opt/stack/glance/glance/db/sqlalchemy/migrate_repo/versions/009_add_mindisk_and_minram.py loaded successfully __init__ /usr/local/lib/python2.7/dist-packages/migrate/versioning/script/base.py:30
2014-12-12 16:31:22.155 15678 DEBUG migrate.versioning.script.base [-] Loading script /opt/stack/glance/glance/db/sqlalchemy/migrate_repo/versions/010_default_update_at.py... __init__ /usr/local/lib/python2.7/dist-packages/migrate/versioning/script/base.py:27
2014-12-12 16:31:22.155 15678 DEBUG migrate.versioning.script.base [-] Script /opt/stack/glance/glance/db/sqlalchemy/migrate_repo/versions/010_default_update_at.py loaded successfully __init__ /usr/local/lib/python2.7/dist-packages/migrate/versioning/script/base.py:30
2014-12-12 16:31:22.155 15678 DEBUG migrate.versioning.script.base [-] Loading script /opt/stack/glance/glance/db/sqlalchemy/migrate_repo/versions/011_make_mindisk_and_minram_notnull.py... __init__ /usr/local/lib/python2.7/dist-packages/migrate/versioning/script/base.py:27
2014-12-12 16:31:22.155 15678 DEBUG migrate.versioning.script.base [-] Script /opt/stack/glance/glance/db/sqlalchemy/migrate_repo/versions/011_make_mindisk_and_minram_notnull.py loaded successfully __init__ /usr/local/lib/python2.7/dist-packages/migrate/versioning/script/base.py:30
2014-12-12 16:31:22.155 15678 DEBUG migrate.versioning.script.base [-] Loading script /opt/stack/glance/glance/db/sqlalchemy/migrate_repo/versions/011_sqlite_upgrade.sql... __init__ /usr/local/lib/python2.7/dist-packages/migrate/versioning/script/base.py:27
2014-12-12 16:31:22.156 15678 DEBUG migrate.versioning.script.base [-] Script /opt/stack/glance/glance/db/sqlalchemy/migrate_repo/versions/011_sqlite_upgrade.sql loaded successfully __init__ /usr/local/lib/python2.7/dist-packages/migrate/versioning/script/base.py:30
2014-12-12 16:31:22.156 15678 DEBUG migrate.versioning.script.base [-] Loading script /opt/stack/glance/glance/db/sqlalchemy/migrate_repo/versions/011_sqlite_downgrade.sql... __init__ /usr/local/lib/python2.7/dist-packages/migrate/versioning/script/base.py:27
2014-12-12 16:31:22.156 15678 DEBUG migrate.versioning.script.base [-] Script /opt/stack/glance/glance/db/sqlalchemy/migrate_repo/versions/011_sqlite_downgrade.sql loaded successfully __init__ /usr/local/lib/python2.7/dist-packages/migrate/versioning/script/base.py:30
2014-12-12 16:31:22.156 15678 DEBUG migrate.versioning.script.base [-] Loading script /opt/stack/glance/glance/db/sqlalchemy/migrate_repo/versions/012_id_to_uuid.py... __init__ /usr/local/lib/python2.7/dist-packages/migrate/versioning/script/base.py:27
2014-12-12 16:31:22.156 15678 DEBUG migrate.versioning.script.base [-] Script /opt/stack/glance/glance/db/sqlalchemy/migrate_repo/versions/012_id_to_uuid.py loaded successfully __init__ /usr/local/lib/python2.7/dist-packages/migrate/versioning/script/base.py:30
2014-12-12 16:31:22.156 15678 DEBUG migrate.versioning.script.base [-] Loading script /opt/stack/glance/glance/db/sqlalchemy/migrate_repo/versions/013_sqlite_downgrade.sql... __init__ /usr/local/lib/python2.7/dist-packages/migrate/versioning/script/base.py:27
2014-12-12 16:31:22.156 15678 DEBUG migrate.versioning.script.base [-] Script /opt/stack/glance/glance/db/sqlalchemy/migrate_repo/versions/013_sqlite_downgrade.sql loaded successfully __init__ /usr/local/lib/python2.7/dist-packages/migrate/versioning/script/base.py:30
2014-12-12 16:31:22.156 15678 DEBUG migrate.versioning.script.base [-] Loading script /opt/stack/glance/glance/db/sqlalchemy/migrate_repo/versions/013_add_protected.py... __init__ /usr/local/lib/python2.7/dist-packages/migrate/versioning/script/base.py:27
2014-12-12 16:31:22.156 15678 DEBUG migrate.versioning.script.base [-] Script /opt/stack/glance/glance/db/sqlalchemy/migrate_repo/versions/013_add_protected.py loaded successfully __init__ /usr/local/lib/python2.7/dist-packages/migrate/versioning/script/base.py:30
2014-12-12 16:31:22.156 15678 DEBUG migrate.versioning.script.base [-] Loading script /opt/stack/glance/glance/db/sqlalchemy/migrate_repo/versions/014_add_image_tags_table.py... __init__ /usr/local/lib/python2.7/dist-packages/migrate/versioning/script/base.py:27
2014-12-12 16:31:22.156 15678 DEBUG migrate.versioning.script.base [-] Script /opt/stack/glance/glance/db/sqlalchemy/migrate_repo/versions/014_add_image_tags_table.py loaded successfully __init__ /usr/local/lib/python2.7/dist-packages/migrate/versioning/script/base.py:30
2014-12-12 16:31:22.156 15678 DEBUG migrate.versioning.script.base [-] Loading script /opt/stack/glance/glance/db/sqlalchemy/migrate_repo/versions/015_quote_swift_credentials.py... __init__ /usr/local/lib/python2.7/dist-packages/migrate/versioning/script/base.py:27
2014-12-12 16:31:22.156 15678 DEBUG migrate.versioning.script.base [-] Script /opt/stack/glance/glance/db/sqlalchemy/migrate_repo/versions/015_quote_swift_credentials.py loaded successfully __init__ /usr/local/lib/python2.7/dist-packages/migrate/versioning/script/base.py:30
2014-12-12 16:31:22.156 15678 DEBUG migrate.versioning.script.base [-] Loading script /opt/stack/glance/glance/db/sqlalchemy/migrate_repo/versions/016_sqlite_downgrade.sql... __init__ /usr/local/lib/python2.7/dist-packages/migrate/versioning/script/base.py:27
2014-12-12 16:31:22.156 15678 DEBUG migrate.versioning.script.base [-] Script /opt/stack/glance/glance/db/sqlalchemy/migrate_repo/versions/016_sqlite_downgrade.sql loaded successfully __init__ /usr/local/lib/python2.7/dist-packages/migrate/versioning/script/base.py:30
2014-12-12 16:31:22.156 15678 DEBUG migrate.versioning.script.base [-] Loading script /opt/stack/glance/glance/db/sqlalchemy/migrate_repo/versions/016_add_status_image_member.py... __init__ /usr/local/lib/python2.7/dist-packages/migrate/versioning/script/base.py:27
2014-12-12 16:31:22.156 15678 DEBUG migrate.versioning.script.base [-] Script /opt/stack/glance/glance/db/sqlalchemy/migrate_repo/versions/016_add_status_image_member.py loaded successfully __init__ /usr/local/lib/python2.7/dist-packages/migrate/versioning/script/base.py:30
2014-12-12 16:31:22.157 15678 DEBUG migrate.versioning.script.base [-] Loading script /opt/stack/glance/glance/db/sqlalchemy/migrate_repo/versions/017_quote_encrypted_swift_credentials.py... __init__ /usr/local/lib/python2.7/dist-packages/migrate/versioning/script/base.py:27
2014-12-12 16:31:22.157 15678 DEBUG migrate.versioning.script.base [-] Script /opt/stack/glance/glance/db/sqlalchemy/migrate_repo/versions/017_quote_encrypted_swift_credentials.py loaded successfully __init__ /usr/local/lib/python2.7/dist-packages/migrate/versioning/script/base.py:30
2014-12-12 16:31:22.157 15678 DEBUG migrate.versioning.script.base [-] Loading script /opt/stack/glance/glance/db/sqlalchemy/migrate_repo/versions/018_add_image_locations_table.py... __init__ /usr/local/lib/python2.7/dist-packages/migrate/versioning/script/base.py:27
2014-12-12 16:31:22.157 15678 DEBUG migrate.versioning.script.base [-] Script /opt/stack/glance/glance/db/sqlalchemy/migrate_repo/versions/018_add_image_locations_table.py loaded successfully __init__ /usr/local/lib/python2.7/dist-packages/migrate/versioning/script/base.py:30
2014-12-12 16:31:22.157 15678 DEBUG migrate.versioning.script.base [-] Loading script /opt/stack/glance/glance/db/sqlalchemy/migrate_repo/versions/019_migrate_image_locations.py... __init__ /usr/local/lib/python2.7/dist-packages/migrate/versioning/script/base.py:27
2014-12-12 16:31:22.157 15678 DEBUG migrate.versioning.script.base [-] Script /opt/stack/glance/glance/db/sqlalchemy/migrate_repo/versions/019_migrate_image_locations.py loaded successfully __init__ /usr/local/lib/python2.7/dist-packages/migrate/versioning/script/base.py:30
2014-12-12 16:31:22.157 15678 DEBUG migrate.versioning.script.base [-] Loading script /opt/stack/glance/glance/db/sqlalchemy/migrate_repo/versions/020_drop_images_table_location.py... __init__ /usr/local/lib/python2.7/dist-packages/migrate/versioning/script/base.py:27
2014-12-12 16:31:22.157 15678 DEBUG migrate.versioning.script.base [-] Script /opt/stack/glance/glance/db/sqlalchemy/migrate_repo/versions/020_drop_images_table_location.py loaded successfully __init__ /usr/local/lib/python2.7/dist-packages/migrate/versioning/script/base.py:30
2014-12-12 16:31:22.157 15678 DEBUG migrate.versioning.script.base [-] Loading script /opt/stack/glance/glance/db/sqlalchemy/migrate_repo/versions/021_set_engine_mysql_innodb.py... __init__ /usr/local/lib/python2.7/dist-packages/migrate/versioning/script/base.py:27
2014-12-12 16:31:22.157 15678 DEBUG migrate.versioning.script.base [-] Script /opt/stack/glance/glance/db/sqlalchemy/migrate_repo/versions/021_set_engine_mysql_innodb.py loaded successfully __init__ /usr/local/lib/python2.7/dist-packages/migrate/versioning/script/base.py:30
2014-12-12 16:31:22.157 15678 DEBUG migrate.versioning.script.base [-] Loading script /opt/stack/glance/glance/db/sqlalchemy/migrate_repo/versions/022_image_member_index.py... __init__ /usr/local/lib/python2.7/dist-packages/migrate/versioning/script/base.py:27
2014-12-12 16:31:22.157 15678 DEBUG migrate.versioning.script.base [-] Script /opt/stack/glance/glance/db/sqlalchemy/migrate_repo/versions/022_image_member_index.py loaded successfully __init__ /usr/local/lib/python2.7/dist-packages/migrate/versioning/script/base.py:30
2014-12-12 16:31:22.157 15678 DEBUG migrate.versioning.script.base [-] Loading script /opt/stack/glance/glance/db/sqlalchemy/migrate_repo/versions/023_placeholder.py... __init__ /usr/local/lib/python2.7/dist-packages/migrate/versioning/script/base.py:27
2014-12-12 16:31:22.157 15678 DEBUG migrate.versioning.script.base [-] Script /opt/stack/glance/glance/db/sqlalchemy/migrate_repo/versions/023_placeholder.py loaded successfully __init__ /usr/local/lib/python2.7/dist-packages/migrate/versioning/script/base.py:30
2014-12-12 16:31:22.157 15678 DEBUG migrate.versioning.script.base [-] Loading script /opt/stack/glance/glance/db/sqlalchemy/migrate_repo/versions/024_placeholder.py... __init__ /usr/local/lib/python2.7/dist-packages/migrate/versioning/script/base.py:27
2014-12-12 16:31:22.158 15678 DEBUG migrate.versioning.script.base [-] Script /opt/stack/glance/glance/db/sqlalchemy/migrate_repo/versions/024_placeholder.py loaded successfully __init__ /usr/local/lib/python2.7/dist-packages/migrate/versioning/script/base.py:30
2014-12-12 16:31:22.158 15678 DEBUG migrate.versioning.script.base [-] Loading script /opt/stack/glance/glance/db/sqlalchemy/migrate_repo/versions/025_placeholder.py... __init__ /usr/local/lib/python2.7/dist-packages/migrate/versioning/script/base.py:27
2014-12-12 16:31:22.158 15678 DEBUG migrate.versioning.script.base [-] Script /opt/stack/glance/glance/db/sqlalchemy/migrate_repo/versions/025_placeholder.py loaded successfully __init__ /usr/local/lib/python2.7/dist-packages/migrate/versioning/script/base.py:30
2014-12-12 16:31:22.158 15678 DEBUG migrate.versioning.script.base [-] Loading script /opt/stack/glance/glance/db/sqlalchemy/migrate_repo/versions/026_add_location_storage_information.py... __init__ /usr/local/lib/python2.7/dist-packages/migrate/versioning/script/base.py:27
2014-12-12 16:31:22.158 15678 DEBUG migrate.versioning.script.base [-] Script /opt/stack/glance/glance/db/sqlalchemy/migrate_repo/versions/026_add_location_storage_information.py loaded successfully __init__ /usr/local/lib/python2.7/dist-packages/migrate/versioning/script/base.py:30
2014-12-12 16:31:22.158 15678 DEBUG migrate.versioning.script.base [-] Loading script /opt/stack/glance/glance/db/sqlalchemy/migrate_repo/versions/027_checksum_index.py... __init__ /usr/local/lib/python2.7/dist-packages/migrate/versioning/script/base.py:27
2014-12-12 16:31:22.158 15678 DEBUG migrate.versioning.script.base [-] Script /opt/stack/glance/glance/db/sqlalchemy/migrate_repo/versions/027_checksum_index.py loaded successfully __init__ /usr/local/lib/python2.7/dist-packages/migrate/versioning/script/base.py:30
2014-12-12 16:31:22.158 15678 DEBUG migrate.versioning.script.base [-] Loading script /opt/stack/glance/glance/db/sqlalchemy/migrate_repo/versions/028_owner_index.py... __init__ /usr/local/lib/python2.7/dist-packages/migrate/versioning/script/base.py:27
2014-12-12 16:31:22.158 15678 DEBUG migrate.versioning.script.base [-] Script /opt/stack/glance/glance/db/sqlalchemy/migrate_repo/versions/028_owner_index.py loaded successfully __init__ /usr/local/lib/python2.7/dist-packages/migrate/versioning/script/base.py:30
2014-12-12 16:31:22.158 15678 DEBUG migrate.versioning.script.base [-] Loading script /opt/stack/glance/glance/db/sqlalchemy/migrate_repo/versions/029_location_meta_data_pickle_to_string.py... __init__ /usr/local/lib/python2.7/dist-packages/migrate/versioning/script/base.py:27
2014-12-12 16:31:22.158 15678 DEBUG migrate.versioning.script.base [-] Script /opt/stack/glance/glance/db/sqlalchemy/migrate_repo/versions/029_location_meta_data_pickle_to_string.py loaded successfully __init__ /usr/local/lib/python2.7/dist-packages/migrate/versioning/script/base.py:30
2014-12-12 16:31:22.158 15678 DEBUG migrate.versioning.script.base [-] Loading script /opt/stack/glance/glance/db/sqlalchemy/migrate_repo/versions/030_add_tasks_table.py... __init__ /usr/local/lib/python2.7/dist-packages/migrate/versioning/script/base.py:27
2014-12-12 16:31:22.158 15678 DEBUG migrate.versioning.script.base [-] Script /opt/stack/glance/glance/db/sqlalchemy/migrate_repo/versions/030_add_tasks_table.py loaded successfully __init__ /usr/local/lib/python2.7/dist-packages/migrate/versioning/script/base.py:30
2014-12-12 16:31:22.158 15678 DEBUG migrate.versioning.script.base [-] Loading script /opt/stack/glance/glance/db/sqlalchemy/migrate_repo/versions/031_remove_duplicated_locations.py... __init__ /usr/local/lib/python2.7/dist-packages/migrate/versioning/script/base.py:27
2014-12-12 16:31:22.158 15678 DEBUG migrate.versioning.script.base [-] Script /opt/stack/glance/glance/db/sqlalchemy/migrate_repo/versions/031_remove_duplicated_locations.py loaded successfully __init__ /usr/local/lib/python2.7/dist-packages/migrate/versioning/script/base.py:30
2014-12-12 16:31:22.158 15678 DEBUG migrate.versioning.script.base [-] Loading script /opt/stack/glance/glance/db/sqlalchemy/migrate_repo/versions/032_add_task_info_table.py... __init__ /usr/local/lib/python2.7/dist-packages/migrate/versioning/script/base.py:27
2014-12-12 16:31:22.159 15678 DEBUG migrate.versioning.script.base [-] Script /opt/stack/glance/glance/db/sqlalchemy/migrate_repo/versions/032_add_task_info_table.py loaded successfully __init__ /usr/local/lib/python2.7/dist-packages/migrate/versioning/script/base.py:30
2014-12-12 16:31:22.159 15678 DEBUG migrate.versioning.script.base [-] Loading script /opt/stack/glance/glance/db/sqlalchemy/migrate_repo/versions/033_add_location_status.py... __init__ /usr/local/lib/python2.7/dist-packages/migrate/versioning/script/base.py:27
2014-12-12 16:31:22.159 15678 DEBUG migrate.versioning.script.base [-] Script /opt/stack/glance/glance/db/sqlalchemy/migrate_repo/versions/033_add_location_status.py loaded successfully __init__ /usr/local/lib/python2.7/dist-packages/migrate/versioning/script/base.py:30
2014-12-12 16:31:22.159 15678 DEBUG migrate.versioning.script.base [-] Loading script /opt/stack/glance/glance/db/sqlalchemy/migrate_repo/versions/034_add_virtual_size.py... __init__ /usr/local/lib/python2.7/dist-packages/migrate/versioning/script/base.py:27
2014-12-12 16:31:22.159 15678 DEBUG migrate.versioning.script.base [-] Script /opt/stack/glance/glance/db/sqlalchemy/migrate_repo/versions/034_add_virtual_size.py loaded successfully __init__ /usr/local/lib/python2.7/dist-packages/migrate/versioning/script/base.py:30
2014-12-12 16:31:22.159 15678 DEBUG migrate.versioning.script.base [-] Loading script /opt/stack/glance/glance/db/sqlalchemy/migrate_repo/versions/035_add_metadef_tables.py... __init__ /usr/local/lib/python2.7/dist-packages/migrate/versioning/script/base.py:27
2014-12-12 16:31:22.159 15678 DEBUG migrate.versioning.script.base [-] Script /opt/stack/glance/glance/db/sqlalchemy/migrate_repo/versions/035_add_metadef_tables.py loaded successfully __init__ /usr/local/lib/python2.7/dist-packages/migrate/versioning/script/base.py:30
2014-12-12 16:31:22.159 15678 DEBUG migrate.versioning.script.base [-] Loading script /opt/stack/glance/glance/db/sqlalchemy/migrate_repo/versions/036_rename_metadef_schema_columns.py... __init__ /usr/local/lib/python2.7/dist-packages/migrate/versioning/script/base.py:27
2014-12-12 16:31:22.159 15678 DEBUG migrate.versioning.script.base [-] Script /opt/stack/glance/glance/db/sqlalchemy/migrate_repo/versions/036_rename_metadef_schema_columns.py loaded successfully __init__ /usr/local/lib/python2.7/dist-packages/migrate/versioning/script/base.py:30
2014-12-12 16:31:22.159 15678 DEBUG migrate.versioning.repository [-] Repository /opt/stack/glance/glance/db/sqlalchemy/migrate_repo loaded successfully __init__ /usr/local/lib/python2.7/dist-packages/migrate/versioning/repository.py:82
2014-12-12 16:31:22.159 15678 DEBUG migrate.versioning.repository [-] Config: OrderedDict([('db_settings', OrderedDict([('__name__', 'db_settings'), ('repository_id', 'Glance Migrations'), ('version_table', 'migrate_version'), ('required_dbs', '[]')]))]) __init__ /usr/local/lib/python2.7/dist-packages/migrate/versioning/repository.py:83
2014-12-12 16:31:22.171 15678 DEBUG migrate.versioning.repository [-] Loading repository /opt/stack/glance/glance/db/sqlalchemy/migrate_repo... __init__ /usr/local/lib/python2.7/dist-packages/migrate/versioning/repository.py:76
2014-12-12 16:31:22.172 15678 DEBUG migrate.versioning.script.base [-] Loading script /opt/stack/glance/glance/db/sqlalchemy/migrate_repo/versions/001_add_images_table.py... __init__ /usr/local/lib/python2.7/dist-packages/migrate/versioning/script/base.py:27
2014-12-12 16:31:22.172 15678 DEBUG migrate.versioning.script.base [-] Script /opt/stack/glance/glance/db/sqlalchemy/migrate_repo/versions/001_add_images_table.py loaded successfully __init__ /usr/local/lib/python2.7/dist-packages/migrate/versioning/script/base.py:30
2014-12-12 16:31:22.172 15678 DEBUG migrate.versioning.script.base [-] Loading script /opt/stack/glance/glance/db/sqlalchemy/migrate_repo/versions/002_add_image_properties_table.py... __init__ /usr/local/lib/python2.7/dist-packages/migrate/versioning/script/base.py:27
2014-12-12 16:31:22.172 15678 DEBUG migrate.versioning.script.base [-] Script /opt/stack/glance/glance/db/sqlalchemy/migrate_repo/versions/002_add_image_properties_table.py loaded successfully __init__ /usr/local/lib/python2.7/dist-packages/migrate/versioning/script/base.py:30
2014-12-12 16:31:22.172 15678 DEBUG migrate.versioning.script.base [-] Loading script /opt/stack/glance/glance/db/sqlalchemy/migrate_repo/versions/003_sqlite_downgrade.sql... __init__ /usr/local/lib/python2.7/dist-packages/migrate/versioning/script/base.py:27
2014-12-12 16:31:22.172 15678 DEBUG migrate.versioning.script.base [-] Script /opt/stack/glance/glance/db/sqlalchemy/migrate_repo/versions/003_sqlite_downgrade.sql loaded successfully __init__ /usr/local/lib/python2.7/dist-packages/migrate/versioning/script/base.py:30
2014-12-12 16:31:22.172 15678 DEBUG migrate.versioning.script.base [-] Loading script /opt/stack/glance/glance/db/sqlalchemy/migrate_repo/versions/003_sqlite_upgrade.sql... __init__ /usr/local/lib/python2.7/dist-packages/migrate/versioning/script/base.py:27
2014-12-12 16:31:22.172 15678 DEBUG migrate.versioning.script.base [-] Script /opt/stack/glance/glance/db/sqlalchemy/migrate_repo/versions/003_sqlite_upgrade.sql loaded successfully __init__ /usr/local/lib/python2.7/dist-packages/migrate/versioning/script/base.py:30
2014-12-12 16:31:22.172 15678 DEBUG migrate.versioning.script.base [-] Loading script /opt/stack/glance/glance/db/sqlalchemy/migrate_repo/versions/003_add_disk_format.py... __init__ /usr/local/lib/python2.7/dist-packages/migrate/versioning/script/base.py:27
2014-12-12 16:31:22.172 15678 DEBUG migrate.versioning.script.base [-] Script /opt/stack/glance/glance/db/sqlalchemy/migrate_repo/versions/003_add_disk_format.py loaded successfully __init__ /usr/local/lib/python2.7/dist-packages/migrate/versioning/script/base.py:30
2014-12-12 16:31:22.172 15678 DEBUG migrate.versioning.script.base [-] Loading script /opt/stack/glance/glance/db/sqlalchemy/migrate_repo/versions/004_add_checksum.py... __init__ /usr/local/lib/python2.7/dist-packages/migrate/versioning/script/base.py:27
2014-12-12 16:31:22.172 15678 DEBUG migrate.versioning.script.base [-] Script /opt/stack/glance/glance/db/sqlalchemy/migrate_repo/versions/004_add_checksum.py loaded successfully __init__ /usr/local/lib/python2.7/dist-packages/migrate/versioning/script/base.py:30
2014-12-12 16:31:22.172 15678 DEBUG migrate.versioning.script.base [-] Loading script /opt/stack/glance/glance/db/sqlalchemy/migrate_repo/versions/005_size_big_integer.py... __init__ /usr/local/lib/python2.7/dist-packages/migrate/versioning/script/base.py:27
2014-12-12 16:31:22.172 15678 DEBUG migrate.versioning.script.base [-] Script /opt/stack/glance/glance/db/sqlalchemy/migrate_repo/versions/005_size_big_integer.py loaded successfully __init__ /usr/local/lib/python2.7/dist-packages/migrate/versioning/script/base.py:30
2014-12-12 16:31:22.173 15678 DEBUG migrate.versioning.script.base [-] Loading script /opt/stack/glance/glance/db/sqlalchemy/migrate_repo/versions/006_mysql_upgrade.sql... __init__ /usr/local/lib/python2.7/dist-packages/migrate/versioning/script/base.py:27
2014-12-12 16:31:22.173 15678 DEBUG migrate.versioning.script.base [-] Script /opt/stack/glance/glance/db/sqlalchemy/migrate_repo/versions/006_mysql_upgrade.sql loaded successfully __init__ /usr/local/lib/python2.7/dist-packages/migrate/versioning/script/base.py:30
2014-12-12 16:31:22.173 15678 DEBUG migrate.versioning.script.base [-] Loading script /opt/stack/glance/glance/db/sqlalchemy/migrate_repo/versions/006_sqlite_downgrade.sql... __init__ /usr/local/lib/python2.7/dist-packages/migrate/versioning/script/base.py:27
2014-12-12 16:31:22.173 15678 DEBUG migrate.versioning.script.base [-] Script /opt/stack/glance/glance/db/sqlalchemy/migrate_repo/versions/006_sqlite_downgrade.sql loaded successfully __init__ /usr/local/lib/python2.7/dist-packages/migrate/versioning/script/base.py:30
2014-12-12 16:31:22.173 15678 DEBUG migrate.versioning.script.base [-] Loading script /opt/stack/glance/glance/db/sqlalchemy/migrate_repo/versions/006_key_to_name.py... __init__ /usr/local/lib/python2.7/dist-packages/migrate/versioning/script/base.py:27
2014-12-12 16:31:22.173 15678 DEBUG migrate.versioning.script.base [-] Script /opt/stack/glance/glance/db/sqlalchemy/migrate_repo/versions/006_key_to_name.py loaded successfully __init__ /usr/local/lib/python2.7/dist-packages/migrate/versioning/script/base.py:30
2014-12-12 16:31:22.173 15678 DEBUG migrate.versioning.script.base [-] Loading script /opt/stack/glance/glance/db/sqlalchemy/migrate_repo/versions/006_sqlite_upgrade.sql... __init__ /usr/local/lib/python2.7/dist-packages/migrate/versioning/script/base.py:27
2014-12-12 16:31:22.173 15678 DEBUG migrate.versioning.script.base [-] Script /opt/stack/glance/glance/db/sqlalchemy/migrate_repo/versions/006_sqlite_upgrade.sql loaded successfully __init__ /usr/local/lib/python2.7/dist-packages/migrate/versioning/script/base.py:30
2014-12-12 16:31:22.173 15678 DEBUG migrate.versioning.script.base [-] Loading script /opt/stack/glance/glance/db/sqlalchemy/migrate_repo/versions/006_mysql_downgrade.sql... __init__ /usr/local/lib/python2.7/dist-packages/migrate/versioning/script/base.py:27
2014-12-12 16:31:22.173 15678 DEBUG migrate.versioning.script.base [-] Script /opt/stack/glance/glance/db/sqlalchemy/migrate_repo/versions/006_mysql_downgrade.sql loaded successfully __init__ /usr/local/lib/python2.7/dist-packages/migrate/versioning/script/base.py:30
2014-12-12 16:31:22.173 15678 DEBUG migrate.versioning.script.base [-] Loading script /opt/stack/glance/glance/db/sqlalchemy/migrate_repo/versions/007_add_owner.py... __init__ /usr/local/lib/python2.7/dist-packages/migrate/versioning/script/base.py:27
2014-12-12 16:31:22.173 15678 DEBUG migrate.versioning.script.base [-] Script /opt/stack/glance/glance/db/sqlalchemy/migrate_repo/versions/007_add_owner.py loaded successfully __init__ /usr/local/lib/python2.7/dist-packages/migrate/versioning/script/base.py:30
2014-12-12 16:31:22.173 15678 DEBUG migrate.versioning.script.base [-] Loading script /opt/stack/glance/glance/db/sqlalchemy/migrate_repo/versions/008_add_image_members_table.py... __init__ /usr/local/lib/python2.7/dist-packages/migrate/versioning/script/base.py:27
2014-12-12 16:31:22.173 15678 DEBUG migrate.versioning.script.base [-] Script /opt/stack/glance/glance/db/sqlalchemy/migrate_repo/versions/008_add_image_members_table.py loaded successfully __init__ /usr/local/lib/python2.7/dist-packages/migrate/versioning/script/base.py:30
2014-12-12 16:31:22.173 15678 DEBUG migrate.versioning.script.base [-] Loading script /opt/stack/glance/glance/db/sqlalchemy/migrate_repo/versions/009_add_mindisk_and_minram.py... __init__ /usr/local/lib/python2.7/dist-packages/migrate/versioning/script/base.py:27
2014-12-12 16:31:22.173 15678 DEBUG migrate.versioning.script.base [-] Script /opt/stack/glance/glance/db/sqlalchemy/migrate_repo/versions/009_add_mindisk_and_minram.py loaded successfully __init__ /usr/local/lib/python2.7/dist-packages/migrate/versioning/script/base.py:30
2014-12-12 16:31:22.173 15678 DEBUG migrate.versioning.script.base [-] Loading script /opt/stack/glance/glance/db/sqlalchemy/migrate_repo/versions/010_default_update_at.py... __init__ /usr/local/lib/python2.7/dist-packages/migrate/versioning/script/base.py:27
2014-12-12 16:31:22.173 15678 DEBUG migrate.versioning.script.base [-] Script /opt/stack/glance/glance/db/sqlalchemy/migrate_repo/versions/010_default_update_at.py loaded successfully __init__ /usr/local/lib/python2.7/dist-packages/migrate/versioning/script/base.py:30
2014-12-12 16:31:22.174 15678 DEBUG migrate.versioning.script.base [-] Loading script /opt/stack/glance/glance/db/sqlalchemy/migrate_repo/versions/011_make_mindisk_and_minram_notnull.py... __init__ /usr/local/lib/python2.7/dist-packages/migrate/versioning/script/base.py:27
2014-12-12 16:31:22.174 15678 DEBUG migrate.versioning.script.base [-] Script /opt/stack/glance/glance/db/sqlalchemy/migrate_repo/versions/011_make_mindisk_and_minram_notnull.py loaded successfully __init__ /usr/local/lib/python2.7/dist-packages/migrate/versioning/script/base.py:30
2014-12-12 16:31:22.174 15678 DEBUG migrate.versioning.script.base [-] Loading script /opt/stack/glance/glance/db/sqlalchemy/migrate_repo/versions/011_sqlite_upgrade.sql... __init__ /usr/local/lib/python2.7/dist-packages/migrate/versioning/script/base.py:27
2014-12-12 16:31:22.174 15678 DEBUG migrate.versioning.script.base [-] Script /opt/stack/glance/glance/db/sqlalchemy/migrate_repo/versions/011_sqlite_upgrade.sql loaded successfully __init__ /usr/local/lib/python2.7/dist-packages/migrate/versioning/script/base.py:30
2014-12-12 16:31:22.174 15678 DEBUG migrate.versioning.script.base [-] Loading script /opt/stack/glance/glance/db/sqlalchemy/migrate_repo/versions/011_sqlite_downgrade.sql... __init__ /usr/local/lib/python2.7/dist-packages/migrate/versioning/script/base.py:27
2014-12-12 16:31:22.174 15678 DEBUG migrate.versioning.script.base [-] Script /opt/stack/glance/glance/db/sqlalchemy/migrate_repo/versions/011_sqlite_downgrade.sql loaded successfully __init__ /usr/local/lib/python2.7/dist-packages/migrate/versioning/script/base.py:30
2014-12-12 16:31:22.174 15678 DEBUG migrate.versioning.script.base [-] Loading script /opt/stack/glance/glance/db/sqlalchemy/migrate_repo/versions/012_id_to_uuid.py... __init__ /usr/local/lib/python2.7/dist-packages/migrate/versioning/script/base.py:27
2014-12-12 16:31:22.174 15678 DEBUG migrate.versioning.script.base [-] Script /opt/stack/glance/glance/db/sqlalchemy/migrate_repo/versions/012_id_to_uuid.py loaded successfully __init__ /usr/local/lib/python2.7/dist-packages/migrate/versioning/script/base.py:30
2014-12-12 16:31:22.174 15678 DEBUG migrate.versioning.script.base [-] Loading script /opt/stack/glance/glance/db/sqlalchemy/migrate_repo/versions/013_sqlite_downgrade.sql... __init__ /usr/local/lib/python2.7/dist-packages/migrate/versioning/script/base.py:27
2014-12-12 16:31:22.174 15678 DEBUG migrate.versioning.script.base [-] Script /opt/stack/glance/glance/db/sqlalchemy/migrate_repo/versions/013_sqlite_downgrade.sql loaded successfully __init__ /usr/local/lib/python2.7/dist-packages/migrate/versioning/script/base.py:30
2014-12-12 16:31:22.174 15678 DEBUG migrate.versioning.script.base [-] Loading script /opt/stack/glance/glance/db/sqlalchemy/migrate_repo/versions/013_add_protected.py... __init__ /usr/local/lib/python2.7/dist-packages/migrate/versioning/script/base.py:27
2014-12-12 16:31:22.174 15678 DEBUG migrate.versioning.script.base [-] Script /opt/stack/glance/glance/db/sqlalchemy/migrate_repo/versions/013_add_protected.py loaded successfully __init__ /usr/local/lib/python2.7/dist-packages/migrate/versioning/script/base.py:30
2014-12-12 16:31:22.174 15678 DEBUG migrate.versioning.script.base [-] Loading script /opt/stack/glance/glance/db/sqlalchemy/migrate_repo/versions/014_add_image_tags_table.py... __init__ /usr/local/lib/python2.7/dist-packages/migrate/versioning/script/base.py:27
2014-12-12 16:31:22.174 15678 DEBUG migrate.versioning.script.base [-] Script /opt/stack/glance/glance/db/sqlalchemy/migrate_repo/versions/014_add_image_tags_table.py loaded successfully __init__ /usr/local/lib/python2.7/dist-packages/migrate/versioning/script/base.py:30
2014-12-12 16:31:22.174 15678 DEBUG migrate.versioning.script.base [-] Loading script /opt/stack/glance/glance/db/sqlalchemy/migrate_repo/versions/015_quote_swift_credentials.py... __init__ /usr/local/lib/python2.7/dist-packages/migrate/versioning/script/base.py:27
2014-12-12 16:31:22.174 15678 DEBUG migrate.versioning.script.base [-] Script /opt/stack/glance/glance/db/sqlalchemy/migrate_repo/versions/015_quote_swift_credentials.py loaded successfully __init__ /usr/local/lib/python2.7/dist-packages/migrate/versioning/script/base.py:30
2014-12-12 16:31:22.174 15678 DEBUG migrate.versioning.script.base [-] Loading script /opt/stack/glance/glance/db/sqlalchemy/migrate_repo/versions/016_sqlite_downgrade.sql... __init__ /usr/local/lib/python2.7/dist-packages/migrate/versioning/script/base.py:27
2014-12-12 16:31:22.175 15678 DEBUG migrate.versioning.script.base [-] Script /opt/stack/glance/glance/db/sqlalchemy/migrate_repo/versions/016_sqlite_downgrade.sql loaded successfully __init__ /usr/local/lib/python2.7/dist-packages/migrate/versioning/script/base.py:30
2014-12-12 16:31:22.175 15678 DEBUG migrate.versioning.script.base [-] Loading script /opt/stack/glance/glance/db/sqlalchemy/migrate_repo/versions/016_add_status_image_member.py... __init__ /usr/local/lib/python2.7/dist-packages/migrate/versioning/script/base.py:27
2014-12-12 16:31:22.175 15678 DEBUG migrate.versioning.script.base [-] Script /opt/stack/glance/glance/db/sqlalchemy/migrate_repo/versions/016_add_status_image_member.py loaded successfully __init__ /usr/local/lib/python2.7/dist-packages/migrate/versioning/script/base.py:30
2014-12-12 16:31:22.175 15678 DEBUG migrate.versioning.script.base [-] Loading script /opt/stack/glance/glance/db/sqlalchemy/migrate_repo/versions/017_quote_encrypted_swift_credentials.py... __init__ /usr/local/lib/python2.7/dist-packages/migrate/versioning/script/base.py:27
2014-12-12 16:31:22.175 15678 DEBUG migrate.versioning.script.base [-] Script /opt/stack/glance/glance/db/sqlalchemy/migrate_repo/versions/017_quote_encrypted_swift_credentials.py loaded successfully __init__ /usr/local/lib/python2.7/dist-packages/migrate/versioning/script/base.py:30
2014-12-12 16:31:22.175 15678 DEBUG migrate.versioning.script.base [-] Loading script /opt/stack/glance/glance/db/sqlalchemy/migrate_repo/versions/018_add_image_locations_table.py... __init__ /usr/local/lib/python2.7/dist-packages/migrate/versioning/script/base.py:27
2014-12-12 16:31:22.175 15678 DEBUG migrate.versioning.script.base [-] Script /opt/stack/glance/glance/db/sqlalchemy/migrate_repo/versions/018_add_image_locations_table.py loaded successfully __init__ /usr/local/lib/python2.7/dist-packages/migrate/versioning/script/base.py:30
2014-12-12 16:31:22.175 15678 DEBUG migrate.versioning.script.base [-] Loading script /opt/stack/glance/glance/db/sqlalchemy/migrate_repo/versions/019_migrate_image_locations.py... __init__ /usr/local/lib/python2.7/dist-packages/migrate/versioning/script/base.py:27
2014-12-12 16:31:22.175 15678 DEBUG migrate.versioning.script.base [-] Script /opt/stack/glance/glance/db/sqlalchemy/migrate_repo/versions/019_migrate_image_locations.py loaded successfully __init__ /usr/local/lib/python2.7/dist-packages/migrate/versioning/script/base.py:30
2014-12-12 16:31:22.175 15678 DEBUG migrate.versioning.script.base [-] Loading script /opt/stack/glance/glance/db/sqlalchemy/migrate_repo/versions/020_drop_images_table_location.py... __init__ /usr/local/lib/python2.7/dist-packages/migrate/versioning/script/base.py:27
2014-12-12 16:31:22.175 15678 DEBUG migrate.versioning.script.base [-] Script /opt/stack/glance/glance/db/sqlalchemy/migrate_repo/versions/020_drop_images_table_location.py loaded successfully __init__ /usr/local/lib/python2.7/dist-packages/migrate/versioning/script/base.py:30
2014-12-12 16:31:22.175 15678 DEBUG migrate.versioning.script.base [-] Loading script /opt/stack/glance/glance/db/sqlalchemy/migrate_repo/versions/021_set_engine_mysql_innodb.py... __init__ /usr/local/lib/python2.7/dist-packages/migrate/versioning/script/base.py:27
2014-12-12 16:31:22.175 15678 DEBUG migrate.versioning.script.base [-] Script /opt/stack/glance/glance/db/sqlalchemy/migrate_repo/versions/021_set_engine_mysql_innodb.py loaded successfully __init__ /usr/local/lib/python2.7/dist-packages/migrate/versioning/script/base.py:30
2014-12-12 16:31:22.175 15678 DEBUG migrate.versioning.script.base [-] Loading script /opt/stack/glance/glance/db/sqlalchemy/migrate_repo/versions/022_image_member_index.py... __init__ /usr/local/lib/python2.7/dist-packages/migrate/versioning/script/base.py:27
2014-12-12 16:31:22.175 15678 DEBUG migrate.versioning.script.base [-] Script /opt/stack/glance/glance/db/sqlalchemy/migrate_repo/versions/022_image_member_index.py loaded successfully __init__ /usr/local/lib/python2.7/dist-packages/migrate/versioning/script/base.py:30
2014-12-12 16:31:22.175 15678 DEBUG migrate.versioning.script.base [-] Loading script /opt/stack/glance/glance/db/sqlalchemy/migrate_repo/versions/023_placeholder.py... __init__ /usr/local/lib/python2.7/dist-packages/migrate/versioning/script/base.py:27
2014-12-12 16:31:22.175 15678 DEBUG migrate.versioning.script.base [-] Script /opt/stack/glance/glance/db/sqlalchemy/migrate_repo/versions/023_placeholder.py loaded successfully __init__ /usr/local/lib/python2.7/dist-packages/migrate/versioning/script/base.py:30
2014-12-12 16:31:22.176 15678 DEBUG migrate.versioning.script.base [-] Loading script /opt/stack/glance/glance/db/sqlalchemy/migrate_repo/versions/024_placeholder.py... __init__ /usr/local/lib/python2.7/dist-packages/migrate/versioning/script/base.py:27
2014-12-12 16:31:22.176 15678 DEBUG migrate.versioning.script.base [-] Script /opt/stack/glance/glance/db/sqlalchemy/migrate_repo/versions/024_placeholder.py loaded successfully __init__ /usr/local/lib/python2.7/dist-packages/migrate/versioning/script/base.py:30
2014-12-12 16:31:22.176 15678 DEBUG migrate.versioning.script.base [-] Loading script /opt/stack/glance/glance/db/sqlalchemy/migrate_repo/versions/025_placeholder.py... __init__ /usr/local/lib/python2.7/dist-packages/migrate/versioning/script/base.py:27
2014-12-12 16:31:22.176 15678 DEBUG migrate.versioning.script.base [-] Script /opt/stack/glance/glance/db/sqlalchemy/migrate_repo/versions/025_placeholder.py loaded successfully __init__ /usr/local/lib/python2.7/dist-packages/migrate/versioning/script/base.py:30
2014-12-12 16:31:22.176 15678 DEBUG migrate.versioning.script.base [-] Loading script /opt/stack/glance/glance/db/sqlalchemy/migrate_repo/versions/026_add_location_storage_information.py... __init__ /usr/local/lib/python2.7/dist-packages/migrate/versioning/script/base.py:27
2014-12-12 16:31:22.176 15678 DEBUG migrate.versioning.script.base [-] Script /opt/stack/glance/glance/db/sqlalchemy/migrate_repo/versions/026_add_location_storage_information.py loaded successfully __init__ /usr/local/lib/python2.7/dist-packages/migrate/versioning/script/base.py:30
2014-12-12 16:31:22.176 15678 DEBUG migrate.versioning.script.base [-] Loading script /opt/stack/glance/glance/db/sqlalchemy/migrate_repo/versions/027_checksum_index.py... __init__ /usr/local/lib/python2.7/dist-packages/migrate/versioning/script/base.py:27
2014-12-12 16:31:22.176 15678 DEBUG migrate.versioning.script.base [-] Script /opt/stack/glance/glance/db/sqlalchemy/migrate_repo/versions/027_checksum_index.py loaded successfully __init__ /usr/local/lib/python2.7/dist-packages/migrate/versioning/script/base.py:30
2014-12-12 16:31:22.176 15678 DEBUG migrate.versioning.script.base [-] Loading script /opt/stack/glance/glance/db/sqlalchemy/migrate_repo/versions/028_owner_index.py... __init__ /usr/local/lib/python2.7/dist-packages/migrate/versioning/script/base.py:27
2014-12-12 16:31:22.176 15678 DEBUG migrate.versioning.script.base [-] Script /opt/stack/glance/glance/db/sqlalchemy/migrate_repo/versions/028_owner_index.py loaded successfully __init__ /usr/local/lib/python2.7/dist-packages/migrate/versioning/script/base.py:30
2014-12-12 16:31:22.176 15678 DEBUG migrate.versioning.script.base [-] Loading script /opt/stack/glance/glance/db/sqlalchemy/migrate_repo/versions/029_location_meta_data_pickle_to_string.py... __init__ /usr/local/lib/python2.7/dist-packages/migrate/versioning/script/base.py:27
2014-12-12 16:31:22.176 15678 DEBUG migrate.versioning.script.base [-] Script /opt/stack/glance/glance/db/sqlalchemy/migrate_repo/versions/029_location_meta_data_pickle_to_string.py loaded successfully __init__ /usr/local/lib/python2.7/dist-packages/migrate/versioning/script/base.py:30
2014-12-12 16:31:22.176 15678 DEBUG migrate.versioning.script.base [-] Loading script /opt/stack/glance/glance/db/sqlalchemy/migrate_repo/versions/030_add_tasks_table.py... __init__ /usr/local/lib/python2.7/dist-packages/migrate/versioning/script/base.py:27
2014-12-12 16:31:22.176 15678 DEBUG migrate.versioning.script.base [-] Script /opt/stack/glance/glance/db/sqlalchemy/migrate_repo/versions/030_add_tasks_table.py loaded successfully __init__ /usr/local/lib/python2.7/dist-packages/migrate/versioning/script/base.py:30
2014-12-12 16:31:22.176 15678 DEBUG migrate.versioning.script.base [-] Loading script /opt/stack/glance/glance/db/sqlalchemy/migrate_repo/versions/031_remove_duplicated_locations.py... __init__ /usr/local/lib/python2.7/dist-packages/migrate/versioning/script/base.py:27
2014-12-12 16:31:22.176 15678 DEBUG migrate.versioning.script.base [-] Script /opt/stack/glance/glance/db/sqlalchemy/migrate_repo/versions/031_remove_duplicated_locations.py loaded successfully __init__ /usr/local/lib/python2.7/dist-packages/migrate/versioning/script/base.py:30
2014-12-12 16:31:22.176 15678 DEBUG migrate.versioning.script.base [-] Loading script /opt/stack/glance/glance/db/sqlalchemy/migrate_repo/versions/032_add_task_info_table.py... __init__ /usr/local/lib/python2.7/dist-packages/migrate/versioning/script/base.py:27
2014-12-12 16:31:22.177 15678 DEBUG migrate.versioning.script.base [-] Script /opt/stack/glance/glance/db/sqlalchemy/migrate_repo/versions/032_add_task_info_table.py loaded successfully __init__ /usr/local/lib/python2.7/dist-packages/migrate/versioning/script/base.py:30
2014-12-12 16:31:22.177 15678 DEBUG migrate.versioning.script.base [-] Loading script /opt/stack/glance/glance/db/sqlalchemy/migrate_repo/versions/033_add_location_status.py... __init__ /usr/local/lib/python2.7/dist-packages/migrate/versioning/script/base.py:27
2014-12-12 16:31:22.177 15678 DEBUG migrate.versioning.script.base [-] Script /opt/stack/glance/glance/db/sqlalchemy/migrate_repo/versions/033_add_location_status.py loaded successfully __init__ /usr/local/lib/python2.7/dist-packages/migrate/versioning/script/base.py:30
2014-12-12 16:31:22.177 15678 DEBUG migrate.versioning.script.base [-] Loading script /opt/stack/glance/glance/db/sqlalchemy/migrate_repo/versions/034_add_virtual_size.py... __init__ /usr/local/lib/python2.7/dist-packages/migrate/versioning/script/base.py:27
2014-12-12 16:31:22.177 15678 DEBUG migrate.versioning.script.base [-] Script /opt/stack/glance/glance/db/sqlalchemy/migrate_repo/versions/034_add_virtual_size.py loaded successfully __init__ /usr/local/lib/python2.7/dist-packages/migrate/versioning/script/base.py:30
2014-12-12 16:31:22.177 15678 DEBUG migrate.versioning.script.base [-] Loading script /opt/stack/glance/glance/db/sqlalchemy/migrate_repo/versions/035_add_metadef_tables.py... __init__ /usr/local/lib/python2.7/dist-packages/migrate/versioning/script/base.py:27
2014-12-12 16:31:22.177 15678 DEBUG migrate.versioning.script.base [-] Script /opt/stack/glance/glance/db/sqlalchemy/migrate_repo/versions/035_add_metadef_tables.py loaded successfully __init__ /usr/local/lib/python2.7/dist-packages/migrate/versioning/script/base.py:30
2014-12-12 16:31:22.177 15678 DEBUG migrate.versioning.script.base [-] Loading script /opt/stack/glance/glance/db/sqlalchemy/migrate_repo/versions/036_rename_metadef_schema_columns.py... __init__ /usr/local/lib/python2.7/dist-packages/migrate/versioning/script/base.py:27
2014-12-12 16:31:22.177 15678 DEBUG migrate.versioning.script.base [-] Script /opt/stack/glance/glance/db/sqlalchemy/migrate_repo/versions/036_rename_metadef_schema_columns.py loaded successfully __init__ /usr/local/lib/python2.7/dist-packages/migrate/versioning/script/base.py:30
2014-12-12 16:31:22.177 15678 DEBUG migrate.versioning.repository [-] Repository /opt/stack/glance/glance/db/sqlalchemy/migrate_repo loaded successfully __init__ /usr/local/lib/python2.7/dist-packages/migrate/versioning/repository.py:82
2014-12-12 16:31:22.177 15678 DEBUG migrate.versioning.repository [-] Config: OrderedDict([('db_settings', OrderedDict([('__name__', 'db_settings'), ('repository_id', 'Glance Migrations'), ('version_table', 'migrate_version'), ('required_dbs', '[]')]))]) __init__ /usr/local/lib/python2.7/dist-packages/migrate/versioning/repository.py:83
2014-12-12 16:31:22.226 15678 DEBUG migrate.versioning.repository [-] Loading repository /opt/stack/glance/glance/db/sqlalchemy/migrate_repo... __init__ /usr/local/lib/python2.7/dist-packages/migrate/versioning/repository.py:76
2014-12-12 16:31:22.227 15678 DEBUG migrate.versioning.script.base [-] Loading script /opt/stack/glance/glance/db/sqlalchemy/migrate_repo/versions/001_add_images_table.py... __init__ /usr/local/lib/python2.7/dist-packages/migrate/versioning/script/base.py:27
2014-12-12 16:31:22.227 15678 DEBUG migrate.versioning.script.base [-] Script /opt/stack/glance/glance/db/sqlalchemy/migrate_repo/versions/001_add_images_table.py loaded successfully __init__ /usr/local/lib/python2.7/dist-packages/migrate/versioning/script/base.py:30
2014-12-12 16:31:22.227 15678 DEBUG migrate.versioning.script.base [-] Loading script /opt/stack/glance/glance/db/sqlalchemy/migrate_repo/versions/002_add_image_properties_table.py... __init__ /usr/local/lib/python2.7/dist-packages/migrate/versioning/script/base.py:27
2014-12-12 16:31:22.227 15678 DEBUG migrate.versioning.script.base [-] Script /opt/stack/glance/glance/db/sqlalchemy/migrate_repo/versions/002_add_image_properties_table.py loaded successfully __init__ /usr/local/lib/python2.7/dist-packages/migrate/versioning/script/base.py:30
2014-12-12 16:31:22.227 15678 DEBUG migrate.versioning.script.base [-] Loading script /opt/stack/glance/glance/db/sqlalchemy/migrate_repo/versions/003_sqlite_downgrade.sql... __init__ /usr/local/lib/python2.7/dist-packages/migrate/versioning/script/base.py:27
2014-12-12 16:31:22.227 15678 DEBUG migrate.versioning.script.base [-] Script /opt/stack/glance/glance/db/sqlalchemy/migrate_repo/versions/003_sqlite_downgrade.sql loaded successfully __init__ /usr/local/lib/python2.7/dist-packages/migrate/versioning/script/base.py:30
2014-12-12 16:31:22.227 15678 DEBUG migrate.versioning.script.base [-] Loading script /opt/stack/glance/glance/db/sqlalchemy/migrate_repo/versions/003_sqlite_upgrade.sql... __init__ /usr/local/lib/python2.7/dist-packages/migrate/versioning/script/base.py:27
2014-12-12 16:31:22.227 15678 DEBUG migrate.versioning.script.base [-] Script /opt/stack/glance/glance/db/sqlalchemy/migrate_repo/versions/003_sqlite_upgrade.sql loaded successfully __init__ /usr/local/lib/python2.7/dist-packages/migrate/versioning/script/base.py:30
2014-12-12 16:31:22.227 15678 DEBUG migrate.versioning.script.base [-] Loading script /opt/stack/glance/glance/db/sqlalchemy/migrate_repo/versions/003_add_disk_format.py... __init__ /usr/local/lib/python2.7/dist-packages/migrate/versioning/script/base.py:27
2014-12-12 16:31:22.227 15678 DEBUG migrate.versioning.script.base [-] Script /opt/stack/glance/glance/db/sqlalchemy/migrate_repo/versions/003_add_disk_format.py loaded successfully __init__ /usr/local/lib/python2.7/dist-packages/migrate/versioning/script/base.py:30
2014-12-12 16:31:22.228 15678 DEBUG migrate.versioning.script.base [-] Loading script /opt/stack/glance/glance/db/sqlalchemy/migrate_repo/versions/004_add_checksum.py... __init__ /usr/local/lib/python2.7/dist-packages/migrate/versioning/script/base.py:27
2014-12-12 16:31:22.228 15678 DEBUG migrate.versioning.script.base [-] Script /opt/stack/glance/glance/db/sqlalchemy/migrate_repo/versions/004_add_checksum.py loaded successfully __init__ /usr/local/lib/python2.7/dist-packages/migrate/versioning/script/base.py:30
2014-12-12 16:31:22.228 15678 DEBUG migrate.versioning.script.base [-] Loading script /opt/stack/glance/glance/db/sqlalchemy/migrate_repo/versions/005_size_big_integer.py... __init__ /usr/local/lib/python2.7/dist-packages/migrate/versioning/script/base.py:27
2014-12-12 16:31:22.228 15678 DEBUG migrate.versioning.script.base [-] Script /opt/stack/glance/glance/db/sqlalchemy/migrate_repo/versions/005_size_big_integer.py loaded successfully __init__ /usr/local/lib/python2.7/dist-packages/migrate/versioning/script/base.py:30
2014-12-12 16:31:22.228 15678 DEBUG migrate.versioning.script.base [-] Loading script /opt/stack/glance/glance/db/sqlalchemy/migrate_repo/versions/006_mysql_upgrade.sql... __init__ /usr/local/lib/python2.7/dist-packages/migrate/versioning/script/base.py:27
2014-12-12 16:31:22.228 15678 DEBUG migrate.versioning.script.base [-] Script /opt/stack/glance/glance/db/sqlalchemy/migrate_repo/versions/006_mysql_upgrade.sql loaded successfully __init__ /usr/local/lib/python2.7/dist-packages/migrate/versioning/script/base.py:30
2014-12-12 16:31:22.228 15678 DEBUG migrate.versioning.script.base [-] Loading script /opt/stack/glance/glance/db/sqlalchemy/migrate_repo/versions/006_sqlite_downgrade.sql... __init__ /usr/local/lib/python2.7/dist-packages/migrate/versioning/script/base.py:27
2014-12-12 16:31:22.228 15678 DEBUG migrate.versioning.script.base [-] Script /opt/stack/glance/glance/db/sqlalchemy/migrate_repo/versions/006_sqlite_downgrade.sql loaded successfully __init__ /usr/local/lib/python2.7/dist-packages/migrate/versioning/script/base.py:30
2014-12-12 16:31:22.228 15678 DEBUG migrate.versioning.script.base [-] Loading script /opt/stack/glance/glance/db/sqlalchemy/migrate_repo/versions/006_key_to_name.py... __init__ /usr/local/lib/python2.7/dist-packages/migrate/versioning/script/base.py:27
2014-12-12 16:31:22.228 15678 DEBUG migrate.versioning.script.base [-] Script /opt/stack/glance/glance/db/sqlalchemy/migrate_repo/versions/006_key_to_name.py loaded successfully __init__ /usr/local/lib/python2.7/dist-packages/migrate/versioning/script/base.py:30
2014-12-12 16:31:22.228 15678 DEBUG migrate.versioning.script.base [-] Loading script /opt/stack/glance/glance/db/sqlalchemy/migrate_repo/versions/006_sqlite_upgrade.sql... __init__ /usr/local/lib/python2.7/dist-packages/migrate/versioning/script/base.py:27
2014-12-12 16:31:22.228 15678 DEBUG migrate.versioning.script.base [-] Script /opt/stack/glance/glance/db/sqlalchemy/migrate_repo/versions/006_sqlite_upgrade.sql loaded successfully __init__ /usr/local/lib/python2.7/dist-packages/migrate/versioning/script/base.py:30
2014-12-12 16:31:22.228 15678 DEBUG migrate.versioning.script.base [-] Loading script /opt/stack/glance/glance/db/sqlalchemy/migrate_repo/versions/006_mysql_downgrade.sql... __init__ /usr/local/lib/python2.7/dist-packages/migrate/versioning/script/base.py:27
2014-12-12 16:31:22.228 15678 DEBUG migrate.versioning.script.base [-] Script /opt/stack/glance/glance/db/sqlalchemy/migrate_repo/versions/006_mysql_downgrade.sql loaded successfully __init__ /usr/local/lib/python2.7/dist-packages/migrate/versioning/script/base.py:30
2014-12-12 16:31:22.228 15678 DEBUG migrate.versioning.script.base [-] Loading script /opt/stack/glance/glance/db/sqlalchemy/migrate_repo/versions/007_add_owner.py... __init__ /usr/local/lib/python2.7/dist-packages/migrate/versioning/script/base.py:27
2014-12-12 16:31:22.228 15678 DEBUG migrate.versioning.script.base [-] Script /opt/stack/glance/glance/db/sqlalchemy/migrate_repo/versions/007_add_owner.py loaded successfully __init__ /usr/local/lib/python2.7/dist-packages/migrate/versioning/script/base.py:30
2014-12-12 16:31:22.228 15678 DEBUG migrate.versioning.script.base [-] Loading script /opt/stack/glance/glance/db/sqlalchemy/migrate_repo/versions/008_add_image_members_table.py... __init__ /usr/local/lib/python2.7/dist-packages/migrate/versioning/script/base.py:27
2014-12-12 16:31:22.228 15678 DEBUG migrate.versioning.script.base [-] Script /opt/stack/glance/glance/db/sqlalchemy/migrate_repo/versions/008_add_image_members_table.py loaded successfully __init__ /usr/local/lib/python2.7/dist-packages/migrate/versioning/script/base.py:30
2014-12-12 16:31:22.229 15678 DEBUG migrate.versioning.script.base [-] Loading script /opt/stack/glance/glance/db/sqlalchemy/migrate_repo/versions/009_add_mindisk_and_minram.py... __init__ /usr/local/lib/python2.7/dist-packages/migrate/versioning/script/base.py:27
2014-12-12 16:31:22.229 15678 DEBUG migrate.versioning.script.base [-] Script /opt/stack/glance/glance/db/sqlalchemy/migrate_repo/versions/009_add_mindisk_and_minram.py loaded successfully __init__ /usr/local/lib/python2.7/dist-packages/migrate/versioning/script/base.py:30
2014-12-12 16:31:22.229 15678 DEBUG migrate.versioning.script.base [-] Loading script /opt/stack/glance/glance/db/sqlalchemy/migrate_repo/versions/010_default_update_at.py... __init__ /usr/local/lib/python2.7/dist-packages/migrate/versioning/script/base.py:27
2014-12-12 16:31:22.229 15678 DEBUG migrate.versioning.script.base [-] Script /opt/stack/glance/glance/db/sqlalchemy/migrate_repo/versions/010_default_update_at.py loaded successfully __init__ /usr/local/lib/python2.7/dist-packages/migrate/versioning/script/base.py:30
2014-12-12 16:31:22.229 15678 DEBUG migrate.versioning.script.base [-] Loading script /opt/stack/glance/glance/db/sqlalchemy/migrate_repo/versions/011_make_mindisk_and_minram_notnull.py... __init__ /usr/local/lib/python2.7/dist-packages/migrate/versioning/script/base.py:27
2014-12-12 16:31:22.229 15678 DEBUG migrate.versioning.script.base [-] Script /opt/stack/glance/glance/db/sqlalchemy/migrate_repo/versions/011_make_mindisk_and_minram_notnull.py loaded successfully __init__ /usr/local/lib/python2.7/dist-packages/migrate/versioning/script/base.py:30
2014-12-12 16:31:22.229 15678 DEBUG migrate.versioning.script.base [-] Loading script /opt/stack/glance/glance/db/sqlalchemy/migrate_repo/versions/011_sqlite_upgrade.sql... __init__ /usr/local/lib/python2.7/dist-packages/migrate/versioning/script/base.py:27
2014-12-12 16:31:22.229 15678 DEBUG migrate.versioning.script.base [-] Script /opt/stack/glance/glance/db/sqlalchemy/migrate_repo/versions/011_sqlite_upgrade.sql loaded successfully __init__ /usr/local/lib/python2.7/dist-packages/migrate/versioning/script/base.py:30
2014-12-12 16:31:22.229 15678 DEBUG migrate.versioning.script.base [-] Loading script /opt/stack/glance/glance/db/sqlalchemy/migrate_repo/versions/011_sqlite_downgrade.sql... __init__ /usr/local/lib/python2.7/dist-packages/migrate/versioning/script/base.py:27
2014-12-12 16:31:22.229 15678 DEBUG migrate.versioning.script.base [-] Script /opt/stack/glance/glance/db/sqlalchemy/migrate_repo/versions/011_sqlite_downgrade.sql loaded successfully __init__ /usr/local/lib/python2.7/dist-packages/migrate/versioning/script/base.py:30
2014-12-12 16:31:22.229 15678 DEBUG migrate.versioning.script.base [-] Loading script /opt/stack/glance/glance/db/sqlalchemy/migrate_repo/versions/012_id_to_uuid.py... __init__ /usr/local/lib/python2.7/dist-packages/migrate/versioning/script/base.py:27
2014-12-12 16:31:22.229 15678 DEBUG migrate.versioning.script.base [-] Script /opt/stack/glance/glance/db/sqlalchemy/migrate_repo/versions/012_id_to_uuid.py loaded successfully __init__ /usr/local/lib/python2.7/dist-packages/migrate/versioning/script/base.py:30
2014-12-12 16:31:22.229 15678 DEBUG migrate.versioning.script.base [-] Loading script /opt/stack/glance/glance/db/sqlalchemy/migrate_repo/versions/013_sqlite_downgrade.sql... __init__ /usr/local/lib/python2.7/dist-packages/migrate/versioning/script/base.py:27
2014-12-12 16:31:22.229 15678 DEBUG migrate.versioning.script.base [-] Script /opt/stack/glance/glance/db/sqlalchemy/migrate_repo/versions/013_sqlite_downgrade.sql loaded successfully __init__ /usr/local/lib/python2.7/dist-packages/migrate/versioning/script/base.py:30
2014-12-12 16:31:22.229 15678 DEBUG migrate.versioning.script.base [-] Loading script /opt/stack/glance/glance/db/sqlalchemy/migrate_repo/versions/013_add_protected.py... __init__ /usr/local/lib/python2.7/dist-packages/migrate/versioning/script/base.py:27
2014-12-12 16:31:22.229 15678 DEBUG migrate.versioning.script.base [-] Script /opt/stack/glance/glance/db/sqlalchemy/migrate_repo/versions/013_add_protected.py loaded successfully __init__ /usr/local/lib/python2.7/dist-packages/migrate/versioning/script/base.py:30
2014-12-12 16:31:22.229 15678 DEBUG migrate.versioning.script.base [-] Loading script /opt/stack/glance/glance/db/sqlalchemy/migrate_repo/versions/014_add_image_tags_table.py... __init__ /usr/local/lib/python2.7/dist-packages/migrate/versioning/script/base.py:27
2014-12-12 16:31:22.229 15678 DEBUG migrate.versioning.script.base [-] Script /opt/stack/glance/glance/db/sqlalchemy/migrate_repo/versions/014_add_image_tags_table.py loaded successfully __init__ /usr/local/lib/python2.7/dist-packages/migrate/versioning/script/base.py:30
2014-12-12 16:31:22.230 15678 DEBUG migrate.versioning.script.base [-] Loading script /opt/stack/glance/glance/db/sqlalchemy/migrate_repo/versions/015_quote_swift_credentials.py... __init__ /usr/local/lib/python2.7/dist-packages/migrate/versioning/script/base.py:27
2014-12-12 16:31:22.230 15678 DEBUG migrate.versioning.script.base [-] Script /opt/stack/glance/glance/db/sqlalchemy/migrate_repo/versions/015_quote_swift_credentials.py loaded successfully __init__ /usr/local/lib/python2.7/dist-packages/migrate/versioning/script/base.py:30
2014-12-12 16:31:22.230 15678 DEBUG migrate.versioning.script.base [-] Loading script /opt/stack/glance/glance/db/sqlalchemy/migrate_repo/versions/016_sqlite_downgrade.sql... __init__ /usr/local/lib/python2.7/dist-packages/migrate/versioning/script/base.py:27
2014-12-12 16:31:22.230 15678 DEBUG migrate.versioning.script.base [-] Script /opt/stack/glance/glance/db/sqlalchemy/migrate_repo/versions/016_sqlite_downgrade.sql loaded successfully __init__ /usr/local/lib/python2.7/dist-packages/migrate/versioning/script/base.py:30
2014-12-12 16:31:22.230 15678 DEBUG migrate.versioning.script.base [-] Loading script /opt/stack/glance/glance/db/sqlalchemy/migrate_repo/versions/016_add_status_image_member.py... __init__ /usr/local/lib/python2.7/dist-packages/migrate/versioning/script/base.py:27
2014-12-12 16:31:22.230 15678 DEBUG migrate.versioning.script.base [-] Script /opt/stack/glance/glance/db/sqlalchemy/migrate_repo/versions/016_add_status_image_member.py loaded successfully __init__ /usr/local/lib/python2.7/dist-packages/migrate/versioning/script/base.py:30
2014-12-12 16:31:22.230 15678 DEBUG migrate.versioning.script.base [-] Loading script /opt/stack/glance/glance/db/sqlalchemy/migrate_repo/versions/017_quote_encrypted_swift_credentials.py... __init__ /usr/local/lib/python2.7/dist-packages/migrate/versioning/script/base.py:27
2014-12-12 16:31:22.230 15678 DEBUG migrate.versioning.script.base [-] Script /opt/stack/glance/glance/db/sqlalchemy/migrate_repo/versions/017_quote_encrypted_swift_credentials.py loaded successfully __init__ /usr/local/lib/python2.7/dist-packages/migrate/versioning/script/base.py:30
2014-12-12 16:31:22.230 15678 DEBUG migrate.versioning.script.base [-] Loading script /opt/stack/glance/glance/db/sqlalchemy/migrate_repo/versions/018_add_image_locations_table.py... __init__ /usr/local/lib/python2.7/dist-packages/migrate/versioning/script/base.py:27
2014-12-12 16:31:22.230 15678 DEBUG migrate.versioning.script.base [-] Script /opt/stack/glance/glance/db/sqlalchemy/migrate_repo/versions/018_add_image_locations_table.py loaded successfully __init__ /usr/local/lib/python2.7/dist-packages/migrate/versioning/script/base.py:30
2014-12-12 16:31:22.230 15678 DEBUG migrate.versioning.script.base [-] Loading script /opt/stack/glance/glance/db/sqlalchemy/migrate_repo/versions/019_migrate_image_locations.py... __init__ /usr/local/lib/python2.7/dist-packages/migrate/versioning/script/base.py:27
2014-12-12 16:31:22.230 15678 DEBUG migrate.versioning.script.base [-] Script /opt/stack/glance/glance/db/sqlalchemy/migrate_repo/versions/019_migrate_image_locations.py loaded successfully __init__ /usr/local/lib/python2.7/dist-packages/migrate/versioning/script/base.py:30
2014-12-12 16:31:22.230 15678 DEBUG migrate.versioning.script.base [-] Loading script /opt/stack/glance/glance/db/sqlalchemy/migrate_repo/versions/020_drop_images_table_location.py... __init__ /usr/local/lib/python2.7/dist-packages/migrate/versioning/script/base.py:27
2014-12-12 16:31:22.230 15678 DEBUG migrate.versioning.script.base [-] Script /opt/stack/glance/glance/db/sqlalchemy/migrate_repo/versions/020_drop_images_table_location.py loaded successfully __init__ /usr/local/lib/python2.7/dist-packages/migrate/versioning/script/base.py:30
2014-12-12 16:31:22.230 15678 DEBUG migrate.versioning.script.base [-] Loading script /opt/stack/glance/glance/db/sqlalchemy/migrate_repo/versions/021_set_engine_mysql_innodb.py... __init__ /usr/local/lib/python2.7/dist-packages/migrate/versioning/script/base.py:27
2014-12-12 16:31:22.230 15678 DEBUG migrate.versioning.script.base [-] Script /opt/stack/glance/glance/db/sqlalchemy/migrate_repo/versions/021_set_engine_mysql_innodb.py loaded successfully __init__ /usr/local/lib/python2.7/dist-packages/migrate/versioning/script/base.py:30
2014-12-12 16:31:22.230 15678 DEBUG migrate.versioning.script.base [-] Loading script /opt/stack/glance/glance/db/sqlalchemy/migrate_repo/versions/022_image_member_index.py... __init__ /usr/local/lib/python2.7/dist-packages/migrate/versioning/script/base.py:27
2014-12-12 16:31:22.231 15678 DEBUG migrate.versioning.script.base [-] Script /opt/stack/glance/glance/db/sqlalchemy/migrate_repo/versions/022_image_member_index.py loaded successfully __init__ /usr/local/lib/python2.7/dist-packages/migrate/versioning/script/base.py:30
2014-12-12 16:31:22.231 15678 DEBUG migrate.versioning.script.base [-] Loading script /opt/stack/glance/glance/db/sqlalchemy/migrate_repo/versions/023_placeholder.py... __init__ /usr/local/lib/python2.7/dist-packages/migrate/versioning/script/base.py:27
2014-12-12 16:31:22.231 15678 DEBUG migrate.versioning.script.base [-] Script /opt/stack/glance/glance/db/sqlalchemy/migrate_repo/versions/023_placeholder.py loaded successfully __init__ /usr/local/lib/python2.7/dist-packages/migrate/versioning/script/base.py:30
2014-12-12 16:31:22.231 15678 DEBUG migrate.versioning.script.base [-] Loading script /opt/stack/glance/glance/db/sqlalchemy/migrate_repo/versions/024_placeholder.py... __init__ /usr/local/lib/python2.7/dist-packages/migrate/versioning/script/base.py:27
2014-12-12 16:31:22.231 15678 DEBUG migrate.versioning.script.base [-] Script /opt/stack/glance/glance/db/sqlalchemy/migrate_repo/versions/024_placeholder.py loaded successfully __init__ /usr/local/lib/python2.7/dist-packages/migrate/versioning/script/base.py:30
2014-12-12 16:31:22.231 15678 DEBUG migrate.versioning.script.base [-] Loading script /opt/stack/glance/glance/db/sqlalchemy/migrate_repo/versions/025_placeholder.py... __init__ /usr/local/lib/python2.7/dist-packages/migrate/versioning/script/base.py:27
2014-12-12 16:31:22.231 15678 DEBUG migrate.versioning.script.base [-] Script /opt/stack/glance/glance/db/sqlalchemy/migrate_repo/versions/025_placeholder.py loaded successfully __init__ /usr/local/lib/python2.7/dist-packages/migrate/versioning/script/base.py:30
2014-12-12 16:31:22.231 15678 DEBUG migrate.versioning.script.base [-] Loading script /opt/stack/glance/glance/db/sqlalchemy/migrate_repo/versions/026_add_location_storage_information.py... __init__ /usr/local/lib/python2.7/dist-packages/migrate/versioning/script/base.py:27
2014-12-12 16:31:22.231 15678 DEBUG migrate.versioning.script.base [-] Script /opt/stack/glance/glance/db/sqlalchemy/migrate_repo/versions/026_add_location_storage_information.py loaded successfully __init__ /usr/local/lib/python2.7/dist-packages/migrate/versioning/script/base.py:30
2014-12-12 16:31:22.231 15678 DEBUG migrate.versioning.script.base [-] Loading script /opt/stack/glance/glance/db/sqlalchemy/migrate_repo/versions/027_checksum_index.py... __init__ /usr/local/lib/python2.7/dist-packages/migrate/versioning/script/base.py:27
2014-12-12 16:31:22.231 15678 DEBUG migrate.versioning.script.base [-] Script /opt/stack/glance/glance/db/sqlalchemy/migrate_repo/versions/027_checksum_index.py loaded successfully __init__ /usr/local/lib/python2.7/dist-packages/migrate/versioning/script/base.py:30
2014-12-12 16:31:22.231 15678 DEBUG migrate.versioning.script.base [-] Loading script /opt/stack/glance/glance/db/sqlalchemy/migrate_repo/versions/028_owner_index.py... __init__ /usr/local/lib/python2.7/dist-packages/migrate/versioning/script/base.py:27
2014-12-12 16:31:22.231 15678 DEBUG migrate.versioning.script.base [-] Script /opt/stack/glance/glance/db/sqlalchemy/migrate_repo/versions/028_owner_index.py loaded successfully __init__ /usr/local/lib/python2.7/dist-packages/migrate/versioning/script/base.py:30
2014-12-12 16:31:22.231 15678 DEBUG migrate.versioning.script.base [-] Loading script /opt/stack/glance/glance/db/sqlalchemy/migrate_repo/versions/029_location_meta_data_pickle_to_string.py... __init__ /usr/local/lib/python2.7/dist-packages/migrate/versioning/script/base.py:27
2014-12-12 16:31:22.231 15678 DEBUG migrate.versioning.script.base [-] Script /opt/stack/glance/glance/db/sqlalchemy/migrate_repo/versions/029_location_meta_data_pickle_to_string.py loaded successfully __init__ /usr/local/lib/python2.7/dist-packages/migrate/versioning/script/base.py:30
2014-12-12 16:31:22.231 15678 DEBUG migrate.versioning.script.base [-] Loading script /opt/stack/glance/glance/db/sqlalchemy/migrate_repo/versions/030_add_tasks_table.py... __init__ /usr/local/lib/python2.7/dist-packages/migrate/versioning/script/base.py:27
2014-12-12 16:31:22.231 15678 DEBUG migrate.versioning.script.base [-] Script /opt/stack/glance/glance/db/sqlalchemy/migrate_repo/versions/030_add_tasks_table.py loaded successfully __init__ /usr/local/lib/python2.7/dist-packages/migrate/versioning/script/base.py:30
2014-12-12 16:31:22.231 15678 DEBUG migrate.versioning.script.base [-] Loading script /opt/stack/glance/glance/db/sqlalchemy/migrate_repo/versions/031_remove_duplicated_locations.py... __init__ /usr/local/lib/python2.7/dist-packages/migrate/versioning/script/base.py:27
2014-12-12 16:31:22.232 15678 DEBUG migrate.versioning.script.base [-] Script /opt/stack/glance/glance/db/sqlalchemy/migrate_repo/versions/031_remove_duplicated_locations.py loaded successfully __init__ /usr/local/lib/python2.7/dist-packages/migrate/versioning/script/base.py:30
2014-12-12 16:31:22.232 15678 DEBUG migrate.versioning.script.base [-] Loading script /opt/stack/glance/glance/db/sqlalchemy/migrate_repo/versions/032_add_task_info_table.py... __init__ /usr/local/lib/python2.7/dist-packages/migrate/versioning/script/base.py:27
2014-12-12 16:31:22.232 15678 DEBUG migrate.versioning.script.base [-] Script /opt/stack/glance/glance/db/sqlalchemy/migrate_repo/versions/032_add_task_info_table.py loaded successfully __init__ /usr/local/lib/python2.7/dist-packages/migrate/versioning/script/base.py:30
2014-12-12 16:31:22.232 15678 DEBUG migrate.versioning.script.base [-] Loading script /opt/stack/glance/glance/db/sqlalchemy/migrate_repo/versions/033_add_location_status.py... __init__ /usr/local/lib/python2.7/dist-packages/migrate/versioning/script/base.py:27
2014-12-12 16:31:22.232 15678 DEBUG migrate.versioning.script.base [-] Script /opt/stack/glance/glance/db/sqlalchemy/migrate_repo/versions/033_add_location_status.py loaded successfully __init__ /usr/local/lib/python2.7/dist-packages/migrate/versioning/script/base.py:30
2014-12-12 16:31:22.232 15678 DEBUG migrate.versioning.script.base [-] Loading script /opt/stack/glance/glance/db/sqlalchemy/migrate_repo/versions/034_add_virtual_size.py... __init__ /usr/local/lib/python2.7/dist-packages/migrate/versioning/script/base.py:27
2014-12-12 16:31:22.232 15678 DEBUG migrate.versioning.script.base [-] Script /opt/stack/glance/glance/db/sqlalchemy/migrate_repo/versions/034_add_virtual_size.py loaded successfully __init__ /usr/local/lib/python2.7/dist-packages/migrate/versioning/script/base.py:30
2014-12-12 16:31:22.232 15678 DEBUG migrate.versioning.script.base [-] Loading script /opt/stack/glance/glance/db/sqlalchemy/migrate_repo/versions/035_add_metadef_tables.py... __init__ /usr/local/lib/python2.7/dist-packages/migrate/versioning/script/base.py:27
2014-12-12 16:31:22.232 15678 DEBUG migrate.versioning.script.base [-] Script /opt/stack/glance/glance/db/sqlalchemy/migrate_repo/versions/035_add_metadef_tables.py loaded successfully __init__ /usr/local/lib/python2.7/dist-packages/migrate/versioning/script/base.py:30
2014-12-12 16:31:22.232 15678 DEBUG migrate.versioning.script.base [-] Loading script /opt/stack/glance/glance/db/sqlalchemy/migrate_repo/versions/036_rename_metadef_schema_columns.py... __init__ /usr/local/lib/python2.7/dist-packages/migrate/versioning/script/base.py:27
2014-12-12 16:31:22.232 15678 DEBUG migrate.versioning.script.base [-] Script /opt/stack/glance/glance/db/sqlalchemy/migrate_repo/versions/036_rename_metadef_schema_columns.py loaded successfully __init__ /usr/local/lib/python2.7/dist-packages/migrate/versioning/script/base.py:30
2014-12-12 16:31:22.232 15678 DEBUG migrate.versioning.repository [-] Repository /opt/stack/glance/glance/db/sqlalchemy/migrate_repo loaded successfully __init__ /usr/local/lib/python2.7/dist-packages/migrate/versioning/repository.py:82
2014-12-12 16:31:22.232 15678 DEBUG migrate.versioning.repository [-] Config: OrderedDict([('db_settings', OrderedDict([('__name__', 'db_settings'), ('repository_id', 'Glance Migrations'), ('version_table', 'migrate_version'), ('required_dbs', '[]')]))]) __init__ /usr/local/lib/python2.7/dist-packages/migrate/versioning/repository.py:83
2014-12-12 16:31:22.237 15678 INFO migrate.versioning.api [-] 0 -> 1... 
2014-12-12 16:31:22.240 15678 INFO glance.db.sqlalchemy.migrate_repo.schema [-] creating table images
2014-12-12 16:31:22.343 15678 INFO migrate.versioning.api [-] done
2014-12-12 16:31:22.343 15678 INFO migrate.versioning.api [-] 1 -> 2... 
2014-12-12 16:31:22.348 15678 INFO glance.db.sqlalchemy.migrate_repo.schema [-] creating table image_properties
2014-12-12 16:31:22.492 15678 INFO migrate.versioning.api [-] done
2014-12-12 16:31:22.492 15678 INFO migrate.versioning.api [-] 2 -> 3... 
2014-12-12 16:31:22.664 15678 INFO migrate.versioning.api [-] done
2014-12-12 16:31:22.664 15678 INFO migrate.versioning.api [-] 3 -> 4... 
2014-12-12 16:31:22.733 15678 INFO migrate.versioning.api [-] done
2014-12-12 16:31:22.734 15678 INFO migrate.versioning.api [-] 4 -> 5... 
2014-12-12 16:31:22.809 15678 INFO migrate.versioning.api [-] done
2014-12-12 16:31:22.809 15678 INFO migrate.versioning.api [-] 5 -> 6... 
2014-12-12 16:31:22.938 15678 INFO migrate.versioning.api [-] done
2014-12-12 16:31:22.938 15678 INFO migrate.versioning.api [-] 6 -> 7... 
2014-12-12 16:31:23.023 15678 INFO migrate.versioning.api [-] done
2014-12-12 16:31:23.024 15678 INFO migrate.versioning.api [-] 7 -> 8... 
2014-12-12 16:31:23.034 15678 INFO glance.db.sqlalchemy.migrate_repo.schema [-] creating table image_members
2014-12-12 16:31:23.189 15678 INFO migrate.versioning.api [-] done
2014-12-12 16:31:23.189 15678 INFO migrate.versioning.api [-] 8 -> 9... 
2014-12-12 16:31:23.321 15678 INFO migrate.versioning.api [-] done
2014-12-12 16:31:23.321 15678 INFO migrate.versioning.api [-] 9 -> 10... 
2014-12-12 16:31:23.342 15678 INFO migrate.versioning.api [-] done
2014-12-12 16:31:23.343 15678 INFO migrate.versioning.api [-] 10 -> 11... 
2014-12-12 16:31:23.466 15678 INFO migrate.versioning.api [-] done
2014-12-12 16:31:23.466 15678 INFO migrate.versioning.api [-] 11 -> 12... 
2014-12-12 16:31:23.862 15678 INFO migrate.versioning.api [-] done
2014-12-12 16:31:23.862 15678 INFO migrate.versioning.api [-] 12 -> 13... 
2014-12-12 16:31:23.926 15678 INFO migrate.versioning.api [-] done
2014-12-12 16:31:23.926 15678 INFO migrate.versioning.api [-] 13 -> 14... 
2014-12-12 16:31:23.931 15678 INFO glance.db.sqlalchemy.migrate_repo.schema [-] creating table image_tags
2014-12-12 16:31:24.088 15678 INFO migrate.versioning.api [-] done
2014-12-12 16:31:24.089 15678 INFO migrate.versioning.api [-] 14 -> 15... 
2014-12-12 16:31:24.115 15678 INFO migrate.versioning.api [-] done
2014-12-12 16:31:24.115 15678 INFO migrate.versioning.api [-] 15 -> 16... 
2014-12-12 16:31:24.201 15678 INFO migrate.versioning.api [-] done
2014-12-12 16:31:24.202 15678 INFO migrate.versioning.api [-] 16 -> 17... 
2014-12-12 16:31:24.235 15678 INFO 017_quote_encrypted_swift_credentials [-] 'metadata_encryption_key' was not specified in the config file or a config file was not specified. This means that this migration is a NOOP.
2014-12-12 16:31:24.246 15678 INFO migrate.versioning.api [-] done
2014-12-12 16:31:24.247 15678 INFO migrate.versioning.api [-] 17 -> 18... 
2014-12-12 16:31:24.259 15678 INFO glance.db.sqlalchemy.migrate_repo.schema [-] creating table image_locations
2014-12-12 16:31:24.392 15678 INFO migrate.versioning.api [-] done
2014-12-12 16:31:24.392 15678 INFO migrate.versioning.api [-] 18 -> 19... 
2014-12-12 16:31:24.423 15678 INFO migrate.versioning.api [-] done
2014-12-12 16:31:24.424 15678 INFO migrate.versioning.api [-] 19 -> 20... 
2014-12-12 16:31:24.495 15678 INFO migrate.versioning.api [-] done
2014-12-12 16:31:24.495 15678 INFO migrate.versioning.api [-] 20 -> 21... 
2014-12-12 16:31:24.519 15678 INFO migrate.versioning.api [-] done
2014-12-12 16:31:24.519 15678 INFO migrate.versioning.api [-] 21 -> 22... 
2014-12-12 16:31:24.620 15678 INFO migrate.versioning.api [-] done
2014-12-12 16:31:24.620 15678 INFO migrate.versioning.api [-] 22 -> 23... 
2014-12-12 16:31:24.636 15678 INFO migrate.versioning.api [-] done
2014-12-12 16:31:24.636 15678 INFO migrate.versioning.api [-] 23 -> 24... 
2014-12-12 16:31:24.648 15678 INFO migrate.versioning.api [-] done
2014-12-12 16:31:24.649 15678 INFO migrate.versioning.api [-] 24 -> 25... 
2014-12-12 16:31:24.660 15678 INFO migrate.versioning.api [-] done
2014-12-12 16:31:24.661 15678 INFO migrate.versioning.api [-] 25 -> 26... 
2014-12-12 16:31:24.737 15678 INFO migrate.versioning.api [-] done
2014-12-12 16:31:24.737 15678 INFO migrate.versioning.api [-] 26 -> 27... 
2014-12-12 16:31:24.795 15678 INFO migrate.versioning.api [-] done
2014-12-12 16:31:24.795 15678 INFO migrate.versioning.api [-] 27 -> 28... 
2014-12-12 16:31:24.847 15678 INFO migrate.versioning.api [-] done
2014-12-12 16:31:24.847 15678 INFO migrate.versioning.api [-] 28 -> 29... 
2014-12-12 16:31:25.042 15678 INFO migrate.versioning.api [-] done
2014-12-12 16:31:25.042 15678 INFO migrate.versioning.api [-] 29 -> 30... 
2014-12-12 16:31:25.046 15678 INFO glance.db.sqlalchemy.migrate_repo.schema [-] creating table tasks
2014-12-12 16:31:25.286 15678 INFO migrate.versioning.api [-] done
2014-12-12 16:31:25.286 15678 INFO migrate.versioning.api [-] 30 -> 31... 
2014-12-12 16:31:25.310 15678 INFO migrate.versioning.api [-] done
2014-12-12 16:31:25.310 15678 INFO migrate.versioning.api [-] 31 -> 32... 
2014-12-12 16:31:25.314 15678 INFO glance.db.sqlalchemy.migrate_repo.schema [-] creating table task_info
2014-12-12 16:31:25.499 15678 INFO migrate.versioning.api [-] done
2014-12-12 16:31:25.500 15678 INFO migrate.versioning.api [-] 32 -> 33... 
2014-12-12 16:31:25.581 15678 INFO migrate.versioning.api [-] done
2014-12-12 16:31:25.581 15678 INFO migrate.versioning.api [-] 33 -> 34... 
2014-12-12 16:31:25.646 15678 INFO migrate.versioning.api [-] done
2014-12-12 16:31:25.646 15678 INFO migrate.versioning.api [-] 34 -> 35... 
2014-12-12 16:31:25.651 15678 INFO glance.db.sqlalchemy.migrate_repo.schema [-] creating table metadef_namespaces
2014-12-12 16:31:25.713 15678 INFO glance.db.sqlalchemy.migrate_repo.schema [-] creating table metadef_objects
2014-12-12 16:31:25.773 15678 INFO glance.db.sqlalchemy.migrate_repo.schema [-] creating table metadef_properties
2014-12-12 16:31:25.833 15678 INFO glance.db.sqlalchemy.migrate_repo.schema [-] creating table metadef_resource_types
2014-12-12 16:31:25.891 15678 INFO glance.db.sqlalchemy.migrate_repo.schema [-] creating table metadef_namespace_resource_types
2014-12-12 16:31:26.050 15678 INFO migrate.versioning.api [-] done
2014-12-12 16:31:26.051 15678 INFO migrate.versioning.api [-] 35 -> 36... 
2014-12-12 16:31:26.184 15678 INFO migrate.versioning.api [-] done
+ /usr/local/bin/glance-manage db_load_metadefs
2014-12-12 16:31:26.651 15685 DEBUG oslo.db.sqlalchemy.session [-] MySQL server mode set to STRICT_TRANS_TABLES,STRICT_ALL_TABLES,NO_ZERO_IN_DATE,NO_ZERO_DATE,ERROR_FOR_DIVISION_BY_ZERO,TRADITIONAL,NO_AUTO_CREATE_USER,NO_ENGINE_SUBSTITUTION _init_events /usr/local/lib/python2.7/dist-packages/oslo/db/sqlalchemy/session.py:474
2014-12-12 16:31:26.718 15685 INFO glance.db.sqlalchemy.metadata [-] File /etc/glance/metadefs/compute-aggr-num-instances.json loaded to database.
2014-12-12 16:31:26.820 15685 INFO glance.db.sqlalchemy.metadata [-] File /etc/glance/metadefs/glance-common-image-props.json loaded to database.
2014-12-12 16:31:26.864 15685 INFO glance.db.sqlalchemy.metadata [-] File /etc/glance/metadefs/compute-guest-shutdown.json loaded to database.
2014-12-12 16:31:27.012 15685 INFO glance.db.sqlalchemy.metadata [-] File /etc/glance/metadefs/compute-libvirt.json loaded to database.
2014-12-12 16:31:27.093 15685 INFO glance.db.sqlalchemy.metadata [-] File /etc/glance/metadefs/compute-vmware.json loaded to database.
2014-12-12 16:31:27.150 15685 INFO glance.db.sqlalchemy.metadata [-] File /etc/glance/metadefs/compute-xenapi.json loaded to database.
2014-12-12 16:31:27.232 15685 INFO glance.db.sqlalchemy.metadata [-] File /etc/glance/metadefs/compute-quota.json loaded to database.
2014-12-12 16:31:27.367 15685 INFO glance.db.sqlalchemy.metadata [-] File /etc/glance/metadefs/compute-host-capabilities.json loaded to database.
2014-12-12 16:31:27.435 15685 INFO glance.db.sqlalchemy.metadata [-] File /etc/glance/metadefs/compute-randomgen.json loaded to database.
2014-12-12 16:31:27.562 15685 INFO glance.db.sqlalchemy.metadata [-] File /etc/glance/metadefs/compute-vcputopology.json loaded to database.
2014-12-12 16:31:27.614 15685 INFO glance.db.sqlalchemy.metadata [-] File /etc/glance/metadefs/compute-hypervisor.json loaded to database.
2014-12-12 16:31:27.669 15685 INFO glance.db.sqlalchemy.metadata [-] File /etc/glance/metadefs/compute-instance-data.json loaded to database.
2014-12-12 16:31:27.734 15685 INFO glance.db.sqlalchemy.metadata [-] File /etc/glance/metadefs/compute-watchdog.json loaded to database.
2014-12-12 16:31:27.777 15685 INFO glance.db.sqlalchemy.metadata [-] File /etc/glance/metadefs/compute-aggr-disk-filter.json loaded to database.
2014-12-12 16:31:27.821 15685 INFO glance.db.sqlalchemy.metadata [-] File /etc/glance/metadefs/compute-aggr-iops-filter.json loaded to database.
2014-12-12 16:31:27.868 15685 INFO glance.db.sqlalchemy.metadata [-] File /etc/glance/metadefs/compute-trust.json loaded to database.
2014-12-12 16:31:27.868 15685 INFO glance.db.sqlalchemy.metadata [-] Metadata loading finished
+ create_glance_cache_dir
+ sudo mkdir -p /var/cache/glance/api
+ sudo chown cloudbase /var/cache/glance/api
+ rm -f '/var/cache/glance/api/*'
+ sudo mkdir -p /var/cache/glance/registry
+ sudo chown cloudbase /var/cache/glance/registry
+ rm -f '/var/cache/glance/registry/*'
+ is_service_enabled neutron
++ set +o
++ grep xtrace
+ local 'xtrace=set -o xtrace'
+ set +o xtrace
+ return 0
+ echo_summary 'Configuring Neutron'
+ [[ -t 3 ]]
+ echo -e Configuring Neutron
+ configure_neutron
+ _configure_neutron_common
+ [[ ! -d /etc/neutron ]]
+ sudo chown cloudbase /etc/neutron
+ cp /opt/stack/neutron/etc/neutron.conf /etc/neutron/neutron.conf
+ neutron_plugin_configure_common
+ Q_PLUGIN_CONF_PATH=etc/neutron/plugins/ml2
+ Q_PLUGIN_CONF_FILENAME=ml2_conf.ini
+ Q_PLUGIN_CLASS=neutron.plugins.ml2.plugin.Ml2Plugin
+ _neutron_service_plugin_class_add neutron.services.l3_router.l3_router_plugin.L3RouterPlugin
+ local service_plugin_class=neutron.services.l3_router.l3_router_plugin.L3RouterPlugin
+ [[ '' == '' ]]
+ Q_SERVICE_PLUGIN_CLASSES=neutron.services.l3_router.l3_router_plugin.L3RouterPlugin
+ [[ etc/neutron/plugins/ml2 == '' ]]
+ [[ ml2_conf.ini == '' ]]
+ [[ neutron.plugins.ml2.plugin.Ml2Plugin == '' ]]
+ mkdir -p /etc/neutron/plugins/ml2
+ Q_PLUGIN_CONF_FILE=etc/neutron/plugins/ml2/ml2_conf.ini
+ cp /opt/stack/neutron/etc/neutron/plugins/ml2/ml2_conf.ini /etc/neutron/plugins/ml2/ml2_conf.ini
++ database_connection_url neutron
++ local db=neutron
++ database_connection_url_mysql neutron
++ local db=neutron
++ echo 'mysql://root:Passw0rd@127.0.0.1/neutron?charset=utf8'
+ iniset /etc/neutron/neutron.conf database connection 'mysql://root:Passw0rd@127.0.0.1/neutron?charset=utf8'
++ set +o
++ grep xtrace
+ local 'xtrace=set -o xtrace'
+ set +o xtrace
+ iniset /etc/neutron/neutron.conf DEFAULT state_path /opt/stack/data/neutron
++ set +o
++ grep xtrace
+ local 'xtrace=set -o xtrace'
+ set +o xtrace
+ [[ 0 > 0 ]]
+ [[ '' != '' ]]
+ '[' libvirt = fake ']'
+ '[' False == True ']'
+ is_service_enabled tls-proxy
++ set +o
++ grep xtrace
+ local 'xtrace=set -o xtrace'
+ set +o xtrace
+ return 1
+ is_ssl_enabled_service nova
+ local services=nova
+ local service=
+ '[' False == False ']'
+ return 1
+ is_ssl_enabled_service neutron
+ local services=neutron
+ local service=
+ '[' False == False ']'
+ return 1
+ _neutron_setup_rootwrap
+ [[ True == \F\a\l\s\e ]]
+ Q_CONF_ROOTWRAP_D=/etc/neutron/rootwrap.d
+ [[ -d /etc/neutron/rootwrap.d ]]
+ sudo rm -rf /etc/neutron/rootwrap.d
+ mkdir -p -m 755 /etc/neutron/rootwrap.d
+ cp -pr /opt/stack/neutron/etc/neutron/rootwrap.d/cisco-apic.filters /opt/stack/neutron/etc/neutron/rootwrap.d/debug.filters /opt/stack/neutron/etc/neutron/rootwrap.d/dhcp.filters /opt/stack/neutron/etc/neutron/rootwrap.d/ipset-firewall.filters /opt/stack/neutron/etc/neutron/rootwrap.d/iptables-firewall.filters /opt/stack/neutron/etc/neutron/rootwrap.d/l3.filters /opt/stack/neutron/etc/neutron/rootwrap.d/lbaas-haproxy.filters /opt/stack/neutron/etc/neutron/rootwrap.d/linuxbridge-plugin.filters /opt/stack/neutron/etc/neutron/rootwrap.d/nec-plugin.filters /opt/stack/neutron/etc/neutron/rootwrap.d/openvswitch-plugin.filters /opt/stack/neutron/etc/neutron/rootwrap.d/ryu-plugin.filters /opt/stack/neutron/etc/neutron/rootwrap.d/vpnaas.filters /etc/neutron/rootwrap.d/
+ sudo chown -R root:root /etc/neutron/rootwrap.d
+ sudo chmod 644 /etc/neutron/rootwrap.d/cisco-apic.filters /etc/neutron/rootwrap.d/debug.filters /etc/neutron/rootwrap.d/dhcp.filters /etc/neutron/rootwrap.d/ipset-firewall.filters /etc/neutron/rootwrap.d/iptables-firewall.filters /etc/neutron/rootwrap.d/l3.filters /etc/neutron/rootwrap.d/lbaas-haproxy.filters /etc/neutron/rootwrap.d/linuxbridge-plugin.filters /etc/neutron/rootwrap.d/nec-plugin.filters /etc/neutron/rootwrap.d/openvswitch-plugin.filters /etc/neutron/rootwrap.d/ryu-plugin.filters /etc/neutron/rootwrap.d/vpnaas.filters
+ test -r /opt/stack/neutron/etc/neutron/rootwrap.conf
+ sudo cp -p /opt/stack/neutron/etc/rootwrap.conf /etc/neutron/rootwrap.conf
+ sudo sed -e 's:^filters_path=.*$:filters_path=/etc/neutron/rootwrap.d:' -i /etc/neutron/rootwrap.conf
+ sudo chown root:root /etc/neutron/rootwrap.conf
+ sudo chmod 0644 /etc/neutron/rootwrap.conf
+ ROOTWRAP_SUDOER_CMD='/usr/local/bin/neutron-rootwrap /etc/neutron/rootwrap.conf *'
++ mktemp
+ TEMPFILE=/tmp/tmp.Euvp1iDlfq
+ echo 'cloudbase ALL=(root) NOPASSWD: /usr/local/bin/neutron-rootwrap /etc/neutron/rootwrap.conf *'
+ chmod 0440 /tmp/tmp.Euvp1iDlfq
+ sudo chown root:root /tmp/tmp.Euvp1iDlfq
+ sudo mv /tmp/tmp.Euvp1iDlfq /etc/sudoers.d/neutron-rootwrap
+ iniset /etc/neutron/neutron.conf agent root_helper 'sudo /usr/local/bin/neutron-rootwrap /etc/neutron/rootwrap.conf'
++ set +o
++ grep xtrace
+ local 'xtrace=set -o xtrace'
+ set +o xtrace
+ iniset_rpc_backend neutron /etc/neutron/neutron.conf DEFAULT
+ local package=neutron
+ local file=/etc/neutron/neutron.conf
+ local section=DEFAULT
+ is_service_enabled zeromq
++ set +o
++ grep xtrace
+ local 'xtrace=set -o xtrace'
+ set +o xtrace
+ return 1
+ is_service_enabled qpid
++ set +o
++ grep xtrace
+ local 'xtrace=set -o xtrace'
+ set +o xtrace
+ return 1
+ '[' -n '' ']'
+ is_service_enabled rabbit
++ set +o
++ grep xtrace
+ local 'xtrace=set -o xtrace'
+ set +o xtrace
+ return 0
+ iniset /etc/neutron/neutron.conf DEFAULT rpc_backend neutron.openstack.common.rpc.impl_kombu
++ set +o
++ grep xtrace
+ local 'xtrace=set -o xtrace'
+ set +o xtrace
+ iniset /etc/neutron/neutron.conf DEFAULT rabbit_hosts 10.14.0.26
++ set +o
++ grep xtrace
+ local 'xtrace=set -o xtrace'
+ set +o xtrace
+ iniset /etc/neutron/neutron.conf DEFAULT rabbit_password Passw0rd
++ set +o
++ grep xtrace
+ local 'xtrace=set -o xtrace'
+ set +o xtrace
+ is_service_enabled q-lbaas
++ set +o
++ grep xtrace
+ local 'xtrace=set -o xtrace'
+ set +o xtrace
+ return 0
+ _configure_neutron_lbaas
+ neutron_agent_lbaas_configure_common
+ _neutron_service_plugin_class_add neutron.services.loadbalancer.plugin.LoadBalancerPlugin
+ local service_plugin_class=neutron.services.loadbalancer.plugin.LoadBalancerPlugin
+ [[ neutron.services.l3_router.l3_router_plugin.L3RouterPlugin == '' ]]
+ [[ ! ,neutron.services.l3_router.l3_router_plugin.L3RouterPlugin, =~ ,neutron.services.loadbalancer.plugin.LoadBalancerPlugin, ]]
+ Q_SERVICE_PLUGIN_CLASSES=neutron.services.l3_router.l3_router_plugin.L3RouterPlugin,neutron.services.loadbalancer.plugin.LoadBalancerPlugin
+ neutron_agent_lbaas_configure_agent
+ LBAAS_AGENT_CONF_PATH=/etc/neutron/services/loadbalancer/haproxy
+ mkdir -p /etc/neutron/services/loadbalancer/haproxy
+ LBAAS_AGENT_CONF_FILENAME=/etc/neutron/services/loadbalancer/haproxy/lbaas_agent.ini
+ cp /opt/stack/neutron/etc/lbaas_agent.ini /etc/neutron/services/loadbalancer/haproxy/lbaas_agent.ini
+ iniset /etc/neutron/services/loadbalancer/haproxy/lbaas_agent.ini DEFAULT ovs_use_veth False
++ set +o
++ grep xtrace
+ local 'xtrace=set -o xtrace'
+ set +o xtrace
+ neutron_plugin_setup_interface_driver /etc/neutron/services/loadbalancer/haproxy/lbaas_agent.ini
+ local conf_file=/etc/neutron/services/loadbalancer/haproxy/lbaas_agent.ini
+ iniset /etc/neutron/services/loadbalancer/haproxy/lbaas_agent.ini DEFAULT interface_driver neutron.agent.linux.interface.OVSInterfaceDriver
++ set +o
++ grep xtrace
+ local 'xtrace=set -o xtrace'
+ set +o xtrace
+ is_fedora
+ [[ -z Ubuntu ]]
+ '[' Ubuntu = Fedora ']'
+ '[' Ubuntu = 'Red Hat' ']'
+ '[' Ubuntu = CentOS ']'
+ '[' Ubuntu = OracleServer ']'
+ is_service_enabled q-metering
++ set +o
++ grep xtrace
+ local 'xtrace=set -o xtrace'
+ set +o xtrace
+ return 0
+ _configure_neutron_metering
+ neutron_agent_metering_configure_common
+ _neutron_service_plugin_class_add neutron.services.metering.metering_plugin.MeteringPlugin
+ local service_plugin_class=neutron.services.metering.metering_plugin.MeteringPlugin
+ [[ neutron.services.l3_router.l3_router_plugin.L3RouterPlugin,neutron.services.loadbalancer.plugin.LoadBalancerPlugin == '' ]]
+ [[ ! ,neutron.services.l3_router.l3_router_plugin.L3RouterPlugin,neutron.services.loadbalancer.plugin.LoadBalancerPlugin, =~ ,neutron.services.metering.metering_plugin.MeteringPlugin, ]]
+ Q_SERVICE_PLUGIN_CLASSES=neutron.services.l3_router.l3_router_plugin.L3RouterPlugin,neutron.services.loadbalancer.plugin.LoadBalancerPlugin,neutron.services.metering.metering_plugin.MeteringPlugin
+ neutron_agent_metering_configure_agent
+ METERING_AGENT_CONF_PATH=/etc/neutron/services/metering
+ mkdir -p /etc/neutron/services/metering
+ METERING_AGENT_CONF_FILENAME=/etc/neutron/services/metering/metering_agent.ini
+ cp /opt/stack/neutron/etc/metering_agent.ini /etc/neutron/services/metering/metering_agent.ini
+ is_service_enabled q-vpn
++ set +o
++ grep xtrace
+ local 'xtrace=set -o xtrace'
+ set +o xtrace
+ return 0
+ _configure_neutron_vpn
+ neutron_vpn_install_agent_packages
+ install_package openswan
+ update_package_repo
+ [[ '' = \T\r\u\e ]]
+ is_ubuntu
+ [[ -z deb ]]
+ '[' deb = deb ']'
++ set +o
++ grep xtrace
+ local 'xtrace=set -o xtrace'
+ set +o xtrace
+ real_install_package openswan
+ is_ubuntu
+ [[ -z deb ]]
+ '[' deb = deb ']'
+ apt_get install openswan
++ set +o
++ grep xtrace
+ local 'xtrace=set -o xtrace'
+ set +o xtrace
+ sudo DEBIAN_FRONTEND=noninteractive http_proxy= https_proxy= no_proxy= apt-get --option Dpkg::Options::=--force-confold --assume-yes install openswan
+ real_install_package openswan
+ is_ubuntu
+ [[ -z deb ]]
+ '[' deb = deb ']'
+ apt_get install openswan
++ set +o
++ grep xtrace
+ local 'xtrace=set -o xtrace'
+ set +o xtrace
+ sudo DEBIAN_FRONTEND=noninteractive http_proxy= https_proxy= no_proxy= apt-get --option Dpkg::Options::=--force-confold --assume-yes install openswan
+ neutron_vpn_configure_common
+ _neutron_service_plugin_class_add neutron.services.vpn.plugin.VPNDriverPlugin
+ local service_plugin_class=neutron.services.vpn.plugin.VPNDriverPlugin
+ [[ neutron.services.l3_router.l3_router_plugin.L3RouterPlugin,neutron.services.loadbalancer.plugin.LoadBalancerPlugin,neutron.services.metering.metering_plugin.MeteringPlugin == '' ]]
+ [[ ! ,neutron.services.l3_router.l3_router_plugin.L3RouterPlugin,neutron.services.loadbalancer.plugin.LoadBalancerPlugin,neutron.services.metering.metering_plugin.MeteringPlugin, =~ ,neutron.services.vpn.plugin.VPNDriverPlugin, ]]
+ Q_SERVICE_PLUGIN_CLASSES=neutron.services.l3_router.l3_router_plugin.L3RouterPlugin,neutron.services.loadbalancer.plugin.LoadBalancerPlugin,neutron.services.metering.metering_plugin.MeteringPlugin,neutron.services.vpn.plugin.VPNDriverPlugin
+ is_service_enabled q-fwaas
++ set +o
++ grep xtrace
+ local 'xtrace=set -o xtrace'
+ set +o xtrace
+ return 0
+ _configure_neutron_fwaas
+ neutron_fwaas_configure_common
+ _neutron_service_plugin_class_add neutron.services.firewall.fwaas_plugin.FirewallPlugin
+ local service_plugin_class=neutron.services.firewall.fwaas_plugin.FirewallPlugin
+ [[ neutron.services.l3_router.l3_router_plugin.L3RouterPlugin,neutron.services.loadbalancer.plugin.LoadBalancerPlugin,neutron.services.metering.metering_plugin.MeteringPlugin,neutron.services.vpn.plugin.VPNDriverPlugin == '' ]]
+ [[ ! ,neutron.services.l3_router.l3_router_plugin.L3RouterPlugin,neutron.services.loadbalancer.plugin.LoadBalancerPlugin,neutron.services.metering.metering_plugin.MeteringPlugin,neutron.services.vpn.plugin.VPNDriverPlugin, =~ ,neutron.services.firewall.fwaas_plugin.FirewallPlugin, ]]
+ Q_SERVICE_PLUGIN_CLASSES=neutron.services.l3_router.l3_router_plugin.L3RouterPlugin,neutron.services.loadbalancer.plugin.LoadBalancerPlugin,neutron.services.metering.metering_plugin.MeteringPlugin,neutron.services.vpn.plugin.VPNDriverPlugin,neutron.services.firewall.fwaas_plugin.FirewallPlugin
+ neutron_fwaas_configure_driver
+ FWAAS_DRIVER_CONF_FILENAME=/etc/neutron/fwaas_driver.ini
+ cp /opt/stack/neutron/etc/fwaas_driver.ini /etc/neutron/fwaas_driver.ini
+ iniset_multiline /etc/neutron/fwaas_driver.ini fwaas enabled True
++ set +o
++ grep xtrace
+ local 'xtrace=set -o xtrace'
+ set +o xtrace
+ iniset_multiline /etc/neutron/fwaas_driver.ini fwaas driver neutron.services.firewall.drivers.linux.iptables_fwaas.IptablesFwaasDriver
++ set +o
++ grep xtrace
+ local 'xtrace=set -o xtrace'
+ set +o xtrace
+ is_service_enabled q-agt q-svc
++ set +o
++ grep xtrace
+ local 'xtrace=set -o xtrace'
+ set +o xtrace
+ return 0
+ _configure_neutron_service
+ Q_API_PASTE_FILE=/etc/neutron/api-paste.ini
+ Q_POLICY_FILE=/etc/neutron/policy.json
+ cp /opt/stack/neutron/etc/api-paste.ini /etc/neutron/api-paste.ini
+ cp /opt/stack/neutron/etc/policy.json /etc/neutron/policy.json
+ sed -i 's/"context_is_admin":  "role:admin"/"context_is_admin":  "role:admin or user_name:neutron"/g' /etc/neutron/policy.json
+ iniset /etc/neutron/neutron.conf DEFAULT core_plugin neutron.plugins.ml2.plugin.Ml2Plugin
++ set +o
++ grep xtrace
+ local 'xtrace=set -o xtrace'
+ set +o xtrace
+ [[ neutron.services.l3_router.l3_router_plugin.L3RouterPlugin,neutron.services.loadbalancer.plugin.LoadBalancerPlugin,neutron.services.metering.metering_plugin.MeteringPlugin,neutron.services.vpn.plugin.VPNDriverPlugin,neutron.services.firewall.fwaas_plugin.FirewallPlugin != '' ]]
+ iniset /etc/neutron/neutron.conf DEFAULT service_plugins neutron.services.l3_router.l3_router_plugin.L3RouterPlugin,neutron.services.loadbalancer.plugin.LoadBalancerPlugin,neutron.services.metering.metering_plugin.MeteringPlugin,neutron.services.vpn.plugin.VPNDriverPlugin,neutron.services.firewall.fwaas_plugin.FirewallPlugin
++ set +o
++ grep xtrace
+ local 'xtrace=set -o xtrace'
+ set +o xtrace
+ iniset /etc/neutron/neutron.conf DEFAULT verbose True
++ set +o
++ grep xtrace
+ local 'xtrace=set -o xtrace'
+ set +o xtrace
+ iniset /etc/neutron/neutron.conf DEFAULT debug True
++ set +o
++ grep xtrace
+ local 'xtrace=set -o xtrace'
+ set +o xtrace
+ iniset /etc/neutron/neutron.conf DEFAULT policy_file /etc/neutron/policy.json
++ set +o
++ grep xtrace
+ local 'xtrace=set -o xtrace'
+ set +o xtrace
+ iniset /etc/neutron/neutron.conf DEFAULT allow_overlapping_ips True
++ set +o
++ grep xtrace
+ local 'xtrace=set -o xtrace'
+ set +o xtrace
+ iniset /etc/neutron/neutron.conf DEFAULT auth_strategy keystone
++ set +o
++ grep xtrace
+ local 'xtrace=set -o xtrace'
+ set +o xtrace
+ _neutron_setup_keystone /etc/neutron/neutron.conf keystone_authtoken
+ local conf_file=/etc/neutron/neutron.conf
+ local section=keystone_authtoken
+ create_neutron_cache_dir
+ sudo mkdir -p /var/cache/neutron
+ sudo chown cloudbase /var/cache/neutron
+ rm -f '/var/cache/neutron/*'
+ configure_auth_token_middleware /etc/neutron/neutron.conf neutron /var/cache/neutron keystone_authtoken
+ local conf_file=/etc/neutron/neutron.conf
+ local admin_user=neutron
+ local signing_dir=/var/cache/neutron
+ local section=keystone_authtoken
+ iniset /etc/neutron/neutron.conf keystone_authtoken auth_host 10.14.0.26
++ set +o
++ grep xtrace
+ local 'xtrace=set -o xtrace'
+ set +o xtrace
+ iniset /etc/neutron/neutron.conf keystone_authtoken auth_port 35357
++ set +o
++ grep xtrace
+ local 'xtrace=set -o xtrace'
+ set +o xtrace
+ iniset /etc/neutron/neutron.conf keystone_authtoken auth_protocol http
++ set +o
++ grep xtrace
+ local 'xtrace=set -o xtrace'
+ set +o xtrace
+ iniset /etc/neutron/neutron.conf keystone_authtoken identity_uri http://10.14.0.26:35357
++ set +o
++ grep xtrace
+ local 'xtrace=set -o xtrace'
+ set +o xtrace
+ iniset /etc/neutron/neutron.conf keystone_authtoken cafile /opt/stack/data/ca-bundle.pem
++ set +o
++ grep xtrace
+ local 'xtrace=set -o xtrace'
+ set +o xtrace
+ configure_API_version /etc/neutron/neutron.conf 2.0 keystone_authtoken
+ local conf_file=/etc/neutron/neutron.conf
+ local api_version=2.0
+ local section=keystone_authtoken
+ iniset /etc/neutron/neutron.conf keystone_authtoken auth_uri http://10.14.0.26:5000/v2.0
++ set +o
++ grep xtrace
+ local 'xtrace=set -o xtrace'
+ set +o xtrace
+ iniset /etc/neutron/neutron.conf keystone_authtoken admin_tenant_name service
++ set +o
++ grep xtrace
+ local 'xtrace=set -o xtrace'
+ set +o xtrace
+ iniset /etc/neutron/neutron.conf keystone_authtoken admin_user neutron
++ set +o
++ grep xtrace
+ local 'xtrace=set -o xtrace'
+ set +o xtrace
+ iniset /etc/neutron/neutron.conf keystone_authtoken admin_password Passw0rd
++ set +o
++ grep xtrace
+ local 'xtrace=set -o xtrace'
+ set +o xtrace
+ iniset /etc/neutron/neutron.conf keystone_authtoken signing_dir /var/cache/neutron
++ set +o
++ grep xtrace
+ local 'xtrace=set -o xtrace'
+ set +o xtrace
+ [[ -n '' ]]
+ iniset /etc/neutron/neutron.conf DEFAULT notify_nova_on_port_status_changes True
++ set +o
++ grep xtrace
+ local 'xtrace=set -o xtrace'
+ set +o xtrace
+ iniset /etc/neutron/neutron.conf DEFAULT notify_nova_on_port_data_changes True
++ set +o
++ grep xtrace
+ local 'xtrace=set -o xtrace'
+ set +o xtrace
+ iniset /etc/neutron/neutron.conf DEFAULT nova_url http://10.14.0.26:8774/v2
++ set +o
++ grep xtrace
+ local 'xtrace=set -o xtrace'
+ set +o xtrace
+ iniset /etc/neutron/neutron.conf DEFAULT nova_admin_username nova
++ set +o
++ grep xtrace
+ local 'xtrace=set -o xtrace'
+ set +o xtrace
+ iniset /etc/neutron/neutron.conf DEFAULT nova_admin_password Passw0rd
++ set +o
++ grep xtrace
+ local 'xtrace=set -o xtrace'
+ set +o xtrace
++ openstack project list
++ awk '/ service / { print $2 }'
+ ADMIN_TENANT_ID=8d6b5a09210d46e69aaf5d0d3693fb5d
+ iniset /etc/neutron/neutron.conf DEFAULT nova_admin_tenant_id 8d6b5a09210d46e69aaf5d0d3693fb5d
++ set +o
++ grep xtrace
+ local 'xtrace=set -o xtrace'
+ set +o xtrace
+ iniset /etc/neutron/neutron.conf DEFAULT nova_admin_auth_url http://10.14.0.26:35357/v2.0
++ set +o
++ grep xtrace
+ local 'xtrace=set -o xtrace'
+ set +o xtrace
+ neutron_plugin_configure_service
+ [[ vlan != \l\o\c\a\l ]]
+ Q_SRV_EXTRA_OPTS+=(tenant_network_types=$Q_ML2_TENANT_NETWORK_TYPE)
+ '[' '' == '' ']'
+ [[ '' == '' ]]
+ [[ physnet1 != '' ]]
+ ML2_VLAN_RANGES=physnet1
+ [[ 500:2000 != '' ]]
+ ML2_VLAN_RANGES=physnet1:500:2000
+ [[ physnet1:500:2000 != '' ]]
+ Q_ML2_PLUGIN_VLAN_TYPE_OPTIONS=(network_vlan_ranges=$ML2_VLAN_RANGES)
+ [[ True == \T\r\u\e ]]
+ iniset /etc/neutron/plugins/ml2/ml2_conf.ini securitygroup firewall_driver neutron.agent.not.a.real.FirewallDriver
++ set +o
++ grep xtrace
+ local 'xtrace=set -o xtrace'
+ set +o xtrace
+ iniset /etc/neutron/plugins/ml2/ml2_conf.ini ovs local_ip 10.14.0.26
++ set +o
++ grep xtrace
+ local 'xtrace=set -o xtrace'
+ set +o xtrace
+ populate_ml2_config /etc/neutron/plugins/ml2/ml2_conf.ini ml2 mechanism_drivers=openvswitch,hyperv
+ CONF=/etc/neutron/plugins/ml2/ml2_conf.ini
+ SECTION=ml2
+ OPTS=mechanism_drivers=openvswitch,hyperv
+ '[' -z mechanism_drivers=openvswitch,hyperv ']'
+ for I in '"${OPTS[@]}"'
+ iniset /etc/neutron/plugins/ml2/ml2_conf.ini ml2 mechanism_drivers openvswitch,hyperv
++ set +o
++ grep xtrace
+ local 'xtrace=set -o xtrace'
+ set +o xtrace
+ populate_ml2_config /etc/neutron/plugins/ml2/ml2_conf.ini ml2 type_drivers=local,flat,vlan,gre,vxlan
+ CONF=/etc/neutron/plugins/ml2/ml2_conf.ini
+ SECTION=ml2
+ OPTS=type_drivers=local,flat,vlan,gre,vxlan
+ '[' -z type_drivers=local,flat,vlan,gre,vxlan ']'
+ for I in '"${OPTS[@]}"'
+ iniset /etc/neutron/plugins/ml2/ml2_conf.ini ml2 type_drivers local,flat,vlan,gre,vxlan
++ set +o
++ grep xtrace
+ local 'xtrace=set -o xtrace'
+ set +o xtrace
+ populate_ml2_config /etc/neutron/plugins/ml2/ml2_conf.ini ml2 tenant_network_types=vlan
+ CONF=/etc/neutron/plugins/ml2/ml2_conf.ini
+ SECTION=ml2
+ OPTS=tenant_network_types=vlan
+ '[' -z tenant_network_types=vlan ']'
+ for I in '"${OPTS[@]}"'
+ iniset /etc/neutron/plugins/ml2/ml2_conf.ini ml2 tenant_network_types vlan
++ set +o
++ grep xtrace
+ local 'xtrace=set -o xtrace'
+ set +o xtrace
+ populate_ml2_config /etc/neutron/plugins/ml2/ml2_conf.ini ml2_type_gre tunnel_id_ranges=1:1000
+ CONF=/etc/neutron/plugins/ml2/ml2_conf.ini
+ SECTION=ml2_type_gre
+ OPTS=tunnel_id_ranges=1:1000
+ '[' -z tunnel_id_ranges=1:1000 ']'
+ for I in '"${OPTS[@]}"'
+ iniset /etc/neutron/plugins/ml2/ml2_conf.ini ml2_type_gre tunnel_id_ranges 1:1000
++ set +o
++ grep xtrace
+ local 'xtrace=set -o xtrace'
+ set +o xtrace
+ populate_ml2_config /etc/neutron/plugins/ml2/ml2_conf.ini ml2_type_vxlan vni_ranges=1001:2000
+ CONF=/etc/neutron/plugins/ml2/ml2_conf.ini
+ SECTION=ml2_type_vxlan
+ OPTS=vni_ranges=1001:2000
+ '[' -z vni_ranges=1001:2000 ']'
+ for I in '"${OPTS[@]}"'
+ iniset /etc/neutron/plugins/ml2/ml2_conf.ini ml2_type_vxlan vni_ranges 1001:2000
++ set +o
++ grep xtrace
+ local 'xtrace=set -o xtrace'
+ set +o xtrace
+ populate_ml2_config /etc/neutron/plugins/ml2/ml2_conf.ini ml2_type_vlan network_vlan_ranges=physnet1:500:2000
+ CONF=/etc/neutron/plugins/ml2/ml2_conf.ini
+ SECTION=ml2_type_vlan
+ OPTS=network_vlan_ranges=physnet1:500:2000
+ '[' -z network_vlan_ranges=physnet1:500:2000 ']'
+ for I in '"${OPTS[@]}"'
+ iniset /etc/neutron/plugins/ml2/ml2_conf.ini ml2_type_vlan network_vlan_ranges physnet1:500:2000
++ set +o
++ grep xtrace
+ local 'xtrace=set -o xtrace'
+ set +o xtrace
+ [[ legacy != \l\e\g\a\c\y ]]
+ is_service_enabled q-agt
++ set +o
++ grep xtrace
+ local 'xtrace=set -o xtrace'
+ set +o xtrace
+ return 0
+ _configure_neutron_plugin_agent
+ iniset /etc/neutron/plugins/ml2/ml2_conf.ini agent root_helper 'sudo /usr/local/bin/neutron-rootwrap /etc/neutron/rootwrap.conf'
++ set +o
++ grep xtrace
+ local 'xtrace=set -o xtrace'
+ set +o xtrace
+ iniset /etc/neutron/neutron.conf DEFAULT verbose True
++ set +o
++ grep xtrace
+ local 'xtrace=set -o xtrace'
+ set +o xtrace
+ iniset /etc/neutron/neutron.conf DEFAULT debug True
++ set +o
++ grep xtrace
+ local 'xtrace=set -o xtrace'
+ set +o xtrace
+ neutron_plugin_configure_plugin_agent
+ _neutron_ovs_base_setup_bridge br-int
+ local bridge=br-int
+ neutron-ovs-cleanup
+ sudo ovs-vsctl --no-wait -- --may-exist add-br br-int
+ [[ '' != '' ]]
+ sudo ovs-vsctl --no-wait br-set-external-id br-int bridge-id br-int
+ _neutron_ovs_base_configure_firewall_driver
+ [[ True == \T\r\u\e ]]
+ iniset /etc/neutron/plugins/ml2/ml2_conf.ini securitygroup firewall_driver neutron.agent.linux.iptables_firewall.OVSHybridIptablesFirewallDriver
++ set +o
++ grep xtrace
+ local 'xtrace=set -o xtrace'
+ set +o xtrace
+ [[ False == \T\r\u\e ]]
+ [[ physnet1:br-eth1 == '' ]]
+ [[ physnet1:br-eth1 != '' ]]
+ iniset /etc/neutron/plugins/ml2/ml2_conf.ini ovs bridge_mappings physnet1:br-eth1
++ set +o
++ grep xtrace
+ local 'xtrace=set -o xtrace'
+ set +o xtrace
+ AGENT_BINARY=/usr/local/bin/neutron-openvswitch-agent
+ '[' libvirt == xenserver ']'
+ iniset /etc/neutron/plugins/ml2/ml2_conf.ini agent tunnel_types gre
++ set +o
++ grep xtrace
+ local 'xtrace=set -o xtrace'
+ set +o xtrace
+ is_service_enabled q-dhcp
++ set +o
++ grep xtrace
+ local 'xtrace=set -o xtrace'
+ set +o xtrace
+ return 0
+ _configure_neutron_dhcp_agent
+ cp /opt/stack/neutron/etc/dhcp_agent.ini /etc/neutron/dhcp_agent.ini
+ iniset /etc/neutron/dhcp_agent.ini DEFAULT verbose True
++ set +o
++ grep xtrace
+ local 'xtrace=set -o xtrace'
+ set +o xtrace
+ iniset /etc/neutron/dhcp_agent.ini DEFAULT debug True
++ set +o
++ grep xtrace
+ local 'xtrace=set -o xtrace'
+ set +o xtrace
+ iniset /etc/neutron/dhcp_agent.ini DEFAULT use_namespaces True
++ set +o
++ grep xtrace
+ local 'xtrace=set -o xtrace'
+ set +o xtrace
+ iniset /etc/neutron/dhcp_agent.ini DEFAULT root_helper 'sudo /usr/local/bin/neutron-rootwrap /etc/neutron/rootwrap.conf'
++ set +o
++ grep xtrace
+ local 'xtrace=set -o xtrace'
+ set +o xtrace
+ _neutron_setup_interface_driver /etc/neutron/dhcp_agent.ini
+ iniset /etc/neutron/dhcp_agent.ini DEFAULT ovs_use_veth False
++ set +o
++ grep xtrace
+ local 'xtrace=set -o xtrace'
+ set +o xtrace
+ neutron_plugin_setup_interface_driver /etc/neutron/dhcp_agent.ini
+ local conf_file=/etc/neutron/dhcp_agent.ini
+ iniset /etc/neutron/dhcp_agent.ini DEFAULT interface_driver neutron.agent.linux.interface.OVSInterfaceDriver
++ set +o
++ grep xtrace
+ local 'xtrace=set -o xtrace'
+ set +o xtrace
+ neutron_plugin_configure_dhcp_agent
+ iniset /etc/neutron/dhcp_agent.ini DEFAULT dhcp_agent_manager neutron.agent.dhcp_agent.DhcpAgentWithStateReport
++ set +o
++ grep xtrace
+ local 'xtrace=set -o xtrace'
+ set +o xtrace
+ is_service_enabled q-l3
++ set +o
++ grep xtrace
+ local 'xtrace=set -o xtrace'
+ set +o xtrace
+ return 0
+ _configure_neutron_l3_agent
+ local cfg_file
+ Q_L3_ENABLED=True
+ Q_L3_ROUTER_PER_TENANT=True
+ is_service_enabled q-vpn
++ set +o
++ grep xtrace
+ local 'xtrace=set -o xtrace'
+ set +o xtrace
+ return 0
+ cp /opt/stack/neutron/etc/vpn_agent.ini /etc/neutron/vpn_agent.ini
+ cp /opt/stack/neutron/etc/l3_agent.ini /etc/neutron/l3_agent.ini
+ iniset /etc/neutron/l3_agent.ini DEFAULT verbose True
++ set +o
++ grep xtrace
+ local 'xtrace=set -o xtrace'
+ set +o xtrace
+ iniset /etc/neutron/l3_agent.ini DEFAULT debug True
++ set +o
++ grep xtrace
+ local 'xtrace=set -o xtrace'
+ set +o xtrace
+ iniset /etc/neutron/l3_agent.ini DEFAULT use_namespaces True
++ set +o
++ grep xtrace
+ local 'xtrace=set -o xtrace'
+ set +o xtrace
+ iniset /etc/neutron/l3_agent.ini DEFAULT root_helper 'sudo /usr/local/bin/neutron-rootwrap /etc/neutron/rootwrap.conf'
++ set +o
++ grep xtrace
+ local 'xtrace=set -o xtrace'
+ set +o xtrace
+ _neutron_setup_interface_driver /etc/neutron/l3_agent.ini
+ iniset /etc/neutron/l3_agent.ini DEFAULT ovs_use_veth False
++ set +o
++ grep xtrace
+ local 'xtrace=set -o xtrace'
+ set +o xtrace
+ neutron_plugin_setup_interface_driver /etc/neutron/l3_agent.ini
+ local conf_file=/etc/neutron/l3_agent.ini
+ iniset /etc/neutron/l3_agent.ini DEFAULT interface_driver neutron.agent.linux.interface.OVSInterfaceDriver
++ set +o
++ grep xtrace
+ local 'xtrace=set -o xtrace'
+ set +o xtrace
+ neutron_plugin_configure_l3_agent
+ _neutron_ovs_base_configure_l3_agent
+ '[' False = True ']'
+ iniset /etc/neutron/l3_agent.ini DEFAULT external_network_bridge br-ex
++ set +o
++ grep xtrace
+ local 'xtrace=set -o xtrace'
+ set +o xtrace
+ neutron-ovs-cleanup
+ [[ False = \T\r\u\e ]]
+ sudo ovs-vsctl -- --may-exist add-br br-ex
+ sudo ovs-vsctl br-set-external-id br-ex bridge-id br-ex
+ sudo ip addr flush dev br-ex
+ iniset /etc/neutron/l3_agent.ini DEFAULT l3_agent_manager neutron.agent.l3_agent.L3NATAgentWithStateReport
++ set +o
++ grep xtrace
+ local 'xtrace=set -o xtrace'
+ set +o xtrace
+ is_service_enabled q-meta
++ set +o
++ grep xtrace
+ local 'xtrace=set -o xtrace'
+ set +o xtrace
+ return 0
+ _configure_neutron_metadata_agent
+ cp /opt/stack/neutron/etc/metadata_agent.ini /etc/neutron/metadata_agent.ini
+ iniset /etc/neutron/metadata_agent.ini DEFAULT verbose True
++ set +o
++ grep xtrace
+ local 'xtrace=set -o xtrace'
+ set +o xtrace
+ iniset /etc/neutron/metadata_agent.ini DEFAULT debug True
++ set +o
++ grep xtrace
+ local 'xtrace=set -o xtrace'
+ set +o xtrace
+ iniset /etc/neutron/metadata_agent.ini DEFAULT nova_metadata_ip 10.14.0.26
++ set +o
++ grep xtrace
+ local 'xtrace=set -o xtrace'
+ set +o xtrace
+ iniset /etc/neutron/metadata_agent.ini DEFAULT root_helper 'sudo /usr/local/bin/neutron-rootwrap /etc/neutron/rootwrap.conf'
++ set +o
++ grep xtrace
+ local 'xtrace=set -o xtrace'
+ set +o xtrace
+ _neutron_setup_keystone /etc/neutron/metadata_agent.ini DEFAULT
+ local conf_file=/etc/neutron/metadata_agent.ini
+ local section=DEFAULT
+ create_neutron_cache_dir
+ sudo mkdir -p /var/cache/neutron
+ sudo chown cloudbase /var/cache/neutron
+ rm -f '/var/cache/neutron/*'
+ configure_auth_token_middleware /etc/neutron/metadata_agent.ini neutron /var/cache/neutron DEFAULT
+ local conf_file=/etc/neutron/metadata_agent.ini
+ local admin_user=neutron
+ local signing_dir=/var/cache/neutron
+ local section=DEFAULT
+ iniset /etc/neutron/metadata_agent.ini DEFAULT auth_host 10.14.0.26
++ set +o
++ grep xtrace
+ local 'xtrace=set -o xtrace'
+ set +o xtrace
+ iniset /etc/neutron/metadata_agent.ini DEFAULT auth_port 35357
++ set +o
++ grep xtrace
+ local 'xtrace=set -o xtrace'
+ set +o xtrace
+ iniset /etc/neutron/metadata_agent.ini DEFAULT auth_protocol http
++ set +o
++ grep xtrace
+ local 'xtrace=set -o xtrace'
+ set +o xtrace
+ iniset /etc/neutron/metadata_agent.ini DEFAULT identity_uri http://10.14.0.26:35357
++ set +o
++ grep xtrace
+ local 'xtrace=set -o xtrace'
+ set +o xtrace
+ iniset /etc/neutron/metadata_agent.ini DEFAULT cafile /opt/stack/data/ca-bundle.pem
++ set +o
++ grep xtrace
+ local 'xtrace=set -o xtrace'
+ set +o xtrace
+ configure_API_version /etc/neutron/metadata_agent.ini 2.0 DEFAULT
+ local conf_file=/etc/neutron/metadata_agent.ini
+ local api_version=2.0
+ local section=DEFAULT
+ iniset /etc/neutron/metadata_agent.ini DEFAULT auth_uri http://10.14.0.26:5000/v2.0
++ set +o
++ grep xtrace
+ local 'xtrace=set -o xtrace'
+ set +o xtrace
+ iniset /etc/neutron/metadata_agent.ini DEFAULT admin_tenant_name service
++ set +o
++ grep xtrace
+ local 'xtrace=set -o xtrace'
+ set +o xtrace
+ iniset /etc/neutron/metadata_agent.ini DEFAULT admin_user neutron
++ set +o
++ grep xtrace
+ local 'xtrace=set -o xtrace'
+ set +o xtrace
+ iniset /etc/neutron/metadata_agent.ini DEFAULT admin_password Passw0rd
++ set +o
++ grep xtrace
+ local 'xtrace=set -o xtrace'
+ set +o xtrace
+ iniset /etc/neutron/metadata_agent.ini DEFAULT signing_dir /var/cache/neutron
++ set +o
++ grep xtrace
+ local 'xtrace=set -o xtrace'
+ set +o xtrace
+ [[ -n '' ]]
+ [[ legacy != \l\e\g\a\c\y ]]
+ is_service_enabled ceilometer
++ set +o
++ grep xtrace
+ local 'xtrace=set -o xtrace'
+ set +o xtrace
+ return 0
+ _configure_neutron_ceilometer_notifications
+ iniset /etc/neutron/neutron.conf DEFAULT notification_driver messaging
++ set +o
++ grep xtrace
+ local 'xtrace=set -o xtrace'
+ set +o xtrace
+ _configure_neutron_debug_command
+ [[ False != \T\r\u\e ]]
+ return
+ is_service_enabled mysql postgresql
++ set +o
++ grep xtrace
+ local 'xtrace=set -o xtrace'
+ set +o xtrace
+ return 0
+ is_service_enabled q-svc
++ set +o
++ grep xtrace
+ local 'xtrace=set -o xtrace'
+ set +o xtrace
+ return 0
+ init_neutron
+ recreate_database neutron utf8
+ local db=neutron
+ local charset=utf8
+ recreate_database_mysql neutron utf8
+ local db=neutron
+ local charset=utf8
+ mysql -uroot -pPassw0rd -h127.0.0.1 -e 'DROP DATABASE IF EXISTS neutron;'
+ mysql -uroot -pPassw0rd -h127.0.0.1 -e 'CREATE DATABASE neutron CHARACTER SET utf8;'
+ /usr/local/bin/neutron-db-manage --config-file /etc/neutron/neutron.conf --config-file /etc/neutron/plugins/ml2/ml2_conf.ini upgrade head
INFO  [alembic.migration] Context impl MySQLImpl.
INFO  [alembic.migration] Will assume non-transactional DDL.
INFO  [alembic.migration] Running upgrade None -> havana, havana_initial
INFO  [alembic.migration] Running upgrade havana -> e197124d4b9, add unique constraint to members
INFO  [alembic.migration] Running upgrade e197124d4b9 -> 1fcfc149aca4, Add a unique constraint on (agent_type, host) columns to prevent a race
condition when an agent entry is 'upserted'.
INFO  [alembic.migration] Running upgrade 1fcfc149aca4 -> 50e86cb2637a, nsx_mappings
INFO  [alembic.migration] Running upgrade 50e86cb2637a -> 1421183d533f, NSX DHCP/metadata support
INFO  [alembic.migration] Running upgrade 1421183d533f -> 3d3cb89d84ee, nsx_switch_mappings
INFO  [alembic.migration] Running upgrade 3d3cb89d84ee -> 4ca36cfc898c, nsx_router_mappings
INFO  [alembic.migration] Running upgrade 4ca36cfc898c -> 27cc183af192, ml2_vnic_type
INFO  [alembic.migration] Running upgrade 27cc183af192 -> 50d5ba354c23, ml2 binding:vif_details
INFO  [alembic.migration] Running upgrade 50d5ba354c23 -> 157a5d299379, ml2 binding:profile
INFO  [alembic.migration] Running upgrade 157a5d299379 -> 3d2585038b95, VMware NSX rebranding
INFO  [alembic.migration] Running upgrade 3d2585038b95 -> abc88c33f74f, lb stats
INFO  [alembic.migration] Running upgrade abc88c33f74f -> 1b2580001654, nsx_sec_group_mapping
INFO  [alembic.migration] Running upgrade 1b2580001654 -> e766b19a3bb, nuage_initial
INFO  [alembic.migration] Running upgrade e766b19a3bb -> 2eeaf963a447, floatingip_status
INFO  [alembic.migration] Running upgrade 2eeaf963a447 -> 492a106273f8, Brocade ML2 Mech. Driver
INFO  [alembic.migration] Running upgrade 492a106273f8 -> 24c7ea5160d7, Cisco CSR VPNaaS
INFO  [alembic.migration] Running upgrade 24c7ea5160d7 -> 81c553f3776c, bsn_consistencyhashes
INFO  [alembic.migration] Running upgrade 81c553f3776c -> 117643811bca, nec: delete old ofc mapping tables
INFO  [alembic.migration] Running upgrade 117643811bca -> 19180cf98af6, nsx_gw_devices
INFO  [alembic.migration] Running upgrade 19180cf98af6 -> 33dd0a9fa487, embrane_lbaas_driver
INFO  [alembic.migration] Running upgrade 33dd0a9fa487 -> 2447ad0e9585, Add IPv6 Subnet properties
INFO  [alembic.migration] Running upgrade 2447ad0e9585 -> 538732fa21e1, NEC Rename quantum_id to neutron_id
INFO  [alembic.migration] Running upgrade 538732fa21e1 -> 5ac1c354a051, n1kv segment allocs for cisco n1kv plugin
INFO  [alembic.migration] Running upgrade 5ac1c354a051 -> icehouse, icehouse
INFO  [alembic.migration] Running upgrade icehouse -> 54f7549a0e5f, set_not_null_peer_address
INFO  [alembic.migration] Running upgrade 54f7549a0e5f -> 1e5dd1d09b22, set_not_null_fields_lb_stats
INFO  [alembic.migration] Running upgrade 1e5dd1d09b22 -> b65aa907aec, set_length_of_protocol_field
INFO  [alembic.migration] Running upgrade b65aa907aec -> 33c3db036fe4, set_length_of_description_field_metering
INFO  [alembic.migration] Running upgrade 33c3db036fe4 -> 4eca4a84f08a, Remove ML2 Cisco Credentials DB
INFO  [alembic.migration] Running upgrade 4eca4a84f08a -> d06e871c0d5, set_admin_state_up_not_null_ml2
INFO  [alembic.migration] Running upgrade d06e871c0d5 -> 6be312499f9, set_not_null_vlan_id_cisco
INFO  [alembic.migration] Running upgrade 6be312499f9 -> 1b837a7125a9, Cisco APIC Mechanism Driver
INFO  [alembic.migration] Running upgrade 1b837a7125a9 -> 10cd28e692e9, nuage_extraroute
INFO  [alembic.migration] Running upgrade 10cd28e692e9 -> 2db5203cb7a9, nuage_floatingip
INFO  [alembic.migration] Running upgrade 2db5203cb7a9 -> 5446f2a45467, set_server_default
INFO  [alembic.migration] Running upgrade 5446f2a45467 -> db_healing, Include all tables and make migrations unconditional.
INFO  [alembic.migration] Context impl MySQLImpl.
INFO  [alembic.migration] Will assume non-transactional DDL.
INFO  [alembic.autogenerate.compare] Detected server default on column 'cisco_ml2_apic_epgs.provider'
INFO  [alembic.autogenerate.compare] Detected removed index 'cisco_n1kv_vlan_allocations_ibfk_1' on 'cisco_n1kv_vlan_allocations'
INFO  [alembic.autogenerate.compare] Detected server default on column 'cisco_n1kv_vxlan_allocations.allocated'
INFO  [alembic.autogenerate.compare] Detected removed index 'cisco_n1kv_vxlan_allocations_ibfk_1' on 'cisco_n1kv_vxlan_allocations'
INFO  [alembic.autogenerate.compare] Detected removed index 'embrane_pool_port_ibfk_2' on 'embrane_pool_port'
INFO  [alembic.autogenerate.compare] Detected removed index 'firewall_rules_ibfk_1' on 'firewall_rules'
INFO  [alembic.autogenerate.compare] Detected removed index 'firewalls_ibfk_1' on 'firewalls'
INFO  [alembic.autogenerate.compare] Detected server default on column 'meteringlabelrules.excluded'
INFO  [alembic.autogenerate.compare] Detected server default on column 'ml2_port_bindings.host'
INFO  [alembic.autogenerate.compare] Detected added column 'nuage_routerroutes_mapping.destination'
INFO  [alembic.autogenerate.compare] Detected added column 'nuage_routerroutes_mapping.nexthop'
INFO  [alembic.autogenerate.compare] Detected server default on column 'poolmonitorassociations.status'
INFO  [alembic.autogenerate.compare] Detected added index 'ix_quotas_tenant_id' on '['tenant_id']'
INFO  [alembic.autogenerate.compare] Detected NULL on column 'tz_network_bindings.phy_uuid'
INFO  [alembic.autogenerate.compare] Detected NULL on column 'tz_network_bindings.vlan_id'
INFO  [neutron.db.migration.alembic_migrations.heal_script] Detected removed foreign key u'nuage_floatingip_pool_mapping_ibfk_2' on table u'nuage_floatingip_pool_mapping'
INFO  [alembic.migration] Running upgrade db_healing -> 3927f7f7c456, L3 extension distributed mode
INFO  [alembic.migration] Running upgrade 3927f7f7c456 -> 2026156eab2f, L2 models to support DVR
INFO  [alembic.migration] Running upgrade 2026156eab2f -> 37f322991f59, removing_mapping_tables
INFO  [alembic.migration] Running upgrade 37f322991f59 -> 31d7f831a591, add constraint for routerid
INFO  [alembic.migration] Running upgrade 31d7f831a591 -> 5589aa32bf80, L3 scheduler additions to support DVR
INFO  [alembic.migration] Running upgrade 5589aa32bf80 -> 884573acbf1c, Drop NSX table in favor of the extra_attributes one
INFO  [alembic.migration] Running upgrade 884573acbf1c -> 4eba2f05c2f4, correct Vxlan Endpoint primary key
INFO  [alembic.migration] Running upgrade 4eba2f05c2f4 -> 327ee5fde2c7, set_innodb_engine
INFO  [alembic.migration] Running upgrade 327ee5fde2c7 -> 3b85b693a95f, Drop unused servicedefinitions and servicetypes tables.
INFO  [alembic.migration] Running upgrade 3b85b693a95f -> aae5706a396, nuage_provider_networks
INFO  [alembic.migration] Running upgrade aae5706a396 -> 32f3915891fd, cisco_apic_driver_update
INFO  [alembic.migration] Running upgrade 32f3915891fd -> 58fe87a01143, cisco_csr_routing
INFO  [alembic.migration] Running upgrade 58fe87a01143 -> 236b90af57ab, ml2_type_driver_refactor_dynamic_segments
INFO  [alembic.migration] Running upgrade 236b90af57ab -> 86d6d9776e2b, Cisco APIC Mechanism Driver
INFO  [alembic.migration] Running upgrade 86d6d9776e2b -> 16a27a58e093, ext_l3_ha_mode
INFO  [alembic.migration] Running upgrade 16a27a58e093 -> 3c346828361e, metering_label_shared
INFO  [alembic.migration] Running upgrade 3c346828361e -> 1680e1f0c4dc, Remove Cisco Nexus Monolithic Plugin
INFO  [alembic.migration] Running upgrade 1680e1f0c4dc -> 544673ac99ab, add router port relationship
INFO  [alembic.migration] Running upgrade 544673ac99ab -> juno, juno
+ is_service_enabled neutron
++ set +o
++ grep xtrace
+ local 'xtrace=set -o xtrace'
+ set +o xtrace
+ return 0
+ configure_neutron_third_party
+ _neutron_third_party_do configure
+ init_neutron_third_party
+ _neutron_third_party_do init
+ start_neutron_third_party
+ _neutron_third_party_do start
+ is_service_enabled n-net q-dhcp
++ set +o
++ grep xtrace
+ local 'xtrace=set -o xtrace'
+ set +o xtrace
+ return 0
++ pidof NetworkManager
++ true
+ netman_pid=
+ '[' -z '' ']'
+ sudo killall dnsmasq
dnsmasq: no process found
+ true
+ clean_iptables
+ sudo iptables -S -v
+ sed 's/-c [0-9]* [0-9]* //g'
+ grep nova
+ grep '\-A'
+ sed s/-A/-D/g
+ awk '{print "sudo iptables",$0}'
+ bash
+ sudo iptables -S -v -t nat
+ grep nova
+ sed s/-A/-D/g
+ awk '{print "sudo iptables -t nat",$0}'
+ bash
+ grep '\-A'
+ sed 's/-c [0-9]* [0-9]* //g'
+ sudo iptables -S -v
+ sed 's/-c [0-9]* [0-9]* //g'
+ grep nova
+ grep '\-N'
+ awk '{print "sudo iptables",$0}'
+ sed s/-N/-X/g
+ bash
+ sudo iptables -S -v -t nat
+ sed 's/-c [0-9]* [0-9]* //g'
+ grep nova
+ grep '\-N'
+ sed s/-N/-X/g
+ awk '{print "sudo iptables -t nat",$0}'
+ bash
+ is_service_enabled n-net
++ set +o
++ grep xtrace
+ local 'xtrace=set -o xtrace'
+ set +o xtrace
+ return 1
+ sudo sysctl -w net.ipv4.ip_forward=1
+ is_service_enabled s-proxy
++ set +o
++ grep xtrace
+ local 'xtrace=set -o xtrace'
+ set +o xtrace
+ return 0
+ echo_summary 'Configuring Swift'
+ [[ -t 3 ]]
+ echo -e Configuring Swift
+ init_swift
+ local node_number
+ swift-init --run-dir=/opt/stack/data/swift/run all stop
+ true
+ create_swift_disk
+ local node_number
++ id -g cloudbase
+ local user_group=1000
+ sudo mkdir -p /opt/stack/data/swift/drives /opt/stack/data/swift/cache /opt/stack/data/swift/run /opt/stack/data/swift/logs
+ sudo chown -R cloudbase:1000 /opt/stack/data/swift
+ [[ -e /opt/stack/data/swift/drives/images/swift.img ]]
+ mkdir -p /opt/stack/data/swift/drives/images
+ sudo touch /opt/stack/data/swift/drives/images/swift.img
+ sudo chown cloudbase: /opt/stack/data/swift/drives/images/swift.img
+ truncate -s 6G /opt/stack/data/swift/drives/images/swift.img
+ /sbin/mkfs.xfs -f -i size=1024 /opt/stack/data/swift/drives/images/swift.img
+ mkdir -p /opt/stack/data/swift/drives/sdb1
+ egrep -q /opt/stack/data/swift/drives/sdb1 /proc/mounts
+ sudo mount -t xfs -o loop,noatime,nodiratime,nobarrier,logbufs=8 /opt/stack/data/swift/drives/images/swift.img /opt/stack/data/swift/drives/sdb1
+ local node_number
+ for node_number in '${SWIFT_REPLICAS_SEQ}'
+ sudo ln -sf /opt/stack/data/swift/drives/sdb1/1 /opt/stack/data/swift/1
+ local drive=/opt/stack/data/swift/drives/sdb1/1
+ local node=/opt/stack/data/swift/1/node
+ local node_device=/opt/stack/data/swift/1/node/sdb1
+ [[ -d /opt/stack/data/swift/1/node ]]
+ [[ -d /opt/stack/data/swift/drives/sdb1/1 ]]
+ sudo install -o cloudbase -g 1000 -d /opt/stack/data/swift/drives/sdb1/1
+ sudo install -o cloudbase -g 1000 -d /opt/stack/data/swift/1/node/sdb1
+ sudo chown -R cloudbase: /opt/stack/data/swift/1/node
+ pushd /etc/swift
+ rm -f account.builder container.builder object.builder account.ring.gz container.ring.gz object.ring.gz backups/1418391806.account.builder backups/1418391806.container.builder backups/1418391806.object.builder backups/1418391807.account.builder backups/1418391807.container.builder backups/1418391807.object.builder backups/1418391807.account.ring.gz backups/1418391807.container.ring.gz backups/1418391807.object.ring.gz
+ swift-ring-builder object.builder create 9 1 1
+ swift-ring-builder container.builder create 9 1 1
+ swift-ring-builder account.builder create 9 1 1
+ for node_number in '${SWIFT_REPLICAS_SEQ}'
+ swift-ring-builder object.builder add z1-127.0.0.1:6013/sdb1 1
WARNING: No region specified for z1-127.0.0.1:6013/sdb1. Defaulting to region 1.
+ swift-ring-builder container.builder add z1-127.0.0.1:6011/sdb1 1
WARNING: No region specified for z1-127.0.0.1:6011/sdb1. Defaulting to region 1.
+ swift-ring-builder account.builder add z1-127.0.0.1:6012/sdb1 1
WARNING: No region specified for z1-127.0.0.1:6012/sdb1. Defaulting to region 1.
+ swift-ring-builder object.builder rebalance
+ swift-ring-builder container.builder rebalance
+ swift-ring-builder account.builder rebalance
+ popd
+ sudo mkdir -p /var/cache/swift
+ sudo chown cloudbase /var/cache/swift
+ rm -f '/var/cache/swift/*'
+ is_service_enabled cinder
++ set +o
++ grep xtrace
+ local 'xtrace=set -o xtrace'
+ set +o xtrace
+ return 0
+ echo_summary 'Configuring Cinder'
+ [[ -t 3 ]]
+ echo -e Configuring Cinder
+ init_cinder
++ echo ec2,osapi_compute,metadata
++ sed s/osapi_volume,//
+ NOVA_ENABLED_APIS=ec2,osapi_compute,metadata
+ is_service_enabled mysql postgresql
++ set +o
++ grep xtrace
+ local 'xtrace=set -o xtrace'
+ set +o xtrace
+ return 0
+ recreate_database cinder utf8
+ local db=cinder
+ local charset=utf8
+ recreate_database_mysql cinder utf8
+ local db=cinder
+ local charset=utf8
+ mysql -uroot -pPassw0rd -h127.0.0.1 -e 'DROP DATABASE IF EXISTS cinder;'
+ mysql -uroot -pPassw0rd -h127.0.0.1 -e 'CREATE DATABASE cinder CHARACTER SET utf8;'
+ /opt/stack/cinder/bin/cinder-manage db sync
2014-12-12 16:31:44.946 16891 DEBUG cinder.utils [-] backend <module 'cinder.db.sqlalchemy.migration' from '/opt/stack/cinder/cinder/db/sqlalchemy/migration.pyc'> __get_backend /opt/stack/cinder/cinder/utils.py:302
2014-12-12 16:31:44.947 16891 DEBUG migrate.versioning.repository [-] Loading repository /opt/stack/cinder/cinder/db/sqlalchemy/migrate_repo... __init__ /usr/local/lib/python2.7/dist-packages/migrate/versioning/repository.py:76
2014-12-12 16:31:44.947 16891 DEBUG migrate.versioning.script.base [-] Loading script /opt/stack/cinder/cinder/db/sqlalchemy/migrate_repo/versions/001_cinder_init.py... __init__ /usr/local/lib/python2.7/dist-packages/migrate/versioning/script/base.py:27
2014-12-12 16:31:44.947 16891 DEBUG migrate.versioning.script.base [-] Script /opt/stack/cinder/cinder/db/sqlalchemy/migrate_repo/versions/001_cinder_init.py loaded successfully __init__ /usr/local/lib/python2.7/dist-packages/migrate/versioning/script/base.py:30
2014-12-12 16:31:44.947 16891 DEBUG migrate.versioning.script.base [-] Loading script /opt/stack/cinder/cinder/db/sqlalchemy/migrate_repo/versions/002_quota_class.py... __init__ /usr/local/lib/python2.7/dist-packages/migrate/versioning/script/base.py:27
2014-12-12 16:31:44.947 16891 DEBUG migrate.versioning.script.base [-] Script /opt/stack/cinder/cinder/db/sqlalchemy/migrate_repo/versions/002_quota_class.py loaded successfully __init__ /usr/local/lib/python2.7/dist-packages/migrate/versioning/script/base.py:30
2014-12-12 16:31:44.948 16891 DEBUG migrate.versioning.script.base [-] Loading script /opt/stack/cinder/cinder/db/sqlalchemy/migrate_repo/versions/003_glance_metadata.py... __init__ /usr/local/lib/python2.7/dist-packages/migrate/versioning/script/base.py:27
2014-12-12 16:31:44.948 16891 DEBUG migrate.versioning.script.base [-] Script /opt/stack/cinder/cinder/db/sqlalchemy/migrate_repo/versions/003_glance_metadata.py loaded successfully __init__ /usr/local/lib/python2.7/dist-packages/migrate/versioning/script/base.py:30
2014-12-12 16:31:44.948 16891 DEBUG migrate.versioning.script.base [-] Loading script /opt/stack/cinder/cinder/db/sqlalchemy/migrate_repo/versions/004_volume_type_to_uuid.py... __init__ /usr/local/lib/python2.7/dist-packages/migrate/versioning/script/base.py:27
2014-12-12 16:31:44.948 16891 DEBUG migrate.versioning.script.base [-] Script /opt/stack/cinder/cinder/db/sqlalchemy/migrate_repo/versions/004_volume_type_to_uuid.py loaded successfully __init__ /usr/local/lib/python2.7/dist-packages/migrate/versioning/script/base.py:30
2014-12-12 16:31:44.948 16891 DEBUG migrate.versioning.script.base [-] Loading script /opt/stack/cinder/cinder/db/sqlalchemy/migrate_repo/versions/005_sqlite_downgrade.sql... __init__ /usr/local/lib/python2.7/dist-packages/migrate/versioning/script/base.py:27
2014-12-12 16:31:44.948 16891 DEBUG migrate.versioning.script.base [-] Script /opt/stack/cinder/cinder/db/sqlalchemy/migrate_repo/versions/005_sqlite_downgrade.sql loaded successfully __init__ /usr/local/lib/python2.7/dist-packages/migrate/versioning/script/base.py:30
2014-12-12 16:31:44.948 16891 DEBUG migrate.versioning.script.base [-] Loading script /opt/stack/cinder/cinder/db/sqlalchemy/migrate_repo/versions/005_add_source_volume_column.py... __init__ /usr/local/lib/python2.7/dist-packages/migrate/versioning/script/base.py:27
2014-12-12 16:31:44.948 16891 DEBUG migrate.versioning.script.base [-] Script /opt/stack/cinder/cinder/db/sqlalchemy/migrate_repo/versions/005_add_source_volume_column.py loaded successfully __init__ /usr/local/lib/python2.7/dist-packages/migrate/versioning/script/base.py:30
2014-12-12 16:31:44.948 16891 DEBUG migrate.versioning.script.base [-] Loading script /opt/stack/cinder/cinder/db/sqlalchemy/migrate_repo/versions/006_snapshots_add_provider_location.py... __init__ /usr/local/lib/python2.7/dist-packages/migrate/versioning/script/base.py:27
2014-12-12 16:31:44.948 16891 DEBUG migrate.versioning.script.base [-] Script /opt/stack/cinder/cinder/db/sqlalchemy/migrate_repo/versions/006_snapshots_add_provider_location.py loaded successfully __init__ /usr/local/lib/python2.7/dist-packages/migrate/versioning/script/base.py:30
2014-12-12 16:31:44.948 16891 DEBUG migrate.versioning.script.base [-] Loading script /opt/stack/cinder/cinder/db/sqlalchemy/migrate_repo/versions/007_sqlite_downgrade.sql... __init__ /usr/local/lib/python2.7/dist-packages/migrate/versioning/script/base.py:27
2014-12-12 16:31:44.948 16891 DEBUG migrate.versioning.script.base [-] Script /opt/stack/cinder/cinder/db/sqlalchemy/migrate_repo/versions/007_sqlite_downgrade.sql loaded successfully __init__ /usr/local/lib/python2.7/dist-packages/migrate/versioning/script/base.py:30
2014-12-12 16:31:44.948 16891 DEBUG migrate.versioning.script.base [-] Loading script /opt/stack/cinder/cinder/db/sqlalchemy/migrate_repo/versions/007_add_volume_snapshot_fk.py... __init__ /usr/local/lib/python2.7/dist-packages/migrate/versioning/script/base.py:27
2014-12-12 16:31:44.948 16891 DEBUG migrate.versioning.script.base [-] Script /opt/stack/cinder/cinder/db/sqlalchemy/migrate_repo/versions/007_add_volume_snapshot_fk.py loaded successfully __init__ /usr/local/lib/python2.7/dist-packages/migrate/versioning/script/base.py:30
2014-12-12 16:31:44.949 16891 DEBUG migrate.versioning.script.base [-] Loading script /opt/stack/cinder/cinder/db/sqlalchemy/migrate_repo/versions/008_add_backup.py... __init__ /usr/local/lib/python2.7/dist-packages/migrate/versioning/script/base.py:27
2014-12-12 16:31:44.949 16891 DEBUG migrate.versioning.script.base [-] Script /opt/stack/cinder/cinder/db/sqlalchemy/migrate_repo/versions/008_add_backup.py loaded successfully __init__ /usr/local/lib/python2.7/dist-packages/migrate/versioning/script/base.py:30
2014-12-12 16:31:44.949 16891 DEBUG migrate.versioning.script.base [-] Loading script /opt/stack/cinder/cinder/db/sqlalchemy/migrate_repo/versions/009_add_snapshot_metadata_table.py... __init__ /usr/local/lib/python2.7/dist-packages/migrate/versioning/script/base.py:27
2014-12-12 16:31:44.949 16891 DEBUG migrate.versioning.script.base [-] Script /opt/stack/cinder/cinder/db/sqlalchemy/migrate_repo/versions/009_add_snapshot_metadata_table.py loaded successfully __init__ /usr/local/lib/python2.7/dist-packages/migrate/versioning/script/base.py:30
2014-12-12 16:31:44.949 16891 DEBUG migrate.versioning.script.base [-] Loading script /opt/stack/cinder/cinder/db/sqlalchemy/migrate_repo/versions/010_add_transfers_table.py... __init__ /usr/local/lib/python2.7/dist-packages/migrate/versioning/script/base.py:27
2014-12-12 16:31:44.949 16891 DEBUG migrate.versioning.script.base [-] Script /opt/stack/cinder/cinder/db/sqlalchemy/migrate_repo/versions/010_add_transfers_table.py loaded successfully __init__ /usr/local/lib/python2.7/dist-packages/migrate/versioning/script/base.py:30
2014-12-12 16:31:44.949 16891 DEBUG migrate.versioning.script.base [-] Loading script /opt/stack/cinder/cinder/db/sqlalchemy/migrate_repo/versions/011_add_bootable_column.py... __init__ /usr/local/lib/python2.7/dist-packages/migrate/versioning/script/base.py:27
2014-12-12 16:31:44.949 16891 DEBUG migrate.versioning.script.base [-] Script /opt/stack/cinder/cinder/db/sqlalchemy/migrate_repo/versions/011_add_bootable_column.py loaded successfully __init__ /usr/local/lib/python2.7/dist-packages/migrate/versioning/script/base.py:30
2014-12-12 16:31:44.949 16891 DEBUG migrate.versioning.script.base [-] Loading script /opt/stack/cinder/cinder/db/sqlalchemy/migrate_repo/versions/011_sqlite_downgrade.sql... __init__ /usr/local/lib/python2.7/dist-packages/migrate/versioning/script/base.py:27
2014-12-12 16:31:44.949 16891 DEBUG migrate.versioning.script.base [-] Script /opt/stack/cinder/cinder/db/sqlalchemy/migrate_repo/versions/011_sqlite_downgrade.sql loaded successfully __init__ /usr/local/lib/python2.7/dist-packages/migrate/versioning/script/base.py:30
2014-12-12 16:31:44.949 16891 DEBUG migrate.versioning.script.base [-] Loading script /opt/stack/cinder/cinder/db/sqlalchemy/migrate_repo/versions/012_add_attach_host_column.py... __init__ /usr/local/lib/python2.7/dist-packages/migrate/versioning/script/base.py:27
2014-12-12 16:31:44.949 16891 DEBUG migrate.versioning.script.base [-] Script /opt/stack/cinder/cinder/db/sqlalchemy/migrate_repo/versions/012_add_attach_host_column.py loaded successfully __init__ /usr/local/lib/python2.7/dist-packages/migrate/versioning/script/base.py:30
2014-12-12 16:31:44.949 16891 DEBUG migrate.versioning.script.base [-] Loading script /opt/stack/cinder/cinder/db/sqlalchemy/migrate_repo/versions/012_sqlite_downgrade.sql... __init__ /usr/local/lib/python2.7/dist-packages/migrate/versioning/script/base.py:27
2014-12-12 16:31:44.949 16891 DEBUG migrate.versioning.script.base [-] Script /opt/stack/cinder/cinder/db/sqlalchemy/migrate_repo/versions/012_sqlite_downgrade.sql loaded successfully __init__ /usr/local/lib/python2.7/dist-packages/migrate/versioning/script/base.py:30
2014-12-12 16:31:44.950 16891 DEBUG migrate.versioning.script.base [-] Loading script /opt/stack/cinder/cinder/db/sqlalchemy/migrate_repo/versions/013_sqlite_downgrade.sql... __init__ /usr/local/lib/python2.7/dist-packages/migrate/versioning/script/base.py:27
2014-12-12 16:31:44.950 16891 DEBUG migrate.versioning.script.base [-] Script /opt/stack/cinder/cinder/db/sqlalchemy/migrate_repo/versions/013_sqlite_downgrade.sql loaded successfully __init__ /usr/local/lib/python2.7/dist-packages/migrate/versioning/script/base.py:30
2014-12-12 16:31:44.950 16891 DEBUG migrate.versioning.script.base [-] Loading script /opt/stack/cinder/cinder/db/sqlalchemy/migrate_repo/versions/013_add_provider_geometry_column.py... __init__ /usr/local/lib/python2.7/dist-packages/migrate/versioning/script/base.py:27
2014-12-12 16:31:44.950 16891 DEBUG migrate.versioning.script.base [-] Script /opt/stack/cinder/cinder/db/sqlalchemy/migrate_repo/versions/013_add_provider_geometry_column.py loaded successfully __init__ /usr/local/lib/python2.7/dist-packages/migrate/versioning/script/base.py:30
2014-12-12 16:31:44.950 16891 DEBUG migrate.versioning.script.base [-] Loading script /opt/stack/cinder/cinder/db/sqlalchemy/migrate_repo/versions/014_add_name_id.py... __init__ /usr/local/lib/python2.7/dist-packages/migrate/versioning/script/base.py:27
2014-12-12 16:31:44.950 16891 DEBUG migrate.versioning.script.base [-] Script /opt/stack/cinder/cinder/db/sqlalchemy/migrate_repo/versions/014_add_name_id.py loaded successfully __init__ /usr/local/lib/python2.7/dist-packages/migrate/versioning/script/base.py:30
2014-12-12 16:31:44.950 16891 DEBUG migrate.versioning.script.base [-] Loading script /opt/stack/cinder/cinder/db/sqlalchemy/migrate_repo/versions/014_sqlite_downgrade.sql... __init__ /usr/local/lib/python2.7/dist-packages/migrate/versioning/script/base.py:27
2014-12-12 16:31:44.950 16891 DEBUG migrate.versioning.script.base [-] Script /opt/stack/cinder/cinder/db/sqlalchemy/migrate_repo/versions/014_sqlite_downgrade.sql loaded successfully __init__ /usr/local/lib/python2.7/dist-packages/migrate/versioning/script/base.py:30
2014-12-12 16:31:44.950 16891 DEBUG migrate.versioning.script.base [-] Loading script /opt/stack/cinder/cinder/db/sqlalchemy/migrate_repo/versions/015_drop_migrations_table.py... __init__ /usr/local/lib/python2.7/dist-packages/migrate/versioning/script/base.py:27
2014-12-12 16:31:44.950 16891 DEBUG migrate.versioning.script.base [-] Script /opt/stack/cinder/cinder/db/sqlalchemy/migrate_repo/versions/015_drop_migrations_table.py loaded successfully __init__ /usr/local/lib/python2.7/dist-packages/migrate/versioning/script/base.py:30
2014-12-12 16:31:44.950 16891 DEBUG migrate.versioning.script.base [-] Loading script /opt/stack/cinder/cinder/db/sqlalchemy/migrate_repo/versions/016_drop_sm_tables.py... __init__ /usr/local/lib/python2.7/dist-packages/migrate/versioning/script/base.py:27
2014-12-12 16:31:44.950 16891 DEBUG migrate.versioning.script.base [-] Script /opt/stack/cinder/cinder/db/sqlalchemy/migrate_repo/versions/016_drop_sm_tables.py loaded successfully __init__ /usr/local/lib/python2.7/dist-packages/migrate/versioning/script/base.py:30
2014-12-12 16:31:44.951 16891 DEBUG migrate.versioning.script.base [-] Loading script /opt/stack/cinder/cinder/db/sqlalchemy/migrate_repo/versions/017_add_encryption_information.py... __init__ /usr/local/lib/python2.7/dist-packages/migrate/versioning/script/base.py:27
2014-12-12 16:31:44.951 16891 DEBUG migrate.versioning.script.base [-] Script /opt/stack/cinder/cinder/db/sqlalchemy/migrate_repo/versions/017_add_encryption_information.py loaded successfully __init__ /usr/local/lib/python2.7/dist-packages/migrate/versioning/script/base.py:30
2014-12-12 16:31:44.951 16891 DEBUG migrate.versioning.script.base [-] Loading script /opt/stack/cinder/cinder/db/sqlalchemy/migrate_repo/versions/018_add_qos_specs.py... __init__ /usr/local/lib/python2.7/dist-packages/migrate/versioning/script/base.py:27
2014-12-12 16:31:44.951 16891 DEBUG migrate.versioning.script.base [-] Script /opt/stack/cinder/cinder/db/sqlalchemy/migrate_repo/versions/018_add_qos_specs.py loaded successfully __init__ /usr/local/lib/python2.7/dist-packages/migrate/versioning/script/base.py:30
2014-12-12 16:31:44.951 16891 DEBUG migrate.versioning.script.base [-] Loading script /opt/stack/cinder/cinder/db/sqlalchemy/migrate_repo/versions/019_add_migration_status.py... __init__ /usr/local/lib/python2.7/dist-packages/migrate/versioning/script/base.py:27
2014-12-12 16:31:44.951 16891 DEBUG migrate.versioning.script.base [-] Script /opt/stack/cinder/cinder/db/sqlalchemy/migrate_repo/versions/019_add_migration_status.py loaded successfully __init__ /usr/local/lib/python2.7/dist-packages/migrate/versioning/script/base.py:30
2014-12-12 16:31:44.951 16891 DEBUG migrate.versioning.script.base [-] Loading script /opt/stack/cinder/cinder/db/sqlalchemy/migrate_repo/versions/020_add_volume_admin_metadata_table.py... __init__ /usr/local/lib/python2.7/dist-packages/migrate/versioning/script/base.py:27
2014-12-12 16:31:44.951 16891 DEBUG migrate.versioning.script.base [-] Script /opt/stack/cinder/cinder/db/sqlalchemy/migrate_repo/versions/020_add_volume_admin_metadata_table.py loaded successfully __init__ /usr/local/lib/python2.7/dist-packages/migrate/versioning/script/base.py:30
2014-12-12 16:31:44.951 16891 DEBUG migrate.versioning.script.base [-] Loading script /opt/stack/cinder/cinder/db/sqlalchemy/migrate_repo/versions/021_add_default_quota_class.py... __init__ /usr/local/lib/python2.7/dist-packages/migrate/versioning/script/base.py:27
2014-12-12 16:31:44.951 16891 DEBUG migrate.versioning.script.base [-] Script /opt/stack/cinder/cinder/db/sqlalchemy/migrate_repo/versions/021_add_default_quota_class.py loaded successfully __init__ /usr/local/lib/python2.7/dist-packages/migrate/versioning/script/base.py:30
2014-12-12 16:31:44.951 16891 DEBUG migrate.versioning.script.base [-] Loading script /opt/stack/cinder/cinder/db/sqlalchemy/migrate_repo/versions/022_add_reason_column_to_service.py... __init__ /usr/local/lib/python2.7/dist-packages/migrate/versioning/script/base.py:27
2014-12-12 16:31:44.951 16891 DEBUG migrate.versioning.script.base [-] Script /opt/stack/cinder/cinder/db/sqlalchemy/migrate_repo/versions/022_add_reason_column_to_service.py loaded successfully __init__ /usr/local/lib/python2.7/dist-packages/migrate/versioning/script/base.py:30
2014-12-12 16:31:44.951 16891 DEBUG migrate.versioning.script.base [-] Loading script /opt/stack/cinder/cinder/db/sqlalchemy/migrate_repo/versions/023_add_expire_reservations_index.py... __init__ /usr/local/lib/python2.7/dist-packages/migrate/versioning/script/base.py:27
2014-12-12 16:31:44.952 16891 DEBUG migrate.versioning.script.base [-] Script /opt/stack/cinder/cinder/db/sqlalchemy/migrate_repo/versions/023_add_expire_reservations_index.py loaded successfully __init__ /usr/local/lib/python2.7/dist-packages/migrate/versioning/script/base.py:30
2014-12-12 16:31:44.952 16891 DEBUG migrate.versioning.script.base [-] Loading script /opt/stack/cinder/cinder/db/sqlalchemy/migrate_repo/versions/024_add_replication_support.py... __init__ /usr/local/lib/python2.7/dist-packages/migrate/versioning/script/base.py:27
2014-12-12 16:31:44.952 16891 DEBUG migrate.versioning.script.base [-] Script /opt/stack/cinder/cinder/db/sqlalchemy/migrate_repo/versions/024_add_replication_support.py loaded successfully __init__ /usr/local/lib/python2.7/dist-packages/migrate/versioning/script/base.py:30
2014-12-12 16:31:44.952 16891 DEBUG migrate.versioning.script.base [-] Loading script /opt/stack/cinder/cinder/db/sqlalchemy/migrate_repo/versions/025_add_consistencygroup.py... __init__ /usr/local/lib/python2.7/dist-packages/migrate/versioning/script/base.py:27
2014-12-12 16:31:44.952 16891 DEBUG migrate.versioning.script.base [-] Script /opt/stack/cinder/cinder/db/sqlalchemy/migrate_repo/versions/025_add_consistencygroup.py loaded successfully __init__ /usr/local/lib/python2.7/dist-packages/migrate/versioning/script/base.py:30
2014-12-12 16:31:44.952 16891 DEBUG migrate.versioning.script.base [-] Loading script /opt/stack/cinder/cinder/db/sqlalchemy/migrate_repo/versions/026_add_consistencygroup_quota_class.py... __init__ /usr/local/lib/python2.7/dist-packages/migrate/versioning/script/base.py:27
2014-12-12 16:31:44.952 16891 DEBUG migrate.versioning.script.base [-] Script /opt/stack/cinder/cinder/db/sqlalchemy/migrate_repo/versions/026_add_consistencygroup_quota_class.py loaded successfully __init__ /usr/local/lib/python2.7/dist-packages/migrate/versioning/script/base.py:30
2014-12-12 16:31:44.952 16891 DEBUG migrate.versioning.repository [-] Repository /opt/stack/cinder/cinder/db/sqlalchemy/migrate_repo loaded successfully __init__ /usr/local/lib/python2.7/dist-packages/migrate/versioning/repository.py:82
2014-12-12 16:31:44.952 16891 DEBUG migrate.versioning.repository [-] Config: OrderedDict([('db_settings', OrderedDict([('__name__', 'db_settings'), ('repository_id', 'cinder'), ('version_table', 'migrate_version'), ('required_dbs', '[]')]))]) __init__ /usr/local/lib/python2.7/dist-packages/migrate/versioning/repository.py:83
2014-12-12 16:31:44.967 16891 DEBUG oslo.db.sqlalchemy.session [-] MySQL server mode set to STRICT_TRANS_TABLES,STRICT_ALL_TABLES,NO_ZERO_IN_DATE,NO_ZERO_DATE,ERROR_FOR_DIVISION_BY_ZERO,TRADITIONAL,NO_AUTO_CREATE_USER,NO_ENGINE_SUBSTITUTION _init_events /usr/local/lib/python2.7/dist-packages/oslo/db/sqlalchemy/session.py:474
2014-12-12 16:31:45.038 16891 INFO migrate.versioning.api [-] 0 -> 1... 
2014-12-12 16:31:46.063 16891 INFO migrate.versioning.api [-] done
2014-12-12 16:31:46.063 16891 INFO migrate.versioning.api [-] 1 -> 2... 
2014-12-12 16:31:46.265 16891 INFO migrate.versioning.api [-] done
2014-12-12 16:31:46.266 16891 INFO migrate.versioning.api [-] 2 -> 3... 
2014-12-12 16:31:46.314 16891 INFO migrate.versioning.api [-] done
2014-12-12 16:31:46.314 16891 INFO migrate.versioning.api [-] 3 -> 4... 
2014-12-12 16:31:46.579 16891 INFO 004_volume_type_to_uuid [-] Created foreign key volume_type_extra_specs_ibfk_1
2014-12-12 16:31:46.592 16891 INFO migrate.versioning.api [-] done
2014-12-12 16:31:46.593 16891 INFO migrate.versioning.api [-] 4 -> 5... 
2014-12-12 16:31:46.673 16891 INFO migrate.versioning.api [-] done
2014-12-12 16:31:46.674 16891 INFO migrate.versioning.api [-] 5 -> 6... 
2014-12-12 16:31:46.745 16891 INFO migrate.versioning.api [-] done
2014-12-12 16:31:46.745 16891 INFO migrate.versioning.api [-] 6 -> 7... 
2014-12-12 16:31:46.812 16891 INFO migrate.versioning.api [-] done
2014-12-12 16:31:46.812 16891 INFO migrate.versioning.api [-] 7 -> 8... 
2014-12-12 16:31:46.851 16891 INFO migrate.versioning.api [-] done
2014-12-12 16:31:46.851 16891 INFO migrate.versioning.api [-] 8 -> 9... 
2014-12-12 16:31:46.893 16891 INFO migrate.versioning.api [-] done
2014-12-12 16:31:46.893 16891 INFO migrate.versioning.api [-] 9 -> 10... 
2014-12-12 16:31:46.930 16891 INFO migrate.versioning.api [-] done
2014-12-12 16:31:46.930 16891 INFO migrate.versioning.api [-] 10 -> 11... 
2014-12-12 16:31:47.012 16891 INFO migrate.versioning.api [-] done
2014-12-12 16:31:47.012 16891 INFO migrate.versioning.api [-] 11 -> 12... 
2014-12-12 16:31:47.081 16891 INFO migrate.versioning.api [-] done
2014-12-12 16:31:47.081 16891 INFO migrate.versioning.api [-] 12 -> 13... 
2014-12-12 16:31:47.155 16891 INFO migrate.versioning.api [-] done
2014-12-12 16:31:47.155 16891 INFO migrate.versioning.api [-] 13 -> 14... 
2014-12-12 16:31:47.223 16891 INFO migrate.versioning.api [-] done
2014-12-12 16:31:47.224 16891 INFO migrate.versioning.api [-] 14 -> 15... 
2014-12-12 16:31:47.256 16891 INFO migrate.versioning.api [-] done
2014-12-12 16:31:47.256 16891 INFO migrate.versioning.api [-] 15 -> 16... 
2014-12-12 16:31:47.316 16891 INFO migrate.versioning.api [-] done
2014-12-12 16:31:47.316 16891 INFO migrate.versioning.api [-] 16 -> 17... 
2014-12-12 16:31:47.512 16891 INFO migrate.versioning.api [-] done
2014-12-12 16:31:47.512 16891 INFO migrate.versioning.api [-] 17 -> 18... 
2014-12-12 16:31:47.669 16891 INFO migrate.versioning.api [-] done
2014-12-12 16:31:47.669 16891 INFO migrate.versioning.api [-] 18 -> 19... 
2014-12-12 16:31:47.746 16891 INFO migrate.versioning.api [-] done
2014-12-12 16:31:47.747 16891 INFO migrate.versioning.api [-] 19 -> 20... 
2014-12-12 16:31:47.794 16891 INFO migrate.versioning.api [-] done
2014-12-12 16:31:47.794 16891 INFO migrate.versioning.api [-] 20 -> 21... 
2014-12-12 16:31:47.845 16891 INFO 021_add_default_quota_class [-] Added default quota class data into the DB.
2014-12-12 16:31:47.860 16891 INFO migrate.versioning.api [-] done
2014-12-12 16:31:47.860 16891 INFO migrate.versioning.api [-] 21 -> 22... 
2014-12-12 16:31:47.933 16891 INFO migrate.versioning.api [-] done
2014-12-12 16:31:47.933 16891 INFO migrate.versioning.api [-] 22 -> 23... 
2014-12-12 16:31:47.986 16891 INFO migrate.versioning.api [-] done
2014-12-12 16:31:47.986 16891 INFO migrate.versioning.api [-] 23 -> 24... 
2014-12-12 16:31:48.169 16891 INFO migrate.versioning.api [-] done
2014-12-12 16:31:48.169 16891 INFO migrate.versioning.api [-] 24 -> 25... 
2014-12-12 16:31:48.457 16891 INFO migrate.versioning.api [-] done
2014-12-12 16:31:48.457 16891 INFO migrate.versioning.api [-] 25 -> 26... 
2014-12-12 16:31:48.474 16891 INFO 026_add_consistencygroup_quota_class [-] Added default consistencygroups quota class data into the DB.
2014-12-12 16:31:48.486 16891 INFO migrate.versioning.api [-] done
+ is_service_enabled c-vol
++ set +o
++ grep xtrace
+ local 'xtrace=set -o xtrace'
+ set +o xtrace
+ return 0
+ [[ -n lvm:lvmdriver-1 ]]
+ local be be_name be_type
+ for be in '${CINDER_ENABLED_BACKENDS//,/ }'
+ be_type=lvm
+ be_name=lvmdriver-1
+ type init_cinder_backend_lvm
+ init_cinder_backend_lvm lvmdriver-1
+ local be_name=lvmdriver-1
++ get_volume_group_name lvmdriver-1
++ local be_name=lvmdriver-1
++ local volume_group_name=stack-volumes
++ [[ -z '' ]]
++ volume_group_name+=-lvmdriver-1
++ echo stack-volumes-lvmdriver-1
+ local volume_group_name=stack-volumes-lvmdriver-1
+ _create_cinder_volume_group stack-volumes-lvmdriver-1 /opt/stack/data/stack-volumes-lvmdriver-1-backing-file
+ local vg_name=stack-volumes-lvmdriver-1
+ local backing_file=/opt/stack/data/stack-volumes-lvmdriver-1-backing-file
+ sudo vgs stack-volumes-lvmdriver-1
  Volume group "stack-volumes-lvmdriver-1" not found
+ '[' -z '' ']'
+ [[ -f /opt/stack/data/stack-volumes-lvmdriver-1-backing-file ]]
+ truncate -s 50000M /opt/stack/data/stack-volumes-lvmdriver-1-backing-file
++ sudo losetup -f --show /opt/stack/data/stack-volumes-lvmdriver-1-backing-file
+ local vg_dev=/dev/loop1
+ sudo vgs stack-volumes-lvmdriver-1
  Volume group "stack-volumes-lvmdriver-1" not found
+ sudo vgcreate stack-volumes-lvmdriver-1 /dev/loop1
  No physical volume label read from /dev/loop1
+ is_fedora
+ [[ -z Ubuntu ]]
+ '[' Ubuntu = Fedora ']'
+ '[' Ubuntu = 'Red Hat' ']'
+ '[' Ubuntu = CentOS ']'
+ '[' Ubuntu = OracleServer ']'
+ is_suse
+ [[ -z Ubuntu ]]
+ '[' Ubuntu = openSUSE ']'
+ '[' Ubuntu = 'SUSE LINUX' ']'
+ sudo tgtadm --op show --mode target
+ grep volume-
+ grep Target
+ cut -f3 -d ' '
+ sudo xargs -n1 tgt-admin --delete
tgtadm: failed to send request hdr to tgt daemon, Transport endpoint is not connected
Option delete requires an argument
+ _clean_lvm_lv stack-volumes-lvmdriver-1 volume-
+ local vg=stack-volumes-lvmdriver-1
+ local lv_prefix=volume-
+ local lv
++ sudo lvs --noheadings -o lv_name stack-volumes-lvmdriver-1
+ mkdir -p /opt/stack/data/cinder/volumes
+ create_cinder_cache_dir
+ sudo mkdir -p /var/cache/cinder
+ sudo chown cloudbase /var/cache/cinder
+ rm -f '/var/cache/cinder/*'
+ is_service_enabled nova
++ set +o
++ grep xtrace
+ local 'xtrace=set -o xtrace'
+ set +o xtrace
+ return 0
+ echo_summary 'Configuring Nova'
+ [[ -t 3 ]]
+ echo -e Configuring Nova
+ init_nova
+ is_service_enabled mysql postgresql
++ set +o
++ grep xtrace
+ local 'xtrace=set -o xtrace'
+ set +o xtrace
+ return 0
+ is_service_enabled n-api
++ set +o
++ grep xtrace
+ local 'xtrace=set -o xtrace'
+ set +o xtrace
+ return 0
+ recreate_database nova latin1
+ local db=nova
+ local charset=latin1
+ recreate_database_mysql nova latin1
+ local db=nova
+ local charset=latin1
+ mysql -uroot -pPassw0rd -h127.0.0.1 -e 'DROP DATABASE IF EXISTS nova;'
+ mysql -uroot -pPassw0rd -h127.0.0.1 -e 'CREATE DATABASE nova CHARACTER SET latin1;'
+ /usr/local/bin/nova-manage db sync
2014-12-12 16:31:50.496 16955 DEBUG migrate.versioning.repository [-] Loading repository /opt/stack/nova/nova/db/sqlalchemy/migrate_repo... __init__ /usr/local/lib/python2.7/dist-packages/migrate/versioning/repository.py:76
2014-12-12 16:31:50.497 16955 DEBUG migrate.versioning.script.base [-] Loading script /opt/stack/nova/nova/db/sqlalchemy/migrate_repo/versions/216_havana.py... __init__ /usr/local/lib/python2.7/dist-packages/migrate/versioning/script/base.py:27
2014-12-12 16:31:50.497 16955 DEBUG migrate.versioning.script.base [-] Script /opt/stack/nova/nova/db/sqlalchemy/migrate_repo/versions/216_havana.py loaded successfully __init__ /usr/local/lib/python2.7/dist-packages/migrate/versioning/script/base.py:30
2014-12-12 16:31:50.497 16955 DEBUG migrate.versioning.script.base [-] Loading script /opt/stack/nova/nova/db/sqlalchemy/migrate_repo/versions/217_placeholder.py... __init__ /usr/local/lib/python2.7/dist-packages/migrate/versioning/script/base.py:27
2014-12-12 16:31:50.497 16955 DEBUG migrate.versioning.script.base [-] Script /opt/stack/nova/nova/db/sqlalchemy/migrate_repo/versions/217_placeholder.py loaded successfully __init__ /usr/local/lib/python2.7/dist-packages/migrate/versioning/script/base.py:30
2014-12-12 16:31:50.497 16955 DEBUG migrate.versioning.script.base [-] Loading script /opt/stack/nova/nova/db/sqlalchemy/migrate_repo/versions/218_placeholder.py... __init__ /usr/local/lib/python2.7/dist-packages/migrate/versioning/script/base.py:27
2014-12-12 16:31:50.497 16955 DEBUG migrate.versioning.script.base [-] Script /opt/stack/nova/nova/db/sqlalchemy/migrate_repo/versions/218_placeholder.py loaded successfully __init__ /usr/local/lib/python2.7/dist-packages/migrate/versioning/script/base.py:30
2014-12-12 16:31:50.498 16955 DEBUG migrate.versioning.script.base [-] Loading script /opt/stack/nova/nova/db/sqlalchemy/migrate_repo/versions/219_placeholder.py... __init__ /usr/local/lib/python2.7/dist-packages/migrate/versioning/script/base.py:27
2014-12-12 16:31:50.498 16955 DEBUG migrate.versioning.script.base [-] Script /opt/stack/nova/nova/db/sqlalchemy/migrate_repo/versions/219_placeholder.py loaded successfully __init__ /usr/local/lib/python2.7/dist-packages/migrate/versioning/script/base.py:30
2014-12-12 16:31:50.498 16955 DEBUG migrate.versioning.script.base [-] Loading script /opt/stack/nova/nova/db/sqlalchemy/migrate_repo/versions/220_placeholder.py... __init__ /usr/local/lib/python2.7/dist-packages/migrate/versioning/script/base.py:27
2014-12-12 16:31:50.498 16955 DEBUG migrate.versioning.script.base [-] Script /opt/stack/nova/nova/db/sqlalchemy/migrate_repo/versions/220_placeholder.py loaded successfully __init__ /usr/local/lib/python2.7/dist-packages/migrate/versioning/script/base.py:30
2014-12-12 16:31:50.498 16955 DEBUG migrate.versioning.script.base [-] Loading script /opt/stack/nova/nova/db/sqlalchemy/migrate_repo/versions/221_placeholder.py... __init__ /usr/local/lib/python2.7/dist-packages/migrate/versioning/script/base.py:27
2014-12-12 16:31:50.498 16955 DEBUG migrate.versioning.script.base [-] Script /opt/stack/nova/nova/db/sqlalchemy/migrate_repo/versions/221_placeholder.py loaded successfully __init__ /usr/local/lib/python2.7/dist-packages/migrate/versioning/script/base.py:30
2014-12-12 16:31:50.498 16955 DEBUG migrate.versioning.script.base [-] Loading script /opt/stack/nova/nova/db/sqlalchemy/migrate_repo/versions/222_placeholder.py... __init__ /usr/local/lib/python2.7/dist-packages/migrate/versioning/script/base.py:27
2014-12-12 16:31:50.498 16955 DEBUG migrate.versioning.script.base [-] Script /opt/stack/nova/nova/db/sqlalchemy/migrate_repo/versions/222_placeholder.py loaded successfully __init__ /usr/local/lib/python2.7/dist-packages/migrate/versioning/script/base.py:30
2014-12-12 16:31:50.498 16955 DEBUG migrate.versioning.script.base [-] Loading script /opt/stack/nova/nova/db/sqlalchemy/migrate_repo/versions/223_placeholder.py... __init__ /usr/local/lib/python2.7/dist-packages/migrate/versioning/script/base.py:27
2014-12-12 16:31:50.498 16955 DEBUG migrate.versioning.script.base [-] Script /opt/stack/nova/nova/db/sqlalchemy/migrate_repo/versions/223_placeholder.py loaded successfully __init__ /usr/local/lib/python2.7/dist-packages/migrate/versioning/script/base.py:30
2014-12-12 16:31:50.499 16955 DEBUG migrate.versioning.script.base [-] Loading script /opt/stack/nova/nova/db/sqlalchemy/migrate_repo/versions/224_placeholder.py... __init__ /usr/local/lib/python2.7/dist-packages/migrate/versioning/script/base.py:27
2014-12-12 16:31:50.499 16955 DEBUG migrate.versioning.script.base [-] Script /opt/stack/nova/nova/db/sqlalchemy/migrate_repo/versions/224_placeholder.py loaded successfully __init__ /usr/local/lib/python2.7/dist-packages/migrate/versioning/script/base.py:30
2014-12-12 16:31:50.499 16955 DEBUG migrate.versioning.script.base [-] Loading script /opt/stack/nova/nova/db/sqlalchemy/migrate_repo/versions/225_placeholder.py... __init__ /usr/local/lib/python2.7/dist-packages/migrate/versioning/script/base.py:27
2014-12-12 16:31:50.499 16955 DEBUG migrate.versioning.script.base [-] Script /opt/stack/nova/nova/db/sqlalchemy/migrate_repo/versions/225_placeholder.py loaded successfully __init__ /usr/local/lib/python2.7/dist-packages/migrate/versioning/script/base.py:30
2014-12-12 16:31:50.499 16955 DEBUG migrate.versioning.script.base [-] Loading script /opt/stack/nova/nova/db/sqlalchemy/migrate_repo/versions/226_placeholder.py... __init__ /usr/local/lib/python2.7/dist-packages/migrate/versioning/script/base.py:27
2014-12-12 16:31:50.499 16955 DEBUG migrate.versioning.script.base [-] Script /opt/stack/nova/nova/db/sqlalchemy/migrate_repo/versions/226_placeholder.py loaded successfully __init__ /usr/local/lib/python2.7/dist-packages/migrate/versioning/script/base.py:30
2014-12-12 16:31:50.499 16955 DEBUG migrate.versioning.script.base [-] Loading script /opt/stack/nova/nova/db/sqlalchemy/migrate_repo/versions/227_fix_project_user_quotas_resource_length.py... __init__ /usr/local/lib/python2.7/dist-packages/migrate/versioning/script/base.py:27
2014-12-12 16:31:50.499 16955 DEBUG migrate.versioning.script.base [-] Script /opt/stack/nova/nova/db/sqlalchemy/migrate_repo/versions/227_fix_project_user_quotas_resource_length.py loaded successfully __init__ /usr/local/lib/python2.7/dist-packages/migrate/versioning/script/base.py:30
2014-12-12 16:31:50.499 16955 DEBUG migrate.versioning.script.base [-] Loading script /opt/stack/nova/nova/db/sqlalchemy/migrate_repo/versions/228_add_metrics_in_compute_nodes.py... __init__ /usr/local/lib/python2.7/dist-packages/migrate/versioning/script/base.py:27
2014-12-12 16:31:50.499 16955 DEBUG migrate.versioning.script.base [-] Script /opt/stack/nova/nova/db/sqlalchemy/migrate_repo/versions/228_add_metrics_in_compute_nodes.py loaded successfully __init__ /usr/local/lib/python2.7/dist-packages/migrate/versioning/script/base.py:30
2014-12-12 16:31:50.499 16955 DEBUG migrate.versioning.script.base [-] Loading script /opt/stack/nova/nova/db/sqlalchemy/migrate_repo/versions/229_add_extra_resources_in_compute_nodes.py... __init__ /usr/local/lib/python2.7/dist-packages/migrate/versioning/script/base.py:27
2014-12-12 16:31:50.499 16955 DEBUG migrate.versioning.script.base [-] Script /opt/stack/nova/nova/db/sqlalchemy/migrate_repo/versions/229_add_extra_resources_in_compute_nodes.py loaded successfully __init__ /usr/local/lib/python2.7/dist-packages/migrate/versioning/script/base.py:30
2014-12-12 16:31:50.500 16955 DEBUG migrate.versioning.script.base [-] Loading script /opt/stack/nova/nova/db/sqlalchemy/migrate_repo/versions/230_add_details_column_to_instance_actions_events.py... __init__ /usr/local/lib/python2.7/dist-packages/migrate/versioning/script/base.py:27
2014-12-12 16:31:50.500 16955 DEBUG migrate.versioning.script.base [-] Script /opt/stack/nova/nova/db/sqlalchemy/migrate_repo/versions/230_add_details_column_to_instance_actions_events.py loaded successfully __init__ /usr/local/lib/python2.7/dist-packages/migrate/versioning/script/base.py:30
2014-12-12 16:31:50.500 16955 DEBUG migrate.versioning.script.base [-] Loading script /opt/stack/nova/nova/db/sqlalchemy/migrate_repo/versions/231_add_ephemeral_key_uuid.py... __init__ /usr/local/lib/python2.7/dist-packages/migrate/versioning/script/base.py:27
2014-12-12 16:31:50.500 16955 DEBUG migrate.versioning.script.base [-] Script /opt/stack/nova/nova/db/sqlalchemy/migrate_repo/versions/231_add_ephemeral_key_uuid.py loaded successfully __init__ /usr/local/lib/python2.7/dist-packages/migrate/versioning/script/base.py:30
2014-12-12 16:31:50.500 16955 DEBUG migrate.versioning.script.base [-] Loading script /opt/stack/nova/nova/db/sqlalchemy/migrate_repo/versions/232_drop_dump_tables.py... __init__ /usr/local/lib/python2.7/dist-packages/migrate/versioning/script/base.py:27
2014-12-12 16:31:50.500 16955 DEBUG migrate.versioning.script.base [-] Script /opt/stack/nova/nova/db/sqlalchemy/migrate_repo/versions/232_drop_dump_tables.py loaded successfully __init__ /usr/local/lib/python2.7/dist-packages/migrate/versioning/script/base.py:30
2014-12-12 16:31:50.500 16955 DEBUG migrate.versioning.script.base [-] Loading script /opt/stack/nova/nova/db/sqlalchemy/migrate_repo/versions/233_add_stats_in_compute_nodes.py... __init__ /usr/local/lib/python2.7/dist-packages/migrate/versioning/script/base.py:27
2014-12-12 16:31:50.500 16955 DEBUG migrate.versioning.script.base [-] Script /opt/stack/nova/nova/db/sqlalchemy/migrate_repo/versions/233_add_stats_in_compute_nodes.py loaded successfully __init__ /usr/local/lib/python2.7/dist-packages/migrate/versioning/script/base.py:30
2014-12-12 16:31:50.500 16955 DEBUG migrate.versioning.script.base [-] Loading script /opt/stack/nova/nova/db/sqlalchemy/migrate_repo/versions/234_add_expire_reservations_index.py... __init__ /usr/local/lib/python2.7/dist-packages/migrate/versioning/script/base.py:27
2014-12-12 16:31:50.500 16955 DEBUG migrate.versioning.script.base [-] Script /opt/stack/nova/nova/db/sqlalchemy/migrate_repo/versions/234_add_expire_reservations_index.py loaded successfully __init__ /usr/local/lib/python2.7/dist-packages/migrate/versioning/script/base.py:30
2014-12-12 16:31:50.501 16955 DEBUG migrate.versioning.script.base [-] Loading script /opt/stack/nova/nova/db/sqlalchemy/migrate_repo/versions/235_placeholder.py... __init__ /usr/local/lib/python2.7/dist-packages/migrate/versioning/script/base.py:27
2014-12-12 16:31:50.501 16955 DEBUG migrate.versioning.script.base [-] Script /opt/stack/nova/nova/db/sqlalchemy/migrate_repo/versions/235_placeholder.py loaded successfully __init__ /usr/local/lib/python2.7/dist-packages/migrate/versioning/script/base.py:30
2014-12-12 16:31:50.501 16955 DEBUG migrate.versioning.script.base [-] Loading script /opt/stack/nova/nova/db/sqlalchemy/migrate_repo/versions/236_placeholder.py... __init__ /usr/local/lib/python2.7/dist-packages/migrate/versioning/script/base.py:27
2014-12-12 16:31:50.501 16955 DEBUG migrate.versioning.script.base [-] Script /opt/stack/nova/nova/db/sqlalchemy/migrate_repo/versions/236_placeholder.py loaded successfully __init__ /usr/local/lib/python2.7/dist-packages/migrate/versioning/script/base.py:30
2014-12-12 16:31:50.501 16955 DEBUG migrate.versioning.script.base [-] Loading script /opt/stack/nova/nova/db/sqlalchemy/migrate_repo/versions/237_placeholder.py... __init__ /usr/local/lib/python2.7/dist-packages/migrate/versioning/script/base.py:27
2014-12-12 16:31:50.501 16955 DEBUG migrate.versioning.script.base [-] Script /opt/stack/nova/nova/db/sqlalchemy/migrate_repo/versions/237_placeholder.py loaded successfully __init__ /usr/local/lib/python2.7/dist-packages/migrate/versioning/script/base.py:30
2014-12-12 16:31:50.501 16955 DEBUG migrate.versioning.script.base [-] Loading script /opt/stack/nova/nova/db/sqlalchemy/migrate_repo/versions/238_placeholder.py... __init__ /usr/local/lib/python2.7/dist-packages/migrate/versioning/script/base.py:27
2014-12-12 16:31:50.501 16955 DEBUG migrate.versioning.script.base [-] Script /opt/stack/nova/nova/db/sqlalchemy/migrate_repo/versions/238_placeholder.py loaded successfully __init__ /usr/local/lib/python2.7/dist-packages/migrate/versioning/script/base.py:30
2014-12-12 16:31:50.501 16955 DEBUG migrate.versioning.script.base [-] Loading script /opt/stack/nova/nova/db/sqlalchemy/migrate_repo/versions/239_placeholder.py... __init__ /usr/local/lib/python2.7/dist-packages/migrate/versioning/script/base.py:27
2014-12-12 16:31:50.501 16955 DEBUG migrate.versioning.script.base [-] Script /opt/stack/nova/nova/db/sqlalchemy/migrate_repo/versions/239_placeholder.py loaded successfully __init__ /usr/local/lib/python2.7/dist-packages/migrate/versioning/script/base.py:30
2014-12-12 16:31:50.501 16955 DEBUG migrate.versioning.script.base [-] Loading script /opt/stack/nova/nova/db/sqlalchemy/migrate_repo/versions/240_placeholder.py... __init__ /usr/local/lib/python2.7/dist-packages/migrate/versioning/script/base.py:27
2014-12-12 16:31:50.501 16955 DEBUG migrate.versioning.script.base [-] Script /opt/stack/nova/nova/db/sqlalchemy/migrate_repo/versions/240_placeholder.py loaded successfully __init__ /usr/local/lib/python2.7/dist-packages/migrate/versioning/script/base.py:30
2014-12-12 16:31:50.502 16955 DEBUG migrate.versioning.script.base [-] Loading script /opt/stack/nova/nova/db/sqlalchemy/migrate_repo/versions/241_placeholder.py... __init__ /usr/local/lib/python2.7/dist-packages/migrate/versioning/script/base.py:27
2014-12-12 16:31:50.502 16955 DEBUG migrate.versioning.script.base [-] Script /opt/stack/nova/nova/db/sqlalchemy/migrate_repo/versions/241_placeholder.py loaded successfully __init__ /usr/local/lib/python2.7/dist-packages/migrate/versioning/script/base.py:30
2014-12-12 16:31:50.502 16955 DEBUG migrate.versioning.script.base [-] Loading script /opt/stack/nova/nova/db/sqlalchemy/migrate_repo/versions/242_placeholder.py... __init__ /usr/local/lib/python2.7/dist-packages/migrate/versioning/script/base.py:27
2014-12-12 16:31:50.502 16955 DEBUG migrate.versioning.script.base [-] Script /opt/stack/nova/nova/db/sqlalchemy/migrate_repo/versions/242_placeholder.py loaded successfully __init__ /usr/local/lib/python2.7/dist-packages/migrate/versioning/script/base.py:30
2014-12-12 16:31:50.502 16955 DEBUG migrate.versioning.script.base [-] Loading script /opt/stack/nova/nova/db/sqlalchemy/migrate_repo/versions/243_placeholder.py... __init__ /usr/local/lib/python2.7/dist-packages/migrate/versioning/script/base.py:27
2014-12-12 16:31:50.502 16955 DEBUG migrate.versioning.script.base [-] Script /opt/stack/nova/nova/db/sqlalchemy/migrate_repo/versions/243_placeholder.py loaded successfully __init__ /usr/local/lib/python2.7/dist-packages/migrate/versioning/script/base.py:30
2014-12-12 16:31:50.502 16955 DEBUG migrate.versioning.script.base [-] Loading script /opt/stack/nova/nova/db/sqlalchemy/migrate_repo/versions/244_increase_user_id_length_volume_usage_cache.py... __init__ /usr/local/lib/python2.7/dist-packages/migrate/versioning/script/base.py:27
2014-12-12 16:31:50.502 16955 DEBUG migrate.versioning.script.base [-] Script /opt/stack/nova/nova/db/sqlalchemy/migrate_repo/versions/244_increase_user_id_length_volume_usage_cache.py loaded successfully __init__ /usr/local/lib/python2.7/dist-packages/migrate/versioning/script/base.py:30
2014-12-12 16:31:50.502 16955 DEBUG migrate.versioning.script.base [-] Loading script /opt/stack/nova/nova/db/sqlalchemy/migrate_repo/versions/245_add_mtu_and_dhcp_server.py... __init__ /usr/local/lib/python2.7/dist-packages/migrate/versioning/script/base.py:27
2014-12-12 16:31:50.502 16955 DEBUG migrate.versioning.script.base [-] Script /opt/stack/nova/nova/db/sqlalchemy/migrate_repo/versions/245_add_mtu_and_dhcp_server.py loaded successfully __init__ /usr/local/lib/python2.7/dist-packages/migrate/versioning/script/base.py:30
2014-12-12 16:31:50.502 16955 DEBUG migrate.versioning.script.base [-] Loading script /opt/stack/nova/nova/db/sqlalchemy/migrate_repo/versions/246_add_compute_node_id_fk.py... __init__ /usr/local/lib/python2.7/dist-packages/migrate/versioning/script/base.py:27
2014-12-12 16:31:50.503 16955 DEBUG migrate.versioning.script.base [-] Script /opt/stack/nova/nova/db/sqlalchemy/migrate_repo/versions/246_add_compute_node_id_fk.py loaded successfully __init__ /usr/local/lib/python2.7/dist-packages/migrate/versioning/script/base.py:30
2014-12-12 16:31:50.503 16955 DEBUG migrate.versioning.script.base [-] Loading script /opt/stack/nova/nova/db/sqlalchemy/migrate_repo/versions/246_sqlite_downgrade.sql... __init__ /usr/local/lib/python2.7/dist-packages/migrate/versioning/script/base.py:27
2014-12-12 16:31:50.503 16955 DEBUG migrate.versioning.script.base [-] Script /opt/stack/nova/nova/db/sqlalchemy/migrate_repo/versions/246_sqlite_downgrade.sql loaded successfully __init__ /usr/local/lib/python2.7/dist-packages/migrate/versioning/script/base.py:30
2014-12-12 16:31:50.503 16955 DEBUG migrate.versioning.script.base [-] Loading script /opt/stack/nova/nova/db/sqlalchemy/migrate_repo/versions/246_sqlite_upgrade.sql... __init__ /usr/local/lib/python2.7/dist-packages/migrate/versioning/script/base.py:27
2014-12-12 16:31:50.503 16955 DEBUG migrate.versioning.script.base [-] Script /opt/stack/nova/nova/db/sqlalchemy/migrate_repo/versions/246_sqlite_upgrade.sql loaded successfully __init__ /usr/local/lib/python2.7/dist-packages/migrate/versioning/script/base.py:30
2014-12-12 16:31:50.503 16955 DEBUG migrate.versioning.script.base [-] Loading script /opt/stack/nova/nova/db/sqlalchemy/migrate_repo/versions/247_nullable_mismatch.py... __init__ /usr/local/lib/python2.7/dist-packages/migrate/versioning/script/base.py:27
2014-12-12 16:31:50.503 16955 DEBUG migrate.versioning.script.base [-] Script /opt/stack/nova/nova/db/sqlalchemy/migrate_repo/versions/247_nullable_mismatch.py loaded successfully __init__ /usr/local/lib/python2.7/dist-packages/migrate/versioning/script/base.py:30
2014-12-12 16:31:50.503 16955 DEBUG migrate.versioning.script.base [-] Loading script /opt/stack/nova/nova/db/sqlalchemy/migrate_repo/versions/248_add_expire_reservations_index.py... __init__ /usr/local/lib/python2.7/dist-packages/migrate/versioning/script/base.py:27
2014-12-12 16:31:50.503 16955 DEBUG migrate.versioning.script.base [-] Script /opt/stack/nova/nova/db/sqlalchemy/migrate_repo/versions/248_add_expire_reservations_index.py loaded successfully __init__ /usr/local/lib/python2.7/dist-packages/migrate/versioning/script/base.py:30
2014-12-12 16:31:50.503 16955 DEBUG migrate.versioning.script.base [-] Loading script /opt/stack/nova/nova/db/sqlalchemy/migrate_repo/versions/249_remove_duplicate_index.py... __init__ /usr/local/lib/python2.7/dist-packages/migrate/versioning/script/base.py:27
2014-12-12 16:31:50.503 16955 DEBUG migrate.versioning.script.base [-] Script /opt/stack/nova/nova/db/sqlalchemy/migrate_repo/versions/249_remove_duplicate_index.py loaded successfully __init__ /usr/local/lib/python2.7/dist-packages/migrate/versioning/script/base.py:30
2014-12-12 16:31:50.503 16955 DEBUG migrate.versioning.script.base [-] Loading script /opt/stack/nova/nova/db/sqlalchemy/migrate_repo/versions/250_remove_instance_groups_metadata.py... __init__ /usr/local/lib/python2.7/dist-packages/migrate/versioning/script/base.py:27
2014-12-12 16:31:50.504 16955 DEBUG migrate.versioning.script.base [-] Script /opt/stack/nova/nova/db/sqlalchemy/migrate_repo/versions/250_remove_instance_groups_metadata.py loaded successfully __init__ /usr/local/lib/python2.7/dist-packages/migrate/versioning/script/base.py:30
2014-12-12 16:31:50.504 16955 DEBUG migrate.versioning.script.base [-] Loading script /opt/stack/nova/nova/db/sqlalchemy/migrate_repo/versions/251_add_numa_topology_to_comput_nodes.py... __init__ /usr/local/lib/python2.7/dist-packages/migrate/versioning/script/base.py:27
2014-12-12 16:31:50.504 16955 DEBUG migrate.versioning.script.base [-] Script /opt/stack/nova/nova/db/sqlalchemy/migrate_repo/versions/251_add_numa_topology_to_comput_nodes.py loaded successfully __init__ /usr/local/lib/python2.7/dist-packages/migrate/versioning/script/base.py:30
2014-12-12 16:31:50.504 16955 DEBUG migrate.versioning.script.base [-] Loading script /opt/stack/nova/nova/db/sqlalchemy/migrate_repo/versions/252_add_instance_extra_table.py... __init__ /usr/local/lib/python2.7/dist-packages/migrate/versioning/script/base.py:27
2014-12-12 16:31:50.504 16955 DEBUG migrate.versioning.script.base [-] Script /opt/stack/nova/nova/db/sqlalchemy/migrate_repo/versions/252_add_instance_extra_table.py loaded successfully __init__ /usr/local/lib/python2.7/dist-packages/migrate/versioning/script/base.py:30
2014-12-12 16:31:50.504 16955 DEBUG migrate.versioning.script.base [-] Loading script /opt/stack/nova/nova/db/sqlalchemy/migrate_repo/versions/253_add_pci_requests_to_instance_extra_table.py... __init__ /usr/local/lib/python2.7/dist-packages/migrate/versioning/script/base.py:27
2014-12-12 16:31:50.504 16955 DEBUG migrate.versioning.script.base [-] Script /opt/stack/nova/nova/db/sqlalchemy/migrate_repo/versions/253_add_pci_requests_to_instance_extra_table.py loaded successfully __init__ /usr/local/lib/python2.7/dist-packages/migrate/versioning/script/base.py:30
2014-12-12 16:31:50.504 16955 DEBUG migrate.versioning.script.base [-] Loading script /opt/stack/nova/nova/db/sqlalchemy/migrate_repo/versions/254_add_request_id_in_pci_devices.py... __init__ /usr/local/lib/python2.7/dist-packages/migrate/versioning/script/base.py:27
2014-12-12 16:31:50.504 16955 DEBUG migrate.versioning.script.base [-] Script /opt/stack/nova/nova/db/sqlalchemy/migrate_repo/versions/254_add_request_id_in_pci_devices.py loaded successfully __init__ /usr/local/lib/python2.7/dist-packages/migrate/versioning/script/base.py:30
2014-12-12 16:31:50.504 16955 DEBUG migrate.versioning.repository [-] Repository /opt/stack/nova/nova/db/sqlalchemy/migrate_repo loaded successfully __init__ /usr/local/lib/python2.7/dist-packages/migrate/versioning/repository.py:82
2014-12-12 16:31:50.504 16955 DEBUG migrate.versioning.repository [-] Config: OrderedDict([('db_settings', OrderedDict([('__name__', 'db_settings'), ('repository_id', 'nova'), ('version_table', 'migrate_version'), ('required_dbs', '[]')]))]) __init__ /usr/local/lib/python2.7/dist-packages/migrate/versioning/repository.py:83
2014-12-12 16:31:50.518 16955 DEBUG oslo.db.sqlalchemy.session [-] MySQL server mode set to STRICT_TRANS_TABLES,STRICT_ALL_TABLES,NO_ZERO_IN_DATE,NO_ZERO_DATE,ERROR_FOR_DIVISION_BY_ZERO,TRADITIONAL,NO_AUTO_CREATE_USER,NO_ENGINE_SUBSTITUTION _init_events /usr/local/lib/python2.7/dist-packages/oslo/db/sqlalchemy/session.py:474
2014-12-12 16:31:50.581 16955 INFO migrate.versioning.api [-] 215 -> 216... 
2014-12-12 16:31:58.452 16955 INFO migrate.versioning.api [-] done
2014-12-12 16:31:58.452 16955 INFO migrate.versioning.api [-] 216 -> 217... 
2014-12-12 16:31:58.464 16955 INFO migrate.versioning.api [-] done
2014-12-12 16:31:58.464 16955 INFO migrate.versioning.api [-] 217 -> 218... 
2014-12-12 16:31:58.481 16955 INFO migrate.versioning.api [-] done
2014-12-12 16:31:58.481 16955 INFO migrate.versioning.api [-] 218 -> 219... 
2014-12-12 16:31:58.497 16955 INFO migrate.versioning.api [-] done
2014-12-12 16:31:58.497 16955 INFO migrate.versioning.api [-] 219 -> 220... 
2014-12-12 16:31:58.511 16955 INFO migrate.versioning.api [-] done
2014-12-12 16:31:58.511 16955 INFO migrate.versioning.api [-] 220 -> 221... 
2014-12-12 16:31:58.526 16955 INFO migrate.versioning.api [-] done
2014-12-12 16:31:58.526 16955 INFO migrate.versioning.api [-] 221 -> 222... 
2014-12-12 16:31:58.546 16955 INFO migrate.versioning.api [-] done
2014-12-12 16:31:58.546 16955 INFO migrate.versioning.api [-] 222 -> 223... 
2014-12-12 16:31:58.561 16955 INFO migrate.versioning.api [-] done
2014-12-12 16:31:58.561 16955 INFO migrate.versioning.api [-] 223 -> 224... 
2014-12-12 16:31:58.573 16955 INFO migrate.versioning.api [-] done
2014-12-12 16:31:58.573 16955 INFO migrate.versioning.api [-] 224 -> 225... 
2014-12-12 16:31:58.587 16955 INFO migrate.versioning.api [-] done
2014-12-12 16:31:58.587 16955 INFO migrate.versioning.api [-] 225 -> 226... 
2014-12-12 16:31:58.610 16955 INFO migrate.versioning.api [-] done
2014-12-12 16:31:58.610 16955 INFO migrate.versioning.api [-] 226 -> 227... 
2014-12-12 16:31:58.631 16955 INFO migrate.versioning.api [-] done
2014-12-12 16:31:58.631 16955 INFO migrate.versioning.api [-] 227 -> 228... 
2014-12-12 16:31:58.765 16955 INFO migrate.versioning.api [-] done
2014-12-12 16:31:58.766 16955 INFO migrate.versioning.api [-] 228 -> 229... 
2014-12-12 16:31:58.892 16955 INFO migrate.versioning.api [-] done
2014-12-12 16:31:58.892 16955 INFO migrate.versioning.api [-] 229 -> 230... 
2014-12-12 16:31:59.135 16955 INFO migrate.versioning.api [-] done
2014-12-12 16:31:59.135 16955 INFO migrate.versioning.api [-] 230 -> 231... 
2014-12-12 16:31:59.265 16955 INFO migrate.versioning.api [-] done
2014-12-12 16:31:59.265 16955 INFO migrate.versioning.api [-] 231 -> 232... 
2014-12-12 16:31:59.536 16955 INFO migrate.versioning.api [-] done
2014-12-12 16:31:59.537 16955 INFO migrate.versioning.api [-] 232 -> 233... 
2014-12-12 16:31:59.700 16955 INFO migrate.versioning.api [-] done
2014-12-12 16:31:59.701 16955 INFO migrate.versioning.api [-] 233 -> 234... 
2014-12-12 16:31:59.767 16955 INFO migrate.versioning.api [-] done
2014-12-12 16:31:59.767 16955 INFO migrate.versioning.api [-] 234 -> 235... 
2014-12-12 16:31:59.784 16955 INFO migrate.versioning.api [-] done
2014-12-12 16:31:59.784 16955 INFO migrate.versioning.api [-] 235 -> 236... 
2014-12-12 16:31:59.800 16955 INFO migrate.versioning.api [-] done
2014-12-12 16:31:59.800 16955 INFO migrate.versioning.api [-] 236 -> 237... 
2014-12-12 16:31:59.813 16955 INFO migrate.versioning.api [-] done
2014-12-12 16:31:59.814 16955 INFO migrate.versioning.api [-] 237 -> 238... 
2014-12-12 16:31:59.828 16955 INFO migrate.versioning.api [-] done
2014-12-12 16:31:59.829 16955 INFO migrate.versioning.api [-] 238 -> 239... 
2014-12-12 16:31:59.848 16955 INFO migrate.versioning.api [-] done
2014-12-12 16:31:59.848 16955 INFO migrate.versioning.api [-] 239 -> 240... 
2014-12-12 16:31:59.864 16955 INFO migrate.versioning.api [-] done
2014-12-12 16:31:59.864 16955 INFO migrate.versioning.api [-] 240 -> 241... 
2014-12-12 16:31:59.878 16955 INFO migrate.versioning.api [-] done
2014-12-12 16:31:59.878 16955 INFO migrate.versioning.api [-] 241 -> 242... 
2014-12-12 16:31:59.891 16955 INFO migrate.versioning.api [-] done
2014-12-12 16:31:59.892 16955 INFO migrate.versioning.api [-] 242 -> 243... 
2014-12-12 16:31:59.909 16955 INFO migrate.versioning.api [-] done
2014-12-12 16:31:59.909 16955 INFO migrate.versioning.api [-] 243 -> 244... 
2014-12-12 16:31:59.987 16955 INFO migrate.versioning.api [-] done
2014-12-12 16:31:59.987 16955 INFO migrate.versioning.api [-] 244 -> 245... 
2014-12-12 16:32:00.442 16955 INFO migrate.versioning.api [-] done
2014-12-12 16:32:00.443 16955 INFO migrate.versioning.api [-] 245 -> 246... 
2014-12-12 16:32:00.521 16955 INFO migrate.versioning.api [-] done
2014-12-12 16:32:00.522 16955 INFO migrate.versioning.api [-] 246 -> 247... 
2014-12-12 16:32:00.830 16955 INFO migrate.versioning.api [-] done
2014-12-12 16:32:00.830 16955 INFO migrate.versioning.api [-] 247 -> 248... 
2014-12-12 16:32:00.836 16955 INFO 248_add_expire_reservations_index [-] Skipped adding reservations_deleted_expire_idx because an equivalent index already exists.
2014-12-12 16:32:00.847 16955 INFO migrate.versioning.api [-] done
2014-12-12 16:32:00.848 16955 INFO migrate.versioning.api [-] 248 -> 249... 
2014-12-12 16:32:00.902 16955 INFO migrate.versioning.api [-] done
2014-12-12 16:32:00.902 16955 INFO migrate.versioning.api [-] 249 -> 250... 
2014-12-12 16:32:00.955 16955 INFO migrate.versioning.api [-] done
2014-12-12 16:32:00.955 16955 INFO migrate.versioning.api [-] 250 -> 251... 
2014-12-12 16:32:01.080 16955 INFO migrate.versioning.api [-] done
2014-12-12 16:32:01.081 16955 INFO migrate.versioning.api [-] 251 -> 252... 
2014-12-12 16:32:01.280 16955 INFO migrate.versioning.api [-] done
2014-12-12 16:32:01.280 16955 INFO migrate.versioning.api [-] 252 -> 253... 
2014-12-12 16:32:01.422 16955 INFO migrate.versioning.api [-] done
2014-12-12 16:32:01.423 16955 INFO migrate.versioning.api [-] 253 -> 254... 
2014-12-12 16:32:01.557 16955 INFO migrate.versioning.api [-] done
+ is_service_enabled n-cell
++ set +o
++ grep xtrace
+ local 'xtrace=set -o xtrace'
+ set +o xtrace
+ return 1
+ is_baremetal
+ [[ g-api,g-reg,key,n-api,n-crt,n-obj,n-cond,n-sch,n-xvnc,n-cauth,c-sch,c-api,c-vol,h-eng,h-api,h-api-cfn,h-api-cw,rabbit,tempest,mysql,neutron,q-svc,q-agt,q-dhcp,q-l3,q-meta,q-lbaas,q-fwaas,q-metering,q-vpn,c-bak,s-proxy,s-object,s-container,s-account,heat,ceilometer-acentral,ceilometer-collector,ceilometer-api =~ baremetal ]]
+ return 1
+ create_nova_cache_dir
+ sudo mkdir -p /var/cache/nova
+ sudo chown cloudbase /var/cache/nova
+ rm -f '/var/cache/nova/*'
+ create_nova_keys_dir
+ sudo mkdir -p /opt/stack/data/nova/keys
+ sudo chown -R cloudbase /opt/stack/data/nova
+ is_service_enabled neutron
++ set +o
++ grep xtrace
+ local 'xtrace=set -o xtrace'
+ set +o xtrace
+ return 0
+ create_nova_conf_neutron
+ iniset /etc/nova/nova.conf DEFAULT network_api_class nova.network.neutronv2.api.API
++ set +o
++ grep xtrace
+ local 'xtrace=set -o xtrace'
+ set +o xtrace
+ iniset /etc/nova/nova.conf neutron admin_username neutron
++ set +o
++ grep xtrace
+ local 'xtrace=set -o xtrace'
+ set +o xtrace
+ iniset /etc/nova/nova.conf neutron admin_password Passw0rd
++ set +o
++ grep xtrace
+ local 'xtrace=set -o xtrace'
+ set +o xtrace
+ iniset /etc/nova/nova.conf neutron admin_auth_url http://10.14.0.26:35357/v2.0
++ set +o
++ grep xtrace
+ local 'xtrace=set -o xtrace'
+ set +o xtrace
+ iniset /etc/nova/nova.conf neutron auth_strategy keystone
++ set +o
++ grep xtrace
+ local 'xtrace=set -o xtrace'
+ set +o xtrace
+ iniset /etc/nova/nova.conf neutron admin_tenant_name service
++ set +o
++ grep xtrace
+ local 'xtrace=set -o xtrace'
+ set +o xtrace
+ iniset /etc/nova/nova.conf neutron region_name RegionOne
++ set +o
++ grep xtrace
+ local 'xtrace=set -o xtrace'
+ set +o xtrace
+ iniset /etc/nova/nova.conf neutron url http://10.14.0.26:9696
++ set +o
++ grep xtrace
+ local 'xtrace=set -o xtrace'
+ set +o xtrace
+ [[ True == \T\r\u\e ]]
+ LIBVIRT_FIREWALL_DRIVER=nova.virt.firewall.NoopFirewallDriver
+ iniset /etc/nova/nova.conf DEFAULT firewall_driver nova.virt.firewall.NoopFirewallDriver
++ set +o
++ grep xtrace
+ local 'xtrace=set -o xtrace'
+ set +o xtrace
+ iniset /etc/nova/nova.conf DEFAULT security_group_api neutron
++ set +o
++ grep xtrace
+ local 'xtrace=set -o xtrace'
+ set +o xtrace
+ neutron_plugin_create_nova_conf
+ _neutron_ovs_base_configure_nova_vif_driver
+ :
+ '[' libvirt == xenserver ']'
+ iniset /etc/nova/nova.conf libvirt vif_driver nova.virt.libvirt.vif.LibvirtGenericVIFDriver
++ set +o
++ grep xtrace
+ local 'xtrace=set -o xtrace'
+ set +o xtrace
+ iniset /etc/nova/nova.conf DEFAULT linuxnet_interface_driver ''
++ set +o
++ grep xtrace
+ local 'xtrace=set -o xtrace'
+ set +o xtrace
+ is_service_enabled q-meta
++ set +o
++ grep xtrace
+ local 'xtrace=set -o xtrace'
+ set +o xtrace
+ return 0
+ iniset /etc/nova/nova.conf neutron service_metadata_proxy True
++ set +o
++ grep xtrace
+ local 'xtrace=set -o xtrace'
+ set +o xtrace
+ iniset /etc/nova/nova.conf DEFAULT vif_plugging_is_fatal True
++ set +o
++ grep xtrace
+ local 'xtrace=set -o xtrace'
+ set +o xtrace
+ iniset /etc/nova/nova.conf DEFAULT vif_plugging_timeout 300
++ set +o
++ grep xtrace
+ local 'xtrace=set -o xtrace'
+ set +o xtrace
+ init_nova_cells
+ is_service_enabled n-cell
++ set +o
++ grep xtrace
+ local 'xtrace=set -o xtrace'
+ set +o xtrace
+ return 1
+ is_service_enabled nova
++ set +o
++ grep xtrace
+ local 'xtrace=set -o xtrace'
+ set +o xtrace
+ return 0
+ is_baremetal
+ [[ g-api,g-reg,key,n-api,n-crt,n-obj,n-cond,n-sch,n-xvnc,n-cauth,c-sch,c-api,c-vol,h-eng,h-api,h-api-cfn,h-api-cw,rabbit,tempest,mysql,neutron,q-svc,q-agt,q-dhcp,q-l3,q-meta,q-lbaas,q-fwaas,q-metering,q-vpn,c-bak,s-proxy,s-object,s-container,s-account,heat,ceilometer-acentral,ceilometer-collector,ceilometer-api =~ baremetal ]]
+ return 1
+ [[ -d /home/cloudbase/devstack/extras.d ]]
+ for i in '$TOP_DIR/extras.d/*.sh'
+ [[ -r /home/cloudbase/devstack/extras.d/40-dib.sh ]]
+ source /home/cloudbase/devstack/extras.d/40-dib.sh stack post-config
++ is_service_enabled dib
+++ set +o
+++ grep xtrace
++ local 'xtrace=set -o xtrace'
++ set +o xtrace
++ return 1
+ for i in '$TOP_DIR/extras.d/*.sh'
+ [[ -r /home/cloudbase/devstack/extras.d/50-ironic.sh ]]
+ source /home/cloudbase/devstack/extras.d/50-ironic.sh stack post-config
++ is_service_enabled ir-api ir-cond
+++ set +o
+++ grep xtrace
++ local 'xtrace=set -o xtrace'
++ set +o xtrace
++ return 1
+ for i in '$TOP_DIR/extras.d/*.sh'
+ [[ -r /home/cloudbase/devstack/extras.d/60-ceph.sh ]]
+ source /home/cloudbase/devstack/extras.d/60-ceph.sh stack post-config
++ is_service_enabled ceph
+++ set +o
+++ grep xtrace
++ local 'xtrace=set -o xtrace'
++ set +o xtrace
++ return 1
+ for i in '$TOP_DIR/extras.d/*.sh'
+ [[ -r /home/cloudbase/devstack/extras.d/70-gantt.sh ]]
+ source /home/cloudbase/devstack/extras.d/70-gantt.sh stack post-config
++ is_service_enabled n-sch
+++ set +o
+++ grep xtrace
++ local 'xtrace=set -o xtrace'
++ set +o xtrace
++ return 0
++ disable_service gantt
++ local tmpsvcs=,g-api,g-reg,key,n-api,n-crt,n-obj,n-cond,n-sch,n-xvnc,n-cauth,c-sch,c-api,c-vol,h-eng,h-api,h-api-cfn,h-api-cw,rabbit,tempest,mysql,neutron,q-svc,q-agt,q-dhcp,q-l3,q-meta,q-lbaas,q-fwaas,q-metering,q-vpn,c-bak,s-proxy,s-object,s-container,s-account,heat,ceilometer-acentral,ceilometer-collector,ceilometer-api,
++ local service
++ for service in '$@'
++ is_service_enabled gantt
+++ set +o
+++ grep xtrace
++ local 'xtrace=set -o xtrace'
++ set +o xtrace
++ return 1
+++ _cleanup_service_list ,g-api,g-reg,key,n-api,n-crt,n-obj,n-cond,n-sch,n-xvnc,n-cauth,c-sch,c-api,c-vol,h-eng,h-api,h-api-cfn,h-api-cw,rabbit,tempest,mysql,neutron,q-svc,q-agt,q-dhcp,q-l3,q-meta,q-lbaas,q-fwaas,q-metering,q-vpn,c-bak,s-proxy,s-object,s-container,s-account,heat,ceilometer-acentral,ceilometer-collector,ceilometer-api,
+++ echo ,g-api,g-reg,key,n-api,n-crt,n-obj,n-cond,n-sch,n-xvnc,n-cauth,c-sch,c-api,c-vol,h-eng,h-api,h-api-cfn,h-api-cw,rabbit,tempest,mysql,neutron,q-svc,q-agt,q-dhcp,q-l3,q-meta,q-lbaas,q-fwaas,q-metering,q-vpn,c-bak,s-proxy,s-object,s-container,s-account,heat,ceilometer-acentral,ceilometer-collector,ceilometer-api,
+++ sed -e '
        s/,,/,/g;
        s/^,//;
        s/,$//
    '
++ ENABLED_SERVICES=g-api,g-reg,key,n-api,n-crt,n-obj,n-cond,n-sch,n-xvnc,n-cauth,c-sch,c-api,c-vol,h-eng,h-api,h-api-cfn,h-api-cw,rabbit,tempest,mysql,neutron,q-svc,q-agt,q-dhcp,q-l3,q-meta,q-lbaas,q-fwaas,q-metering,q-vpn,c-bak,s-proxy,s-object,s-container,s-account,heat,ceilometer-acentral,ceilometer-collector,ceilometer-api
++ is_service_enabled gantt
+++ set +o
+++ grep xtrace
++ local 'xtrace=set -o xtrace'
++ set +o xtrace
++ return 1
+ for i in '$TOP_DIR/extras.d/*.sh'
+ [[ -r /home/cloudbase/devstack/extras.d/70-sahara.sh ]]
+ source /home/cloudbase/devstack/extras.d/70-sahara.sh stack post-config
++ is_service_enabled sahara
+++ set +o
+++ grep xtrace
++ local 'xtrace=set -o xtrace'
++ set +o xtrace
++ return 1
+ for i in '$TOP_DIR/extras.d/*.sh'
+ [[ -r /home/cloudbase/devstack/extras.d/70-trove.sh ]]
+ source /home/cloudbase/devstack/extras.d/70-trove.sh stack post-config
++ is_service_enabled trove
+++ set +o
+++ grep xtrace
++ local 'xtrace=set -o xtrace'
++ set +o xtrace
++ return 1
+ for i in '$TOP_DIR/extras.d/*.sh'
+ [[ -r /home/cloudbase/devstack/extras.d/70-zaqar.sh ]]
+ source /home/cloudbase/devstack/extras.d/70-zaqar.sh stack post-config
++ is_service_enabled zaqar-server
+++ set +o
+++ grep xtrace
++ local 'xtrace=set -o xtrace'
++ set +o xtrace
++ return 1
+ for i in '$TOP_DIR/extras.d/*.sh'
+ [[ -r /home/cloudbase/devstack/extras.d/80-opendaylight.sh ]]
+ source /home/cloudbase/devstack/extras.d/80-opendaylight.sh stack post-config
++ is_service_enabled odl-server odl-compute
+++ set +o
+++ grep xtrace
++ local 'xtrace=set -o xtrace'
++ set +o xtrace
++ return 1
++ is_service_enabled odl-server
+++ set +o
+++ grep xtrace
++ local 'xtrace=set -o xtrace'
++ set +o xtrace
++ return 1
++ is_service_enabled odl-compute
+++ set +o
+++ grep xtrace
++ local 'xtrace=set -o xtrace'
++ set +o xtrace
++ return 1
+ for i in '$TOP_DIR/extras.d/*.sh'
+ [[ -r /home/cloudbase/devstack/extras.d/80-tempest.sh ]]
+ source /home/cloudbase/devstack/extras.d/80-tempest.sh stack post-config
++ is_service_enabled tempest
+++ set +o
+++ grep xtrace
++ local 'xtrace=set -o xtrace'
++ set +o xtrace
++ return 0
++ [[ stack == \s\o\u\r\c\e ]]
++ [[ stack == \s\t\a\c\k ]]
++ [[ post-config == \i\n\s\t\a\l\l ]]
++ [[ stack == \s\t\a\c\k ]]
++ [[ post-config == \p\o\s\t\-\c\o\n\f\i\g ]]
++ create_tempest_accounts
++ is_service_enabled tempest
+++ set +o
+++ grep xtrace
++ local 'xtrace=set -o xtrace'
++ set +o xtrace
++ return 0
++ get_or_create_project alt_demo
+++ openstack project show alt_demo -f value -c id
+++ openstack project create alt_demo -f value -c id
++ local project_id=45ab40d7fb4d4e5494de877ba086c11c
++ echo 45ab40d7fb4d4e5494de877ba086c11c
++ get_or_create_user alt_demo Passw0rd alt_demo alt_demo@example.com
++ [[ ! -z alt_demo@example.com ]]
++ local email=--email=alt_demo@example.com
+++ openstack user show alt_demo -f value -c id
+++ openstack user create alt_demo --password Passw0rd --project alt_demo --email=alt_demo@example.com -f value -c id
++ local user_id=a3623f9f40df4925aa0fc5bd5c4590a2
++ echo a3623f9f40df4925aa0fc5bd5c4590a2
++ get_or_add_user_role Member alt_demo alt_demo
+++ openstack user role list alt_demo --project alt_demo --column ID --column Name
+++ grep ' Member '
+++ get_field 1
+++ local data field
+++ read data
++ local user_role_id=
++ [[ -z '' ]]
+++ openstack role add Member --user alt_demo --project alt_demo
+++ grep ' id '
+++ get_field 2
+++ local data field
+++ read data
+++ '[' 2 -lt 0 ']'
+++ field='$3'
+++ awk '-F[ \t]*\\|[ \t]*' '{print $3}'
+++ echo '| id    | cf9bfac7a7b64c35b930c4c6f98a3673 |'
+++ read data
++ user_role_id=cf9bfac7a7b64c35b930c4c6f98a3673
++ echo cf9bfac7a7b64c35b930c4c6f98a3673
++ [[ stack == \u\n\s\t\a\c\k ]]
++ [[ stack == \c\l\e\a\n ]]
+ merge_config_group /home/cloudbase/devstack/local.conf post-config
+ local localfile=/home/cloudbase/devstack/local.conf
+ shift
+ local matchgroups=post-config
+ [[ -r /home/cloudbase/devstack/local.conf ]]
+ local configfile group
+ for group in '$matchgroups'
++ get_meta_section_files /home/cloudbase/devstack/local.conf post-config
++ local file=/home/cloudbase/devstack/local.conf
++ local matchgroup=post-config
++ [[ -r /home/cloudbase/devstack/local.conf ]]
++ awk -v matchgroup=post-config '
        /^\[\[.+\|.*\]\]/ {
            gsub("[][]", "", $1);
            split($1, a, "|");
            if (a[1] == matchgroup)
                print a[2]
        }
    ' /home/cloudbase/devstack/local.conf
+ for configfile in '$(get_meta_section_files $localfile $group)'
+++ eval 'echo $NOVA_CONF'
++++ echo /etc/nova/nova.conf
++ dirname /etc/nova/nova.conf
+ [[ -d /etc/nova ]]
+ merge_config_file /home/cloudbase/devstack/local.conf post-config '$NOVA_CONF'
+ local file=/home/cloudbase/devstack/local.conf
+ local matchgroup=post-config
+ local 'configfile=$NOVA_CONF'
+ get_meta_section /home/cloudbase/devstack/local.conf post-config '$NOVA_CONF'
+ local file=/home/cloudbase/devstack/local.conf
+ local matchgroup=post-config
+ local 'configfile=$NOVA_CONF'
+ [[ -r /home/cloudbase/devstack/local.conf ]]
N {
            section = ""
            last_section = ""
            section_count = 0
        }
        /^\[.+\]/ {
            gsub("[][]", "", $1);
            section=$1
            next
        }
        /^ *\#/ {
            next
        }
        /^[^ \t]+/ {
            # get offset of first = in $0
            eq_idx = index($0, "=")
            # extract attr & value from $0
            attr = substr($0, 1, eq_idx - 1)
            value = substr($0, eq_idx + 1)
            # only need to strip trailing whitespace from attr
            sub(/[ \t]*$/, "", attr)
            # need to strip leading & trailing whitespace from value
            sub(/^[ \t]*/, "", value)
            sub(/[ \t]*$/, "", value)

            # cfg_attr_count: number of config lines per [section, attr]
            # cfg_attr: three dimensional array to keep all the config lines per [section, attr]
            # cfg_section: keep the section names in the same order as they appear in local.conf
            # cfg_sec_attr_name: keep the attr names in the same order as they appear in local.conf
            if (! (section, attr) in cfg_attr_count) {
                if (section != last_section) {
                    cfg_section[section_count++] = section
                    last_section = section
                }
                attr_count = cfg_sec_attr_count[section_count - 1]++
                cfg_sec_attr_name[section_count - 1, attr_count] = attr

                cfg_attr[section, attr, 0] = value
                cfg_attr_count[section, attr] = 1
            } else {
                lno = cfg_attr_count[section, attr]++
                cfg_attr[section, attr, lno] = value
            }
        }
        END {
            # Process each section in order
            for (sno = 0; sno < section_count; sno++) {
                section = cfg_section[sno]
                # The ini routines simply append a config item immediately
                # after the section header. To keep the same order as defined
                # in local.conf, invoke the ini routines in the reverse order
+ [[ -z $NOVA_CONF ]]
ttr_no = cfg_sec_attr_count[sno] - 1; attr_no >=0; attr_no--) {
                    attr = cfg_sec_attr_name[sno, attr_no]
                    if (cfg_attr_count[section, attr] == 1)
                        print "iniset " configfile " " section " " attr " \"" cfg_attr[section, attr, 0] "\""
                    else {
                        # For multiline, invoke the ini routines in the reverse order
                        count = cfg_attr_count[section, attr]
                        print "iniset " configfile " " section " " attr " \"" cfg_attr[section, attr, count - 1] "\""
                        for (l = count -2; l >= 0; l--)
                            print "iniadd_literal " configfile " " section " " attr " \"" cfg_attr[section, attr, l] "\""
                    }
    ' /home/cloudb            }
        }
    '
+ read a
+ eval 'iniset $NOVA_CONF DEFAULT allow_resize_to_same_host "True"'
++ iniset /etc/nova/nova.conf DEFAULT allow_resize_to_same_host True
+++ set +o
+++ grep xtrace
++ local 'xtrace=set -o xtrace'
++ set +o xtrace
+ read a
+ for configfile in '$(get_meta_section_files $localfile $group)'
+++ eval 'echo $NEUTRON_CONF'
++++ echo /etc/neutron/neutron.conf
++ dirname /etc/neutron/neutron.conf
+ [[ -d /etc/neutron ]]
+ merge_config_file /home/cloudbase/devstack/local.conf post-config '$NEUTRON_CONF'
+ local file=/home/cloudbase/devstack/local.conf
+ local matchgroup=post-config
+ local 'configfile=$NEUTRON_CONF'
+ get_meta_section /home/cloudbase/devstack/local.conf post-config '$NEUTRON_CONF'
+ local file=/home/cloudbase/devstack/local.conf
+ local matchgroup=post-config
+ local 'configfile=$NEUTRON_CONF'
+ [[ -r /home/cloudbase/devstack/local.conf ]]
+ [[ -z $NEUTRON_CONF ]]
+ awk -v 'configfile=$NEUTRON_CONF' '
        BEGIN {
            section = ""
            last_section = ""
            section_count = 0
        }
        /^\[.+\]/ {
            gsub("[][]", "", $1);
            section=$1
            next
        }
        /^ *\#/ {
            next
        }
        /^[^ \t]+/ {
            # get offset of first = in $0
            eq_idx = index($0, "=")
            # extract attr & value from $0
            attr = substr($0, 1, eq_idx - 1)
            value = substr($0, eq_idx + 1)
            # only need to strip trailing whitespace from attr
            sub(/[ \t]*$/, "", attr)
            # need to strip leading & trailing whitespace from value
            sub(/^[ \t]*/, "", value)
            sub(/[ \t]*$/, "", value)

            # cfg_attr_count: number of config lines per [section, attr]
            # cfg_attr: three dimensional array to keep all the config lines per [section, attr]
            # cfg_section: keep the section names in the same order as they appear in local.conf
            # cfg_sec_attr_name: keep the attr names in the same order as they appear in local.conf
            if (! (section, attr) in cfg_attr_count) {
                if (section != last_section) {
                    cfg_section[section_count++] = section
                    last_section = section
                }
                attr_count = cfg_sec_attr_count[section_count - 1]++
                cfg_sec_attr_name[section_count - 1, attr_count] = attr

                cfg_attr[section, attr, 0] = value
                cfg_attr_count[section, attr] = 1
            } else {
                lno = cfg_attr_count[section, attr]++
                cfg_attr[section, attr, lno] = value
            }
        }
        END {
            # Process each section in order
            for (sno = 0; sno < section_count; sno++) {
                section = cfg_section[sno]
                # The ini routines simply append a config item immediately
                # after the section header. To keep the same order as defined
                # in local.conf, invoke the ini routines in the reverse order
                for (attr_no = cfg_sec_attr_count[sno] - 1; attr_no >=0; attr_no--) {
                    attr = cfg_sec_attr_name[sno, attr_no]
+ awk -v matchgroup=post-config -v 'configfile=$NEUTRON_CONF                        print "iniset " configfile " " section " " attr " \"" cfg_attr[section, attr, 0] "\""
    ' /home/cloudbase/devstack/local.conf
                        # For multiline, invoke the ini routines in the reverse order
                        count = cfg_attr_count[section, attr]
                        print "iniset " configfile " " section " " attr " \"" cfg_attr[section, attr, count - 1] "\""
                        for (l = count -2; l >= 0; l--)
                            print "iniadd_literal " configfile " " section " " attr " \"" cfg_attr[section, attr, l] "\""
                    }
                }
            }
        }
    '
+ read a
+ eval 'iniset $NEUTRON_CONF database max_overflow "50"'
++ iniset /etc/neutron/neutron.conf database max_overflow 50
+++ set +o
+++ grep xtrace
++ local 'xtrace=set -o xtrace'
++ set +o xtrace
+ read a
+ eval 'iniset $NEUTRON_CONF database max_pool_size "50"'
++ iniset /etc/neutron/neutron.conf database max_pool_size 50
+++ set +o
+++ grep xtrace
++ local 'xtrace=set -o xtrace'
++ set +o xtrace
+ read a
+ eval 'iniset $NEUTRON_CONF database min_pool_size "5"'
++ iniset /etc/neutron/neutron.conf database min_pool_size 5
+++ set +o
+++ grep xtrace
++ local 'xtrace=set -o xtrace'
++ set +o xtrace
+ read a
+ is_service_enabled s-proxy
++ set +o
++ grep xtrace
+ local 'xtrace=set -o xtrace'
+ set +o xtrace
+ return 0
+ echo_summary 'Starting Swift'
+ [[ -t 3 ]]
+ echo -e Starting Swift
+ start_swift
+ restart_service memcached
+ is_ubuntu
+ [[ -z deb ]]
+ '[' deb = deb ']'
+ sudo /usr/sbin/service memcached restart
+ is_ubuntu
+ [[ -z deb ]]
+ '[' deb = deb ']'
+ sudo /etc/init.d/rsync restart
+ '[' False == True ']'
+ local todo type
+ swift-init --run-dir=/opt/stack/data/swift/run all restart
+ true
+ [[ 1 == 1 ]]
+ todo='object container account'
+ for type in proxy '${todo}'
+ swift-init --run-dir=/opt/stack/data/swift/run proxy stop
+ for type in proxy '${todo}'
+ swift-init --run-dir=/opt/stack/data/swift/run object stop
+ for type in proxy '${todo}'
+ swift-init --run-dir=/opt/stack/data/swift/run container stop
+ for type in proxy '${todo}'
+ swift-init --run-dir=/opt/stack/data/swift/run account stop
+ is_service_enabled tls-proxy
++ set +o
++ grep xtrace
+ local 'xtrace=set -o xtrace'
+ set +o xtrace
+ return 1
+ run_process s-proxy '/opt/stack/swift/bin/swift-proxy-server /etc/swift/proxy-server.conf -v'
+ local service=s-proxy
+ local 'command=/opt/stack/swift/bin/swift-proxy-server /etc/swift/proxy-server.conf -v'
+ local group=
+ is_service_enabled s-proxy
++ set +o
++ grep xtrace
+ local 'xtrace=set -o xtrace'
+ set +o xtrace
+ return 0
+ [[ True = \T\r\u\e ]]
+ screen_service s-proxy '/opt/stack/swift/bin/swift-proxy-server /etc/swift/proxy-server.conf -v' ''
+ local service=s-proxy
+ local 'command=/opt/stack/swift/bin/swift-proxy-server /etc/swift/proxy-server.conf -v'
+ local group=
+ SCREEN_NAME=stack
+ SERVICE_DIR=/opt/stack/status
++ trueorfalse True True
+++ set +o
+++ grep xtrace
++ local 'xtrace=set -o xtrace'
++ set +o xtrace
+ USE_SCREEN=True
+ is_service_enabled s-proxy
++ set +o
++ grep xtrace
+ local 'xtrace=set -o xtrace'
+ set +o xtrace
+ return 0
+ screen_rc s-proxy '/opt/stack/swift/bin/swift-proxy-server /etc/swift/proxy-server.conf -v'
+ SCREEN_NAME=stack
+ SCREENRC=/home/cloudbase/devstack/stack-screenrc
+ [[ ! -e /home/cloudbase/devstack/stack-screenrc ]]
+ grep s-proxy /home/cloudbase/devstack/stack-screenrc
++ echo -ne '\015'
+ NL=$'\r'
+ echo 'screen -t s-proxy bash'
+ echo 'stuff "/opt/stack/swift/bin/swift-proxy-server /etc/swift/proxy-server.conf -v"'
+ [[ -n /home/cloudbase/jenkins/workspace/openstack-hyperv-release-tests/reports/2014_12_12_13_16_55_547646598/HyperV2012_VHD_v1/logs/devstack ]]
+ echo 'logfile /home/cloudbase/jenkins/workspace/openstack-hyperv-release-tests/reports/2014_12_12_13_16_55_547646598/HyperV2012_VHD_v1/logs/devstack/screen-s-proxy.2014-12-12-162857.log'
+ echo 'log on'
+ screen -S stack -X screen -t s-proxy
+ [[ -n /home/cloudbase/jenkins/workspace/openstack-hyperv-release-tests/reports/2014_12_12_13_16_55_547646598/HyperV2012_VHD_v1/logs/devstack ]]
+ screen -S stack -p s-proxy -X logfile /home/cloudbase/jenkins/workspace/openstack-hyperv-release-tests/reports/2014_12_12_13_16_55_547646598/HyperV2012_VHD_v1/logs/devstack/screen-s-proxy.2014-12-12-162857.log
+ screen -S stack -p s-proxy -X log on
+ ln -sf /home/cloudbase/jenkins/workspace/openstack-hyperv-release-tests/reports/2014_12_12_13_16_55_547646598/HyperV2012_VHD_v1/logs/devstack/screen-s-proxy.2014-12-12-162857.log /home/cloudbase/jenkins/workspace/openstack-hyperv-release-tests/reports/2014_12_12_13_16_55_547646598/HyperV2012_VHD_v1/logs/devstack/screen-s-proxy.log
+ sleep 3
++ echo -ne '\015'
+ NL=$'\r'
+ [[ -n '' ]]
+ screen -S stack -p s-proxy -X stuff '/opt/stack/swift/bin/swift-proxy-server /etc/swift/proxy-server.conf -v & echo $! >/opt/stack/status/stack/s-proxy.pid; fg || echo "s-proxy failed to start" | tee "/opt/stack/status/stack/s-proxy.failure"'
+ [[ 1 == 1 ]]
+ for type in object container account
+ run_process s-object '/opt/stack/swift/bin/swift-object-server /etc/swift/object-server/1.conf -v'
+ local service=s-object
+ local 'command=/opt/stack/swift/bin/swift-object-server /etc/swift/object-server/1.conf -v'
+ local group=
+ is_service_enabled s-object
++ set +o
++ grep xtrace
+ local 'xtrace=set -o xtrace'
+ set +o xtrace
+ return 0
+ [[ True = \T\r\u\e ]]
+ screen_service s-object '/opt/stack/swift/bin/swift-object-server /etc/swift/object-server/1.conf -v' ''
+ local service=s-object
+ local 'command=/opt/stack/swift/bin/swift-object-server /etc/swift/object-server/1.conf -v'
+ local group=
+ SCREEN_NAME=stack
+ SERVICE_DIR=/opt/stack/status
++ trueorfalse True True
+++ grep xtrace
++ local 'xtrace=set -o xtrace'
++ set +o xtrace
+ USE_SCREEN=True
+ is_service_enabled s-object
++ set +o
++ grep xtrace
+ local 'xtrace=set -o xtrace'
+ set +o xtrace
+ return 0
+ screen_rc s-object '/opt/stack/swift/bin/swift-object-server /etc/swift/object-server/1.conf -v'
+ SCREEN_NAME=stack
+ SCREENRC=/home/cloudbase/devstack/stack-screenrc
+ [[ ! -e /home/cloudbase/devstack/stack-screenrc ]]
+ grep s-object /home/cloudbase/devstack/stack-screenrc
++ echo -ne '\015'
+ NL=$'\r'
+ echo 'screen -t s-object bash'
+ echo 'stuff "/opt/stack/swift/bin/swift-object-server /etc/swift/object-server/1.conf -v"'
+ [[ -n /home/cloudbase/jenkins/workspace/openstack-hyperv-release-tests/reports/2014_12_12_13_16_55_547646598/HyperV2012_VHD_v1/logs/devstack ]]
+ echo 'logfile /home/cloudbase/jenkins/workspace/openstack-hyperv-release-tests/reports/2014_12_12_13_16_55_547646598/HyperV2012_VHD_v1/logs/devstack/screen-s-object.2014-12-12-162857.log'
+ echo 'log on'
+ screen -S stack -X screen -t s-object
+ [[ -n /home/cloudbase/jenkins/workspace/openstack-hyperv-release-tests/reports/2014_12_12_13_16_55_547646598/HyperV2012_VHD_v1/logs/devstack ]]
+ screen -S stack -p s-object -X logfile /home/cloudbase/jenkins/workspace/openstack-hyperv-release-tests/reports/2014_12_12_13_16_55_547646598/HyperV2012_VHD_v1/logs/devstack/screen-s-object.2014-12-12-162857.log
+ screen -S stack -p s-object -X log on
+ ln -sf /home/cloudbase/jenkins/workspace/openstack-hyperv-release-tests/reports/2014_12_12_13_16_55_547646598/HyperV2012_VHD_v1/logs/devstack/screen-s-object.2014-12-12-162857.log /home/cloudbase/jenkins/workspace/openstack-hyperv-release-tests/reports/2014_12_12_13_16_55_547646598/HyperV2012_VHD_v1/logs/devstack/screen-s-object.log
+ sleep 3
++ echo -ne '\015'
+ NL=$'\r'
+ [[ -n '' ]]
+ screen -S stack -p s-object -X stuff '/opt/stack/swift/bin/swift-object-server /etc/swift/object-server/1.conf -v & echo $! >/opt/stack/status/stack/s-object.pid; fg || echo "s-object failed to start" | tee "/opt/stack/status/stack/s-object.failure"'
+ for type in object container account
+ run_process s-container '/opt/stack/swift/bin/swift-container-server /etc/swift/container-server/1.conf -v'
+ local service=s-container
+ local 'command=/opt/stack/swift/bin/swift-container-server /etc/swift/container-server/1.conf -v'
+ local group=
+ is_service_enabled s-container
++ set +o
++ grep xtrace
+ local 'xtrace=set -o xtrace'
+ set +o xtrace
+ return 0
+ [[ True = \T\r\u\e ]]
+ screen_service s-container '/opt/stack/swift/bin/swift-container-server /etc/swift/container-server/1.conf -v' ''
+ local service=s-container
+ local 'command=/opt/stack/swift/bin/swift-container-server /etc/swift/container-server/1.conf -v'
+ local group=
+ SCREEN_NAME=stack
+ SERVICE_DIR=/opt/stack/status
++ trueorfalse True True
+++ set +o
+++ grep xtrace
++ local 'xtrace=set -o xtrace'
++ set +o xtrace
+ USE_SCREEN=True
+ is_service_enabled s-container
++ set +o
++ grep xtrace
+ local 'xtrace=set -o xtrace'
+ set +o xtrace
+ return 0
+ screen_rc s-container '/opt/stack/swift/bin/swift-container-server /etc/swift/container-server/1.conf -v'
+ SCREEN_NAME=stack
+ SCREENRC=/home/cloudbase/devstack/stack-screenrc
+ [[ ! -e /home/cloudbase/devstack/stack-screenrc ]]
+ grep s-container /home/cloudbase/devstack/stack-screenrc
++ echo -ne '\015'
+ NL=$'\r'
+ echo 'screen -t s-container bash'
+ echo 'stuff "/opt/stack/swift/bin/swift-container-server /etc/swift/container-server/1.conf -v"'
+ [[ -n /home/cloudbase/jenkins/workspace/openstack-hyperv-release-tests/reports/2014_12_12_13_16_55_547646598/HyperV2012_VHD_v1/logs/devstack ]]
+ echo 'logfile /home/cloudbase/jenkins/workspace/openstack-hyperv-release-tests/reports/2014_12_12_13_16_55_547646598/HyperV2012_VHD_v1/logs/devstack/screen-s-container.2014-12-12-162857.log'
+ echo 'log on'
+ screen -S stack -X screen -t s-container
+ [[ -n /home/cloudbase/jenkins/workspace/openstack-hyperv-release-tests/reports/2014_12_12_13_16_55_547646598/HyperV2012_VHD_v1/logs/devstack ]]
+ screen -S stack -p s-container -X logfile /home/cloudbase/jenkins/workspace/openstack-hyperv-release-tests/reports/2014_12_12_13_16_55_547646598/HyperV2012_VHD_v1/logs/devstack/screen-s-container.2014-12-12-162857.log
+ screen -S stack -p s-container -X log on
+ ln -sf /home/cloudbase/jenkins/workspace/openstack-hyperv-release-tests/reports/2014_12_12_13_16_55_547646598/HyperV2012_VHD_v1/logs/devstack/screen-s-container.2014-12-12-162857.log /home/cloudbase/jenkins/workspace/openstack-hyperv-release-tests/reports/2014_12_12_13_16_55_547646598/HyperV2012_VHD_v1/logs/devstack/screen-s-container.log
+ sleep 3
++ echo -ne '\015'
+ NL=$'\r'
+ [[ -n '' ]]
+ screen -S stack -p s-container -X stuff '/opt/stack/swift/bin/swift-container-server /etc/swift/container-server/1.conf -v & echo $! >/opt/stack/status/stack/s-container.pid; fg || echo "s-container failed to start" | tee "/opt/stack/status/stack/s-container.failure"'
+ for type in object container account
+ run_process s-account '/opt/stack/swift/bin/swift-account-server /etc/swift/account-server/1.conf -v'
+ local service=s-account
+ local 'command=/opt/stack/swift/bin/swift-account-server /etc/swift/account-server/1.conf -v'
+ local group=
+ is_service_enabled s-account
++ set +o
++ grep xtrace
+ local 'xtrace=set -o xtrace'
+ set +o xtrace
+ return 0
+ [[ True = \T\r\u\e ]]
+ screen_service s-account '/opt/stack/swift/bin/swift-account-server /etc/swift/account-server/1.conf -v' ''
+ local service=s-account
+ local 'command=/opt/stack/swift/bin/swift-account-server /etc/swift/account-server/1.conf -v'
+ local group=
+ SCREEN_NAME=stack
+ SERVICE_DIR=/opt/stack/status
++ trueorfalse True True
+++ set +o
+++ grep xtrace
++ local 'xtrace=set -o xtrace'
++ set +o xtrace
+ USE_SCREEN=True
+ is_service_enabled s-account
++ set +o
++ grep xtrace
+ local 'xtrace=set -o xtrace'
+ set +o xtrace
+ return 0
+ screen_rc s-account '/opt/stack/swift/bin/swift-account-server /etc/swift/account-server/1.conf -v'
+ SCREEN_NAME=stack
+ SCREENRC=/home/cloudbase/devstack/stack-screenrc
+ [[ ! -e /home/cloudbase/devstack/stack-screenrc ]]
+ grep s-account /home/cloudbase/devstack/stack-screenrc
++ echo -ne '\015'
+ NL=$'\r'
+ echo 'screen -t s-account bash'
+ echo 'stuff "/opt/stack/swift/bin/swift-account-server /etc/swift/account-server/1.conf -v"'
+ [[ -n /home/cloudbase/jenkins/workspace/openstack-hyperv-release-tests/reports/2014_12_12_13_16_55_547646598/HyperV2012_VHD_v1/logs/devstack ]]
+ echo 'logfile /home/cloudbase/jenkins/workspace/openstack-hyperv-release-tests/reports/2014_12_12_13_16_55_547646598/HyperV2012_VHD_v1/logs/devstack/screen-s-account.2014-12-12-162857.log'
+ echo 'log on'
+ screen -S stack -X screen -t s-account
+ [[ -n /home/cloudbase/jenkins/workspace/openstack-hyperv-release-tests/reports/2014_12_12_13_16_55_547646598/HyperV2012_VHD_v1/logs/devstack ]]
+ screen -S stack -p s-account -X logfile /home/cloudbase/jenkins/workspace/openstack-hyperv-release-tests/reports/2014_12_12_13_16_55_547646598/HyperV2012_VHD_v1/logs/devstack/screen-s-account.2014-12-12-162857.log
+ screen -S stack -p s-account -X log on
+ ln -sf /home/cloudbase/jenkins/workspace/openstack-hyperv-release-tests/reports/2014_12_12_13_16_55_547646598/HyperV2012_VHD_v1/logs/devstack/screen-s-account.2014-12-12-162857.log /home/cloudbase/jenkins/workspace/openstack-hyperv-release-tests/reports/2014_12_12_13_16_55_547646598/HyperV2012_VHD_v1/logs/devstack/screen-s-account.log
+ sleep 3
++ echo -ne '\015'
+ NL=$'\r'
+ [[ -n '' ]]
+ screen -S stack -p s-account -X stuff '/opt/stack/swift/bin/swift-account-server /etc/swift/account-server/1.conf -v & echo $! >/opt/stack/status/stack/s-account.pid; fg || echo "s-account failed to start" | tee "/opt/stack/status/stack/s-account.failure"'
+ [[ False == \T\r\u\e ]]
+ is_service_enabled glance
++ set +o
++ grep xtrace
+ local 'xtrace=set -o xtrace'
+ set +o xtrace
+ return 0
+ echo_summary 'Starting Glance'
+ [[ -t 3 ]]
+ echo -e Starting Glance
+ start_glance
+ local service_protocol=http
+ is_service_enabled tls-proxy
++ grep xtrace
++ set +o
+ local 'xtrace=set -o xtrace'
+ set +o xtrace
+ return 1
+ run_process g-reg '/usr/local/bin/glance-registry --config-file=/etc/glance/glance-registry.conf'
+ local service=g-reg
+ local 'command=/usr/local/bin/glance-registry --config-file=/etc/glance/glance-registry.conf'
+ local group=
+ is_service_enabled g-reg
++ set +o
++ grep xtrace
+ local 'xtrace=set -o xtrace'
+ set +o xtrace
+ return 0
+ [[ True = \T\r\u\e ]]
+ screen_service g-reg '/usr/local/bin/glance-registry --config-file=/etc/glance/glance-registry.conf' ''
+ local service=g-reg
+ local 'command=/usr/local/bin/glance-registry --config-file=/etc/glance/glance-registry.conf'
+ local group=
+ SCREEN_NAME=stack
+ SERVICE_DIR=/opt/stack/status
++ trueorfalse True True
+++ set +o
+++ grep xtrace
++ local 'xtrace=set -o xtrace'
++ set +o xtrace
+ USE_SCREEN=True
+ is_service_enabled g-reg
++ set +o
++ grep xtrace
+ local 'xtrace=set -o xtrace'
+ set +o xtrace
+ return 0
+ screen_rc g-reg '/usr/local/bin/glance-registry --config-file=/etc/glance/glance-registry.conf'
+ SCREEN_NAME=stack
+ SCREENRC=/home/cloudbase/devstack/stack-screenrc
+ [[ ! -e /home/cloudbase/devstack/stack-screenrc ]]
+ grep g-reg /home/cloudbase/devstack/stack-screenrc
++ echo -ne '\015'
+ NL=$'\r'
+ echo 'screen -t g-reg bash'
+ echo 'stuff "/usr/local/bin/glance-registry --config-file=/etc/glance/glance-registry.conf"'
+ [[ -n /home/cloudbase/jenkins/workspace/openstack-hyperv-release-tests/reports/2014_12_12_13_16_55_547646598/HyperV2012_VHD_v1/logs/devstack ]]
+ echo 'logfile /home/cloudbase/jenkins/workspace/openstack-hyperv-release-tests/reports/2014_12_12_13_16_55_547646598/HyperV2012_VHD_v1/logs/devstack/screen-g-reg.2014-12-12-162857.log'
+ echo 'log on'
+ screen -S stack -X screen -t g-reg
+ [[ -n /home/cloudbase/jenkins/workspace/openstack-hyperv-release-tests/reports/2014_12_12_13_16_55_547646598/HyperV2012_VHD_v1/logs/devstack ]]
+ screen -S stack -p g-reg -X logfile /home/cloudbase/jenkins/workspace/openstack-hyperv-release-tests/reports/2014_12_12_13_16_55_547646598/HyperV2012_VHD_v1/logs/devstack/screen-g-reg.2014-12-12-162857.log
+ screen -S stack -p g-reg -X log on
+ ln -sf /home/cloudbase/jenkins/workspace/openstack-hyperv-release-tests/reports/2014_12_12_13_16_55_547646598/HyperV2012_VHD_v1/logs/devstack/screen-g-reg.2014-12-12-162857.log /home/cloudbase/jenkins/workspace/openstack-hyperv-release-tests/reports/2014_12_12_13_16_55_547646598/HyperV2012_VHD_v1/logs/devstack/screen-g-reg.log
+ sleep 3
++ echo -ne '\015'
+ NL=$'\r'
+ [[ -n '' ]]
+ screen -S stack -p g-reg -X stuff '/usr/local/bin/glance-registry --config-file=/etc/glance/glance-registry.conf & echo $! >/opt/stack/status/stack/g-reg.pid; fg || echo "g-reg failed to start" | tee "/opt/stack/status/stack/g-reg.failure"'
+ run_process g-api '/usr/local/bin/glance-api --config-file=/etc/glance/glance-api.conf'
+ local service=g-api
+ local 'command=/usr/local/bin/glance-api --config-file=/etc/glance/glance-api.conf'
+ local group=
+ is_service_enabled g-api
++ set +o
++ grep xtrace
+ local 'xtrace=set -o xtrace'
+ set +o xtrace
+ return 0
+ [[ True = \T\r\u\e ]]
+ screen_service g-api '/usr/local/bin/glance-api --config-file=/etc/glance/glance-api.conf' ''
+ local service=g-api
+ local 'command=/usr/local/bin/glance-api --config-file=/etc/glance/glance-api.conf'
+ local group=
+ SCREEN_NAME=stack
+ SERVICE_DIR=/opt/stack/status
++ trueorfalse True True
+++ set +o
+++ grep xtrace
++ local 'xtrace=set -o xtrace'
++ set +o xtrace
+ USE_SCREEN=True
+ is_service_enabled g-api
++ set +o
++ grep xtrace
+ local 'xtrace=set -o xtrace'
+ set +o xtrace
+ return 0
+ screen_rc g-api '/usr/local/bin/glance-api --config-file=/etc/glance/glance-api.conf'
+ SCREEN_NAME=stack
+ SCREENRC=/home/cloudbase/devstack/stack-screenrc
+ [[ ! -e /home/cloudbase/devstack/stack-screenrc ]]
+ grep g-api /home/cloudbase/devstack/stack-screenrc
++ echo -ne '\015'
+ NL=$'\r'
+ echo 'screen -t g-api bash'
+ echo 'stuff "/usr/local/bin/glance-api --config-file=/etc/glance/glance-api.conf"'
+ [[ -n /home/cloudbase/jenkins/workspace/openstack-hyperv-release-tests/reports/2014_12_12_13_16_55_547646598/HyperV2012_VHD_v1/logs/devstack ]]
+ echo 'logfile /home/cloudbase/jenkins/workspace/openstack-hyperv-release-tests/reports/2014_12_12_13_16_55_547646598/HyperV2012_VHD_v1/logs/devstack/screen-g-api.2014-12-12-162857.log'
+ echo 'log on'
+ screen -S stack -X screen -t g-api
+ [[ -n /home/cloudbase/jenkins/workspace/openstack-hyperv-release-tests/reports/2014_12_12_13_16_55_547646598/HyperV2012_VHD_v1/logs/devstack ]]
+ screen -S stack -p g-api -X logfile /home/cloudbase/jenkins/workspace/openstack-hyperv-release-tests/reports/2014_12_12_13_16_55_547646598/HyperV2012_VHD_v1/logs/devstack/screen-g-api.2014-12-12-162857.log
+ screen -S stack -p g-api -X log on
+ ln -sf /home/cloudbase/jenkins/workspace/openstack-hyperv-release-tests/reports/2014_12_12_13_16_55_547646598/HyperV2012_VHD_v1/logs/devstack/screen-g-api.2014-12-12-162857.log /home/cloudbase/jenkins/workspace/openstack-hyperv-release-tests/reports/2014_12_12_13_16_55_547646598/HyperV2012_VHD_v1/logs/devstack/screen-g-api.log
+ sleep 3
++ echo -ne '\015'
+ NL=$'\r'
+ [[ -n '' ]]
+ screen -S stack -p g-api -X stuff '/usr/local/bin/glance-api --config-file=/etc/glance/glance-api.conf & echo $! >/opt/stack/status/stack/g-api.pid; fg || echo "g-api failed to start" | tee "/opt/stack/status/stack/g-api.failure"'
+ echo 'Waiting for g-api (10.14.0.26:9292) to start...'
+ wait_for_service 60 http://10.14.0.26:9292
+ local timeout=60
+ local url=http://10.14.0.26:9292
+ timeout 60 sh -c 'while ! curl -k --noproxy '\''*'\'' -s http://10.14.0.26:9292 >/dev/null; do sleep 1; done'
+ is_service_enabled g-reg
++ set +o
++ grep xtrace
+ local 'xtrace=set -o xtrace'
+ set +o xtrace
+ return 0
++ keystone token-get
++ grep ' id '
++ get_field 2
++ local data field
++ read data
++ '[' 2 -lt 0 ']'
++ field='$3'
++ echo '|     id    | 230c6b392a1a4ecf9c8cac0ad505943b |'
++ awk '-F[ \t]*\\|[ \t]*' '{print $3}'
++ read data
+ TOKEN=230c6b392a1a4ecf9c8cac0ad505943b
+ die_if_not_set 1202 TOKEN 'Keystone fail to get token'
+ local exitcode=0
++ set +o
++ grep xtrace
+ local 'xtrace=set -o xtrace'
+ set +o xtrace
+ is_baremetal
+ [[ g-api,g-reg,key,n-api,n-crt,n-obj,n-cond,n-sch,n-xvnc,n-cauth,c-sch,c-api,c-vol,h-eng,h-api,h-api-cfn,h-api-cw,rabbit,tempest,mysql,neutron,q-svc,q-agt,q-dhcp,q-l3,q-meta,q-lbaas,q-fwaas,q-metering,q-vpn,c-bak,s-proxy,s-object,s-container,s-account,heat,ceilometer-acentral,ceilometer-collector,ceilometer-api =~ baremetal ]]
+ return 1
+ echo_summary 'Uploading images'
+ [[ -t 3 ]]
+ echo -e Uploading images
+ [[ -n '' ]]
+ for image_url in '${IMAGE_URLS//,/ }'
+ upload_image file:///home/cloudbase/devstack/cirros-0.3.3-x86_64.vhd 230c6b392a1a4ecf9c8cac0ad505943b
+ local image_url=file:///home/cloudbase/devstack/cirros-0.3.3-x86_64.vhd
+ local token=230c6b392a1a4ecf9c8cac0ad505943b
+ local image image_fname image_name
+ mkdir -p /home/cloudbase/devstack/files/images
++ basename file:///home/cloudbase/devstack/cirros-0.3.3-x86_64.vhd
+ image_fname=cirros-0.3.3-x86_64.vhd
+ [[ file:///home/cloudbase/devstack/cirros-0.3.3-x86_64.vhd != file* ]]
++ echo file:///home/cloudbase/devstack/cirros-0.3.3-x86_64.vhd
++ sed 's/^file:\/\///g'
+ image=/home/cloudbase/devstack/cirros-0.3.3-x86_64.vhd
+ [[ ! -f /home/cloudbase/devstack/cirros-0.3.3-x86_64.vhd ]]
++ stat -c %s /home/cloudbase/devstack/cirros-0.3.3-x86_64.vhd
+ [[ 29369856 == \0 ]]
+ [[ file:///home/cloudbase/devstack/cirros-0.3.3-x86_64.vhd =~ openvz ]]
+ [[ file:///home/cloudbase/devstack/cirros-0.3.3-x86_64.vhd =~ \.vmdk ]]
+ [[ file:///home/cloudbase/devstack/cirros-0.3.3-x86_64.vhd =~ \.vhd\.tgz ]]
+ [[ file:///home/cloudbase/devstack/cirros-0.3.3-x86_64.vhd =~ \.xen-raw\.tgz ]]
+ local kernel=
+ local ramdisk=
+ local disk_format=
+ local container_format=
+ local unpack=
+ local img_property=
+ case "$image_fname" in
+ local extension=3.3-x86_64.vhd
++ basename /home/cloudbase/devstack/cirros-0.3.3-x86_64.vhd .3.3-x86_64.vhd
+ image_name=cirros-0
+ disk_format=vhd
+ container_format=bare
+ '[' vhd == gz ']'
+ is_arch ppc64
++ uname -m
+ [[ x86_64 == \p\p\c\6\4 ]]
+ '[' bare = bare ']'
+ '[' '' = zcat ']'
+ openstack --os-token 230c6b392a1a4ecf9c8cac0ad505943b --os-url http://10.14.0.26:9292 image create cirros-0 --public --container-format=bare --disk-format vhd
+ for image_url in '${IMAGE_URLS//,/ }'
+ upload_image file:///home/cloudbase/devstack/Fedora-x86_64-20-20140618-sda.vhd 230c6b392a1a4ecf9c8cac0ad505943b
+ local image_url=file:///home/cloudbase/devstack/Fedora-x86_64-20-20140618-sda.vhd
+ local token=230c6b392a1a4ecf9c8cac0ad505943b
+ local image image_fname image_name
+ mkdir -p /home/cloudbase/devstack/files/images
++ basename file:///home/cloudbase/devstack/Fedora-x86_64-20-20140618-sda.vhd
+ image_fname=Fedora-x86_64-20-20140618-sda.vhd
+ [[ file:///home/cloudbase/devstack/Fedora-x86_64-20-20140618-sda.vhd != file* ]]
++ echo file:///home/cloudbase/devstack/Fedora-x86_64-20-20140618-sda.vhd
++ sed 's/^file:\/\///g'
+ image=/home/cloudbase/devstack/Fedora-x86_64-20-20140618-sda.vhd
+ [[ ! -f /home/cloudbase/devstack/Fedora-x86_64-20-20140618-sda.vhd ]]
++ stat -c %s /home/cloudbase/devstack/Fedora-x86_64-20-20140618-sda.vhd
+ [[ 685942784 == \0 ]]
+ [[ file:///home/cloudbase/devstack/Fedora-x86_64-20-20140618-sda.vhd =~ openvz ]]
+ [[ file:///home/cloudbase/devstack/Fedora-x86_64-20-20140618-sda.vhd =~ \.vmdk ]]
+ [[ file:///home/cloudbase/devstack/Fedora-x86_64-20-20140618-sda.vhd =~ \.vhd\.tgz ]]
+ [[ file:///home/cloudbase/devstack/Fedora-x86_64-20-20140618-sda.vhd =~ \.xen-raw\.tgz ]]
+ local kernel=
+ local ramdisk=
+ local disk_format=
+ local container_format=
+ local unpack=
+ local img_property=
+ case "$image_fname" in
+ local extension=vhd
++ basename /home/cloudbase/devstack/Fedora-x86_64-20-20140618-sda.vhd .vhd
+ image_name=Fedora-x86_64-20-20140618-sda
+ disk_format=vhd
+ container_format=bare
+ '[' vhd == gz ']'
+ is_arch ppc64
++ uname -m
+ [[ x86_64 == \p\p\c\6\4 ]]
+ '[' bare = bare ']'
+ '[' '' = zcat ']'
+ openstack --os-token 230c6b392a1a4ecf9c8cac0ad505943b --os-url http://10.14.0.26:9292 image create Fedora-x86_64-20-20140618-sda --public --container-format=bare --disk-format vhd
+ is_service_enabled key
++ set +o
++ grep xtrace
+ local 'xtrace=set -o xtrace'
+ set +o xtrace
+ return 0
+ is_service_enabled swift3
++ set +o
++ grep xtrace
+ local 'xtrace=set -o xtrace'
+ set +o xtrace
+ return 1
+ is_service_enabled nova
++ set +o
++ grep xtrace
+ local 'xtrace=set -o xtrace'
+ set +o xtrace
+ return 0
++ generate_hex_string 32
++ local size=32
++ hexdump -n 32 -v -e '/1 "%02x"' /dev/urandom
+ iniset /etc/nova/nova.conf keymgr fixed_key 7bda571b32d547b67da6db7e3127aeeea5f621e5e480143766c74da734717419
++ set +o
++ grep xtrace
+ local 'xtrace=set -o xtrace'
+ set +o xtrace
+ is_service_enabled zeromq
++ set +o
++ grep xtrace
+ local 'xtrace=set -o xtrace'
+ set +o xtrace
+ return 1
+ is_service_enabled n-api
++ set +o
++ grep xtrace
+ local 'xtrace=set -o xtrace'
+ set +o xtrace
+ return 0
+ echo_summary 'Starting Nova API'
+ [[ -t 3 ]]
+ echo -e Starting Nova API
+ start_nova_api
+ local service_port=8774
+ local service_protocol=http
+ is_service_enabled tls-proxy
++ set +o
++ grep xtrace
+ local 'xtrace=set -o xtrace'
+ set +o xtrace
+ return 1
+ run_process n-api /usr/local/bin/nova-api
+ local service=n-api
+ local command=/usr/local/bin/nova-api
+ local group=
+ is_service_enabled n-api
++ set +o
++ grep xtrace
+ local 'xtrace=set -o xtrace'
+ set +o xtrace
+ return 0
+ [[ True = \T\r\u\e ]]
+ screen_service n-api /usr/local/bin/nova-api ''
+ local service=n-api
+ local command=/usr/local/bin/nova-api
+ local group=
+ SCREEN_NAME=stack
+ SERVICE_DIR=/opt/stack/status
++ trueorfalse True True
+++ set +o
+++ grep xtrace
++ local 'xtrace=set -o xtrace'
++ set +o xtrace
+ USE_SCREEN=True
+ is_service_enabled n-api
++ set +o
++ grep xtrace
+ local 'xtrace=set -o xtrace'
+ set +o xtrace
+ return 0
+ screen_rc n-api /usr/local/bin/nova-api
+ SCREEN_NAME=stack
+ SCREENRC=/home/cloudbase/devstack/stack-screenrc
+ [[ ! -e /home/cloudbase/devstack/stack-screenrc ]]
+ grep n-api /home/cloudbase/devstack/stack-screenrc
++ echo -ne '\015'
+ NL=$'\r'
+ echo 'screen -t n-api bash'
+ echo 'stuff "/usr/local/bin/nova-api"'
+ [[ -n /home/cloudbase/jenkins/workspace/openstack-hyperv-release-tests/reports/2014_12_12_13_16_55_547646598/HyperV2012_VHD_v1/logs/devstack ]]
+ echo 'logfile /home/cloudbase/jenkins/workspace/openstack-hyperv-release-tests/reports/2014_12_12_13_16_55_547646598/HyperV2012_VHD_v1/logs/devstack/screen-n-api.2014-12-12-162857.log'
+ echo 'log on'
+ screen -S stack -X screen -t n-api
+ [[ -n /home/cloudbase/jenkins/workspace/openstack-hyperv-release-tests/reports/2014_12_12_13_16_55_547646598/HyperV2012_VHD_v1/logs/devstack ]]
+ screen -S stack -p n-api -X logfile /home/cloudbase/jenkins/workspace/openstack-hyperv-release-tests/reports/2014_12_12_13_16_55_547646598/HyperV2012_VHD_v1/logs/devstack/screen-n-api.2014-12-12-162857.log
+ screen -S stack -p n-api -X log on
+ ln -sf /home/cloudbase/jenkins/workspace/openstack-hyperv-release-tests/reports/2014_12_12_13_16_55_547646598/HyperV2012_VHD_v1/logs/devstack/screen-n-api.2014-12-12-162857.log /home/cloudbase/jenkins/workspace/openstack-hyperv-release-tests/reports/2014_12_12_13_16_55_547646598/HyperV2012_VHD_v1/logs/devstack/screen-n-api.log
+ sleep 3
++ echo -ne '\015'
+ NL=$'\r'
+ [[ -n '' ]]
+ screen -S stack -p n-api -X stuff '/usr/local/bin/nova-api & echo $! >/opt/stack/status/stack/n-api.pid; fg || echo "n-api failed to start" | tee "/opt/stack/status/stack/n-api.failure"'
+ echo 'Waiting for nova-api to start...'
+ wait_for_service 60 http://10.14.0.26:8774
+ local timeout=60
+ local url=http://10.14.0.26:8774
+ timeout 60 sh -c 'while ! curl -k --noproxy '\''*'\'' -s http://10.14.0.26:8774 >/dev/null; do sleep 1; done'
+ is_service_enabled tls-proxy
++ set +o
++ grep xtrace
+ local 'xtrace=set -o xtrace'
+ set +o xtrace
+ return 1
+ is_service_enabled q-svc
++ set +o
++ grep xtrace
+ local 'xtrace=set -o xtrace'
+ set +o xtrace
+ return 0
+ echo_summary 'Starting Neutron'
+ [[ -t 3 ]]
+ echo -e Starting Neutron
+ start_neutron_service_and_check
++ determine_config_files neutron-server
++ local opts=
++ case "$1" in
+++ _determine_config_server
+++ local cfg_file
+++ local 'opts=--config-file /etc/neutron/neutron.conf --config-file /etc/neutron/plugins/ml2/ml2_conf.ini'
+++ echo '--config-file /etc/neutron/neutron.conf --config-file /etc/neutron/plugins/ml2/ml2_conf.ini'
++ opts='--config-file /etc/neutron/neutron.conf --config-file /etc/neutron/plugins/ml2/ml2_conf.ini'
++ '[' -z '--config-file /etc/neutron/neutron.conf --config-file /etc/neutron/plugins/ml2/ml2_conf.ini' ']'
++ echo '--config-file /etc/neutron/neutron.conf --config-file /etc/neutron/plugins/ml2/ml2_conf.ini'
+ local 'cfg_file_options=--config-file /etc/neutron/neutron.conf --config-file /etc/neutron/plugins/ml2/ml2_conf.ini'
+ local service_port=9696
+ local service_protocol=http
+ is_service_enabled tls-proxy
++ set +o
++ grep xtrace
+ local 'xtrace=set -o xtrace'
+ set +o xtrace
+ return 1
+ run_process q-svc 'python /usr/local/bin/neutron-server --config-file /etc/neutron/neutron.conf --config-file /etc/neutron/plugins/ml2/ml2_conf.ini'
+ local service=q-svc
+ local 'command=python /usr/local/bin/neutron-server --config-file /etc/neutron/neutron.conf --config-file /etc/neutron/plugins/ml2/ml2_conf.ini'
+ local group=
+ is_service_enabled q-svc
++ set +o
++ grep xtrace
+ local 'xtrace=set -o xtrace'
+ set +o xtrace
+ return 0
+ [[ True = \T\r\u\e ]]
+ screen_service q-svc 'python /usr/local/bin/neutron-server --config-file /etc/neutron/neutron.conf --config-file /etc/neutron/plugins/ml2/ml2_conf.ini' ''
+ local service=q-svc
+ local 'command=python /usr/local/bin/neutron-server --config-file /etc/neutron/neutron.conf --config-file /etc/neutron/plugins/ml2/ml2_conf.ini'
+ local group=
+ SCREEN_NAME=stack
+ SERVICE_DIR=/opt/stack/status
++ trueorfalse True True
+++ set +o
+++ grep xtrace
++ local 'xtrace=set -o xtrace'
++ set +o xtrace
+ USE_SCREEN=True
+ is_service_enabled q-svc
++ set +o
++ grep xtrace
+ local 'xtrace=set -o xtrace'
+ set +o xtrace
+ return 0
+ screen_rc q-svc 'python /usr/local/bin/neutron-server --config-file /etc/neutron/neutron.conf --config-file /etc/neutron/plugins/ml2/ml2_conf.ini'
+ SCREEN_NAME=stack
+ SCREENRC=/home/cloudbase/devstack/stack-screenrc
+ [[ ! -e /home/cloudbase/devstack/stack-screenrc ]]
+ grep q-svc /home/cloudbase/devstack/stack-screenrc
++ echo -ne '\015'
+ NL=$'\r'
+ echo 'screen -t q-svc bash'
+ echo 'stuff "python /usr/local/bin/neutron-server --config-file /etc/neutron/neutron.conf --config-file /etc/neutron/plugins/ml2/ml2_conf.ini"'
+ [[ -n /home/cloudbase/jenkins/workspace/openstack-hyperv-release-tests/reports/2014_12_12_13_16_55_547646598/HyperV2012_VHD_v1/logs/devstack ]]
+ echo 'logfile /home/cloudbase/jenkins/workspace/openstack-hyperv-release-tests/reports/2014_12_12_13_16_55_547646598/HyperV2012_VHD_v1/logs/devstack/screen-q-svc.2014-12-12-162857.log'
+ echo 'log on'
+ screen -S stack -X screen -t q-svc
+ [[ -n /home/cloudbase/jenkins/workspace/openstack-hyperv-release-tests/reports/2014_12_12_13_16_55_547646598/HyperV2012_VHD_v1/logs/devstack ]]
+ screen -S stack -p q-svc -X logfile /home/cloudbase/jenkins/workspace/openstack-hyperv-release-tests/reports/2014_12_12_13_16_55_547646598/HyperV2012_VHD_v1/logs/devstack/screen-q-svc.2014-12-12-162857.log
+ screen -S stack -p q-svc -X log on
+ ln -sf /home/cloudbase/jenkins/workspace/openstack-hyperv-release-tests/reports/2014_12_12_13_16_55_547646598/HyperV2012_VHD_v1/logs/devstack/screen-q-svc.2014-12-12-162857.log /home/cloudbase/jenkins/workspace/openstack-hyperv-release-tests/reports/2014_12_12_13_16_55_547646598/HyperV2012_VHD_v1/logs/devstack/screen-q-svc.log
+ sleep 3
++ echo -ne '\015'
+ NL=$'\r'
+ [[ -n '' ]]
+ screen -S stack -p q-svc -X stuff 'python /usr/local/bin/neutron-server --config-file /etc/neutron/neutron.conf --config-file /etc/neutron/plugins/ml2/ml2_conf.ini & echo $! >/opt/stack/status/stack/q-svc.pid; fg || echo "q-svc failed to start" | tee "/opt/stack/status/stack/q-svc.failure"'
+ echo 'Waiting for Neutron to start...'
+ is_ssl_enabled_service neutron
+ local services=neutron
+ local service=
+ '[' False == False ']'
+ return 1
+ timeout 60 sh -c 'while ! wget  --no-proxy -q -O- http://10.14.0.26:9696; do sleep 1; done'
+ is_service_enabled tls-proxy
++ set +o
++ grep xtrace
+ local 'xtrace=set -o xtrace'
+ set +o xtrace
+ return 1
+ check_neutron_third_party_integration
+ _neutron_third_party_do check
+ is_service_enabled neutron
++ set +o
++ grep xtrace
+ local 'xtrace=set -o xtrace'
+ set +o xtrace
+ return 0
+ start_neutron_agents
+ run_process q-agt 'python /usr/local/bin/neutron-openvswitch-agent --config-file /etc/neutron/neutron.conf --config-file /etc/neutron/plugins/ml2/ml2_conf.ini'
+ local service=q-agt
+ local 'command=python /usr/local/bin/neutron-openvswitch-agent --config-file /etc/neutron/neutron.conf --config-file /etc/neutron/plugins/ml2/ml2_conf.ini'
+ local group=
+ is_service_enabled q-agt
++ set +o
++ grep xtrace
+ local 'xtrace=set -o xtrace'
+ set +o xtrace
+ return 0
+ [[ True = \T\r\u\e ]]
+ screen_service q-agt 'python /usr/local/bin/neutron-openvswitch-agent --config-file /etc/neutron/neutron.conf --config-file /etc/neutron/plugins/ml2/ml2_conf.ini' ''
+ local service=q-agt
+ local 'command=python /usr/local/bin/neutron-openvswitch-agent --config-file /etc/neutron/neutron.conf --config-file /etc/neutron/plugins/ml2/ml2_conf.ini'
+ local group=
+ SCREEN_NAME=stack
+ SERVICE_DIR=/opt/stack/status
++ trueorfalse True True
+++ set +o
+++ grep xtrace
++ local 'xtrace=set -o xtrace'
++ set +o xtrace
+ USE_SCREEN=True
+ is_service_enabled q-agt
++ set +o
++ grep xtrace
+ local 'xtrace=set -o xtrace'
+ set +o xtrace
+ return 0
+ screen_rc q-agt 'python /usr/local/bin/neutron-openvswitch-agent --config-file /etc/neutron/neutron.conf --config-file /etc/neutron/plugins/ml2/ml2_conf.ini'
+ SCREEN_NAME=stack
+ SCREENRC=/home/cloudbase/devstack/stack-screenrc
+ [[ ! -e /home/cloudbase/devstack/stack-screenrc ]]
+ grep q-agt /home/cloudbase/devstack/stack-screenrc
++ echo -ne '\015'
+ NL=$'\r'
+ echo 'screen -t q-agt bash'
+ echo 'stuff "python /usr/local/bin/neutron-openvswitch-agent --config-file /etc/neutron/neutron.conf --config-file /etc/neutron/plugins/ml2/ml2_conf.ini"'
+ [[ -n /home/cloudbase/jenkins/workspace/openstack-hyperv-release-tests/reports/2014_12_12_13_16_55_547646598/HyperV2012_VHD_v1/logs/devstack ]]
+ echo 'logfile /home/cloudbase/jenkins/workspace/openstack-hyperv-release-tests/reports/2014_12_12_13_16_55_547646598/HyperV2012_VHD_v1/logs/devstack/screen-q-agt.2014-12-12-162857.log'
+ echo 'log on'
+ screen -S stack -X screen -t q-agt
+ [[ -n /home/cloudbase/jenkins/workspace/openstack-hyperv-release-tests/reports/2014_12_12_13_16_55_547646598/HyperV2012_VHD_v1/logs/devstack ]]
+ screen -S stack -p q-agt -X logfile /home/cloudbase/jenkins/workspace/openstack-hyperv-release-tests/reports/2014_12_12_13_16_55_547646598/HyperV2012_VHD_v1/logs/devstack/screen-q-agt.2014-12-12-162857.log
+ screen -S stack -p q-agt -X log on
+ ln -sf /home/cloudbase/jenkins/workspace/openstack-hyperv-release-tests/reports/2014_12_12_13_16_55_547646598/HyperV2012_VHD_v1/logs/devstack/screen-q-agt.2014-12-12-162857.log /home/cloudbase/jenkins/workspace/openstack-hyperv-release-tests/reports/2014_12_12_13_16_55_547646598/HyperV2012_VHD_v1/logs/devstack/screen-q-agt.log
+ sleep 3
++ echo -ne '\015'
+ NL=$'\r'
+ [[ -n '' ]]
+ screen -S stack -p q-agt -X stuff 'python /usr/local/bin/neutron-openvswitch-agent --config-file /etc/neutron/neutron.conf --config-file /etc/neutron/plugins/ml2/ml2_conf.ini & echo $! >/opt/stack/status/stack/q-agt.pid; fg || echo "q-agt failed to start" | tee "/opt/stack/status/stack/q-agt.failure"'
+ run_process q-dhcp 'python /usr/local/bin/neutron-dhcp-agent --config-file /etc/neutron/neutron.conf --config-file=/etc/neutron/dhcp_agent.ini'
+ local service=q-dhcp
+ local 'command=python /usr/local/bin/neutron-dhcp-agent --config-file /etc/neutron/neutron.conf --config-file=/etc/neutron/dhcp_agent.ini'
+ local group=
+ is_service_enabled q-dhcp
++ set +o
++ grep xtrace
+ local 'xtrace=set -o xtrace'
+ set +o xtrace
+ return 0
+ [[ True = \T\r\u\e ]]
+ screen_service q-dhcp 'python /usr/local/bin/neutron-dhcp-agent --config-file /etc/neutron/neutron.conf --config-file=/etc/neutron/dhcp_agent.ini' ''
+ local service=q-dhcp
+ local 'command=python /usr/local/bin/neutron-dhcp-agent --config-file /etc/neutron/neutron.conf --config-file=/etc/neutron/dhcp_agent.ini'
+ local group=
+ SCREEN_NAME=stack
+ SERVICE_DIR=/opt/stack/status
++ trueorfalse True True
+++ set +o
+++ grep xtrace
++ local 'xtrace=set -o xtrace'
++ set +o xtrace
+ USE_SCREEN=True
+ is_service_enabled q-dhcp
++ grep xtrace
+ local 'xtrace=set -o xtrace'
+ set +o xtrace
+ return 0
+ screen_rc q-dhcp 'python /usr/local/bin/neutron-dhcp-agent --config-file /etc/neutron/neutron.conf --config-file=/etc/neutron/dhcp_agent.ini'
+ SCREEN_NAME=stack
+ SCREENRC=/home/cloudbase/devstack/stack-screenrc
+ [[ ! -e /home/cloudbase/devstack/stack-screenrc ]]
+ grep q-dhcp /home/cloudbase/devstack/stack-screenrc
++ echo -ne '\015'
+ NL=$'\r'
+ echo 'screen -t q-dhcp bash'
+ echo 'stuff "python /usr/local/bin/neutron-dhcp-agent --config-file /etc/neutron/neutron.conf --config-file=/etc/neutron/dhcp_agent.ini"'
+ [[ -n /home/cloudbase/jenkins/workspace/openstack-hyperv-release-tests/reports/2014_12_12_13_16_55_547646598/HyperV2012_VHD_v1/logs/devstack ]]
+ echo 'logfile /home/cloudbase/jenkins/workspace/openstack-hyperv-release-tests/reports/2014_12_12_13_16_55_547646598/HyperV2012_VHD_v1/logs/devstack/screen-q-dhcp.2014-12-12-162857.log'
+ echo 'log on'
+ screen -S stack -X screen -t q-dhcp
+ [[ -n /home/cloudbase/jenkins/workspace/openstack-hyperv-release-tests/reports/2014_12_12_13_16_55_547646598/HyperV2012_VHD_v1/logs/devstack ]]
+ screen -S stack -p q-dhcp -X logfile /home/cloudbase/jenkins/workspace/openstack-hyperv-release-tests/reports/2014_12_12_13_16_55_547646598/HyperV2012_VHD_v1/logs/devstack/screen-q-dhcp.2014-12-12-162857.log
+ screen -S stack -p q-dhcp -X log on
+ ln -sf /home/cloudbase/jenkins/workspace/openstack-hyperv-release-tests/reports/2014_12_12_13_16_55_547646598/HyperV2012_VHD_v1/logs/devstack/screen-q-dhcp.2014-12-12-162857.log /home/cloudbase/jenkins/workspace/openstack-hyperv-release-tests/reports/2014_12_12_13_16_55_547646598/HyperV2012_VHD_v1/logs/devstack/screen-q-dhcp.log
+ sleep 3
++ echo -ne '\015'
+ NL=$'\r'
+ [[ -n '' ]]
+ screen -S stack -p q-dhcp -X stuff 'python /usr/local/bin/neutron-dhcp-agent --config-file /etc/neutron/neutron.conf --config-file=/etc/neutron/dhcp_agent.ini & echo $! >/opt/stack/status/stack/q-dhcp.pid; fg || echo "q-dhcp failed to start" | tee "/opt/stack/status/stack/q-dhcp.failure"'
+ is_provider_network
+ '[' '' == True ']'
+ return 1
+ is_service_enabled q-vpn
++ grep xtrace
++ set +o
+ local 'xtrace=set -o xtrace'
+ set +o xtrace
+ return 0
++ determine_config_files neutron-vpn-agent
++ local opts=
++ case "$1" in
+++ _determine_config_vpn
+++ local cfg_file
+++ local 'opts=--config-file /etc/neutron/neutron.conf --config-file=/etc/neutron/l3_agent.ini --config-file=/etc/neutron/vpn_agent.ini'
+++ is_service_enabled q-fwaas
++++ grep xtrace
++++ set +o
+++ local 'xtrace=set -o xtrace'
+++ set +o xtrace
+++ return 0
+++ opts+=' --config-file /etc/neutron/fwaas_driver.ini'
+++ echo '--config-file /etc/neutron/neutron.conf --config-file=/etc/neutron/l3_agent.ini --config-file=/etc/neutron/vpn_agent.ini --config-file /etc/neutron/fwaas_driver.ini'
++ opts='--config-file /etc/neutron/neutron.conf --config-file=/etc/neutron/l3_agent.ini --config-file=/etc/neutron/vpn_agent.ini --config-file /etc/neutron/fwaas_driver.ini'
++ '[' -z '--config-file /etc/neutron/neutron.conf --config-file=/etc/neutron/l3_agent.ini --config-file=/etc/neutron/vpn_agent.ini --config-file /etc/neutron/fwaas_driver.ini' ']'
++ echo '--config-file /etc/neutron/neutron.conf --config-file=/etc/neutron/l3_agent.ini --config-file=/etc/neutron/vpn_agent.ini --config-file /etc/neutron/fwaas_driver.ini'
+ run_process q-vpn '/usr/local/bin/neutron-vpn-agent --config-file /etc/neutron/neutron.conf --config-file=/etc/neutron/l3_agent.ini --config-file=/etc/neutron/vpn_agent.ini --config-file /etc/neutron/fwaas_driver.ini'
+ local service=q-vpn
+ local 'command=/usr/local/bin/neutron-vpn-agent --config-file /etc/neutron/neutron.conf --config-file=/etc/neutron/l3_agent.ini --config-file=/etc/neutron/vpn_agent.ini --config-file /etc/neutron/fwaas_driver.ini'
+ local group=
+ is_service_enabled q-vpn
++ set +o
++ grep xtrace
+ local 'xtrace=set -o xtrace'
+ set +o xtrace
+ return 0
+ [[ True = \T\r\u\e ]]
+ screen_service q-vpn '/usr/local/bin/neutron-vpn-agent --config-file /etc/neutron/neutron.conf --config-file=/etc/neutron/l3_agent.ini --config-file=/etc/neutron/vpn_agent.ini --config-file /etc/neutron/fwaas_driver.ini' ''
+ local service=q-vpn
+ local 'command=/usr/local/bin/neutron-vpn-agent --config-file /etc/neutron/neutron.conf --config-file=/etc/neutron/l3_agent.ini --config-file=/etc/neutron/vpn_agent.ini --config-file /etc/neutron/fwaas_driver.ini'
+ local group=
+ SCREEN_NAME=stack
+ SERVICE_DIR=/opt/stack/status
++ trueorfalse True True
+++ grep xtrace
+++ set +o
++ local 'xtrace=set -o xtrace'
++ set +o xtrace
+ USE_SCREEN=True
+ is_service_enabled q-vpn
++ grep xtrace
++ set +o
+ local 'xtrace=set -o xtrace'
+ set +o xtrace
+ return 0
+ screen_rc q-vpn '/usr/local/bin/neutron-vpn-agent --config-file /etc/neutron/neutron.conf --config-file=/etc/neutron/l3_agent.ini --config-file=/etc/neutron/vpn_agent.ini --config-file /etc/neutron/fwaas_driver.ini'
+ SCREEN_NAME=stack
+ SCREENRC=/home/cloudbase/devstack/stack-screenrc
+ [[ ! -e /home/cloudbase/devstack/stack-screenrc ]]
+ grep q-vpn /home/cloudbase/devstack/stack-screenrc
++ echo -ne '\015'
+ NL=$'\r'
+ echo 'screen -t q-vpn bash'
+ echo 'stuff "/usr/local/bin/neutron-vpn-agent --config-file /etc/neutron/neutron.conf --config-file=/etc/neutron/l3_agent.ini --config-file=/etc/neutron/vpn_agent.ini --config-file /etc/neutron/fwaas_driver.ini"'
+ [[ -n /home/cloudbase/jenkins/workspace/openstack-hyperv-release-tests/reports/2014_12_12_13_16_55_547646598/HyperV2012_VHD_v1/logs/devstack ]]
+ echo 'logfile /home/cloudbase/jenkins/workspace/openstack-hyperv-release-tests/reports/2014_12_12_13_16_55_547646598/HyperV2012_VHD_v1/logs/devstack/screen-q-vpn.2014-12-12-162857.log'
+ echo 'log on'
+ screen -S stack -X screen -t q-vpn
+ [[ -n /home/cloudbase/jenkins/workspace/openstack-hyperv-release-tests/reports/2014_12_12_13_16_55_547646598/HyperV2012_VHD_v1/logs/devstack ]]
+ screen -S stack -p q-vpn -X logfile /home/cloudbase/jenkins/workspace/openstack-hyperv-release-tests/reports/2014_12_12_13_16_55_547646598/HyperV2012_VHD_v1/logs/devstack/screen-q-vpn.2014-12-12-162857.log
+ screen -S stack -p q-vpn -X log on
+ ln -sf /home/cloudbase/jenkins/workspace/openstack-hyperv-release-tests/reports/2014_12_12_13_16_55_547646598/HyperV2012_VHD_v1/logs/devstack/screen-q-vpn.2014-12-12-162857.log /home/cloudbase/jenkins/workspace/openstack-hyperv-release-tests/reports/2014_12_12_13_16_55_547646598/HyperV2012_VHD_v1/logs/devstack/screen-q-vpn.log
+ sleep 3
++ echo -ne '\015'
+ NL=$'\r'
+ [[ -n '' ]]
+ screen -S stack -p q-vpn -X stuff '/usr/local/bin/neutron-vpn-agent --config-file /etc/neutron/neutron.conf --config-file=/etc/neutron/l3_agent.ini --config-file=/etc/neutron/vpn_agent.ini --config-file /etc/neutron/fwaas_driver.ini & echo $! >/opt/stack/status/stack/q-vpn.pid; fg || echo "q-vpn failed to start" | tee "/opt/stack/status/stack/q-vpn.failure"'
+ run_process q-meta 'python /usr/local/bin/neutron-metadata-agent --config-file /etc/neutron/neutron.conf --config-file=/etc/neutron/metadata_agent.ini'
+ local service=q-meta
+ local 'command=python /usr/local/bin/neutron-metadata-agent --config-file /etc/neutron/neutron.conf --config-file=/etc/neutron/metadata_agent.ini'
+ local group=
+ is_service_enabled q-meta
++ set +o
++ grep xtrace
+ local 'xtrace=set -o xtrace'
+ set +o xtrace
+ return 0
+ [[ True = \T\r\u\e ]]
+ screen_service q-meta 'python /usr/local/bin/neutron-metadata-agent --config-file /etc/neutron/neutron.conf --config-file=/etc/neutron/metadata_agent.ini' ''
+ local service=q-meta
+ local 'command=python /usr/local/bin/neutron-metadata-agent --config-file /etc/neutron/neutron.conf --config-file=/etc/neutron/metadata_agent.ini'
+ local group=
+ SCREEN_NAME=stack
+ SERVICE_DIR=/opt/stack/status
++ trueorfalse True True
+++ set +o
+++ grep xtrace
++ local 'xtrace=set -o xtrace'
++ set +o xtrace
+ USE_SCREEN=True
+ is_service_enabled q-meta
++ grep xtrace
++ set +o
+ local 'xtrace=set -o xtrace'
+ set +o xtrace
+ return 0
+ screen_rc q-meta 'python /usr/local/bin/neutron-metadata-agent --config-file /etc/neutron/neutron.conf --config-file=/etc/neutron/metadata_agent.ini'
+ SCREEN_NAME=stack
+ SCREENRC=/home/cloudbase/devstack/stack-screenrc
+ [[ ! -e /home/cloudbase/devstack/stack-screenrc ]]
+ grep q-meta /home/cloudbase/devstack/stack-screenrc
++ echo -ne '\015'
+ NL=$'\r'
+ echo 'screen -t q-meta bash'
+ echo 'stuff "python /usr/local/bin/neutron-metadata-agent --config-file /etc/neutron/neutron.conf --config-file=/etc/neutron/metadata_agent.ini"'
+ [[ -n /home/cloudbase/jenkins/workspace/openstack-hyperv-release-tests/reports/2014_12_12_13_16_55_547646598/HyperV2012_VHD_v1/logs/devstack ]]
+ echo 'logfile /home/cloudbase/jenkins/workspace/openstack-hyperv-release-tests/reports/2014_12_12_13_16_55_547646598/HyperV2012_VHD_v1/logs/devstack/screen-q-meta.2014-12-12-162857.log'
+ echo 'log on'
+ screen -S stack -X screen -t q-meta
+ [[ -n /home/cloudbase/jenkins/workspace/openstack-hyperv-release-tests/reports/2014_12_12_13_16_55_547646598/HyperV2012_VHD_v1/logs/devstack ]]
+ screen -S stack -p q-meta -X logfile /home/cloudbase/jenkins/workspace/openstack-hyperv-release-tests/reports/2014_12_12_13_16_55_547646598/HyperV2012_VHD_v1/logs/devstack/screen-q-meta.2014-12-12-162857.log
+ screen -S stack -p q-meta -X log on
+ ln -sf /home/cloudbase/jenkins/workspace/openstack-hyperv-release-tests/reports/2014_12_12_13_16_55_547646598/HyperV2012_VHD_v1/logs/devstack/screen-q-meta.2014-12-12-162857.log /home/cloudbase/jenkins/workspace/openstack-hyperv-release-tests/reports/2014_12_12_13_16_55_547646598/HyperV2012_VHD_v1/logs/devstack/screen-q-meta.log
+ sleep 3
++ echo -ne '\015'
+ NL=$'\r'
+ [[ -n '' ]]
+ screen -S stack -p q-meta -X stuff 'python /usr/local/bin/neutron-metadata-agent --config-file /etc/neutron/neutron.conf --config-file=/etc/neutron/metadata_agent.ini & echo $! >/opt/stack/status/stack/q-meta.pid; fg || echo "q-meta failed to start" | tee "/opt/stack/status/stack/q-meta.failure"'
+ '[' libvirt = xenserver ']'
+ is_service_enabled q-lbaas
++ set +o
++ grep xtrace
+ local 'xtrace=set -o xtrace'
+ set +o xtrace
+ return 0
+ run_process q-lbaas 'python /usr/local/bin/neutron-lbaas-agent --config-file /etc/neutron/neutron.conf --config-file=/etc/neutron/services/loadbalancer/haproxy/lbaas_agent.ini'
+ local service=q-lbaas
+ local 'command=python /usr/local/bin/neutron-lbaas-agent --config-file /etc/neutron/neutron.conf --config-file=/etc/neutron/services/loadbalancer/haproxy/lbaas_agent.ini'
+ local group=
+ is_service_enabled q-lbaas
++ set +o
++ grep xtrace
+ local 'xtrace=set -o xtrace'
+ set +o xtrace
+ return 0
+ [[ True = \T\r\u\e ]]
+ screen_service q-lbaas 'python /usr/local/bin/neutron-lbaas-agent --config-file /etc/neutron/neutron.conf --config-file=/etc/neutron/services/loadbalancer/haproxy/lbaas_agent.ini' ''
+ local service=q-lbaas
+ local 'command=python /usr/local/bin/neutron-lbaas-agent --config-file /etc/neutron/neutron.conf --config-file=/etc/neutron/services/loadbalancer/haproxy/lbaas_agent.ini'
+ local group=
+ SCREEN_NAME=stack
+ SERVICE_DIR=/opt/stack/status
++ trueorfalse True True
+++ set +o
+++ grep xtrace
++ local 'xtrace=set -o xtrace'
++ set +o xtrace
+ USE_SCREEN=True
+ is_service_enabled q-lbaas
++ set +o
++ grep xtrace
+ local 'xtrace=set -o xtrace'
+ set +o xtrace
+ return 0
+ screen_rc q-lbaas 'python /usr/local/bin/neutron-lbaas-agent --config-file /etc/neutron/neutron.conf --config-file=/etc/neutron/services/loadbalancer/haproxy/lbaas_agent.ini'
+ SCREEN_NAME=stack
+ SCREENRC=/home/cloudbase/devstack/stack-screenrc
+ [[ ! -e /home/cloudbase/devstack/stack-screenrc ]]
+ grep q-lbaas /home/cloudbase/devstack/stack-screenrc
++ echo -ne '\015'
+ NL=$'\r'
+ echo 'screen -t q-lbaas bash'
+ echo 'stuff "python /usr/local/bin/neutron-lbaas-agent --config-file /etc/neutron/neutron.conf --config-file=/etc/neutron/services/loadbalancer/haproxy/lbaas_agent.ini"'
+ [[ -n /home/cloudbase/jenkins/workspace/openstack-hyperv-release-tests/reports/2014_12_12_13_16_55_547646598/HyperV2012_VHD_v1/logs/devstack ]]
+ echo 'logfile /home/cloudbase/jenkins/workspace/openstack-hyperv-release-tests/reports/2014_12_12_13_16_55_547646598/HyperV2012_VHD_v1/logs/devstack/screen-q-lbaas.2014-12-12-162857.log'
+ echo 'log on'
+ screen -S stack -X screen -t q-lbaas
+ [[ -n /home/cloudbase/jenkins/workspace/openstack-hyperv-release-tests/reports/2014_12_12_13_16_55_547646598/HyperV2012_VHD_v1/logs/devstack ]]
+ screen -S stack -p q-lbaas -X logfile /home/cloudbase/jenkins/workspace/openstack-hyperv-release-tests/reports/2014_12_12_13_16_55_547646598/HyperV2012_VHD_v1/logs/devstack/screen-q-lbaas.2014-12-12-162857.log
+ screen -S stack -p q-lbaas -X log on
+ ln -sf /home/cloudbase/jenkins/workspace/openstack-hyperv-release-tests/reports/2014_12_12_13_16_55_547646598/HyperV2012_VHD_v1/logs/devstack/screen-q-lbaas.2014-12-12-162857.log /home/cloudbase/jenkins/workspace/openstack-hyperv-release-tests/reports/2014_12_12_13_16_55_547646598/HyperV2012_VHD_v1/logs/devstack/screen-q-lbaas.log
+ sleep 3
++ echo -ne '\015'
+ NL=$'\r'
+ [[ -n '' ]]
+ screen -S stack -p q-lbaas -X stuff 'python /usr/local/bin/neutron-lbaas-agent --config-file /etc/neutron/neutron.conf --config-file=/etc/neutron/services/loadbalancer/haproxy/lbaas_agent.ini & echo $! >/opt/stack/status/stack/q-lbaas.pid; fg || echo "q-lbaas failed to start" | tee "/opt/stack/status/stack/q-lbaas.failure"'
+ is_service_enabled q-metering
++ set +o
++ grep xtrace
+ local 'xtrace=set -o xtrace'
+ set +o xtrace
+ return 0
+ run_process q-metering 'python /usr/local/bin/neutron-metering-agent --config-file /etc/neutron/neutron.conf --config-file /etc/neutron/services/metering/metering_agent.ini'
+ local service=q-metering
+ local 'command=python /usr/local/bin/neutron-metering-agent --config-file /etc/neutron/neutron.conf --config-file /etc/neutron/services/metering/metering_agent.ini'
+ local group=
+ is_service_enabled q-metering
++ set +o
++ grep xtrace
+ local 'xtrace=set -o xtrace'
+ set +o xtrace
+ return 0
+ [[ True = \T\r\u\e ]]
+ screen_service q-metering 'python /usr/local/bin/neutron-metering-agent --config-file /etc/neutron/neutron.conf --config-file /etc/neutron/services/metering/metering_agent.ini' ''
+ local service=q-metering
+ local 'command=python /usr/local/bin/neutron-metering-agent --config-file /etc/neutron/neutron.conf --config-file /etc/neutron/services/metering/metering_agent.ini'
+ local group=
+ SCREEN_NAME=stack
+ SERVICE_DIR=/opt/stack/status
++ trueorfalse True True
+++ set +o
+++ grep xtrace
++ local 'xtrace=set -o xtrace'
++ set +o xtrace
+ USE_SCREEN=True
+ is_service_enabled q-metering
++ set +o
++ grep xtrace
+ local 'xtrace=set -o xtrace'
+ set +o xtrace
+ return 0
+ screen_rc q-metering 'python /usr/local/bin/neutron-metering-agent --config-file /etc/neutron/neutron.conf --config-file /etc/neutron/services/metering/metering_agent.ini'
+ SCREEN_NAME=stack
+ SCREENRC=/home/cloudbase/devstack/stack-screenrc
+ [[ ! -e /home/cloudbase/devstack/stack-screenrc ]]
+ grep q-metering /home/cloudbase/devstack/stack-screenrc
++ echo -ne '\015'
+ NL=$'\r'
+ echo 'screen -t q-metering bash'
+ echo 'stuff "python /usr/local/bin/neutron-metering-agent --config-file /etc/neutron/neutron.conf --config-file /etc/neutron/services/metering/metering_agent.ini"'
+ [[ -n /home/cloudbase/jenkins/workspace/openstack-hyperv-release-tests/reports/2014_12_12_13_16_55_547646598/HyperV2012_VHD_v1/logs/devstack ]]
+ echo 'logfile /home/cloudbase/jenkins/workspace/openstack-hyperv-release-tests/reports/2014_12_12_13_16_55_547646598/HyperV2012_VHD_v1/logs/devstack/screen-q-metering.2014-12-12-162857.log'
+ echo 'log on'
+ screen -S stack -X screen -t q-metering
+ [[ -n /home/cloudbase/jenkins/workspace/openstack-hyperv-release-tests/reports/2014_12_12_13_16_55_547646598/HyperV2012_VHD_v1/logs/devstack ]]
+ screen -S stack -p q-metering -X logfile /home/cloudbase/jenkins/workspace/openstack-hyperv-release-tests/reports/2014_12_12_13_16_55_547646598/HyperV2012_VHD_v1/logs/devstack/screen-q-metering.2014-12-12-162857.log
+ screen -S stack -p q-metering -X log on
+ ln -sf /home/cloudbase/jenkins/workspace/openstack-hyperv-release-tests/reports/2014_12_12_13_16_55_547646598/HyperV2012_VHD_v1/logs/devstack/screen-q-metering.2014-12-12-162857.log /home/cloudbase/jenkins/workspace/openstack-hyperv-release-tests/reports/2014_12_12_13_16_55_547646598/HyperV2012_VHD_v1/logs/devstack/screen-q-metering.log
+ sleep 3
++ echo -ne '\015'
+ NL=$'\r'
+ [[ -n '' ]]
+ screen -S stack -p q-metering -X stuff 'python /usr/local/bin/neutron-metering-agent --config-file /etc/neutron/neutron.conf --config-file /etc/neutron/services/metering/metering_agent.ini & echo $! >/opt/stack/status/stack/q-metering.pid; fg || echo "q-metering failed to start" | tee "/opt/stack/status/stack/q-metering.failure"'
+ is_service_enabled q-svc
++ set +o
++ grep xtrace
+ local 'xtrace=set -o xtrace'
+ set +o xtrace
+ return 0
+ echo_summary 'Creating initial neutron network elements'
+ [[ -t 3 ]]
+ echo -e Creating initial neutron network elements
+ create_neutron_initial_network
++ openstack project list
++ grep ' demo '
++ get_field 1
++ local data field
++ read data
++ '[' 1 -lt 0 ']'
++ field='$2'
++ echo '| e925366f53424cdeb40943a8495711df | demo               |'
++ awk '-F[ \t]*\\|[ \t]*' '{print $2}'
++ read data
+ TENANT_ID=e925366f53424cdeb40943a8495711df
+ die_if_not_set 501 TENANT_ID 'Failure retrieving TENANT_ID for demo'
+ local exitcode=0
++ set +o
++ grep xtrace
+ local 'xtrace=set -o xtrace'
+ set +o xtrace
+ is_baremetal
+ [[ g-api,g-reg,key,n-api,n-crt,n-obj,n-cond,n-sch,n-xvnc,n-cauth,c-sch,c-api,c-vol,h-eng,h-api,h-api-cfn,h-api-cw,rabbit,tempest,mysql,neutron,q-svc,q-agt,q-dhcp,q-l3,q-meta,q-lbaas,q-fwaas,q-metering,q-vpn,c-bak,s-proxy,s-object,s-container,s-account,heat,ceilometer-acentral,ceilometer-collector,ceilometer-api =~ baremetal ]]
+ return 1
+ is_provider_network
+ '[' '' == True ']'
+ return 1
++ neutron net-create --tenant-id e925366f53424cdeb40943a8495711df private
++ grep ' id '
++ get_field 2
++ local data field
++ read data
++ '[' 2 -lt 0 ']'
++ field='$3'
++ echo '| id                        | 9924ed72-64e9-4065-afbc-fa7a0f9a7c0a |'
++ awk '-F[ \t]*\\|[ \t]*' '{print $3}'
++ read data
+ NET_ID=9924ed72-64e9-4065-afbc-fa7a0f9a7c0a
+ die_if_not_set 532 NET_ID 'Failure creating NET_ID for physnet1 e925366f53424cdeb40943a8495711df'
+ local exitcode=0
++ set +o
++ grep xtrace
+ local 'xtrace=set -o xtrace'
+ set +o xtrace
++ neutron subnet-create --tenant-id e925366f53424cdeb40943a8495711df --ip_version 4 --gateway 10.0.0.1 --name private-subnet 9924ed72-64e9-4065-afbc-fa7a0f9a7c0a 10.0.0.0/24
++ grep ' id '
++ get_field 2
++ local data field
++ read data
++ '[' 2 -lt 0 ']'
++ field='$3'
++ echo '| id                | 19288f46-3d3a-47d6-ae2c-a5400d441758       |'
++ awk '-F[ \t]*\\|[ \t]*' '{print $3}'
++ read data
+ SUBNET_ID=19288f46-3d3a-47d6-ae2c-a5400d441758
+ die_if_not_set 534 SUBNET_ID 'Failure creating SUBNET_ID for e925366f53424cdeb40943a8495711df'
+ local exitcode=0
++ set +o
++ grep xtrace
+ local 'xtrace=set -o xtrace'
+ set +o xtrace
+ [[ True == \T\r\u\e ]]
+ [[ True == \T\r\u\e ]]
++ neutron router-create --tenant-id e925366f53424cdeb40943a8495711df router1
++ grep ' id '
++ get_field 2
++ local data field
++ read data
++ '[' 2 -lt 0 ']'
++ field='$3'
++ echo '| id                    | 8a4a157a-5cfb-4303-b8dd-12da493e2528 |'
++ awk '-F[ \t]*\\|[ \t]*' '{print $3}'
++ read data
+ ROUTER_ID=8a4a157a-5cfb-4303-b8dd-12da493e2528
+ die_if_not_set 542 ROUTER_ID 'Failure creating ROUTER_ID for e925366f53424cdeb40943a8495711df router1'
+ local exitcode=0
++ set +o
++ grep xtrace
+ local 'xtrace=set -o xtrace'
+ set +o xtrace
+ neutron router-interface-add 8a4a157a-5cfb-4303-b8dd-12da493e2528 19288f46-3d3a-47d6-ae2c-a5400d441758
+ '[' False = True ']'
++ neutron net-create public -- --router:external=True
++ get_field 2
++ local data field
++ read data
++ grep ' id '
++ '[' 2 -lt 0 ']'
++ field='$3'
++ echo '| id                        | b7d1f5c2-5e53-4435-9e9a-f492fe1b3ab2 |'
++ awk '-F[ \t]*\\|[ \t]*' '{print $3}'
++ read data
+ EXT_NET_ID=b7d1f5c2-5e53-4435-9e9a-f492fe1b3ab2
+ die_if_not_set 555 EXT_NET_ID 'Failure creating EXT_NET_ID for public'
+ local exitcode=0
++ set +o
++ grep xtrace
+ local 'xtrace=set -o xtrace'
+ set +o xtrace
++ neutron subnet-create --ip_version 4 --gateway 172.24.4.1 --name public-subnet b7d1f5c2-5e53-4435-9e9a-f492fe1b3ab2 172.24.4.0/24 -- --enable_dhcp=False
++ get_field 2
++ local data field
++ read data
++ grep gateway_ip
++ '[' 2 -lt 0 ']'
++ field='$3'
++ echo '| gateway_ip        | 172.24.4.1                                     |'
++ awk '-F[ \t]*\\|[ \t]*' '{print $3}'
++ read data
+ EXT_GW_IP=172.24.4.1
+ die_if_not_set 557 EXT_GW_IP 'Failure creating EXT_GW_IP'
+ local exitcode=0
++ grep xtrace
++ set +o
+ local 'xtrace=set -o xtrace'
+ set +o xtrace
+ neutron router-gateway-set 8a4a157a-5cfb-4303-b8dd-12da493e2528 b7d1f5c2-5e53-4435-9e9a-f492fe1b3ab2
+ is_service_enabled q-l3
++ grep xtrace
++ set +o
+ local 'xtrace=set -o xtrace'
+ set +o xtrace
+ return 0
+ is_neutron_ovs_base_plugin
+ return 0
+ [[ True = \T\r\u\e ]]
+ local ext_gw_interface
+ [[ False = \T\r\u\e ]]
+ sudo ovs-vsctl set Bridge br-ex other_config:disable-in-band=true
+ ext_gw_interface=br-ex
+ CIDR_LEN=24
+ sudo ip addr add 172.24.4.1/24 dev br-ex
+ sudo ip link set br-ex up
++ neutron port-list -c fixed_ips -c device_owner
++ grep router_gateway
++ awk -F '"' '{ print $8; }'
+ ROUTER_GW_IP=172.24.4.2
+ die_if_not_set 578 ROUTER_GW_IP 'Failure retrieving ROUTER_GW_IP'
+ local exitcode=0
++ set +o
++ grep xtrace
+ local 'xtrace=set -o xtrace'
+ set +o xtrace
+ sudo route add -net 10.0.0.0/24 gw 172.24.4.2
+ [[ True == \F\a\l\s\e ]]
+ setup_neutron_debug
+ [[ False == \T\r\u\e ]]
+ is_service_enabled nova
++ set +o
++ grep xtrace
+ local 'xtrace=set -o xtrace'
+ set +o xtrace
+ return 0
+ echo_summary 'Starting Nova'
+ [[ -t 3 ]]
+ echo -e Starting Nova
+ start_nova
+ start_nova_compute
+ is_service_enabled n-cell
++ set +o
++ grep xtrace
+ local 'xtrace=set -o xtrace'
+ set +o xtrace
+ return 1
+ local compute_cell_conf=/etc/nova/nova.conf
+ [[ libvirt = \l\i\b\v\i\r\t ]]
+ run_process n-cpu '/usr/local/bin/nova-compute --config-file /etc/nova/nova.conf' libvirtd
+ local service=n-cpu
+ local 'command=/usr/local/bin/nova-compute --config-file /etc/nova/nova.conf'
+ local group=libvirtd
+ is_service_enabled n-cpu
++ grep xtrace
++ set +o
+ local 'xtrace=set -o xtrace'
+ set +o xtrace
+ return 1
+ start_nova_rest
+ local api_cell_conf=/etc/nova/nova.conf
+ is_service_enabled n-cell
++ grep xtrace
++ set +o
+ local 'xtrace=set -o xtrace'
+ set +o xtrace
+ return 1
+ local compute_cell_conf=/etc/nova/nova.conf
+ run_process n-cond '/usr/local/bin/nova-conductor --config-file /etc/nova/nova.conf'
+ local service=n-cond
+ local 'command=/usr/local/bin/nova-conductor --config-file /etc/nova/nova.conf'
+ local group=
+ is_service_enabled n-cond
++ set +o
++ grep xtrace
+ local 'xtrace=set -o xtrace'
+ set +o xtrace
+ return 0
+ [[ True = \T\r\u\e ]]
+ screen_service n-cond '/usr/local/bin/nova-conductor --config-file /etc/nova/nova.conf' ''
+ local service=n-cond
+ local 'command=/usr/local/bin/nova-conductor --config-file /etc/nova/nova.conf'
+ local group=
+ SCREEN_NAME=stack
+ SERVICE_DIR=/opt/stack/status
++ trueorfalse True True
+++ set +o
+++ grep xtrace
++ local 'xtrace=set -o xtrace'
++ set +o xtrace
+ USE_SCREEN=True
+ is_service_enabled n-cond
++ set +o
++ grep xtrace
+ local 'xtrace=set -o xtrace'
+ set +o xtrace
+ return 0
+ screen_rc n-cond '/usr/local/bin/nova-conductor --config-file /etc/nova/nova.conf'
+ SCREEN_NAME=stack
+ SCREENRC=/home/cloudbase/devstack/stack-screenrc
+ [[ ! -e /home/cloudbase/devstack/stack-screenrc ]]
+ grep n-cond /home/cloudbase/devstack/stack-screenrc
++ echo -ne '\015'
+ NL=$'\r'
+ echo 'screen -t n-cond bash'
+ echo 'stuff "/usr/local/bin/nova-conductor --config-file /etc/nova/nova.conf"'
+ [[ -n /home/cloudbase/jenkins/workspace/openstack-hyperv-release-tests/reports/2014_12_12_13_16_55_547646598/HyperV2012_VHD_v1/logs/devstack ]]
+ echo 'logfile /home/cloudbase/jenkins/workspace/openstack-hyperv-release-tests/reports/2014_12_12_13_16_55_547646598/HyperV2012_VHD_v1/logs/devstack/screen-n-cond.2014-12-12-162857.log'
+ echo 'log on'
+ screen -S stack -X screen -t n-cond
+ [[ -n /home/cloudbase/jenkins/workspace/openstack-hyperv-release-tests/reports/2014_12_12_13_16_55_547646598/HyperV2012_VHD_v1/logs/devstack ]]
+ screen -S stack -p n-cond -X logfile /home/cloudbase/jenkins/workspace/openstack-hyperv-release-tests/reports/2014_12_12_13_16_55_547646598/HyperV2012_VHD_v1/logs/devstack/screen-n-cond.2014-12-12-162857.log
+ screen -S stack -p n-cond -X log on
+ ln -sf /home/cloudbase/jenkins/workspace/openstack-hyperv-release-tests/reports/2014_12_12_13_16_55_547646598/HyperV2012_VHD_v1/logs/devstack/screen-n-cond.2014-12-12-162857.log /home/cloudbase/jenkins/workspace/openstack-hyperv-release-tests/reports/2014_12_12_13_16_55_547646598/HyperV2012_VHD_v1/logs/devstack/screen-n-cond.log
+ sleep 3
++ echo -ne '\015'
+ NL=$'\r'
+ [[ -n '' ]]
+ screen -S stack -p n-cond -X stuff '/usr/local/bin/nova-conductor --config-file /etc/nova/nova.conf & echo $! >/opt/stack/status/stack/n-cond.pid; fg || echo "n-cond failed to start" | tee "/opt/stack/status/stack/n-cond.failure"'
+ run_process n-cell-region '/usr/local/bin/nova-cells --config-file /etc/nova/nova.conf'
+ local service=n-cell-region
+ local 'command=/usr/local/bin/nova-cells --config-file /etc/nova/nova.conf'
+ local group=
+ is_service_enabled n-cell-region
++ grep xtrace
++ set +o
+ local 'xtrace=set -o xtrace'
+ set +o xtrace
+ return 1
+ run_process n-cell-child '/usr/local/bin/nova-cells --config-file /etc/nova/nova.conf'
+ local service=n-cell-child
+ local 'command=/usr/local/bin/nova-cells --config-file /etc/nova/nova.conf'
+ local group=
+ is_service_enabled n-cell-child
++ grep xtrace
++ set +o
+ local 'xtrace=set -o xtrace'
+ set +o xtrace
+ return 1
+ run_process n-crt '/usr/local/bin/nova-cert --config-file /etc/nova/nova.conf'
+ local service=n-crt
+ local 'command=/usr/local/bin/nova-cert --config-file /etc/nova/nova.conf'
+ local group=
+ is_service_enabled n-crt
++ grep xtrace
++ set +o
+ local 'xtrace=set -o xtrace'
+ set +o xtrace
+ return 0
+ [[ True = \T\r\u\e ]]
+ screen_service n-crt '/usr/local/bin/nova-cert --config-file /etc/nova/nova.conf' ''
+ local service=n-crt
+ local 'command=/usr/local/bin/nova-cert --config-file /etc/nova/nova.conf'
+ local group=
+ SCREEN_NAME=stack
+ SERVICE_DIR=/opt/stack/status
++ trueorfalse True True
+++ grep xtrace
+++ set +o
++ local 'xtrace=set -o xtrace'
++ set +o xtrace
+ USE_SCREEN=True
+ is_service_enabled n-crt
++ grep xtrace
++ set +o
+ local 'xtrace=set -o xtrace'
+ set +o xtrace
+ return 0
+ screen_rc n-crt '/usr/local/bin/nova-cert --config-file /etc/nova/nova.conf'
+ SCREEN_NAME=stack
+ SCREENRC=/home/cloudbase/devstack/stack-screenrc
+ [[ ! -e /home/cloudbase/devstack/stack-screenrc ]]
+ grep n-crt /home/cloudbase/devstack/stack-screenrc
++ echo -ne '\015'
+ NL=$'\r'
+ echo 'screen -t n-crt bash'
+ echo 'stuff "/usr/local/bin/nova-cert --config-file /etc/nova/nova.conf"'
+ [[ -n /home/cloudbase/jenkins/workspace/openstack-hyperv-release-tests/reports/2014_12_12_13_16_55_547646598/HyperV2012_VHD_v1/logs/devstack ]]
+ echo 'logfile /home/cloudbase/jenkins/workspace/openstack-hyperv-release-tests/reports/2014_12_12_13_16_55_547646598/HyperV2012_VHD_v1/logs/devstack/screen-n-crt.2014-12-12-162857.log'
+ echo 'log on'
+ screen -S stack -X screen -t n-crt
+ [[ -n /home/cloudbase/jenkins/workspace/openstack-hyperv-release-tests/reports/2014_12_12_13_16_55_547646598/HyperV2012_VHD_v1/logs/devstack ]]
+ screen -S stack -p n-crt -X logfile /home/cloudbase/jenkins/workspace/openstack-hyperv-release-tests/reports/2014_12_12_13_16_55_547646598/HyperV2012_VHD_v1/logs/devstack/screen-n-crt.2014-12-12-162857.log
+ screen -S stack -p n-crt -X log on
+ ln -sf /home/cloudbase/jenkins/workspace/openstack-hyperv-release-tests/reports/2014_12_12_13_16_55_547646598/HyperV2012_VHD_v1/logs/devstack/screen-n-crt.2014-12-12-162857.log /home/cloudbase/jenkins/workspace/openstack-hyperv-release-tests/reports/2014_12_12_13_16_55_547646598/HyperV2012_VHD_v1/logs/devstack/screen-n-crt.log
+ sleep 3
++ echo -ne '\015'
+ NL=$'\r'
+ [[ -n '' ]]
+ screen -S stack -p n-crt -X stuff '/usr/local/bin/nova-cert --config-file /etc/nova/nova.conf & echo $! >/opt/stack/status/stack/n-crt.pid; fg || echo "n-crt failed to start" | tee "/opt/stack/status/stack/n-crt.failure"'
+ run_process n-net '/usr/local/bin/nova-network --config-file /etc/nova/nova.conf'
+ local service=n-net
+ local 'command=/usr/local/bin/nova-network --config-file /etc/nova/nova.conf'
+ local group=
+ is_service_enabled n-net
++ set +o
++ grep xtrace
+ local 'xtrace=set -o xtrace'
+ set +o xtrace
+ return 1
+ run_process n-sch '/usr/local/bin/nova-scheduler --config-file /etc/nova/nova.conf'
+ local service=n-sch
+ local 'command=/usr/local/bin/nova-scheduler --config-file /etc/nova/nova.conf'
+ local group=
+ is_service_enabled n-sch
++ set +o
++ grep xtrace
+ local 'xtrace=set -o xtrace'
+ set +o xtrace
+ return 0
+ [[ True = \T\r\u\e ]]
+ screen_service n-sch '/usr/local/bin/nova-scheduler --config-file /etc/nova/nova.conf' ''
+ local service=n-sch
+ local 'command=/usr/local/bin/nova-scheduler --config-file /etc/nova/nova.conf'
+ local group=
+ SCREEN_NAME=stack
+ SERVICE_DIR=/opt/stack/status
++ trueorfalse True True
+++ grep xtrace
+++ set +o
++ local 'xtrace=set -o xtrace'
++ set +o xtrace
+ USE_SCREEN=True
+ is_service_enabled n-sch
++ set +o
++ grep xtrace
+ local 'xtrace=set -o xtrace'
+ set +o xtrace
+ return 0
+ screen_rc n-sch '/usr/local/bin/nova-scheduler --config-file /etc/nova/nova.conf'
+ SCREEN_NAME=stack
+ SCREENRC=/home/cloudbase/devstack/stack-screenrc
+ [[ ! -e /home/cloudbase/devstack/stack-screenrc ]]
+ grep n-sch /home/cloudbase/devstack/stack-screenrc
++ echo -ne '\015'
+ NL=$'\r'
+ echo 'screen -t n-sch bash'
+ echo 'stuff "/usr/local/bin/nova-scheduler --config-file /etc/nova/nova.conf"'
+ [[ -n /home/cloudbase/jenkins/workspace/openstack-hyperv-release-tests/reports/2014_12_12_13_16_55_547646598/HyperV2012_VHD_v1/logs/devstack ]]
+ echo 'logfile /home/cloudbase/jenkins/workspace/openstack-hyperv-release-tests/reports/2014_12_12_13_16_55_547646598/HyperV2012_VHD_v1/logs/devstack/screen-n-sch.2014-12-12-162857.log'
+ echo 'log on'
+ screen -S stack -X screen -t n-sch
+ [[ -n /home/cloudbase/jenkins/workspace/openstack-hyperv-release-tests/reports/2014_12_12_13_16_55_547646598/HyperV2012_VHD_v1/logs/devstack ]]
+ screen -S stack -p n-sch -X logfile /home/cloudbase/jenkins/workspace/openstack-hyperv-release-tests/reports/2014_12_12_13_16_55_547646598/HyperV2012_VHD_v1/logs/devstack/screen-n-sch.2014-12-12-162857.log
+ screen -S stack -p n-sch -X log on
+ ln -sf /home/cloudbase/jenkins/workspace/openstack-hyperv-release-tests/reports/2014_12_12_13_16_55_547646598/HyperV2012_VHD_v1/logs/devstack/screen-n-sch.2014-12-12-162857.log /home/cloudbase/jenkins/workspace/openstack-hyperv-release-tests/reports/2014_12_12_13_16_55_547646598/HyperV2012_VHD_v1/logs/devstack/screen-n-sch.log
+ sleep 3
++ echo -ne '\015'
+ NL=$'\r'
+ [[ -n '' ]]
+ screen -S stack -p n-sch -X stuff '/usr/local/bin/nova-scheduler --config-file /etc/nova/nova.conf & echo $! >/opt/stack/status/stack/n-sch.pid; fg || echo "n-sch failed to start" | tee "/opt/stack/status/stack/n-sch.failure"'
+ run_process n-api-meta '/usr/local/bin/nova-api-metadata --config-file /etc/nova/nova.conf'
+ local service=n-api-meta
+ local 'command=/usr/local/bin/nova-api-metadata --config-file /etc/nova/nova.conf'
+ local group=
+ is_service_enabled n-api-meta
++ set +o
++ grep xtrace
+ local 'xtrace=set -o xtrace'
+ set +o xtrace
+ return 1
+ run_process n-novnc '/usr/local/bin/nova-novncproxy --config-file /etc/nova/nova.conf --web '
+ local service=n-novnc
+ local 'command=/usr/local/bin/nova-novncproxy --config-file /etc/nova/nova.conf --web '
+ local group=
+ is_service_enabled n-novnc
++ set +o
++ grep xtrace
+ local 'xtrace=set -o xtrace'
+ set +o xtrace
+ return 1
+ run_process n-xvnc '/usr/local/bin/nova-xvpvncproxy --config-file /etc/nova/nova.conf'
+ local service=n-xvnc
+ local 'command=/usr/local/bin/nova-xvpvncproxy --config-file /etc/nova/nova.conf'
+ local group=
+ is_service_enabled n-xvnc
++ set +o
++ grep xtrace
+ local 'xtrace=set -o xtrace'
+ set +o xtrace
+ return 0
+ [[ True = \T\r\u\e ]]
+ screen_service n-xvnc '/usr/local/bin/nova-xvpvncproxy --config-file /etc/nova/nova.conf' ''
+ local service=n-xvnc
+ local 'command=/usr/local/bin/nova-xvpvncproxy --config-file /etc/nova/nova.conf'
+ local group=
+ SCREEN_NAME=stack
+ SERVICE_DIR=/opt/stack/status
++ trueorfalse True True
+++ set +o
+++ grep xtrace
++ local 'xtrace=set -o xtrace'
++ set +o xtrace
+ USE_SCREEN=True
+ is_service_enabled n-xvnc
++ set +o
++ grep xtrace
+ local 'xtrace=set -o xtrace'
+ set +o xtrace
+ return 0
+ screen_rc n-xvnc '/usr/local/bin/nova-xvpvncproxy --config-file /etc/nova/nova.conf'
+ SCREEN_NAME=stack
+ SCREENRC=/home/cloudbase/devstack/stack-screenrc
+ [[ ! -e /home/cloudbase/devstack/stack-screenrc ]]
+ grep n-xvnc /home/cloudbase/devstack/stack-screenrc
++ echo -ne '\015'
+ NL=$'\r'
+ echo 'screen -t n-xvnc bash'
+ echo 'stuff "/usr/local/bin/nova-xvpvncproxy --config-file /etc/nova/nova.conf"'
+ [[ -n /home/cloudbase/jenkins/workspace/openstack-hyperv-release-tests/reports/2014_12_12_13_16_55_547646598/HyperV2012_VHD_v1/logs/devstack ]]
+ echo 'logfile /home/cloudbase/jenkins/workspace/openstack-hyperv-release-tests/reports/2014_12_12_13_16_55_547646598/HyperV2012_VHD_v1/logs/devstack/screen-n-xvnc.2014-12-12-162857.log'
+ echo 'log on'
+ screen -S stack -X screen -t n-xvnc
+ [[ -n /home/cloudbase/jenkins/workspace/openstack-hyperv-release-tests/reports/2014_12_12_13_16_55_547646598/HyperV2012_VHD_v1/logs/devstack ]]
+ screen -S stack -p n-xvnc -X logfile /home/cloudbase/jenkins/workspace/openstack-hyperv-release-tests/reports/2014_12_12_13_16_55_547646598/HyperV2012_VHD_v1/logs/devstack/screen-n-xvnc.2014-12-12-162857.log
+ screen -S stack -p n-xvnc -X log on
+ ln -sf /home/cloudbase/jenkins/workspace/openstack-hyperv-release-tests/reports/2014_12_12_13_16_55_547646598/HyperV2012_VHD_v1/logs/devstack/screen-n-xvnc.2014-12-12-162857.log /home/cloudbase/jenkins/workspace/openstack-hyperv-release-tests/reports/2014_12_12_13_16_55_547646598/HyperV2012_VHD_v1/logs/devstack/screen-n-xvnc.log
+ sleep 3
++ echo -ne '\015'
+ NL=$'\r'
+ [[ -n '' ]]
+ screen -S stack -p n-xvnc -X stuff '/usr/local/bin/nova-xvpvncproxy --config-file /etc/nova/nova.conf & echo $! >/opt/stack/status/stack/n-xvnc.pid; fg || echo "n-xvnc failed to start" | tee "/opt/stack/status/stack/n-xvnc.failure"'
+ run_process n-spice '/usr/local/bin/nova-spicehtml5proxy --config-file /etc/nova/nova.conf --web '
+ local service=n-spice
+ local 'command=/usr/local/bin/nova-spicehtml5proxy --config-file /etc/nova/nova.conf --web '
+ local group=
+ is_service_enabled n-spice
++ set +o
++ grep xtrace
+ local 'xtrace=set -o xtrace'
+ set +o xtrace
+ return 1
+ run_process n-cauth '/usr/local/bin/nova-consoleauth --config-file /etc/nova/nova.conf'
+ local service=n-cauth
+ local 'command=/usr/local/bin/nova-consoleauth --config-file /etc/nova/nova.conf'
+ local group=
+ is_service_enabled n-cauth
++ set +o
++ grep xtrace
+ local 'xtrace=set -o xtrace'
+ set +o xtrace
+ return 0
+ [[ True = \T\r\u\e ]]
+ screen_service n-cauth '/usr/local/bin/nova-consoleauth --config-file /etc/nova/nova.conf' ''
+ local service=n-cauth
+ local 'command=/usr/local/bin/nova-consoleauth --config-file /etc/nova/nova.conf'
+ local group=
+ SCREEN_NAME=stack
+ SERVICE_DIR=/opt/stack/status
++ trueorfalse True True
+++ set +o
+++ grep xtrace
++ local 'xtrace=set -o xtrace'
++ set +o xtrace
+ USE_SCREEN=True
+ is_service_enabled n-cauth
++ grep xtrace
++ set +o
+ local 'xtrace=set -o xtrace'
+ set +o xtrace
+ return 0
+ screen_rc n-cauth '/usr/local/bin/nova-consoleauth --config-file /etc/nova/nova.conf'
+ SCREEN_NAME=stack
+ SCREENRC=/home/cloudbase/devstack/stack-screenrc
+ [[ ! -e /home/cloudbase/devstack/stack-screenrc ]]
+ grep n-cauth /home/cloudbase/devstack/stack-screenrc
++ echo -ne '\015'
+ NL=$'\r'
+ echo 'screen -t n-cauth bash'
+ echo 'stuff "/usr/local/bin/nova-consoleauth --config-file /etc/nova/nova.conf"'
+ [[ -n /home/cloudbase/jenkins/workspace/openstack-hyperv-release-tests/reports/2014_12_12_13_16_55_547646598/HyperV2012_VHD_v1/logs/devstack ]]
+ echo 'logfile /home/cloudbase/jenkins/workspace/openstack-hyperv-release-tests/reports/2014_12_12_13_16_55_547646598/HyperV2012_VHD_v1/logs/devstack/screen-n-cauth.2014-12-12-162857.log'
+ echo 'log on'
+ screen -S stack -X screen -t n-cauth
+ [[ -n /home/cloudbase/jenkins/workspace/openstack-hyperv-release-tests/reports/2014_12_12_13_16_55_547646598/HyperV2012_VHD_v1/logs/devstack ]]
+ screen -S stack -p n-cauth -X logfile /home/cloudbase/jenkins/workspace/openstack-hyperv-release-tests/reports/2014_12_12_13_16_55_547646598/HyperV2012_VHD_v1/logs/devstack/screen-n-cauth.2014-12-12-162857.log
+ screen -S stack -p n-cauth -X log on
+ ln -sf /home/cloudbase/jenkins/workspace/openstack-hyperv-release-tests/reports/2014_12_12_13_16_55_547646598/HyperV2012_VHD_v1/logs/devstack/screen-n-cauth.2014-12-12-162857.log /home/cloudbase/jenkins/workspace/openstack-hyperv-release-tests/reports/2014_12_12_13_16_55_547646598/HyperV2012_VHD_v1/logs/devstack/screen-n-cauth.log
+ sleep 3
++ echo -ne '\015'
+ NL=$'\r'
+ [[ -n '' ]]
+ screen -S stack -p n-cauth -X stuff '/usr/local/bin/nova-consoleauth --config-file /etc/nova/nova.conf & echo $! >/opt/stack/status/stack/n-cauth.pid; fg || echo "n-cauth failed to start" | tee "/opt/stack/status/stack/n-cauth.failure"'
+ is_service_enabled swift3
++ set +o
++ grep xtrace
+ local 'xtrace=set -o xtrace'
+ set +o xtrace
+ return 1
+ run_process n-obj '/usr/local/bin/nova-objectstore --config-file /etc/nova/nova.conf'
+ local service=n-obj
+ local 'command=/usr/local/bin/nova-objectstore --config-file /etc/nova/nova.conf'
+ local group=
+ is_service_enabled n-obj
++ set +o
++ grep xtrace
+ local 'xtrace=set -o xtrace'
+ set +o xtrace
+ return 0
+ [[ True = \T\r\u\e ]]
+ screen_service n-obj '/usr/local/bin/nova-objectstore --config-file /etc/nova/nova.conf' ''
+ local service=n-obj
+ local 'command=/usr/local/bin/nova-objectstore --config-file /etc/nova/nova.conf'
+ local group=
+ SCREEN_NAME=stack
+ SERVICE_DIR=/opt/stack/status
++ trueorfalse True True
+++ set +o
+++ grep xtrace
++ local 'xtrace=set -o xtrace'
++ set +o xtrace
+ USE_SCREEN=True
+ is_service_enabled n-obj
++ set +o
++ grep xtrace
+ local 'xtrace=set -o xtrace'
+ set +o xtrace
+ return 0
+ screen_rc n-obj '/usr/local/bin/nova-objectstore --config-file /etc/nova/nova.conf'
+ SCREEN_NAME=stack
+ SCREENRC=/home/cloudbase/devstack/stack-screenrc
+ [[ ! -e /home/cloudbase/devstack/stack-screenrc ]]
+ grep n-obj /home/cloudbase/devstack/stack-screenrc
++ echo -ne '\015'
+ NL=$'\r'
+ echo 'screen -t n-obj bash'
+ echo 'stuff "/usr/local/bin/nova-objectstore --config-file /etc/nova/nova.conf"'
+ [[ -n /home/cloudbase/jenkins/workspace/openstack-hyperv-release-tests/reports/2014_12_12_13_16_55_547646598/HyperV2012_VHD_v1/logs/devstack ]]
+ echo 'logfile /home/cloudbase/jenkins/workspace/openstack-hyperv-release-tests/reports/2014_12_12_13_16_55_547646598/HyperV2012_VHD_v1/logs/devstack/screen-n-obj.2014-12-12-162857.log'
+ echo 'log on'
+ screen -S stack -X screen -t n-obj
+ [[ -n /home/cloudbase/jenkins/workspace/openstack-hyperv-release-tests/reports/2014_12_12_13_16_55_547646598/HyperV2012_VHD_v1/logs/devstack ]]
+ screen -S stack -p n-obj -X logfile /home/cloudbase/jenkins/workspace/openstack-hyperv-release-tests/reports/2014_12_12_13_16_55_547646598/HyperV2012_VHD_v1/logs/devstack/screen-n-obj.2014-12-12-162857.log
+ screen -S stack -p n-obj -X log on
+ ln -sf /home/cloudbase/jenkins/workspace/openstack-hyperv-release-tests/reports/2014_12_12_13_16_55_547646598/HyperV2012_VHD_v1/logs/devstack/screen-n-obj.2014-12-12-162857.log /home/cloudbase/jenkins/workspace/openstack-hyperv-release-tests/reports/2014_12_12_13_16_55_547646598/HyperV2012_VHD_v1/logs/devstack/screen-n-obj.log
+ sleep 3
++ echo -ne '\015'
+ NL=$'\r'
+ [[ -n '' ]]
+ screen -S stack -p n-obj -X stuff '/usr/local/bin/nova-objectstore --config-file /etc/nova/nova.conf & echo $! >/opt/stack/status/stack/n-obj.pid; fg || echo "n-obj failed to start" | tee "/opt/stack/status/stack/n-obj.failure"'
+ is_service_enabled cinder
++ set +o
++ grep xtrace
+ local 'xtrace=set -o xtrace'
+ set +o xtrace
+ return 0
+ echo_summary 'Starting Cinder'
+ [[ -t 3 ]]
+ echo -e Starting Cinder
+ start_cinder
+ local service_port=8776
+ local service_protocol=http
+ is_service_enabled tls-proxy
++ grep xtrace
++ set +o
+ local 'xtrace=set -o xtrace'
+ set +o xtrace
+ return 1
+ is_service_enabled c-vol
++ grep xtrace
++ set +o
+ local 'xtrace=set -o xtrace'
+ set +o xtrace
+ return 0
+ sudo rm -f /etc/tgt/conf.d/stack.conf
+ _configure_tgt_for_config_d
+ [[ ! -d /etc/tgt/stack.d/ ]]
+ is_ubuntu
+ [[ -z deb ]]
+ '[' deb = deb ']'
+ sudo service tgt restart
stop: Unknown instance: 
+ sudo tgtadm --mode system --op update --name debug --value on
+ run_process c-api '/opt/stack/cinder/bin/cinder-api --config-file /etc/cinder/cinder.conf'
+ local service=c-api
+ local 'command=/opt/stack/cinder/bin/cinder-api --config-file /etc/cinder/cinder.conf'
+ local group=
+ is_service_enabled c-api
++ set +o
++ grep xtrace
+ local 'xtrace=set -o xtrace'
+ set +o xtrace
+ return 0
+ [[ True = \T\r\u\e ]]
+ screen_service c-api '/opt/stack/cinder/bin/cinder-api --config-file /etc/cinder/cinder.conf' ''
+ local service=c-api
+ local 'command=/opt/stack/cinder/bin/cinder-api --config-file /etc/cinder/cinder.conf'
+ local group=
+ SCREEN_NAME=stack
+ SERVICE_DIR=/opt/stack/status
++ trueorfalse True True
+++ set +o
+++ grep xtrace
++ local 'xtrace=set -o xtrace'
++ set +o xtrace
+ USE_SCREEN=True
+ is_service_enabled c-api
++ set +o
++ grep xtrace
+ local 'xtrace=set -o xtrace'
+ set +o xtrace
+ return 0
+ screen_rc c-api '/opt/stack/cinder/bin/cinder-api --config-file /etc/cinder/cinder.conf'
+ SCREEN_NAME=stack
+ SCREENRC=/home/cloudbase/devstack/stack-screenrc
+ [[ ! -e /home/cloudbase/devstack/stack-screenrc ]]
+ grep c-api /home/cloudbase/devstack/stack-screenrc
++ echo -ne '\015'
+ NL=$'\r'
+ echo 'screen -t c-api bash'
+ echo 'stuff "/opt/stack/cinder/bin/cinder-api --config-file /etc/cinder/cinder.conf"'
+ [[ -n /home/cloudbase/jenkins/workspace/openstack-hyperv-release-tests/reports/2014_12_12_13_16_55_547646598/HyperV2012_VHD_v1/logs/devstack ]]
+ echo 'logfile /home/cloudbase/jenkins/workspace/openstack-hyperv-release-tests/reports/2014_12_12_13_16_55_547646598/HyperV2012_VHD_v1/logs/devstack/screen-c-api.2014-12-12-162857.log'
+ echo 'log on'
+ screen -S stack -X screen -t c-api
+ [[ -n /home/cloudbase/jenkins/workspace/openstack-hyperv-release-tests/reports/2014_12_12_13_16_55_547646598/HyperV2012_VHD_v1/logs/devstack ]]
+ screen -S stack -p c-api -X logfile /home/cloudbase/jenkins/workspace/openstack-hyperv-release-tests/reports/2014_12_12_13_16_55_547646598/HyperV2012_VHD_v1/logs/devstack/screen-c-api.2014-12-12-162857.log
+ screen -S stack -p c-api -X log on
+ ln -sf /home/cloudbase/jenkins/workspace/openstack-hyperv-release-tests/reports/2014_12_12_13_16_55_547646598/HyperV2012_VHD_v1/logs/devstack/screen-c-api.2014-12-12-162857.log /home/cloudbase/jenkins/workspace/openstack-hyperv-release-tests/reports/2014_12_12_13_16_55_547646598/HyperV2012_VHD_v1/logs/devstack/screen-c-api.log
+ sleep 3
++ echo -ne '\015'
+ NL=$'\r'
+ [[ -n '' ]]
+ screen -S stack -p c-api -X stuff '/opt/stack/cinder/bin/cinder-api --config-file /etc/cinder/cinder.conf & echo $! >/opt/stack/status/stack/c-api.pid; fg || echo "c-api failed to start" | tee "/opt/stack/status/stack/c-api.failure"'
+ echo 'Waiting for Cinder API to start...'
+ wait_for_service 60 http://10.14.0.26:8776
+ local timeout=60
+ local url=http://10.14.0.26:8776
+ timeout 60 sh -c 'while ! curl -k --noproxy '\''*'\'' -s http://10.14.0.26:8776 >/dev/null; do sleep 1; done'
+ run_process c-sch '/opt/stack/cinder/bin/cinder-scheduler --config-file /etc/cinder/cinder.conf'
+ local service=c-sch
+ local 'command=/opt/stack/cinder/bin/cinder-scheduler --config-file /etc/cinder/cinder.conf'
+ local group=
+ is_service_enabled c-sch
++ set +o
++ grep xtrace
+ local 'xtrace=set -o xtrace'
+ set +o xtrace
+ return 0
+ [[ True = \T\r\u\e ]]
+ screen_service c-sch '/opt/stack/cinder/bin/cinder-scheduler --config-file /etc/cinder/cinder.conf' ''
+ local service=c-sch
+ local 'command=/opt/stack/cinder/bin/cinder-scheduler --config-file /etc/cinder/cinder.conf'
+ local group=
+ SCREEN_NAME=stack
+ SERVICE_DIR=/opt/stack/status
++ trueorfalse True True
+++ set +o
+++ grep xtrace
++ local 'xtrace=set -o xtrace'
++ set +o xtrace
+ USE_SCREEN=True
+ is_service_enabled c-sch
++ set +o
++ grep xtrace
+ local 'xtrace=set -o xtrace'
+ set +o xtrace
+ return 0
+ screen_rc c-sch '/opt/stack/cinder/bin/cinder-scheduler --config-file /etc/cinder/cinder.conf'
+ SCREEN_NAME=stack
+ SCREENRC=/home/cloudbase/devstack/stack-screenrc
+ [[ ! -e /home/cloudbase/devstack/stack-screenrc ]]
+ grep c-sch /home/cloudbase/devstack/stack-screenrc
++ echo -ne '\015'
+ NL=$'\r'
+ echo 'screen -t c-sch bash'
+ echo 'stuff "/opt/stack/cinder/bin/cinder-scheduler --config-file /etc/cinder/cinder.conf"'
+ [[ -n /home/cloudbase/jenkins/workspace/openstack-hyperv-release-tests/reports/2014_12_12_13_16_55_547646598/HyperV2012_VHD_v1/logs/devstack ]]
+ echo 'logfile /home/cloudbase/jenkins/workspace/openstack-hyperv-release-tests/reports/2014_12_12_13_16_55_547646598/HyperV2012_VHD_v1/logs/devstack/screen-c-sch.2014-12-12-162857.log'
+ echo 'log on'
+ screen -S stack -X screen -t c-sch
+ [[ -n /home/cloudbase/jenkins/workspace/openstack-hyperv-release-tests/reports/2014_12_12_13_16_55_547646598/HyperV2012_VHD_v1/logs/devstack ]]
+ screen -S stack -p c-sch -X logfile /home/cloudbase/jenkins/workspace/openstack-hyperv-release-tests/reports/2014_12_12_13_16_55_547646598/HyperV2012_VHD_v1/logs/devstack/screen-c-sch.2014-12-12-162857.log
+ screen -S stack -p c-sch -X log on
+ ln -sf /home/cloudbase/jenkins/workspace/openstack-hyperv-release-tests/reports/2014_12_12_13_16_55_547646598/HyperV2012_VHD_v1/logs/devstack/screen-c-sch.2014-12-12-162857.log /home/cloudbase/jenkins/workspace/openstack-hyperv-release-tests/reports/2014_12_12_13_16_55_547646598/HyperV2012_VHD_v1/logs/devstack/screen-c-sch.log
+ sleep 3
++ echo -ne '\015'
+ NL=$'\r'
+ [[ -n '' ]]
+ screen -S stack -p c-sch -X stuff '/opt/stack/cinder/bin/cinder-scheduler --config-file /etc/cinder/cinder.conf & echo $! >/opt/stack/status/stack/c-sch.pid; fg || echo "c-sch failed to start" | tee "/opt/stack/status/stack/c-sch.failure"'
+ run_process c-bak '/opt/stack/cinder/bin/cinder-backup --config-file /etc/cinder/cinder.conf'
+ local service=c-bak
+ local 'command=/opt/stack/cinder/bin/cinder-backup --config-file /etc/cinder/cinder.conf'
+ local group=
+ is_service_enabled c-bak
++ set +o
++ grep xtrace
+ local 'xtrace=set -o xtrace'
+ set +o xtrace
+ return 0
+ [[ True = \T\r\u\e ]]
+ screen_service c-bak '/opt/stack/cinder/bin/cinder-backup --config-file /etc/cinder/cinder.conf' ''
+ local service=c-bak
+ local 'command=/opt/stack/cinder/bin/cinder-backup --config-file /etc/cinder/cinder.conf'
+ local group=
+ SCREEN_NAME=stack
+ SERVICE_DIR=/opt/stack/status
++ trueorfalse True True
+++ set +o
+++ grep xtrace
++ local 'xtrace=set -o xtrace'
++ set +o xtrace
+ USE_SCREEN=True
+ is_service_enabled c-bak
++ set +o
++ grep xtrace
+ local 'xtrace=set -o xtrace'
+ set +o xtrace
+ return 0
+ screen_rc c-bak '/opt/stack/cinder/bin/cinder-backup --config-file /etc/cinder/cinder.conf'
+ SCREEN_NAME=stack
+ SCREENRC=/home/cloudbase/devstack/stack-screenrc
+ [[ ! -e /home/cloudbase/devstack/stack-screenrc ]]
+ grep c-bak /home/cloudbase/devstack/stack-screenrc
++ echo -ne '\015'
+ NL=$'\r'
+ echo 'screen -t c-bak bash'
+ echo 'stuff "/opt/stack/cinder/bin/cinder-backup --config-file /etc/cinder/cinder.conf"'
+ [[ -n /home/cloudbase/jenkins/workspace/openstack-hyperv-release-tests/reports/2014_12_12_13_16_55_547646598/HyperV2012_VHD_v1/logs/devstack ]]
+ echo 'logfile /home/cloudbase/jenkins/workspace/openstack-hyperv-release-tests/reports/2014_12_12_13_16_55_547646598/HyperV2012_VHD_v1/logs/devstack/screen-c-bak.2014-12-12-162857.log'
+ echo 'log on'
+ screen -S stack -X screen -t c-bak
+ [[ -n /home/cloudbase/jenkins/workspace/openstack-hyperv-release-tests/reports/2014_12_12_13_16_55_547646598/HyperV2012_VHD_v1/logs/devstack ]]
+ screen -S stack -p c-bak -X logfile /home/cloudbase/jenkins/workspace/openstack-hyperv-release-tests/reports/2014_12_12_13_16_55_547646598/HyperV2012_VHD_v1/logs/devstack/screen-c-bak.2014-12-12-162857.log
+ screen -S stack -p c-bak -X log on
+ ln -sf /home/cloudbase/jenkins/workspace/openstack-hyperv-release-tests/reports/2014_12_12_13_16_55_547646598/HyperV2012_VHD_v1/logs/devstack/screen-c-bak.2014-12-12-162857.log /home/cloudbase/jenkins/workspace/openstack-hyperv-release-tests/reports/2014_12_12_13_16_55_547646598/HyperV2012_VHD_v1/logs/devstack/screen-c-bak.log
+ sleep 3
++ echo -ne '\015'
+ NL=$'\r'
+ [[ -n '' ]]
+ screen -S stack -p c-bak -X stuff '/opt/stack/cinder/bin/cinder-backup --config-file /etc/cinder/cinder.conf & echo $! >/opt/stack/status/stack/c-bak.pid; fg || echo "c-bak failed to start" | tee "/opt/stack/status/stack/c-bak.failure"'
+ run_process c-vol '/opt/stack/cinder/bin/cinder-volume --config-file /etc/cinder/cinder.conf'
+ local service=c-vol
+ local 'command=/opt/stack/cinder/bin/cinder-volume --config-file /etc/cinder/cinder.conf'
+ local group=
+ is_service_enabled c-vol
++ set +o
++ grep xtrace
+ local 'xtrace=set -o xtrace'
+ set +o xtrace
+ return 0
+ [[ True = \T\r\u\e ]]
+ screen_service c-vol '/opt/stack/cinder/bin/cinder-volume --config-file /etc/cinder/cinder.conf' ''
+ local service=c-vol
+ local 'command=/opt/stack/cinder/bin/cinder-volume --config-file /etc/cinder/cinder.conf'
+ local group=
+ SCREEN_NAME=stack
+ SERVICE_DIR=/opt/stack/status
++ trueorfalse True True
+++ set +o
+++ grep xtrace
++ local 'xtrace=set -o xtrace'
++ set +o xtrace
+ USE_SCREEN=True
+ is_service_enabled c-vol
++ set +o
++ grep xtrace
+ local 'xtrace=set -o xtrace'
+ set +o xtrace
+ return 0
+ screen_rc c-vol '/opt/stack/cinder/bin/cinder-volume --config-file /etc/cinder/cinder.conf'
+ SCREEN_NAME=stack
+ SCREENRC=/home/cloudbase/devstack/stack-screenrc
+ [[ ! -e /home/cloudbase/devstack/stack-screenrc ]]
+ grep c-vol /home/cloudbase/devstack/stack-screenrc
++ echo -ne '\015'
+ NL=$'\r'
+ echo 'screen -t c-vol bash'
+ echo 'stuff "/opt/stack/cinder/bin/cinder-volume --config-file /etc/cinder/cinder.conf"'
+ [[ -n /home/cloudbase/jenkins/workspace/openstack-hyperv-release-tests/reports/2014_12_12_13_16_55_547646598/HyperV2012_VHD_v1/logs/devstack ]]
+ echo 'logfile /home/cloudbase/jenkins/workspace/openstack-hyperv-release-tests/reports/2014_12_12_13_16_55_547646598/HyperV2012_VHD_v1/logs/devstack/screen-c-vol.2014-12-12-162857.log'
+ echo 'log on'
+ screen -S stack -X screen -t c-vol
+ [[ -n /home/cloudbase/jenkins/workspace/openstack-hyperv-release-tests/reports/2014_12_12_13_16_55_547646598/HyperV2012_VHD_v1/logs/devstack ]]
+ screen -S stack -p c-vol -X logfile /home/cloudbase/jenkins/workspace/openstack-hyperv-release-tests/reports/2014_12_12_13_16_55_547646598/HyperV2012_VHD_v1/logs/devstack/screen-c-vol.2014-12-12-162857.log
+ screen -S stack -p c-vol -X log on
+ ln -sf /home/cloudbase/jenkins/workspace/openstack-hyperv-release-tests/reports/2014_12_12_13_16_55_547646598/HyperV2012_VHD_v1/logs/devstack/screen-c-vol.2014-12-12-162857.log /home/cloudbase/jenkins/workspace/openstack-hyperv-release-tests/reports/2014_12_12_13_16_55_547646598/HyperV2012_VHD_v1/logs/devstack/screen-c-vol.log
+ sleep 3
++ echo -ne '\015'
+ NL=$'\r'
+ [[ -n '' ]]
+ screen -S stack -p c-vol -X stuff '/opt/stack/cinder/bin/cinder-volume --config-file /etc/cinder/cinder.conf & echo $! >/opt/stack/status/stack/c-vol.pid; fg || echo "c-vol failed to start" | tee "/opt/stack/status/stack/c-vol.failure"'
+ is_service_enabled c-api
++ set +o
++ grep xtrace
+ local 'xtrace=set -o xtrace'
+ set +o xtrace
+ return 0
+ is_service_enabled tls-proxy
++ grep xtrace
++ set +o
+ local 'xtrace=set -o xtrace'
+ set +o xtrace
+ return 1
+ create_volume_types
+ is_service_enabled c-api
++ set +o
++ grep xtrace
+ local 'xtrace=set -o xtrace'
+ set +o xtrace
+ return 0
+ [[ -n lvm:lvmdriver-1 ]]
+ local be be_name be_type
+ for be in '${CINDER_ENABLED_BACKENDS//,/ }'
+ be_type=lvm
+ be_name=lvmdriver-1
+ cinder type-create lvmdriver-1
+ cinder type-key lvmdriver-1 set volume_backend_name=lvmdriver-1
+ is_service_enabled ceilometer
++ set +o
++ grep xtrace
+ local 'xtrace=set -o xtrace'
+ set +o xtrace
+ return 0
+ echo_summary 'Starting Ceilometer'
+ [[ -t 3 ]]
+ echo -e Starting Ceilometer
+ init_ceilometer
+ sudo mkdir -p /var/cache/ceilometer
+ sudo chown cloudbase /var/cache/ceilometer
+ rm -f '/var/cache/ceilometer/*'
+ is_service_enabled mysql postgresql
++ set +o
++ grep xtrace
+ local 'xtrace=set -o xtrace'
+ set +o xtrace
+ return 0
+ '[' mongodb = mysql ']'
+ '[' mongodb = postgresql ']'
+ start_ceilometer
+ run_process ceilometer-acentral 'ceilometer-agent-central --config-file /etc/ceilometer/ceilometer.conf'
+ local service=ceilometer-acentral
+ local 'command=ceilometer-agent-central --config-file /etc/ceilometer/ceilometer.conf'
+ local group=
+ is_service_enabled ceilometer-acentral
++ set +o
++ grep xtrace
+ local 'xtrace=set -o xtrace'
+ set +o xtrace
+ return 0
+ [[ True = \T\r\u\e ]]
+ screen_service ceilometer-acentral 'ceilometer-agent-central --config-file /etc/ceilometer/ceilometer.conf' ''
+ local service=ceilometer-acentral
+ local 'command=ceilometer-agent-central --config-file /etc/ceilometer/ceilometer.conf'
+ local group=
+ SCREEN_NAME=stack
+ SERVICE_DIR=/opt/stack/status
++ trueorfalse True True
+++ set +o
+++ grep xtrace
++ local 'xtrace=set -o xtrace'
++ set +o xtrace
+ USE_SCREEN=True
+ is_service_enabled ceilometer-acentral
++ set +o
++ grep xtrace
+ local 'xtrace=set -o xtrace'
+ set +o xtrace
+ return 0
+ screen_rc ceilometer-acentral 'ceilometer-agent-central --config-file /etc/ceilometer/ceilometer.conf'
+ SCREEN_NAME=stack
+ SCREENRC=/home/cloudbase/devstack/stack-screenrc
+ [[ ! -e /home/cloudbase/devstack/stack-screenrc ]]
+ grep ceilometer-acentral /home/cloudbase/devstack/stack-screenrc
++ echo -ne '\015'
+ NL=$'\r'
+ echo 'screen -t ceilometer-acentral bash'
+ echo 'stuff "ceilometer-agent-central --config-file /etc/ceilometer/ceilometer.conf"'
+ [[ -n /home/cloudbase/jenkins/workspace/openstack-hyperv-release-tests/reports/2014_12_12_13_16_55_547646598/HyperV2012_VHD_v1/logs/devstack ]]
+ echo 'logfile /home/cloudbase/jenkins/workspace/openstack-hyperv-release-tests/reports/2014_12_12_13_16_55_547646598/HyperV2012_VHD_v1/logs/devstack/screen-ceilometer-acentral.2014-12-12-162857.log'
+ echo 'log on'
+ screen -S stack -X screen -t ceilometer-acentral
+ [[ -n /home/cloudbase/jenkins/workspace/openstack-hyperv-release-tests/reports/2014_12_12_13_16_55_547646598/HyperV2012_VHD_v1/logs/devstack ]]
+ screen -S stack -p ceilometer-acentral -X logfile /home/cloudbase/jenkins/workspace/openstack-hyperv-release-tests/reports/2014_12_12_13_16_55_547646598/HyperV2012_VHD_v1/logs/devstack/screen-ceilometer-acentral.2014-12-12-162857.log
+ screen -S stack -p ceilometer-acentral -X log on
+ ln -sf /home/cloudbase/jenkins/workspace/openstack-hyperv-release-tests/reports/2014_12_12_13_16_55_547646598/HyperV2012_VHD_v1/logs/devstack/screen-ceilometer-acentral.2014-12-12-162857.log /home/cloudbase/jenkins/workspace/openstack-hyperv-release-tests/reports/2014_12_12_13_16_55_547646598/HyperV2012_VHD_v1/logs/devstack/screen-ceilometer-acentral.log
+ sleep 3
++ echo -ne '\015'
+ NL=$'\r'
+ [[ -n '' ]]
+ screen -S stack -p ceilometer-acentral -X stuff 'ceilometer-agent-central --config-file /etc/ceilometer/ceilometer.conf & echo $! >/opt/stack/status/stack/ceilometer-acentral.pid; fg || echo "ceilometer-acentral failed to start" | tee "/opt/stack/status/stack/ceilometer-acentral.failure"'
+ run_process ceilometer-anotification 'ceilometer-agent-notification --config-file /etc/ceilometer/ceilometer.conf'
+ local service=ceilometer-anotification
+ local 'command=ceilometer-agent-notification --config-file /etc/ceilometer/ceilometer.conf'
+ local group=
+ is_service_enabled ceilometer-anotification
++ set +o
++ grep xtrace
+ local 'xtrace=set -o xtrace'
+ set +o xtrace
+ return 1
+ run_process ceilometer-collector 'ceilometer-collector --config-file /etc/ceilometer/ceilometer.conf'
+ local service=ceilometer-collector
+ local 'command=ceilometer-collector --config-file /etc/ceilometer/ceilometer.conf'
+ local group=
+ is_service_enabled ceilometer-collector
++ set +o
++ grep xtrace
+ local 'xtrace=set -o xtrace'
+ set +o xtrace
+ return 0
+ [[ True = \T\r\u\e ]]
+ screen_service ceilometer-collector 'ceilometer-collector --config-file /etc/ceilometer/ceilometer.conf' ''
+ local service=ceilometer-collector
+ local 'command=ceilometer-collector --config-file /etc/ceilometer/ceilometer.conf'
+ local group=
+ SCREEN_NAME=stack
+ SERVICE_DIR=/opt/stack/status
++ trueorfalse True True
+++ set +o
+++ grep xtrace
++ local 'xtrace=set -o xtrace'
++ set +o xtrace
+ USE_SCREEN=True
+ is_service_enabled ceilometer-collector
++ set +o
++ grep xtrace
+ local 'xtrace=set -o xtrace'
+ set +o xtrace
+ return 0
+ screen_rc ceilometer-collector 'ceilometer-collector --config-file /etc/ceilometer/ceilometer.conf'
+ SCREEN_NAME=stack
+ SCREENRC=/home/cloudbase/devstack/stack-screenrc
+ [[ ! -e /home/cloudbase/devstack/stack-screenrc ]]
+ grep ceilometer-collector /home/cloudbase/devstack/stack-screenrc
++ echo -ne '\015'
+ NL=$'\r'
+ echo 'screen -t ceilometer-collector bash'
+ echo 'stuff "ceilometer-collector --config-file /etc/ceilometer/ceilometer.conf"'
+ [[ -n /home/cloudbase/jenkins/workspace/openstack-hyperv-release-tests/reports/2014_12_12_13_16_55_547646598/HyperV2012_VHD_v1/logs/devstack ]]
+ echo 'logfile /home/cloudbase/jenkins/workspace/openstack-hyperv-release-tests/reports/2014_12_12_13_16_55_547646598/HyperV2012_VHD_v1/logs/devstack/screen-ceilometer-collector.2014-12-12-162857.log'
+ echo 'log on'
+ screen -S stack -X screen -t ceilometer-collector
+ [[ -n /home/cloudbase/jenkins/workspace/openstack-hyperv-release-tests/reports/2014_12_12_13_16_55_547646598/HyperV2012_VHD_v1/logs/devstack ]]
+ screen -S stack -p ceilometer-collector -X logfile /home/cloudbase/jenkins/workspace/openstack-hyperv-release-tests/reports/2014_12_12_13_16_55_547646598/HyperV2012_VHD_v1/logs/devstack/screen-ceilometer-collector.2014-12-12-162857.log
+ screen -S stack -p ceilometer-collector -X log on
+ ln -sf /home/cloudbase/jenkins/workspace/openstack-hyperv-release-tests/reports/2014_12_12_13_16_55_547646598/HyperV2012_VHD_v1/logs/devstack/screen-ceilometer-collector.2014-12-12-162857.log /home/cloudbase/jenkins/workspace/openstack-hyperv-release-tests/reports/2014_12_12_13_16_55_547646598/HyperV2012_VHD_v1/logs/devstack/screen-ceilometer-collector.log
+ sleep 3
++ echo -ne '\015'
+ NL=$'\r'
+ [[ -n '' ]]
+ screen -S stack -p ceilometer-collector -X stuff 'ceilometer-collector --config-file /etc/ceilometer/ceilometer.conf & echo $! >/opt/stack/status/stack/ceilometer-collector.pid; fg || echo "ceilometer-collector failed to start" | tee "/opt/stack/status/stack/ceilometer-collector.failure"'
+ [[ False == \F\a\l\s\e ]]
+ run_process ceilometer-api 'ceilometer-api -d -v --log-dir=/var/log/ceilometer-api --config-file /etc/ceilometer/ceilometer.conf'
+ local service=ceilometer-api
+ local 'command=ceilometer-api -d -v --log-dir=/var/log/ceilometer-api --config-file /etc/ceilometer/ceilometer.conf'
+ local group=
+ is_service_enabled ceilometer-api
++ set +o
++ grep xtrace
+ local 'xtrace=set -o xtrace'
+ set +o xtrace
+ return 0
+ [[ True = \T\r\u\e ]]
+ screen_service ceilometer-api 'ceilometer-api -d -v --log-dir=/var/log/ceilometer-api --config-file /etc/ceilometer/ceilometer.conf' ''
+ local service=ceilometer-api
+ local 'command=ceilometer-api -d -v --log-dir=/var/log/ceilometer-api --config-file /etc/ceilometer/ceilometer.conf'
+ local group=
+ SCREEN_NAME=stack
+ SERVICE_DIR=/opt/stack/status
++ trueorfalse True True
+++ set +o
+++ grep xtrace
++ local 'xtrace=set -o xtrace'
++ set +o xtrace
+ USE_SCREEN=True
+ is_service_enabled ceilometer-api
++ set +o
++ grep xtrace
+ local 'xtrace=set -o xtrace'
+ set +o xtrace
+ return 0
+ screen_rc ceilometer-api 'ceilometer-api -d -v --log-dir=/var/log/ceilometer-api --config-file /etc/ceilometer/ceilometer.conf'
+ SCREEN_NAME=stack
+ SCREENRC=/home/cloudbase/devstack/stack-screenrc
+ [[ ! -e /home/cloudbase/devstack/stack-screenrc ]]
+ grep ceilometer-api /home/cloudbase/devstack/stack-screenrc
++ echo -ne '\015'
+ NL=$'\r'
+ echo 'screen -t ceilometer-api bash'
+ echo 'stuff "ceilometer-api -d -v --log-dir=/var/log/ceilometer-api --config-file /etc/ceilometer/ceilometer.conf"'
+ [[ -n /home/cloudbase/jenkins/workspace/openstack-hyperv-release-tests/reports/2014_12_12_13_16_55_547646598/HyperV2012_VHD_v1/logs/devstack ]]
+ echo 'logfile /home/cloudbase/jenkins/workspace/openstack-hyperv-release-tests/reports/2014_12_12_13_16_55_547646598/HyperV2012_VHD_v1/logs/devstack/screen-ceilometer-api.2014-12-12-162857.log'
+ echo 'log on'
+ screen -S stack -X screen -t ceilometer-api
+ [[ -n /home/cloudbase/jenkins/workspace/openstack-hyperv-release-tests/reports/2014_12_12_13_16_55_547646598/HyperV2012_VHD_v1/logs/devstack ]]
+ screen -S stack -p ceilometer-api -X logfile /home/cloudbase/jenkins/workspace/openstack-hyperv-release-tests/reports/2014_12_12_13_16_55_547646598/HyperV2012_VHD_v1/logs/devstack/screen-ceilometer-api.2014-12-12-162857.log
+ screen -S stack -p ceilometer-api -X log on
+ ln -sf /home/cloudbase/jenkins/workspace/openstack-hyperv-release-tests/reports/2014_12_12_13_16_55_547646598/HyperV2012_VHD_v1/logs/devstack/screen-ceilometer-api.2014-12-12-162857.log /home/cloudbase/jenkins/workspace/openstack-hyperv-release-tests/reports/2014_12_12_13_16_55_547646598/HyperV2012_VHD_v1/logs/devstack/screen-ceilometer-api.log
+ sleep 3
++ echo -ne '\015'
+ NL=$'\r'
+ [[ -n '' ]]
+ screen -S stack -p ceilometer-api -X stuff 'ceilometer-api -d -v --log-dir=/var/log/ceilometer-api --config-file /etc/ceilometer/ceilometer.conf & echo $! >/opt/stack/status/stack/ceilometer-api.pid; fg || echo "ceilometer-api failed to start" | tee "/opt/stack/status/stack/ceilometer-api.failure"'
+ [[ libvirt = \l\i\b\v\i\r\t ]]
+ run_process ceilometer-acompute 'ceilometer-agent-compute --config-file /etc/ceilometer/ceilometer.conf' libvirtd
+ local service=ceilometer-acompute
+ local 'command=ceilometer-agent-compute --config-file /etc/ceilometer/ceilometer.conf'
+ local group=libvirtd
+ is_service_enabled ceilometer-acompute
++ set +o
++ grep xtrace
+ local 'xtrace=set -o xtrace'
+ set +o xtrace
+ return 1
+ [[ libvirt = \v\s\p\h\e\r\e ]]
+ is_service_enabled ceilometer-api
++ set +o
++ grep xtrace
+ local 'xtrace=set -o xtrace'
+ set +o xtrace
+ return 0
+ echo 'Waiting for ceilometer-api to start...'
+ timeout 60 sh -c 'while ! curl --noproxy '\''*'\'' -s http://localhost:8777/v2/ >/dev/null; do sleep 1; done'
+ run_process ceilometer-alarm-notifier 'ceilometer-alarm-notifier --config-file /etc/ceilometer/ceilometer.conf'
+ local service=ceilometer-alarm-notifier
+ local 'command=ceilometer-alarm-notifier --config-file /etc/ceilometer/ceilometer.conf'
+ local group=
+ is_service_enabled ceilometer-alarm-notifier
++ set +o
++ grep xtrace
+ local 'xtrace=set -o xtrace'
+ set +o xtrace
+ return 1
+ run_process ceilometer-alarm-evaluator 'ceilometer-alarm-evaluator --config-file /etc/ceilometer/ceilometer.conf'
+ local service=ceilometer-alarm-evaluator
+ local 'command=ceilometer-alarm-evaluator --config-file /etc/ceilometer/ceilometer.conf'
+ local group=
+ is_service_enabled ceilometer-alarm-evaluator
++ set +o
++ grep xtrace
+ local 'xtrace=set -o xtrace'
+ set +o xtrace
+ return 1
+ is_service_enabled heat
++ set +o
++ grep xtrace
+ local 'xtrace=set -o xtrace'
+ set +o xtrace
+ return 0
+ echo_summary 'Configuring Heat'
+ [[ -t 3 ]]
+ echo -e Configuring Heat
+ init_heat
+ recreate_database heat utf8
+ local db=heat
+ local charset=utf8
+ recreate_database_mysql heat utf8
+ local db=heat
+ local charset=utf8
+ mysql -uroot -pPassw0rd -h127.0.0.1 -e 'DROP DATABASE IF EXISTS heat;'
+ mysql -uroot -pPassw0rd -h127.0.0.1 -e 'CREATE DATABASE heat CHARACTER SET utf8;'
+ /opt/stack/heat/bin/heat-manage db_sync
2014-12-12 16:33:58.628 20132 DEBUG oslo.db.sqlalchemy.session [-] MySQL server mode set to STRICT_TRANS_TABLES,STRICT_ALL_TABLES,NO_ZERO_IN_DATE,NO_ZERO_DATE,ERROR_FOR_DIVISION_BY_ZERO,TRADITIONAL,NO_AUTO_CREATE_USER,NO_ENGINE_SUBSTITUTION _init_events /usr/local/lib/python2.7/dist-packages/oslo/db/sqlalchemy/session.py:474
2014-12-12 16:33:58.629 20132 DEBUG migrate.versioning.repository [-] Loading repository /opt/stack/heat/heat/db/sqlalchemy/migrate_repo... __init__ /usr/local/lib/python2.7/dist-packages/migrate/versioning/repository.py:76
2014-12-12 16:33:58.630 20132 DEBUG migrate.versioning.script.base [-] Loading script /opt/stack/heat/heat/db/sqlalchemy/migrate_repo/versions/015_grizzly.py... __init__ /usr/local/lib/python2.7/dist-packages/migrate/versioning/script/base.py:27
2014-12-12 16:33:58.630 20132 DEBUG migrate.versioning.script.base [-] Script /opt/stack/heat/heat/db/sqlalchemy/migrate_repo/versions/015_grizzly.py loaded successfully __init__ /usr/local/lib/python2.7/dist-packages/migrate/versioning/script/base.py:30
2014-12-12 16:33:58.630 20132 DEBUG migrate.versioning.script.base [-] Loading script /opt/stack/heat/heat/db/sqlalchemy/migrate_repo/versions/016_timeout_nullable.py... __init__ /usr/local/lib/python2.7/dist-packages/migrate/versioning/script/base.py:27
2014-12-12 16:33:58.630 20132 DEBUG migrate.versioning.script.base [-] Script /opt/stack/heat/heat/db/sqlalchemy/migrate_repo/versions/016_timeout_nullable.py loaded successfully __init__ /usr/local/lib/python2.7/dist-packages/migrate/versioning/script/base.py:30
2014-12-12 16:33:58.630 20132 DEBUG migrate.versioning.script.base [-] Loading script /opt/stack/heat/heat/db/sqlalchemy/migrate_repo/versions/017_event_state_status.py... __init__ /usr/local/lib/python2.7/dist-packages/migrate/versioning/script/base.py:27
2014-12-12 16:33:58.630 20132 DEBUG migrate.versioning.script.base [-] Script /opt/stack/heat/heat/db/sqlalchemy/migrate_repo/versions/017_event_state_status.py loaded successfully __init__ /usr/local/lib/python2.7/dist-packages/migrate/versioning/script/base.py:30
2014-12-12 16:33:58.630 20132 DEBUG migrate.versioning.script.base [-] Loading script /opt/stack/heat/heat/db/sqlalchemy/migrate_repo/versions/018_resource_id_uuid.py... __init__ /usr/local/lib/python2.7/dist-packages/migrate/versioning/script/base.py:27
2014-12-12 16:33:58.631 20132 DEBUG migrate.versioning.script.base [-] Script /opt/stack/heat/heat/db/sqlalchemy/migrate_repo/versions/018_resource_id_uuid.py loaded successfully __init__ /usr/local/lib/python2.7/dist-packages/migrate/versioning/script/base.py:30
2014-12-12 16:33:58.631 20132 DEBUG migrate.versioning.script.base [-] Loading script /opt/stack/heat/heat/db/sqlalchemy/migrate_repo/versions/019_resource_action_status.py... __init__ /usr/local/lib/python2.7/dist-packages/migrate/versioning/script/base.py:27
2014-12-12 16:33:58.631 20132 DEBUG migrate.versioning.script.base [-] Script /opt/stack/heat/heat/db/sqlalchemy/migrate_repo/versions/019_resource_action_status.py loaded successfully __init__ /usr/local/lib/python2.7/dist-packages/migrate/versioning/script/base.py:30
2014-12-12 16:33:58.631 20132 DEBUG migrate.versioning.script.base [-] Loading script /opt/stack/heat/heat/db/sqlalchemy/migrate_repo/versions/020_stack_action.py... __init__ /usr/local/lib/python2.7/dist-packages/migrate/versioning/script/base.py:27
2014-12-12 16:33:58.631 20132 DEBUG migrate.versioning.script.base [-] Script /opt/stack/heat/heat/db/sqlalchemy/migrate_repo/versions/020_stack_action.py loaded successfully __init__ /usr/local/lib/python2.7/dist-packages/migrate/versioning/script/base.py:30
2014-12-12 16:33:58.631 20132 DEBUG migrate.versioning.script.base [-] Loading script /opt/stack/heat/heat/db/sqlalchemy/migrate_repo/versions/021_resource_data.py... __init__ /usr/local/lib/python2.7/dist-packages/migrate/versioning/script/base.py:27
2014-12-12 16:33:58.631 20132 DEBUG migrate.versioning.script.base [-] Script /opt/stack/heat/heat/db/sqlalchemy/migrate_repo/versions/021_resource_data.py loaded successfully __init__ /usr/local/lib/python2.7/dist-packages/migrate/versioning/script/base.py:30
2014-12-12 16:33:58.631 20132 DEBUG migrate.versioning.script.base [-] Loading script /opt/stack/heat/heat/db/sqlalchemy/migrate_repo/versions/022_stack_event_soft_delete.py... __init__ /usr/local/lib/python2.7/dist-packages/migrate/versioning/script/base.py:27
2014-12-12 16:33:58.631 20132 DEBUG migrate.versioning.script.base [-] Script /opt/stack/heat/heat/db/sqlalchemy/migrate_repo/versions/022_stack_event_soft_delete.py loaded successfully __init__ /usr/local/lib/python2.7/dist-packages/migrate/versioning/script/base.py:30
2014-12-12 16:33:58.631 20132 DEBUG migrate.versioning.script.base [-] Loading script /opt/stack/heat/heat/db/sqlalchemy/migrate_repo/versions/023_raw_template_mysql_longtext.py... __init__ /usr/local/lib/python2.7/dist-packages/migrate/versioning/script/base.py:27
2014-12-12 16:33:58.631 20132 DEBUG migrate.versioning.script.base [-] Script /opt/stack/heat/heat/db/sqlalchemy/migrate_repo/versions/023_raw_template_mysql_longtext.py loaded successfully __init__ /usr/local/lib/python2.7/dist-packages/migrate/versioning/script/base.py:30
2014-12-12 16:33:58.631 20132 DEBUG migrate.versioning.script.base [-] Loading script /opt/stack/heat/heat/db/sqlalchemy/migrate_repo/versions/024_event_resource_name.py... __init__ /usr/local/lib/python2.7/dist-packages/migrate/versioning/script/base.py:27
2014-12-12 16:33:58.631 20132 DEBUG migrate.versioning.script.base [-] Script /opt/stack/heat/heat/db/sqlalchemy/migrate_repo/versions/024_event_resource_name.py loaded successfully __init__ /usr/local/lib/python2.7/dist-packages/migrate/versioning/script/base.py:30
2014-12-12 16:33:58.631 20132 DEBUG migrate.versioning.script.base [-] Loading script /opt/stack/heat/heat/db/sqlalchemy/migrate_repo/versions/025_user_creds_drop_service.py... __init__ /usr/local/lib/python2.7/dist-packages/migrate/versioning/script/base.py:27
2014-12-12 16:33:58.631 20132 DEBUG migrate.versioning.script.base [-] Script /opt/stack/heat/heat/db/sqlalchemy/migrate_repo/versions/025_user_creds_drop_service.py loaded successfully __init__ /usr/local/lib/python2.7/dist-packages/migrate/versioning/script/base.py:30
2014-12-12 16:33:58.632 20132 DEBUG migrate.versioning.script.base [-] Loading script /opt/stack/heat/heat/db/sqlalchemy/migrate_repo/versions/026_user_creds_drop_aws.py... __init__ /usr/local/lib/python2.7/dist-packages/migrate/versioning/script/base.py:27
2014-12-12 16:33:58.632 20132 DEBUG migrate.versioning.script.base [-] Script /opt/stack/heat/heat/db/sqlalchemy/migrate_repo/versions/026_user_creds_drop_aws.py loaded successfully __init__ /usr/local/lib/python2.7/dist-packages/migrate/versioning/script/base.py:30
2014-12-12 16:33:58.632 20132 DEBUG migrate.versioning.script.base [-] Loading script /opt/stack/heat/heat/db/sqlalchemy/migrate_repo/versions/027_user_creds_trusts.py... __init__ /usr/local/lib/python2.7/dist-packages/migrate/versioning/script/base.py:27
2014-12-12 16:33:58.632 20132 DEBUG migrate.versioning.script.base [-] Script /opt/stack/heat/heat/db/sqlalchemy/migrate_repo/versions/027_user_creds_trusts.py loaded successfully __init__ /usr/local/lib/python2.7/dist-packages/migrate/versioning/script/base.py:30
2014-12-12 16:33:58.632 20132 DEBUG migrate.versioning.script.base [-] Loading script /opt/stack/heat/heat/db/sqlalchemy/migrate_repo/versions/028_text_mysql_longtext.py... __init__ /usr/local/lib/python2.7/dist-packages/migrate/versioning/script/base.py:27
2014-12-12 16:33:58.632 20132 DEBUG migrate.versioning.script.base [-] Script /opt/stack/heat/heat/db/sqlalchemy/migrate_repo/versions/028_text_mysql_longtext.py loaded successfully __init__ /usr/local/lib/python2.7/dist-packages/migrate/versioning/script/base.py:30
2014-12-12 16:33:58.632 20132 DEBUG migrate.versioning.script.base [-] Loading script /opt/stack/heat/heat/db/sqlalchemy/migrate_repo/versions/029_event_id_to_uuid.py... __init__ /usr/local/lib/python2.7/dist-packages/migrate/versioning/script/base.py:27
2014-12-12 16:33:58.632 20132 DEBUG migrate.versioning.script.base [-] Script /opt/stack/heat/heat/db/sqlalchemy/migrate_repo/versions/029_event_id_to_uuid.py loaded successfully __init__ /usr/local/lib/python2.7/dist-packages/migrate/versioning/script/base.py:30
2014-12-12 16:33:58.632 20132 DEBUG migrate.versioning.script.base [-] Loading script /opt/stack/heat/heat/db/sqlalchemy/migrate_repo/versions/030_remove_uuidutils.py... __init__ /usr/local/lib/python2.7/dist-packages/migrate/versioning/script/base.py:27
2014-12-12 16:33:58.632 20132 DEBUG migrate.versioning.script.base [-] Script /opt/stack/heat/heat/db/sqlalchemy/migrate_repo/versions/030_remove_uuidutils.py loaded successfully __init__ /usr/local/lib/python2.7/dist-packages/migrate/versioning/script/base.py:30
2014-12-12 16:33:58.632 20132 DEBUG migrate.versioning.script.base [-] Loading script /opt/stack/heat/heat/db/sqlalchemy/migrate_repo/versions/031_stack_lock.py... __init__ /usr/local/lib/python2.7/dist-packages/migrate/versioning/script/base.py:27
2014-12-12 16:33:58.632 20132 DEBUG migrate.versioning.script.base [-] Script /opt/stack/heat/heat/db/sqlalchemy/migrate_repo/versions/031_stack_lock.py loaded successfully __init__ /usr/local/lib/python2.7/dist-packages/migrate/versioning/script/base.py:30
2014-12-12 16:33:58.632 20132 DEBUG migrate.versioning.script.base [-] Loading script /opt/stack/heat/heat/db/sqlalchemy/migrate_repo/versions/032_decrypt_method.py... __init__ /usr/local/lib/python2.7/dist-packages/migrate/versioning/script/base.py:27
2014-12-12 16:33:58.632 20132 DEBUG migrate.versioning.script.base [-] Script /opt/stack/heat/heat/db/sqlalchemy/migrate_repo/versions/032_decrypt_method.py loaded successfully __init__ /usr/local/lib/python2.7/dist-packages/migrate/versioning/script/base.py:30
2014-12-12 16:33:58.632 20132 DEBUG migrate.versioning.script.base [-] Loading script /opt/stack/heat/heat/db/sqlalchemy/migrate_repo/versions/033_software_config.py... __init__ /usr/local/lib/python2.7/dist-packages/migrate/versioning/script/base.py:27
2014-12-12 16:33:58.633 20132 DEBUG migrate.versioning.script.base [-] Script /opt/stack/heat/heat/db/sqlalchemy/migrate_repo/versions/033_software_config.py loaded successfully __init__ /usr/local/lib/python2.7/dist-packages/migrate/versioning/script/base.py:30
2014-12-12 16:33:58.633 20132 DEBUG migrate.versioning.script.base [-] Loading script /opt/stack/heat/heat/db/sqlalchemy/migrate_repo/versions/034_raw_template_files.py... __init__ /usr/local/lib/python2.7/dist-packages/migrate/versioning/script/base.py:27
2014-12-12 16:33:58.633 20132 DEBUG migrate.versioning.script.base [-] Script /opt/stack/heat/heat/db/sqlalchemy/migrate_repo/versions/034_raw_template_files.py loaded successfully __init__ /usr/local/lib/python2.7/dist-packages/migrate/versioning/script/base.py:30
2014-12-12 16:33:58.633 20132 DEBUG migrate.versioning.script.base [-] Loading script /opt/stack/heat/heat/db/sqlalchemy/migrate_repo/versions/035_event_uuid_to_id.py... __init__ /usr/local/lib/python2.7/dist-packages/migrate/versioning/script/base.py:27
2014-12-12 16:33:58.633 20132 DEBUG migrate.versioning.script.base [-] Script /opt/stack/heat/heat/db/sqlalchemy/migrate_repo/versions/035_event_uuid_to_id.py loaded successfully __init__ /usr/local/lib/python2.7/dist-packages/migrate/versioning/script/base.py:30
2014-12-12 16:33:58.633 20132 DEBUG migrate.versioning.script.base [-] Loading script /opt/stack/heat/heat/db/sqlalchemy/migrate_repo/versions/036_stack_domain_project.py... __init__ /usr/local/lib/python2.7/dist-packages/migrate/versioning/script/base.py:27
2014-12-12 16:33:58.633 20132 DEBUG migrate.versioning.script.base [-] Script /opt/stack/heat/heat/db/sqlalchemy/migrate_repo/versions/036_stack_domain_project.py loaded successfully __init__ /usr/local/lib/python2.7/dist-packages/migrate/versioning/script/base.py:30
2014-12-12 16:33:58.633 20132 DEBUG migrate.versioning.script.base [-] Loading script /opt/stack/heat/heat/db/sqlalchemy/migrate_repo/versions/037_migrate_hot_template.py... __init__ /usr/local/lib/python2.7/dist-packages/migrate/versioning/script/base.py:27
2014-12-12 16:33:58.633 20132 DEBUG migrate.versioning.script.base [-] Script /opt/stack/heat/heat/db/sqlalchemy/migrate_repo/versions/037_migrate_hot_template.py loaded successfully __init__ /usr/local/lib/python2.7/dist-packages/migrate/versioning/script/base.py:30
2014-12-12 16:33:58.633 20132 DEBUG migrate.versioning.script.base [-] Loading script /opt/stack/heat/heat/db/sqlalchemy/migrate_repo/versions/038_software_config_json_config.py... __init__ /usr/local/lib/python2.7/dist-packages/migrate/versioning/script/base.py:27
2014-12-12 16:33:58.633 20132 DEBUG migrate.versioning.script.base [-] Script /opt/stack/heat/heat/db/sqlalchemy/migrate_repo/versions/038_software_config_json_config.py loaded successfully __init__ /usr/local/lib/python2.7/dist-packages/migrate/versioning/script/base.py:30
2014-12-12 16:33:58.633 20132 DEBUG migrate.versioning.script.base [-] Loading script /opt/stack/heat/heat/db/sqlalchemy/migrate_repo/versions/039_user_creds_nullable.py... __init__ /usr/local/lib/python2.7/dist-packages/migrate/versioning/script/base.py:27
2014-12-12 16:33:58.633 20132 DEBUG migrate.versioning.script.base [-] Script /opt/stack/heat/heat/db/sqlalchemy/migrate_repo/versions/039_user_creds_nullable.py loaded successfully __init__ /usr/local/lib/python2.7/dist-packages/migrate/versioning/script/base.py:30
2014-12-12 16:33:58.633 20132 DEBUG migrate.versioning.script.base [-] Loading script /opt/stack/heat/heat/db/sqlalchemy/migrate_repo/versions/040_software_deployment_no_signal_id.py... __init__ /usr/local/lib/python2.7/dist-packages/migrate/versioning/script/base.py:27
2014-12-12 16:33:58.633 20132 DEBUG migrate.versioning.script.base [-] Script /opt/stack/heat/heat/db/sqlalchemy/migrate_repo/versions/040_software_deployment_no_signal_id.py loaded successfully __init__ /usr/local/lib/python2.7/dist-packages/migrate/versioning/script/base.py:30
2014-12-12 16:33:58.634 20132 DEBUG migrate.versioning.script.base [-] Loading script /opt/stack/heat/heat/db/sqlalchemy/migrate_repo/versions/041_migrate_hot_template_resources.py... __init__ /usr/local/lib/python2.7/dist-packages/migrate/versioning/script/base.py:27
2014-12-12 16:33:58.634 20132 DEBUG migrate.versioning.script.base [-] Script /opt/stack/heat/heat/db/sqlalchemy/migrate_repo/versions/041_migrate_hot_template_resources.py loaded successfully __init__ /usr/local/lib/python2.7/dist-packages/migrate/versioning/script/base.py:30
2014-12-12 16:33:58.634 20132 DEBUG migrate.versioning.script.base [-] Loading script /opt/stack/heat/heat/db/sqlalchemy/migrate_repo/versions/042_software_deployment_domain_project.py... __init__ /usr/local/lib/python2.7/dist-packages/migrate/versioning/script/base.py:27
2014-12-12 16:33:58.634 20132 DEBUG migrate.versioning.script.base [-] Script /opt/stack/heat/heat/db/sqlalchemy/migrate_repo/versions/042_software_deployment_domain_project.py loaded successfully __init__ /usr/local/lib/python2.7/dist-packages/migrate/versioning/script/base.py:30
2014-12-12 16:33:58.634 20132 DEBUG migrate.versioning.script.base [-] Loading script /opt/stack/heat/heat/db/sqlalchemy/migrate_repo/versions/043_migrate_template_versions.py... __init__ /usr/local/lib/python2.7/dist-packages/migrate/versioning/script/base.py:27
2014-12-12 16:33:58.634 20132 DEBUG migrate.versioning.script.base [-] Script /opt/stack/heat/heat/db/sqlalchemy/migrate_repo/versions/043_migrate_template_versions.py loaded successfully __init__ /usr/local/lib/python2.7/dist-packages/migrate/versioning/script/base.py:30
2014-12-12 16:33:58.634 20132 DEBUG migrate.versioning.script.base [-] Loading script /opt/stack/heat/heat/db/sqlalchemy/migrate_repo/versions/044_snapshots.py... __init__ /usr/local/lib/python2.7/dist-packages/migrate/versioning/script/base.py:27
2014-12-12 16:33:58.634 20132 DEBUG migrate.versioning.script.base [-] Script /opt/stack/heat/heat/db/sqlalchemy/migrate_repo/versions/044_snapshots.py loaded successfully __init__ /usr/local/lib/python2.7/dist-packages/migrate/versioning/script/base.py:30
2014-12-12 16:33:58.634 20132 DEBUG migrate.versioning.script.base [-] Loading script /opt/stack/heat/heat/db/sqlalchemy/migrate_repo/versions/045_stack_backup.py... __init__ /usr/local/lib/python2.7/dist-packages/migrate/versioning/script/base.py:27
2014-12-12 16:33:58.634 20132 DEBUG migrate.versioning.script.base [-] Script /opt/stack/heat/heat/db/sqlalchemy/migrate_repo/versions/045_stack_backup.py loaded successfully __init__ /usr/local/lib/python2.7/dist-packages/migrate/versioning/script/base.py:30
2014-12-12 16:33:58.634 20132 DEBUG migrate.versioning.script.base [-] Loading script /opt/stack/heat/heat/db/sqlalchemy/migrate_repo/versions/046_properties_data.py... __init__ /usr/local/lib/python2.7/dist-packages/migrate/versioning/script/base.py:27
2014-12-12 16:33:58.634 20132 DEBUG migrate.versioning.script.base [-] Script /opt/stack/heat/heat/db/sqlalchemy/migrate_repo/versions/046_properties_data.py loaded successfully __init__ /usr/local/lib/python2.7/dist-packages/migrate/versioning/script/base.py:30
2014-12-12 16:33:58.634 20132 DEBUG migrate.versioning.repository [-] Repository /opt/stack/heat/heat/db/sqlalchemy/migrate_repo loaded successfully __init__ /usr/local/lib/python2.7/dist-packages/migrate/versioning/repository.py:82
2014-12-12 16:33:58.634 20132 DEBUG migrate.versioning.repository [-] Config: OrderedDict([('db_settings', OrderedDict([('__name__', 'db_settings'), ('repository_id', 'heat'), ('version_table', 'migrate_version'), ('required_dbs', '[]'), ('use_timestamp_numbering', 'False')]))]) __init__ /usr/local/lib/python2.7/dist-packages/migrate/versioning/repository.py:83
2014-12-12 16:33:58.648 20132 DEBUG migrate.versioning.repository [-] Loading repository /opt/stack/heat/heat/db/sqlalchemy/migrate_repo... __init__ /usr/local/lib/python2.7/dist-packages/migrate/versioning/repository.py:76
2014-12-12 16:33:58.649 20132 DEBUG migrate.versioning.script.base [-] Loading script /opt/stack/heat/heat/db/sqlalchemy/migrate_repo/versions/015_grizzly.py... __init__ /usr/local/lib/python2.7/dist-packages/migrate/versioning/script/base.py:27
2014-12-12 16:33:58.649 20132 DEBUG migrate.versioning.script.base [-] Script /opt/stack/heat/heat/db/sqlalchemy/migrate_repo/versions/015_grizzly.py loaded successfully __init__ /usr/local/lib/python2.7/dist-packages/migrate/versioning/script/base.py:30
2014-12-12 16:33:58.649 20132 DEBUG migrate.versioning.script.base [-] Loading script /opt/stack/heat/heat/db/sqlalchemy/migrate_repo/versions/016_timeout_nullable.py... __init__ /usr/local/lib/python2.7/dist-packages/migrate/versioning/script/base.py:27
2014-12-12 16:33:58.649 20132 DEBUG migrate.versioning.script.base [-] Script /opt/stack/heat/heat/db/sqlalchemy/migrate_repo/versions/016_timeout_nullable.py loaded successfully __init__ /usr/local/lib/python2.7/dist-packages/migrate/versioning/script/base.py:30
2014-12-12 16:33:58.649 20132 DEBUG migrate.versioning.script.base [-] Loading script /opt/stack/heat/heat/db/sqlalchemy/migrate_repo/versions/017_event_state_status.py... __init__ /usr/local/lib/python2.7/dist-packages/migrate/versioning/script/base.py:27
2014-12-12 16:33:58.649 20132 DEBUG migrate.versioning.script.base [-] Script /opt/stack/heat/heat/db/sqlalchemy/migrate_repo/versions/017_event_state_status.py loaded successfully __init__ /usr/local/lib/python2.7/dist-packages/migrate/versioning/script/base.py:30
2014-12-12 16:33:58.649 20132 DEBUG migrate.versioning.script.base [-] Loading script /opt/stack/heat/heat/db/sqlalchemy/migrate_repo/versions/018_resource_id_uuid.py... __init__ /usr/local/lib/python2.7/dist-packages/migrate/versioning/script/base.py:27
2014-12-12 16:33:58.649 20132 DEBUG migrate.versioning.script.base [-] Script /opt/stack/heat/heat/db/sqlalchemy/migrate_repo/versions/018_resource_id_uuid.py loaded successfully __init__ /usr/local/lib/python2.7/dist-packages/migrate/versioning/script/base.py:30
2014-12-12 16:33:58.649 20132 DEBUG migrate.versioning.script.base [-] Loading script /opt/stack/heat/heat/db/sqlalchemy/migrate_repo/versions/019_resource_action_status.py... __init__ /usr/local/lib/python2.7/dist-packages/migrate/versioning/script/base.py:27
2014-12-12 16:33:58.650 20132 DEBUG migrate.versioning.script.base [-] Script /opt/stack/heat/heat/db/sqlalchemy/migrate_repo/versions/019_resource_action_status.py loaded successfully __init__ /usr/local/lib/python2.7/dist-packages/migrate/versioning/script/base.py:30
2014-12-12 16:33:58.650 20132 DEBUG migrate.versioning.script.base [-] Loading script /opt/stack/heat/heat/db/sqlalchemy/migrate_repo/versions/020_stack_action.py... __init__ /usr/local/lib/python2.7/dist-packages/migrate/versioning/script/base.py:27
2014-12-12 16:33:58.650 20132 DEBUG migrate.versioning.script.base [-] Script /opt/stack/heat/heat/db/sqlalchemy/migrate_repo/versions/020_stack_action.py loaded successfully __init__ /usr/local/lib/python2.7/dist-packages/migrate/versioning/script/base.py:30
2014-12-12 16:33:58.650 20132 DEBUG migrate.versioning.script.base [-] Loading script /opt/stack/heat/heat/db/sqlalchemy/migrate_repo/versions/021_resource_data.py... __init__ /usr/local/lib/python2.7/dist-packages/migrate/versioning/script/base.py:27
2014-12-12 16:33:58.650 20132 DEBUG migrate.versioning.script.base [-] Script /opt/stack/heat/heat/db/sqlalchemy/migrate_repo/versions/021_resource_data.py loaded successfully __init__ /usr/local/lib/python2.7/dist-packages/migrate/versioning/script/base.py:30
2014-12-12 16:33:58.650 20132 DEBUG migrate.versioning.script.base [-] Loading script /opt/stack/heat/heat/db/sqlalchemy/migrate_repo/versions/022_stack_event_soft_delete.py... __init__ /usr/local/lib/python2.7/dist-packages/migrate/versioning/script/base.py:27
2014-12-12 16:33:58.650 20132 DEBUG migrate.versioning.script.base [-] Script /opt/stack/heat/heat/db/sqlalchemy/migrate_repo/versions/022_stack_event_soft_delete.py loaded successfully __init__ /usr/local/lib/python2.7/dist-packages/migrate/versioning/script/base.py:30
2014-12-12 16:33:58.650 20132 DEBUG migrate.versioning.script.base [-] Loading script /opt/stack/heat/heat/db/sqlalchemy/migrate_repo/versions/023_raw_template_mysql_longtext.py... __init__ /usr/local/lib/python2.7/dist-packages/migrate/versioning/script/base.py:27
2014-12-12 16:33:58.650 20132 DEBUG migrate.versioning.script.base [-] Script /opt/stack/heat/heat/db/sqlalchemy/migrate_repo/versions/023_raw_template_mysql_longtext.py loaded successfully __init__ /usr/local/lib/python2.7/dist-packages/migrate/versioning/script/base.py:30
2014-12-12 16:33:58.650 20132 DEBUG migrate.versioning.script.base [-] Loading script /opt/stack/heat/heat/db/sqlalchemy/migrate_repo/versions/024_event_resource_name.py... __init__ /usr/local/lib/python2.7/dist-packages/migrate/versioning/script/base.py:27
2014-12-12 16:33:58.650 20132 DEBUG migrate.versioning.script.base [-] Script /opt/stack/heat/heat/db/sqlalchemy/migrate_repo/versions/024_event_resource_name.py loaded successfully __init__ /usr/local/lib/python2.7/dist-packages/migrate/versioning/script/base.py:30
2014-12-12 16:33:58.650 20132 DEBUG migrate.versioning.script.base [-] Loading script /opt/stack/heat/heat/db/sqlalchemy/migrate_repo/versions/025_user_creds_drop_service.py... __init__ /usr/local/lib/python2.7/dist-packages/migrate/versioning/script/base.py:27
2014-12-12 16:33:58.651 20132 DEBUG migrate.versioning.script.base [-] Script /opt/stack/heat/heat/db/sqlalchemy/migrate_repo/versions/025_user_creds_drop_service.py loaded successfully __init__ /usr/local/lib/python2.7/dist-packages/migrate/versioning/script/base.py:30
2014-12-12 16:33:58.651 20132 DEBUG migrate.versioning.script.base [-] Loading script /opt/stack/heat/heat/db/sqlalchemy/migrate_repo/versions/026_user_creds_drop_aws.py... __init__ /usr/local/lib/python2.7/dist-packages/migrate/versioning/script/base.py:27
2014-12-12 16:33:58.651 20132 DEBUG migrate.versioning.script.base [-] Script /opt/stack/heat/heat/db/sqlalchemy/migrate_repo/versions/026_user_creds_drop_aws.py loaded successfully __init__ /usr/local/lib/python2.7/dist-packages/migrate/versioning/script/base.py:30
2014-12-12 16:33:58.651 20132 DEBUG migrate.versioning.script.base [-] Loading script /opt/stack/heat/heat/db/sqlalchemy/migrate_repo/versions/027_user_creds_trusts.py... __init__ /usr/local/lib/python2.7/dist-packages/migrate/versioning/script/base.py:27
2014-12-12 16:33:58.651 20132 DEBUG migrate.versioning.script.base [-] Script /opt/stack/heat/heat/db/sqlalchemy/migrate_repo/versions/027_user_creds_trusts.py loaded successfully __init__ /usr/local/lib/python2.7/dist-packages/migrate/versioning/script/base.py:30
2014-12-12 16:33:58.651 20132 DEBUG migrate.versioning.script.base [-] Loading script /opt/stack/heat/heat/db/sqlalchemy/migrate_repo/versions/028_text_mysql_longtext.py... __init__ /usr/local/lib/python2.7/dist-packages/migrate/versioning/script/base.py:27
2014-12-12 16:33:58.651 20132 DEBUG migrate.versioning.script.base [-] Script /opt/stack/heat/heat/db/sqlalchemy/migrate_repo/versions/028_text_mysql_longtext.py loaded successfully __init__ /usr/local/lib/python2.7/dist-packages/migrate/versioning/script/base.py:30
2014-12-12 16:33:58.651 20132 DEBUG migrate.versioning.script.base [-] Loading script /opt/stack/heat/heat/db/sqlalchemy/migrate_repo/versions/029_event_id_to_uuid.py... __init__ /usr/local/lib/python2.7/dist-packages/migrate/versioning/script/base.py:27
2014-12-12 16:33:58.651 20132 DEBUG migrate.versioning.script.base [-] Script /opt/stack/heat/heat/db/sqlalchemy/migrate_repo/versions/029_event_id_to_uuid.py loaded successfully __init__ /usr/local/lib/python2.7/dist-packages/migrate/versioning/script/base.py:30
2014-12-12 16:33:58.651 20132 DEBUG migrate.versioning.script.base [-] Loading script /opt/stack/heat/heat/db/sqlalchemy/migrate_repo/versions/030_remove_uuidutils.py... __init__ /usr/local/lib/python2.7/dist-packages/migrate/versioning/script/base.py:27
2014-12-12 16:33:58.651 20132 DEBUG migrate.versioning.script.base [-] Script /opt/stack/heat/heat/db/sqlalchemy/migrate_repo/versions/030_remove_uuidutils.py loaded successfully __init__ /usr/local/lib/python2.7/dist-packages/migrate/versioning/script/base.py:30
2014-12-12 16:33:58.651 20132 DEBUG migrate.versioning.script.base [-] Loading script /opt/stack/heat/heat/db/sqlalchemy/migrate_repo/versions/031_stack_lock.py... __init__ /usr/local/lib/python2.7/dist-packages/migrate/versioning/script/base.py:27
2014-12-12 16:33:58.651 20132 DEBUG migrate.versioning.script.base [-] Script /opt/stack/heat/heat/db/sqlalchemy/migrate_repo/versions/031_stack_lock.py loaded successfully __init__ /usr/local/lib/python2.7/dist-packages/migrate/versioning/script/base.py:30
2014-12-12 16:33:58.651 20132 DEBUG migrate.versioning.script.base [-] Loading script /opt/stack/heat/heat/db/sqlalchemy/migrate_repo/versions/032_decrypt_method.py... __init__ /usr/local/lib/python2.7/dist-packages/migrate/versioning/script/base.py:27
2014-12-12 16:33:58.651 20132 DEBUG migrate.versioning.script.base [-] Script /opt/stack/heat/heat/db/sqlalchemy/migrate_repo/versions/032_decrypt_method.py loaded successfully __init__ /usr/local/lib/python2.7/dist-packages/migrate/versioning/script/base.py:30
2014-12-12 16:33:58.652 20132 DEBUG migrate.versioning.script.base [-] Loading script /opt/stack/heat/heat/db/sqlalchemy/migrate_repo/versions/033_software_config.py... __init__ /usr/local/lib/python2.7/dist-packages/migrate/versioning/script/base.py:27
2014-12-12 16:33:58.652 20132 DEBUG migrate.versioning.script.base [-] Script /opt/stack/heat/heat/db/sqlalchemy/migrate_repo/versions/033_software_config.py loaded successfully __init__ /usr/local/lib/python2.7/dist-packages/migrate/versioning/script/base.py:30
2014-12-12 16:33:58.652 20132 DEBUG migrate.versioning.script.base [-] Loading script /opt/stack/heat/heat/db/sqlalchemy/migrate_repo/versions/034_raw_template_files.py... __init__ /usr/local/lib/python2.7/dist-packages/migrate/versioning/script/base.py:27
2014-12-12 16:33:58.652 20132 DEBUG migrate.versioning.script.base [-] Script /opt/stack/heat/heat/db/sqlalchemy/migrate_repo/versions/034_raw_template_files.py loaded successfully __init__ /usr/local/lib/python2.7/dist-packages/migrate/versioning/script/base.py:30
2014-12-12 16:33:58.652 20132 DEBUG migrate.versioning.script.base [-] Loading script /opt/stack/heat/heat/db/sqlalchemy/migrate_repo/versions/035_event_uuid_to_id.py... __init__ /usr/local/lib/python2.7/dist-packages/migrate/versioning/script/base.py:27
2014-12-12 16:33:58.652 20132 DEBUG migrate.versioning.script.base [-] Script /opt/stack/heat/heat/db/sqlalchemy/migrate_repo/versions/035_event_uuid_to_id.py loaded successfully __init__ /usr/local/lib/python2.7/dist-packages/migrate/versioning/script/base.py:30
2014-12-12 16:33:58.652 20132 DEBUG migrate.versioning.script.base [-] Loading script /opt/stack/heat/heat/db/sqlalchemy/migrate_repo/versions/036_stack_domain_project.py... __init__ /usr/local/lib/python2.7/dist-packages/migrate/versioning/script/base.py:27
2014-12-12 16:33:58.652 20132 DEBUG migrate.versioning.script.base [-] Script /opt/stack/heat/heat/db/sqlalchemy/migrate_repo/versions/036_stack_domain_project.py loaded successfully __init__ /usr/local/lib/python2.7/dist-packages/migrate/versioning/script/base.py:30
2014-12-12 16:33:58.652 20132 DEBUG migrate.versioning.script.base [-] Loading script /opt/stack/heat/heat/db/sqlalchemy/migrate_repo/versions/037_migrate_hot_template.py... __init__ /usr/local/lib/python2.7/dist-packages/migrate/versioning/script/base.py:27
2014-12-12 16:33:58.652 20132 DEBUG migrate.versioning.script.base [-] Script /opt/stack/heat/heat/db/sqlalchemy/migrate_repo/versions/037_migrate_hot_template.py loaded successfully __init__ /usr/local/lib/python2.7/dist-packages/migrate/versioning/script/base.py:30
2014-12-12 16:33:58.652 20132 DEBUG migrate.versioning.script.base [-] Loading script /opt/stack/heat/heat/db/sqlalchemy/migrate_repo/versions/038_software_config_json_config.py... __init__ /usr/local/lib/python2.7/dist-packages/migrate/versioning/script/base.py:27
2014-12-12 16:33:58.652 20132 DEBUG migrate.versioning.script.base [-] Script /opt/stack/heat/heat/db/sqlalchemy/migrate_repo/versions/038_software_config_json_config.py loaded successfully __init__ /usr/local/lib/python2.7/dist-packages/migrate/versioning/script/base.py:30
2014-12-12 16:33:58.652 20132 DEBUG migrate.versioning.script.base [-] Loading script /opt/stack/heat/heat/db/sqlalchemy/migrate_repo/versions/039_user_creds_nullable.py... __init__ /usr/local/lib/python2.7/dist-packages/migrate/versioning/script/base.py:27
2014-12-12 16:33:58.652 20132 DEBUG migrate.versioning.script.base [-] Script /opt/stack/heat/heat/db/sqlalchemy/migrate_repo/versions/039_user_creds_nullable.py loaded successfully __init__ /usr/local/lib/python2.7/dist-packages/migrate/versioning/script/base.py:30
2014-12-12 16:33:58.652 20132 DEBUG migrate.versioning.script.base [-] Loading script /opt/stack/heat/heat/db/sqlalchemy/migrate_repo/versions/040_software_deployment_no_signal_id.py... __init__ /usr/local/lib/python2.7/dist-packages/migrate/versioning/script/base.py:27
2014-12-12 16:33:58.653 20132 DEBUG migrate.versioning.script.base [-] Script /opt/stack/heat/heat/db/sqlalchemy/migrate_repo/versions/040_software_deployment_no_signal_id.py loaded successfully __init__ /usr/local/lib/python2.7/dist-packages/migrate/versioning/script/base.py:30
2014-12-12 16:33:58.653 20132 DEBUG migrate.versioning.script.base [-] Loading script /opt/stack/heat/heat/db/sqlalchemy/migrate_repo/versions/041_migrate_hot_template_resources.py... __init__ /usr/local/lib/python2.7/dist-packages/migrate/versioning/script/base.py:27
2014-12-12 16:33:58.653 20132 DEBUG migrate.versioning.script.base [-] Script /opt/stack/heat/heat/db/sqlalchemy/migrate_repo/versions/041_migrate_hot_template_resources.py loaded successfully __init__ /usr/local/lib/python2.7/dist-packages/migrate/versioning/script/base.py:30
2014-12-12 16:33:58.653 20132 DEBUG migrate.versioning.script.base [-] Loading script /opt/stack/heat/heat/db/sqlalchemy/migrate_repo/versions/042_software_deployment_domain_project.py... __init__ /usr/local/lib/python2.7/dist-packages/migrate/versioning/script/base.py:27
2014-12-12 16:33:58.653 20132 DEBUG migrate.versioning.script.base [-] Script /opt/stack/heat/heat/db/sqlalchemy/migrate_repo/versions/042_software_deployment_domain_project.py loaded successfully __init__ /usr/local/lib/python2.7/dist-packages/migrate/versioning/script/base.py:30
2014-12-12 16:33:58.653 20132 DEBUG migrate.versioning.script.base [-] Loading script /opt/stack/heat/heat/db/sqlalchemy/migrate_repo/versions/043_migrate_template_versions.py... __init__ /usr/local/lib/python2.7/dist-packages/migrate/versioning/script/base.py:27
2014-12-12 16:33:58.653 20132 DEBUG migrate.versioning.script.base [-] Script /opt/stack/heat/heat/db/sqlalchemy/migrate_repo/versions/043_migrate_template_versions.py loaded successfully __init__ /usr/local/lib/python2.7/dist-packages/migrate/versioning/script/base.py:30
2014-12-12 16:33:58.653 20132 DEBUG migrate.versioning.script.base [-] Loading script /opt/stack/heat/heat/db/sqlalchemy/migrate_repo/versions/044_snapshots.py... __init__ /usr/local/lib/python2.7/dist-packages/migrate/versioning/script/base.py:27
2014-12-12 16:33:58.653 20132 DEBUG migrate.versioning.script.base [-] Script /opt/stack/heat/heat/db/sqlalchemy/migrate_repo/versions/044_snapshots.py loaded successfully __init__ /usr/local/lib/python2.7/dist-packages/migrate/versioning/script/base.py:30
2014-12-12 16:33:58.653 20132 DEBUG migrate.versioning.script.base [-] Loading script /opt/stack/heat/heat/db/sqlalchemy/migrate_repo/versions/045_stack_backup.py... __init__ /usr/local/lib/python2.7/dist-packages/migrate/versioning/script/base.py:27
2014-12-12 16:33:58.653 20132 DEBUG migrate.versioning.script.base [-] Script /opt/stack/heat/heat/db/sqlalchemy/migrate_repo/versions/045_stack_backup.py loaded successfully __init__ /usr/local/lib/python2.7/dist-packages/migrate/versioning/script/base.py:30
2014-12-12 16:33:58.653 20132 DEBUG migrate.versioning.script.base [-] Loading script /opt/stack/heat/heat/db/sqlalchemy/migrate_repo/versions/046_properties_data.py... __init__ /usr/local/lib/python2.7/dist-packages/migrate/versioning/script/base.py:27
2014-12-12 16:33:58.653 20132 DEBUG migrate.versioning.script.base [-] Script /opt/stack/heat/heat/db/sqlalchemy/migrate_repo/versions/046_properties_data.py loaded successfully __init__ /usr/local/lib/python2.7/dist-packages/migrate/versioning/script/base.py:30
2014-12-12 16:33:58.653 20132 DEBUG migrate.versioning.repository [-] Repository /opt/stack/heat/heat/db/sqlalchemy/migrate_repo loaded successfully __init__ /usr/local/lib/python2.7/dist-packages/migrate/versioning/repository.py:82
2014-12-12 16:33:58.653 20132 DEBUG migrate.versioning.repository [-] Config: OrderedDict([('db_settings', OrderedDict([('__name__', 'db_settings'), ('repository_id', 'heat'), ('version_table', 'migrate_version'), ('required_dbs', '[]'), ('use_timestamp_numbering', 'False')]))]) __init__ /usr/local/lib/python2.7/dist-packages/migrate/versioning/repository.py:83
2014-12-12 16:33:58.698 20132 DEBUG migrate.versioning.repository [-] Loading repository /opt/stack/heat/heat/db/sqlalchemy/migrate_repo... __init__ /usr/local/lib/python2.7/dist-packages/migrate/versioning/repository.py:76
2014-12-12 16:33:58.698 20132 DEBUG migrate.versioning.script.base [-] Loading script /opt/stack/heat/heat/db/sqlalchemy/migrate_repo/versions/015_grizzly.py... __init__ /usr/local/lib/python2.7/dist-packages/migrate/versioning/script/base.py:27
2014-12-12 16:33:58.699 20132 DEBUG migrate.versioning.script.base [-] Script /opt/stack/heat/heat/db/sqlalchemy/migrate_repo/versions/015_grizzly.py loaded successfully __init__ /usr/local/lib/python2.7/dist-packages/migrate/versioning/script/base.py:30
2014-12-12 16:33:58.699 20132 DEBUG migrate.versioning.script.base [-] Loading script /opt/stack/heat/heat/db/sqlalchemy/migrate_repo/versions/016_timeout_nullable.py... __init__ /usr/local/lib/python2.7/dist-packages/migrate/versioning/script/base.py:27
2014-12-12 16:33:58.699 20132 DEBUG migrate.versioning.script.base [-] Script /opt/stack/heat/heat/db/sqlalchemy/migrate_repo/versions/016_timeout_nullable.py loaded successfully __init__ /usr/local/lib/python2.7/dist-packages/migrate/versioning/script/base.py:30
2014-12-12 16:33:58.699 20132 DEBUG migrate.versioning.script.base [-] Loading script /opt/stack/heat/heat/db/sqlalchemy/migrate_repo/versions/017_event_state_status.py... __init__ /usr/local/lib/python2.7/dist-packages/migrate/versioning/script/base.py:27
2014-12-12 16:33:58.699 20132 DEBUG migrate.versioning.script.base [-] Script /opt/stack/heat/heat/db/sqlalchemy/migrate_repo/versions/017_event_state_status.py loaded successfully __init__ /usr/local/lib/python2.7/dist-packages/migrate/versioning/script/base.py:30
2014-12-12 16:33:58.699 20132 DEBUG migrate.versioning.script.base [-] Loading script /opt/stack/heat/heat/db/sqlalchemy/migrate_repo/versions/018_resource_id_uuid.py... __init__ /usr/local/lib/python2.7/dist-packages/migrate/versioning/script/base.py:27
2014-12-12 16:33:58.699 20132 DEBUG migrate.versioning.script.base [-] Script /opt/stack/heat/heat/db/sqlalchemy/migrate_repo/versions/018_resource_id_uuid.py loaded successfully __init__ /usr/local/lib/python2.7/dist-packages/migrate/versioning/script/base.py:30
2014-12-12 16:33:58.699 20132 DEBUG migrate.versioning.script.base [-] Loading script /opt/stack/heat/heat/db/sqlalchemy/migrate_repo/versions/019_resource_action_status.py... __init__ /usr/local/lib/python2.7/dist-packages/migrate/versioning/script/base.py:27
2014-12-12 16:33:58.699 20132 DEBUG migrate.versioning.script.base [-] Script /opt/stack/heat/heat/db/sqlalchemy/migrate_repo/versions/019_resource_action_status.py loaded successfully __init__ /usr/local/lib/python2.7/dist-packages/migrate/versioning/script/base.py:30
2014-12-12 16:33:58.699 20132 DEBUG migrate.versioning.script.base [-] Loading script /opt/stack/heat/heat/db/sqlalchemy/migrate_repo/versions/020_stack_action.py... __init__ /usr/local/lib/python2.7/dist-packages/migrate/versioning/script/base.py:27
2014-12-12 16:33:58.699 20132 DEBUG migrate.versioning.script.base [-] Script /opt/stack/heat/heat/db/sqlalchemy/migrate_repo/versions/020_stack_action.py loaded successfully __init__ /usr/local/lib/python2.7/dist-packages/migrate/versioning/script/base.py:30
2014-12-12 16:33:58.700 20132 DEBUG migrate.versioning.script.base [-] Loading script /opt/stack/heat/heat/db/sqlalchemy/migrate_repo/versions/021_resource_data.py... __init__ /usr/local/lib/python2.7/dist-packages/migrate/versioning/script/base.py:27
2014-12-12 16:33:58.700 20132 DEBUG migrate.versioning.script.base [-] Script /opt/stack/heat/heat/db/sqlalchemy/migrate_repo/versions/021_resource_data.py loaded successfully __init__ /usr/local/lib/python2.7/dist-packages/migrate/versioning/script/base.py:30
2014-12-12 16:33:58.700 20132 DEBUG migrate.versioning.script.base [-] Loading script /opt/stack/heat/heat/db/sqlalchemy/migrate_repo/versions/022_stack_event_soft_delete.py... __init__ /usr/local/lib/python2.7/dist-packages/migrate/versioning/script/base.py:27
2014-12-12 16:33:58.700 20132 DEBUG migrate.versioning.script.base [-] Script /opt/stack/heat/heat/db/sqlalchemy/migrate_repo/versions/022_stack_event_soft_delete.py loaded successfully __init__ /usr/local/lib/python2.7/dist-packages/migrate/versioning/script/base.py:30
2014-12-12 16:33:58.700 20132 DEBUG migrate.versioning.script.base [-] Loading script /opt/stack/heat/heat/db/sqlalchemy/migrate_repo/versions/023_raw_template_mysql_longtext.py... __init__ /usr/local/lib/python2.7/dist-packages/migrate/versioning/script/base.py:27
2014-12-12 16:33:58.700 20132 DEBUG migrate.versioning.script.base [-] Script /opt/stack/heat/heat/db/sqlalchemy/migrate_repo/versions/023_raw_template_mysql_longtext.py loaded successfully __init__ /usr/local/lib/python2.7/dist-packages/migrate/versioning/script/base.py:30
2014-12-12 16:33:58.700 20132 DEBUG migrate.versioning.script.base [-] Loading script /opt/stack/heat/heat/db/sqlalchemy/migrate_repo/versions/024_event_resource_name.py... __init__ /usr/local/lib/python2.7/dist-packages/migrate/versioning/script/base.py:27
2014-12-12 16:33:58.700 20132 DEBUG migrate.versioning.script.base [-] Script /opt/stack/heat/heat/db/sqlalchemy/migrate_repo/versions/024_event_resource_name.py loaded successfully __init__ /usr/local/lib/python2.7/dist-packages/migrate/versioning/script/base.py:30
2014-12-12 16:33:58.700 20132 DEBUG migrate.versioning.script.base [-] Loading script /opt/stack/heat/heat/db/sqlalchemy/migrate_repo/versions/025_user_creds_drop_service.py... __init__ /usr/local/lib/python2.7/dist-packages/migrate/versioning/script/base.py:27
2014-12-12 16:33:58.700 20132 DEBUG migrate.versioning.script.base [-] Script /opt/stack/heat/heat/db/sqlalchemy/migrate_repo/versions/025_user_creds_drop_service.py loaded successfully __init__ /usr/local/lib/python2.7/dist-packages/migrate/versioning/script/base.py:30
2014-12-12 16:33:58.700 20132 DEBUG migrate.versioning.script.base [-] Loading script /opt/stack/heat/heat/db/sqlalchemy/migrate_repo/versions/026_user_creds_drop_aws.py... __init__ /usr/local/lib/python2.7/dist-packages/migrate/versioning/script/base.py:27
2014-12-12 16:33:58.700 20132 DEBUG migrate.versioning.script.base [-] Script /opt/stack/heat/heat/db/sqlalchemy/migrate_repo/versions/026_user_creds_drop_aws.py loaded successfully __init__ /usr/local/lib/python2.7/dist-packages/migrate/versioning/script/base.py:30
2014-12-12 16:33:58.700 20132 DEBUG migrate.versioning.script.base [-] Loading script /opt/stack/heat/heat/db/sqlalchemy/migrate_repo/versions/027_user_creds_trusts.py... __init__ /usr/local/lib/python2.7/dist-packages/migrate/versioning/script/base.py:27
2014-12-12 16:33:58.701 20132 DEBUG migrate.versioning.script.base [-] Script /opt/stack/heat/heat/db/sqlalchemy/migrate_repo/versions/027_user_creds_trusts.py loaded successfully __init__ /usr/local/lib/python2.7/dist-packages/migrate/versioning/script/base.py:30
2014-12-12 16:33:58.701 20132 DEBUG migrate.versioning.script.base [-] Loading script /opt/stack/heat/heat/db/sqlalchemy/migrate_repo/versions/028_text_mysql_longtext.py... __init__ /usr/local/lib/python2.7/dist-packages/migrate/versioning/script/base.py:27
2014-12-12 16:33:58.701 20132 DEBUG migrate.versioning.script.base [-] Script /opt/stack/heat/heat/db/sqlalchemy/migrate_repo/versions/028_text_mysql_longtext.py loaded successfully __init__ /usr/local/lib/python2.7/dist-packages/migrate/versioning/script/base.py:30
2014-12-12 16:33:58.701 20132 DEBUG migrate.versioning.script.base [-] Loading script /opt/stack/heat/heat/db/sqlalchemy/migrate_repo/versions/029_event_id_to_uuid.py... __init__ /usr/local/lib/python2.7/dist-packages/migrate/versioning/script/base.py:27
2014-12-12 16:33:58.701 20132 DEBUG migrate.versioning.script.base [-] Script /opt/stack/heat/heat/db/sqlalchemy/migrate_repo/versions/029_event_id_to_uuid.py loaded successfully __init__ /usr/local/lib/python2.7/dist-packages/migrate/versioning/script/base.py:30
2014-12-12 16:33:58.701 20132 DEBUG migrate.versioning.script.base [-] Loading script /opt/stack/heat/heat/db/sqlalchemy/migrate_repo/versions/030_remove_uuidutils.py... __init__ /usr/local/lib/python2.7/dist-packages/migrate/versioning/script/base.py:27
2014-12-12 16:33:58.701 20132 DEBUG migrate.versioning.script.base [-] Script /opt/stack/heat/heat/db/sqlalchemy/migrate_repo/versions/030_remove_uuidutils.py loaded successfully __init__ /usr/local/lib/python2.7/dist-packages/migrate/versioning/script/base.py:30
2014-12-12 16:33:58.701 20132 DEBUG migrate.versioning.script.base [-] Loading script /opt/stack/heat/heat/db/sqlalchemy/migrate_repo/versions/031_stack_lock.py... __init__ /usr/local/lib/python2.7/dist-packages/migrate/versioning/script/base.py:27
2014-12-12 16:33:58.701 20132 DEBUG migrate.versioning.script.base [-] Script /opt/stack/heat/heat/db/sqlalchemy/migrate_repo/versions/031_stack_lock.py loaded successfully __init__ /usr/local/lib/python2.7/dist-packages/migrate/versioning/script/base.py:30
2014-12-12 16:33:58.701 20132 DEBUG migrate.versioning.script.base [-] Loading script /opt/stack/heat/heat/db/sqlalchemy/migrate_repo/versions/032_decrypt_method.py... __init__ /usr/local/lib/python2.7/dist-packages/migrate/versioning/script/base.py:27
2014-12-12 16:33:58.701 20132 DEBUG migrate.versioning.script.base [-] Script /opt/stack/heat/heat/db/sqlalchemy/migrate_repo/versions/032_decrypt_method.py loaded successfully __init__ /usr/local/lib/python2.7/dist-packages/migrate/versioning/script/base.py:30
2014-12-12 16:33:58.701 20132 DEBUG migrate.versioning.script.base [-] Loading script /opt/stack/heat/heat/db/sqlalchemy/migrate_repo/versions/033_software_config.py... __init__ /usr/local/lib/python2.7/dist-packages/migrate/versioning/script/base.py:27
2014-12-12 16:33:58.701 20132 DEBUG migrate.versioning.script.base [-] Script /opt/stack/heat/heat/db/sqlalchemy/migrate_repo/versions/033_software_config.py loaded successfully __init__ /usr/local/lib/python2.7/dist-packages/migrate/versioning/script/base.py:30
2014-12-12 16:33:58.701 20132 DEBUG migrate.versioning.script.base [-] Loading script /opt/stack/heat/heat/db/sqlalchemy/migrate_repo/versions/034_raw_template_files.py... __init__ /usr/local/lib/python2.7/dist-packages/migrate/versioning/script/base.py:27
2014-12-12 16:33:58.701 20132 DEBUG migrate.versioning.script.base [-] Script /opt/stack/heat/heat/db/sqlalchemy/migrate_repo/versions/034_raw_template_files.py loaded successfully __init__ /usr/local/lib/python2.7/dist-packages/migrate/versioning/script/base.py:30
2014-12-12 16:33:58.701 20132 DEBUG migrate.versioning.script.base [-] Loading script /opt/stack/heat/heat/db/sqlalchemy/migrate_repo/versions/035_event_uuid_to_id.py... __init__ /usr/local/lib/python2.7/dist-packages/migrate/versioning/script/base.py:27
2014-12-12 16:33:58.702 20132 DEBUG migrate.versioning.script.base [-] Script /opt/stack/heat/heat/db/sqlalchemy/migrate_repo/versions/035_event_uuid_to_id.py loaded successfully __init__ /usr/local/lib/python2.7/dist-packages/migrate/versioning/script/base.py:30
2014-12-12 16:33:58.702 20132 DEBUG migrate.versioning.script.base [-] Loading script /opt/stack/heat/heat/db/sqlalchemy/migrate_repo/versions/036_stack_domain_project.py... __init__ /usr/local/lib/python2.7/dist-packages/migrate/versioning/script/base.py:27
2014-12-12 16:33:58.702 20132 DEBUG migrate.versioning.script.base [-] Script /opt/stack/heat/heat/db/sqlalchemy/migrate_repo/versions/036_stack_domain_project.py loaded successfully __init__ /usr/local/lib/python2.7/dist-packages/migrate/versioning/script/base.py:30
2014-12-12 16:33:58.702 20132 DEBUG migrate.versioning.script.base [-] Loading script /opt/stack/heat/heat/db/sqlalchemy/migrate_repo/versions/037_migrate_hot_template.py... __init__ /usr/local/lib/python2.7/dist-packages/migrate/versioning/script/base.py:27
2014-12-12 16:33:58.702 20132 DEBUG migrate.versioning.script.base [-] Script /opt/stack/heat/heat/db/sqlalchemy/migrate_repo/versions/037_migrate_hot_template.py loaded successfully __init__ /usr/local/lib/python2.7/dist-packages/migrate/versioning/script/base.py:30
2014-12-12 16:33:58.702 20132 DEBUG migrate.versioning.script.base [-] Loading script /opt/stack/heat/heat/db/sqlalchemy/migrate_repo/versions/038_software_config_json_config.py... __init__ /usr/local/lib/python2.7/dist-packages/migrate/versioning/script/base.py:27
2014-12-12 16:33:58.702 20132 DEBUG migrate.versioning.script.base [-] Script /opt/stack/heat/heat/db/sqlalchemy/migrate_repo/versions/038_software_config_json_config.py loaded successfully __init__ /usr/local/lib/python2.7/dist-packages/migrate/versioning/script/base.py:30
2014-12-12 16:33:58.702 20132 DEBUG migrate.versioning.script.base [-] Loading script /opt/stack/heat/heat/db/sqlalchemy/migrate_repo/versions/039_user_creds_nullable.py... __init__ /usr/local/lib/python2.7/dist-packages/migrate/versioning/script/base.py:27
2014-12-12 16:33:58.702 20132 DEBUG migrate.versioning.script.base [-] Script /opt/stack/heat/heat/db/sqlalchemy/migrate_repo/versions/039_user_creds_nullable.py loaded successfully __init__ /usr/local/lib/python2.7/dist-packages/migrate/versioning/script/base.py:30
2014-12-12 16:33:58.702 20132 DEBUG migrate.versioning.script.base [-] Loading script /opt/stack/heat/heat/db/sqlalchemy/migrate_repo/versions/040_software_deployment_no_signal_id.py... __init__ /usr/local/lib/python2.7/dist-packages/migrate/versioning/script/base.py:27
2014-12-12 16:33:58.702 20132 DEBUG migrate.versioning.script.base [-] Script /opt/stack/heat/heat/db/sqlalchemy/migrate_repo/versions/040_software_deployment_no_signal_id.py loaded successfully __init__ /usr/local/lib/python2.7/dist-packages/migrate/versioning/script/base.py:30
2014-12-12 16:33:58.702 20132 DEBUG migrate.versioning.script.base [-] Loading script /opt/stack/heat/heat/db/sqlalchemy/migrate_repo/versions/041_migrate_hot_template_resources.py... __init__ /usr/local/lib/python2.7/dist-packages/migrate/versioning/script/base.py:27
2014-12-12 16:33:58.702 20132 DEBUG migrate.versioning.script.base [-] Script /opt/stack/heat/heat/db/sqlalchemy/migrate_repo/versions/041_migrate_hot_template_resources.py loaded successfully __init__ /usr/local/lib/python2.7/dist-packages/migrate/versioning/script/base.py:30
2014-12-12 16:33:58.702 20132 DEBUG migrate.versioning.script.base [-] Loading script /opt/stack/heat/heat/db/sqlalchemy/migrate_repo/versions/042_software_deployment_domain_project.py... __init__ /usr/local/lib/python2.7/dist-packages/migrate/versioning/script/base.py:27
2014-12-12 16:33:58.702 20132 DEBUG migrate.versioning.script.base [-] Script /opt/stack/heat/heat/db/sqlalchemy/migrate_repo/versions/042_software_deployment_domain_project.py loaded successfully __init__ /usr/local/lib/python2.7/dist-packages/migrate/versioning/script/base.py:30
2014-12-12 16:33:58.703 20132 DEBUG migrate.versioning.script.base [-] Loading script /opt/stack/heat/heat/db/sqlalchemy/migrate_repo/versions/043_migrate_template_versions.py... __init__ /usr/local/lib/python2.7/dist-packages/migrate/versioning/script/base.py:27
2014-12-12 16:33:58.703 20132 DEBUG migrate.versioning.script.base [-] Script /opt/stack/heat/heat/db/sqlalchemy/migrate_repo/versions/043_migrate_template_versions.py loaded successfully __init__ /usr/local/lib/python2.7/dist-packages/migrate/versioning/script/base.py:30
2014-12-12 16:33:58.703 20132 DEBUG migrate.versioning.script.base [-] Loading script /opt/stack/heat/heat/db/sqlalchemy/migrate_repo/versions/044_snapshots.py... __init__ /usr/local/lib/python2.7/dist-packages/migrate/versioning/script/base.py:27
2014-12-12 16:33:58.703 20132 DEBUG migrate.versioning.script.base [-] Script /opt/stack/heat/heat/db/sqlalchemy/migrate_repo/versions/044_snapshots.py loaded successfully __init__ /usr/local/lib/python2.7/dist-packages/migrate/versioning/script/base.py:30
2014-12-12 16:33:58.703 20132 DEBUG migrate.versioning.script.base [-] Loading script /opt/stack/heat/heat/db/sqlalchemy/migrate_repo/versions/045_stack_backup.py... __init__ /usr/local/lib/python2.7/dist-packages/migrate/versioning/script/base.py:27
2014-12-12 16:33:58.703 20132 DEBUG migrate.versioning.script.base [-] Script /opt/stack/heat/heat/db/sqlalchemy/migrate_repo/versions/045_stack_backup.py loaded successfully __init__ /usr/local/lib/python2.7/dist-packages/migrate/versioning/script/base.py:30
2014-12-12 16:33:58.703 20132 DEBUG migrate.versioning.script.base [-] Loading script /opt/stack/heat/heat/db/sqlalchemy/migrate_repo/versions/046_properties_data.py... __init__ /usr/local/lib/python2.7/dist-packages/migrate/versioning/script/base.py:27
2014-12-12 16:33:58.703 20132 DEBUG migrate.versioning.script.base [-] Script /opt/stack/heat/heat/db/sqlalchemy/migrate_repo/versions/046_properties_data.py loaded successfully __init__ /usr/local/lib/python2.7/dist-packages/migrate/versioning/script/base.py:30
2014-12-12 16:33:58.703 20132 DEBUG migrate.versioning.repository [-] Repository /opt/stack/heat/heat/db/sqlalchemy/migrate_repo loaded successfully __init__ /usr/local/lib/python2.7/dist-packages/migrate/versioning/repository.py:82
2014-12-12 16:33:58.703 20132 DEBUG migrate.versioning.repository [-] Config: OrderedDict([('db_settings', OrderedDict([('__name__', 'db_settings'), ('repository_id', 'heat'), ('version_table', 'migrate_version'), ('required_dbs', '[]'), ('use_timestamp_numbering', 'False')]))]) __init__ /usr/local/lib/python2.7/dist-packages/migrate/versioning/repository.py:83
2014-12-12 16:33:58.709 20132 INFO migrate.versioning.api [-] 14 -> 15... 
2014-12-12 16:33:58.965 20132 INFO migrate.versioning.api [-] done
2014-12-12 16:33:58.965 20132 INFO migrate.versioning.api [-] 15 -> 16... 
2014-12-12 16:33:59.045 20132 INFO migrate.versioning.api [-] done
2014-12-12 16:33:59.045 20132 INFO migrate.versioning.api [-] 16 -> 17... 
2014-12-12 16:33:59.173 20132 INFO migrate.versioning.api [-] done
2014-12-12 16:33:59.174 20132 INFO migrate.versioning.api [-] 17 -> 18... 
2014-12-12 16:33:59.248 20132 INFO migrate.versioning.api [-] done
2014-12-12 16:33:59.249 20132 INFO migrate.versioning.api [-] 18 -> 19... 
2014-12-12 16:33:59.428 20132 INFO migrate.versioning.api [-] done
2014-12-12 16:33:59.428 20132 INFO migrate.versioning.api [-] 19 -> 20... 
2014-12-12 16:33:59.519 20132 INFO migrate.versioning.api [-] done
2014-12-12 16:33:59.520 20132 INFO migrate.versioning.api [-] 20 -> 21... 
2014-12-12 16:33:59.564 20132 INFO migrate.versioning.api [-] done
2014-12-12 16:33:59.564 20132 INFO migrate.versioning.api [-] 21 -> 22... 
2014-12-12 16:33:59.648 20132 INFO migrate.versioning.api [-] done
2014-12-12 16:33:59.649 20132 INFO migrate.versioning.api [-] 22 -> 23... 
2014-12-12 16:33:59.713 20132 INFO migrate.versioning.api [-] done
2014-12-12 16:33:59.713 20132 INFO migrate.versioning.api [-] 23 -> 24... 
2014-12-12 16:33:59.791 20132 INFO migrate.versioning.api [-] done
2014-12-12 16:33:59.791 20132 INFO migrate.versioning.api [-] 24 -> 25... 
2014-12-12 16:33:59.927 20132 INFO migrate.versioning.api [-] done
2014-12-12 16:33:59.927 20132 INFO migrate.versioning.api [-] 25 -> 26... 
2014-12-12 16:34:00.052 20132 INFO migrate.versioning.api [-] done
2014-12-12 16:34:00.052 20132 INFO migrate.versioning.api [-] 26 -> 27... 
2014-12-12 16:34:00.167 20132 INFO migrate.versioning.api [-] done
2014-12-12 16:34:00.168 20132 INFO migrate.versioning.api [-] 27 -> 28... 
2014-12-12 16:34:00.402 20132 INFO migrate.versioning.api [-] done
2014-12-12 16:34:00.402 20132 INFO migrate.versioning.api [-] 28 -> 29... 
2014-12-12 16:34:00.470 20132 INFO migrate.versioning.api [-] done
2014-12-12 16:34:00.471 20132 INFO migrate.versioning.api [-] 29 -> 30... 
2014-12-12 16:34:00.530 20132 INFO migrate.versioning.api [-] done
2014-12-12 16:34:00.531 20132 INFO migrate.versioning.api [-] 30 -> 31... 
2014-12-12 16:34:00.591 20132 INFO migrate.versioning.api [-] done
2014-12-12 16:34:00.591 20132 INFO migrate.versioning.api [-] 31 -> 32... 
2014-12-12 16:34:00.722 20132 INFO migrate.versioning.api [-] done
2014-12-12 16:34:00.723 20132 INFO migrate.versioning.api [-] 32 -> 33... 
2014-12-12 16:34:00.958 20132 INFO migrate.versioning.api [-] done
2014-12-12 16:34:00.958 20132 INFO migrate.versioning.api [-] 33 -> 34... 
2014-12-12 16:34:01.027 20132 INFO migrate.versioning.api [-] done
2014-12-12 16:34:01.028 20132 INFO migrate.versioning.api [-] 34 -> 35... 
2014-12-12 16:34:01.395 20132 INFO migrate.versioning.api [-] done
2014-12-12 16:34:01.395 20132 INFO migrate.versioning.api [-] 35 -> 36... 
2014-12-12 16:34:01.469 20132 INFO migrate.versioning.api [-] done
2014-12-12 16:34:01.470 20132 INFO migrate.versioning.api [-] 36 -> 37... 
2014-12-12 16:34:01.544 20132 INFO migrate.versioning.api [-] done
2014-12-12 16:34:01.545 20132 INFO migrate.versioning.api [-] 37 -> 38... 
2014-12-12 16:34:01.634 20132 INFO migrate.versioning.api [-] done
2014-12-12 16:34:01.634 20132 INFO migrate.versioning.api [-] 38 -> 39... 
2014-12-12 16:34:01.703 20132 INFO migrate.versioning.api [-] done
2014-12-12 16:34:01.703 20132 INFO migrate.versioning.api [-] 39 -> 40... 
2014-12-12 16:34:01.775 20132 INFO migrate.versioning.api [-] done
2014-12-12 16:34:01.775 20132 INFO migrate.versioning.api [-] 40 -> 41... 
2014-12-12 16:34:01.790 20132 INFO migrate.versioning.api [-] done
2014-12-12 16:34:01.791 20132 INFO migrate.versioning.api [-] 41 -> 42... 
2014-12-12 16:34:01.874 20132 INFO migrate.versioning.api [-] done
2014-12-12 16:34:01.874 20132 INFO migrate.versioning.api [-] 42 -> 43... 
2014-12-12 16:34:01.888 20132 INFO migrate.versioning.api [-] done
2014-12-12 16:34:01.888 20132 INFO migrate.versioning.api [-] 43 -> 44... 
2014-12-12 16:34:01.971 20132 INFO migrate.versioning.api [-] done
2014-12-12 16:34:01.972 20132 INFO migrate.versioning.api [-] 44 -> 45... 
2014-12-12 16:34:02.043 20132 INFO migrate.versioning.api [-] done
2014-12-12 16:34:02.043 20132 INFO migrate.versioning.api [-] 45 -> 46... 
2014-12-12 16:34:02.117 20132 INFO migrate.versioning.api [-] done
+ create_heat_cache_dir
+ sudo mkdir -p /var/cache/heat
+ sudo chown cloudbase /var/cache/heat
+ echo_summary 'Starting Heat'
+ [[ -t 3 ]]
+ echo -e Starting Heat
+ start_heat
+ run_process h-eng '/opt/stack/heat/bin/heat-engine --config-file=/etc/heat/heat.conf'
+ local service=h-eng
+ local 'command=/opt/stack/heat/bin/heat-engine --config-file=/etc/heat/heat.conf'
+ local group=
+ is_service_enabled h-eng
++ set +o
++ grep xtrace
+ local 'xtrace=set -o xtrace'
+ set +o xtrace
+ return 0
+ [[ True = \T\r\u\e ]]
+ screen_service h-eng '/opt/stack/heat/bin/heat-engine --config-file=/etc/heat/heat.conf' ''
+ local service=h-eng
+ local 'command=/opt/stack/heat/bin/heat-engine --config-file=/etc/heat/heat.conf'
+ local group=
+ SCREEN_NAME=stack
+ SERVICE_DIR=/opt/stack/status
++ trueorfalse True True
+++ set +o
+++ grep xtrace
++ local 'xtrace=set -o xtrace'
++ set +o xtrace
+ USE_SCREEN=True
+ is_service_enabled h-eng
++ set +o
++ grep xtrace
+ local 'xtrace=set -o xtrace'
+ set +o xtrace
+ return 0
+ screen_rc h-eng '/opt/stack/heat/bin/heat-engine --config-file=/etc/heat/heat.conf'
+ SCREEN_NAME=stack
+ SCREENRC=/home/cloudbase/devstack/stack-screenrc
+ [[ ! -e /home/cloudbase/devstack/stack-screenrc ]]
+ grep h-eng /home/cloudbase/devstack/stack-screenrc
++ echo -ne '\015'
+ NL=$'\r'
+ echo 'screen -t h-eng bash'
+ echo 'stuff "/opt/stack/heat/bin/heat-engine --config-file=/etc/heat/heat.conf"'
+ [[ -n /home/cloudbase/jenkins/workspace/openstack-hyperv-release-tests/reports/2014_12_12_13_16_55_547646598/HyperV2012_VHD_v1/logs/devstack ]]
+ echo 'logfile /home/cloudbase/jenkins/workspace/openstack-hyperv-release-tests/reports/2014_12_12_13_16_55_547646598/HyperV2012_VHD_v1/logs/devstack/screen-h-eng.2014-12-12-162857.log'
+ echo 'log on'
+ screen -S stack -X screen -t h-eng
+ [[ -n /home/cloudbase/jenkins/workspace/openstack-hyperv-release-tests/reports/2014_12_12_13_16_55_547646598/HyperV2012_VHD_v1/logs/devstack ]]
+ screen -S stack -p h-eng -X logfile /home/cloudbase/jenkins/workspace/openstack-hyperv-release-tests/reports/2014_12_12_13_16_55_547646598/HyperV2012_VHD_v1/logs/devstack/screen-h-eng.2014-12-12-162857.log
+ screen -S stack -p h-eng -X log on
+ ln -sf /home/cloudbase/jenkins/workspace/openstack-hyperv-release-tests/reports/2014_12_12_13_16_55_547646598/HyperV2012_VHD_v1/logs/devstack/screen-h-eng.2014-12-12-162857.log /home/cloudbase/jenkins/workspace/openstack-hyperv-release-tests/reports/2014_12_12_13_16_55_547646598/HyperV2012_VHD_v1/logs/devstack/screen-h-eng.log
+ sleep 3
++ echo -ne '\015'
+ NL=$'\r'
+ [[ -n '' ]]
+ screen -S stack -p h-eng -X stuff '/opt/stack/heat/bin/heat-engine --config-file=/etc/heat/heat.conf & echo $! >/opt/stack/status/stack/h-eng.pid; fg || echo "h-eng failed to start" | tee "/opt/stack/status/stack/h-eng.failure"'
+ run_process h-api '/opt/stack/heat/bin/heat-api --config-file=/etc/heat/heat.conf'
+ local service=h-api
+ local 'command=/opt/stack/heat/bin/heat-api --config-file=/etc/heat/heat.conf'
+ local group=
+ is_service_enabled h-api
++ set +o
++ grep xtrace
+ local 'xtrace=set -o xtrace'
+ set +o xtrace
+ return 0
+ [[ True = \T\r\u\e ]]
+ screen_service h-api '/opt/stack/heat/bin/heat-api --config-file=/etc/heat/heat.conf' ''
+ local service=h-api
+ local 'command=/opt/stack/heat/bin/heat-api --config-file=/etc/heat/heat.conf'
+ local group=
+ SCREEN_NAME=stack
+ SERVICE_DIR=/opt/stack/status
++ trueorfalse True True
+++ set +o
+++ grep xtrace
++ local 'xtrace=set -o xtrace'
++ set +o xtrace
+ USE_SCREEN=True
+ is_service_enabled h-api
++ set +o
++ grep xtrace
+ local 'xtrace=set -o xtrace'
+ set +o xtrace
+ return 0
+ screen_rc h-api '/opt/stack/heat/bin/heat-api --config-file=/etc/heat/heat.conf'
+ SCREEN_NAME=stack
+ SCREENRC=/home/cloudbase/devstack/stack-screenrc
+ [[ ! -e /home/cloudbase/devstack/stack-screenrc ]]
+ grep h-api /home/cloudbase/devstack/stack-screenrc
++ echo -ne '\015'
+ NL=$'\r'
+ echo 'screen -t h-api bash'
+ echo 'stuff "/opt/stack/heat/bin/heat-api --config-file=/etc/heat/heat.conf"'
+ [[ -n /home/cloudbase/jenkins/workspace/openstack-hyperv-release-tests/reports/2014_12_12_13_16_55_547646598/HyperV2012_VHD_v1/logs/devstack ]]
+ echo 'logfile /home/cloudbase/jenkins/workspace/openstack-hyperv-release-tests/reports/2014_12_12_13_16_55_547646598/HyperV2012_VHD_v1/logs/devstack/screen-h-api.2014-12-12-162857.log'
+ echo 'log on'
+ screen -S stack -X screen -t h-api
+ [[ -n /home/cloudbase/jenkins/workspace/openstack-hyperv-release-tests/reports/2014_12_12_13_16_55_547646598/HyperV2012_VHD_v1/logs/devstack ]]
+ screen -S stack -p h-api -X logfile /home/cloudbase/jenkins/workspace/openstack-hyperv-release-tests/reports/2014_12_12_13_16_55_547646598/HyperV2012_VHD_v1/logs/devstack/screen-h-api.2014-12-12-162857.log
+ screen -S stack -p h-api -X log on
+ ln -sf /home/cloudbase/jenkins/workspace/openstack-hyperv-release-tests/reports/2014_12_12_13_16_55_547646598/HyperV2012_VHD_v1/logs/devstack/screen-h-api.2014-12-12-162857.log /home/cloudbase/jenkins/workspace/openstack-hyperv-release-tests/reports/2014_12_12_13_16_55_547646598/HyperV2012_VHD_v1/logs/devstack/screen-h-api.log
+ sleep 3
++ echo -ne '\015'
+ NL=$'\r'
+ [[ -n '' ]]
+ screen -S stack -p h-api -X stuff '/opt/stack/heat/bin/heat-api --config-file=/etc/heat/heat.conf & echo $! >/opt/stack/status/stack/h-api.pid; fg || echo "h-api failed to start" | tee "/opt/stack/status/stack/h-api.failure"'
+ run_process h-api-cfn '/opt/stack/heat/bin/heat-api-cfn --config-file=/etc/heat/heat.conf'
+ local service=h-api-cfn
+ local 'command=/opt/stack/heat/bin/heat-api-cfn --config-file=/etc/heat/heat.conf'
+ local group=
+ is_service_enabled h-api-cfn
++ set +o
++ grep xtrace
+ local 'xtrace=set -o xtrace'
+ set +o xtrace
+ return 0
+ [[ True = \T\r\u\e ]]
+ screen_service h-api-cfn '/opt/stack/heat/bin/heat-api-cfn --config-file=/etc/heat/heat.conf' ''
+ local service=h-api-cfn
+ local 'command=/opt/stack/heat/bin/heat-api-cfn --config-file=/etc/heat/heat.conf'
+ local group=
+ SCREEN_NAME=stack
+ SERVICE_DIR=/opt/stack/status
++ trueorfalse True True
+++ set +o
+++ grep xtrace
++ local 'xtrace=set -o xtrace'
++ set +o xtrace
+ USE_SCREEN=True
+ is_service_enabled h-api-cfn
++ set +o
++ grep xtrace
+ local 'xtrace=set -o xtrace'
+ set +o xtrace
+ return 0
+ screen_rc h-api-cfn '/opt/stack/heat/bin/heat-api-cfn --config-file=/etc/heat/heat.conf'
+ SCREEN_NAME=stack
+ SCREENRC=/home/cloudbase/devstack/stack-screenrc
+ [[ ! -e /home/cloudbase/devstack/stack-screenrc ]]
+ grep h-api-cfn /home/cloudbase/devstack/stack-screenrc
++ echo -ne '\015'
+ NL=$'\r'
+ echo 'screen -t h-api-cfn bash'
+ echo 'stuff "/opt/stack/heat/bin/heat-api-cfn --config-file=/etc/heat/heat.conf"'
+ [[ -n /home/cloudbase/jenkins/workspace/openstack-hyperv-release-tests/reports/2014_12_12_13_16_55_547646598/HyperV2012_VHD_v1/logs/devstack ]]
+ echo 'logfile /home/cloudbase/jenkins/workspace/openstack-hyperv-release-tests/reports/2014_12_12_13_16_55_547646598/HyperV2012_VHD_v1/logs/devstack/screen-h-api-cfn.2014-12-12-162857.log'
+ echo 'log on'
+ screen -S stack -X screen -t h-api-cfn
+ [[ -n /home/cloudbase/jenkins/workspace/openstack-hyperv-release-tests/reports/2014_12_12_13_16_55_547646598/HyperV2012_VHD_v1/logs/devstack ]]
+ screen -S stack -p h-api-cfn -X logfile /home/cloudbase/jenkins/workspace/openstack-hyperv-release-tests/reports/2014_12_12_13_16_55_547646598/HyperV2012_VHD_v1/logs/devstack/screen-h-api-cfn.2014-12-12-162857.log
+ screen -S stack -p h-api-cfn -X log on
+ ln -sf /home/cloudbase/jenkins/workspace/openstack-hyperv-release-tests/reports/2014_12_12_13_16_55_547646598/HyperV2012_VHD_v1/logs/devstack/screen-h-api-cfn.2014-12-12-162857.log /home/cloudbase/jenkins/workspace/openstack-hyperv-release-tests/reports/2014_12_12_13_16_55_547646598/HyperV2012_VHD_v1/logs/devstack/screen-h-api-cfn.log
+ sleep 3
++ echo -ne '\015'
+ NL=$'\r'
+ [[ -n '' ]]
+ screen -S stack -p h-api-cfn -X stuff '/opt/stack/heat/bin/heat-api-cfn --config-file=/etc/heat/heat.conf & echo $! >/opt/stack/status/stack/h-api-cfn.pid; fg || echo "h-api-cfn failed to start" | tee "/opt/stack/status/stack/h-api-cfn.failure"'
+ run_process h-api-cw '/opt/stack/heat/bin/heat-api-cloudwatch --config-file=/etc/heat/heat.conf'
+ local service=h-api-cw
+ local 'command=/opt/stack/heat/bin/heat-api-cloudwatch --config-file=/etc/heat/heat.conf'
+ local group=
+ is_service_enabled h-api-cw
++ set +o
++ grep xtrace
+ local 'xtrace=set -o xtrace'
+ set +o xtrace
+ return 0
+ [[ True = \T\r\u\e ]]
+ screen_service h-api-cw '/opt/stack/heat/bin/heat-api-cloudwatch --config-file=/etc/heat/heat.conf' ''
+ local service=h-api-cw
+ local 'command=/opt/stack/heat/bin/heat-api-cloudwatch --config-file=/etc/heat/heat.conf'
+ local group=
+ SCREEN_NAME=stack
+ SERVICE_DIR=/opt/stack/status
++ trueorfalse True True
+++ set +o
+++ grep xtrace
++ local 'xtrace=set -o xtrace'
++ set +o xtrace
+ USE_SCREEN=True
+ is_service_enabled h-api-cw
++ set +o
++ grep xtrace
+ local 'xtrace=set -o xtrace'
+ set +o xtrace
+ return 0
+ screen_rc h-api-cw '/opt/stack/heat/bin/heat-api-cloudwatch --config-file=/etc/heat/heat.conf'
+ SCREEN_NAME=stack
+ SCREENRC=/home/cloudbase/devstack/stack-screenrc
+ [[ ! -e /home/cloudbase/devstack/stack-screenrc ]]
+ grep h-api-cw /home/cloudbase/devstack/stack-screenrc
++ echo -ne '\015'
+ NL=$'\r'
+ echo 'screen -t h-api-cw bash'
+ echo 'stuff "/opt/stack/heat/bin/heat-api-cloudwatch --config-file=/etc/heat/heat.conf"'
+ [[ -n /home/cloudbase/jenkins/workspace/openstack-hyperv-release-tests/reports/2014_12_12_13_16_55_547646598/HyperV2012_VHD_v1/logs/devstack ]]
+ echo 'logfile /home/cloudbase/jenkins/workspace/openstack-hyperv-release-tests/reports/2014_12_12_13_16_55_547646598/HyperV2012_VHD_v1/logs/devstack/screen-h-api-cw.2014-12-12-162857.log'
+ echo 'log on'
+ screen -S stack -X screen -t h-api-cw
+ [[ -n /home/cloudbase/jenkins/workspace/openstack-hyperv-release-tests/reports/2014_12_12_13_16_55_547646598/HyperV2012_VHD_v1/logs/devstack ]]
+ screen -S stack -p h-api-cw -X logfile /home/cloudbase/jenkins/workspace/openstack-hyperv-release-tests/reports/2014_12_12_13_16_55_547646598/HyperV2012_VHD_v1/logs/devstack/screen-h-api-cw.2014-12-12-162857.log
+ screen -S stack -p h-api-cw -X log on
+ ln -sf /home/cloudbase/jenkins/workspace/openstack-hyperv-release-tests/reports/2014_12_12_13_16_55_547646598/HyperV2012_VHD_v1/logs/devstack/screen-h-api-cw.2014-12-12-162857.log /home/cloudbase/jenkins/workspace/openstack-hyperv-release-tests/reports/2014_12_12_13_16_55_547646598/HyperV2012_VHD_v1/logs/devstack/screen-h-api-cw.log
+ sleep 3
++ echo -ne '\015'
+ NL=$'\r'
+ [[ -n '' ]]
+ screen -S stack -p h-api-cw -X stuff '/opt/stack/heat/bin/heat-api-cloudwatch --config-file=/etc/heat/heat.conf & echo $! >/opt/stack/status/stack/h-api-cw.pid; fg || echo "h-api-cw failed to start" | tee "/opt/stack/status/stack/h-api-cw.failure"'
+ '[' '' = True ']'
+ is_service_enabled nova
++ set +o
++ grep xtrace
+ local 'xtrace=set -o xtrace'
+ set +o xtrace
+ return 0
+ is_service_enabled key
++ set +o
++ grep xtrace
+ local 'xtrace=set -o xtrace'
+ set +o xtrace
+ return 0
+ USERRC_PARAMS='-PA --target-dir /home/cloudbase/devstack/accrc'
+ '[' -f /opt/stack/data/ca-bundle.pem ']'
+ [[ False = \T\r\u\e ]]
+ /home/cloudbase/devstack/tools/create_userrc.sh -PA --target-dir /home/cloudbase/devstack/accrc
+ ACCOUNT_DIR=./accrc
++ getopt -o hPAp:u:r:C: -l os-username:,os-password:,os-tenant-name:,os-tenant-id:,os-auth-url:,target-dir:,heat-url:,skip-tenant:,os-cacert:,help,debug -- -PA --target-dir /home/cloudbase/devstack/accrc
+ options=' -P -A --target-dir '\''/home/cloudbase/devstack/accrc'\'' --'
+ eval set -- -P -A --target-dir ''\''/home/cloudbase/devstack/accrc'\''' --
++ set -- -P -A --target-dir /home/cloudbase/devstack/accrc --
+ ADDPASS=
+ HEAT_URL=
+ SKIP_TENANT=service
+ MODE=
+ ROLE=Member
+ USER_NAME=
+ USER_PASS=
+ '[' 5 -gt 0 ']'
+ case "$1" in
+ ADDPASS=yes
+ shift
+ '[' 4 -gt 0 ']'
+ case "$1" in
+ MODE=all
+ shift
+ '[' 3 -gt 0 ']'
+ case "$1" in
+ ACCOUNT_DIR=/home/cloudbase/devstack/accrc
+ shift
+ shift
+ '[' 1 -gt 0 ']'
+ case "$1" in
+ shift
+ break
+ '[' -z Passw0rd ']'
+ '[' -z admin -a -z '' ']'
+ '[' -z admin ']'
+ '[' -z http://10.14.0.26:35357/v2.0 ']'
+ USER_PASS=Passw0rd
+ USER_NAME=admin
+ '[' -z all ']'
+ export -n SERVICE_TOKEN SERVICE_ENDPOINT OS_SERVICE_TOKEN OS_SERVICE_ENDPOINT
++ openstack endpoint show -f value -c publicurl ec2
+ EC2_URL=http://10.14.0.26:8773/services/Cloud
+ [[ -z http://10.14.0.26:8773/services/Cloud ]]
++ openstack endpoint show -f value -c publicurl s3
+ S3_URL=http://10.14.0.26:3333
+ [[ -z http://10.14.0.26:3333 ]]
+ mkdir -p /home/cloudbase/devstack/accrc
++ readlink -f /home/cloudbase/devstack/accrc
+ ACCOUNT_DIR=/home/cloudbase/devstack/accrc
+ EUCALYPTUS_CERT=/home/cloudbase/devstack/accrc/cacert.pem
+ '[' -e /home/cloudbase/devstack/accrc/cacert.pem ']'
+ mv /home/cloudbase/devstack/accrc/cacert.pem /home/cloudbase/devstack/accrc/cacert.pem.old
+ nova x509-get-root-cert /home/cloudbase/devstack/accrc/cacert.pem
+ '[' all '!=' create ']'
+ openstack project list --long --quote none -f csv
+ grep ,True
+ grep -v service
+ IFS=,
+ read tenant_id tenant_name desc enabled
+ openstack user list --project 45ab40d7fb4d4e5494de877ba086c11c --long --quote none -f csv
+ grep ,True
+ IFS=,
+ read user_id user_name project email enabled
+ '[' all = one -a alt_demo '!=' admin ']'
+ eval 'SPECIFIC_UPASSWORD=$alt_demo_password'
++ SPECIFIC_UPASSWORD=
+ '[' -n '' ']'
+ add_entry a3623f9f40df4925aa0fc5bd5c4590a2 alt_demo 45ab40d7fb4d4e5494de877ba086c11c alt_demo Passw0rd
+ local user_id=a3623f9f40df4925aa0fc5bd5c4590a2
+ local user_name=alt_demo
+ local tenant_id=45ab40d7fb4d4e5494de877ba086c11c
+ local tenant_name=alt_demo
+ local user_passwd=Passw0rd
++ openstack ec2 credentials list --user a3623f9f40df4925aa0fc5bd5c4590a2
++ grep ' 45ab40d7fb4d4e5494de877ba086c11c '
+ local line=
+ '[' -z '' ']'
+ openstack ec2 credentials create --user a3623f9f40df4925aa0fc5bd5c4590a2 --project 45ab40d7fb4d4e5494de877ba086c11c
+-----------+----------------------------------+
| Field     | Value                            |
+-----------+----------------------------------+
| access    | 9eae24b4b282485d8566ce6984ecef08 |
| secret    | 09f75fa6f33840fe9a9ad37f522d71a9 |
| tenant_id | 45ab40d7fb4d4e5494de877ba086c11c |
| trust_id  | None                             |
| user_id   | a3623f9f40df4925aa0fc5bd5c4590a2 |
+-----------+----------------------------------+
++ openstack ec2 credentials list --user a3623f9f40df4925aa0fc5bd5c4590a2
++ grep ' 45ab40d7fb4d4e5494de877ba086c11c '
+ line='| 9eae24b4b282485d8566ce6984ecef08 | 09f75fa6f33840fe9a9ad37f522d71a9 | 45ab40d7fb4d4e5494de877ba086c11c | a3623f9f40df4925aa0fc5bd5c4590a2 |'
+ local ec2_access_key ec2_secret_key
+ read ec2_access_key ec2_secret_key
++ echo '|' 9eae24b4b282485d8566ce6984ecef08 '|' 09f75fa6f33840fe9a9ad37f522d71a9 '|' 45ab40d7fb4d4e5494de877ba086c11c '|' a3623f9f40df4925aa0fc5bd5c4590a2 '|'
++ awk '{print $2 " " $4 }'
+ mkdir -p /home/cloudbase/devstack/accrc/alt_demo
+ local rcfile=/home/cloudbase/devstack/accrc/alt_demo/alt_demo
+ local ec2_cert=/home/cloudbase/devstack/accrc/alt_demo/alt_demo-cert.pem
+ local ec2_private_key=/home/cloudbase/devstack/accrc/alt_demo/alt_demo-pk.pem
+ '[' -e /home/cloudbase/devstack/accrc/alt_demo/alt_demo-pk.pem ']'
+ mv -f /home/cloudbase/devstack/accrc/alt_demo/alt_demo-pk.pem /home/cloudbase/devstack/accrc/alt_demo/alt_demo-pk.pem.old
+ '[' -e /home/cloudbase/devstack/accrc/alt_demo/alt_demo-cert.pem ']'
+ mv -f /home/cloudbase/devstack/accrc/alt_demo/alt_demo-cert.pem /home/cloudbase/devstack/accrc/alt_demo/alt_demo-cert.pem.old
+ nova --os-password Passw0rd --os-username alt_demo --os-tenant-name alt_demo x509-create-cert /home/cloudbase/devstack/accrc/alt_demo/alt_demo-pk.pem /home/cloudbase/devstack/accrc/alt_demo/alt_demo-cert.pem
+ cat
+ '[' -n yes ']'
+ echo 'export OS_PASSWORD="Passw0rd"'
+ '[' -n '' ']'
+ IFS=,
+ read user_id user_name project email enabled
+ IFS=,
+ read tenant_id tenant_name desc enabled
+ IFS=,
+ read user_id user_name project email enabled
+ openstack user list --project 5b03c07bc8344c2fb08533c23ea165a2 --long --quote none -f csv
+ grep ,True
+ '[' all = one -a demo '!=' admin ']'
+ eval 'SPECIFIC_UPASSWORD=$demo_password'
++ SPECIFIC_UPASSWORD=
+ '[' -n '' ']'
+ add_entry 02b7ace5c16240b9851a6bce8b1379c7 demo 5b03c07bc8344c2fb08533c23ea165a2 invisible_to_admin Passw0rd
+ local user_id=02b7ace5c16240b9851a6bce8b1379c7
+ local user_name=demo
+ local tenant_id=5b03c07bc8344c2fb08533c23ea165a2
+ local tenant_name=invisible_to_admin
+ local user_passwd=Passw0rd
++ openstack ec2 credentials list --user 02b7ace5c16240b9851a6bce8b1379c7
++ grep ' 5b03c07bc8344c2fb08533c23ea165a2 '
+ local line=
+ '[' -z '' ']'
+ openstack ec2 credentials create --user 02b7ace5c16240b9851a6bce8b1379c7 --project 5b03c07bc8344c2fb08533c23ea165a2
+-----------+----------------------------------+
| Field     | Value                            |
+-----------+----------------------------------+
| access    | 9477e88e1dbe479e9449107b93b2e1cf |
| secret    | 219809647ee54a1f9df4d779396e1aba |
| tenant_id | 5b03c07bc8344c2fb08533c23ea165a2 |
| trust_id  | None                             |
| user_id   | 02b7ace5c16240b9851a6bce8b1379c7 |
+-----------+----------------------------------+
++ openstack ec2 credentials list --user 02b7ace5c16240b9851a6bce8b1379c7
++ grep ' 5b03c07bc8344c2fb08533c23ea165a2 '
+ line='| 9477e88e1dbe479e9449107b93b2e1cf | 219809647ee54a1f9df4d779396e1aba | 5b03c07bc8344c2fb08533c23ea165a2 | 02b7ace5c16240b9851a6bce8b1379c7 |'
+ local ec2_access_key ec2_secret_key
+ read ec2_access_key ec2_secret_key
++ echo '|' 9477e88e1dbe479e9449107b93b2e1cf '|' 219809647ee54a1f9df4d779396e1aba '|' 5b03c07bc8344c2fb08533c23ea165a2 '|' 02b7ace5c16240b9851a6bce8b1379c7 '|'
++ awk '{print $2 " " $4 }'
+ mkdir -p /home/cloudbase/devstack/accrc/invisible_to_admin
+ local rcfile=/home/cloudbase/devstack/accrc/invisible_to_admin/demo
+ local ec2_cert=/home/cloudbase/devstack/accrc/invisible_to_admin/demo-cert.pem
+ local ec2_private_key=/home/cloudbase/devstack/accrc/invisible_to_admin/demo-pk.pem
+ '[' -e /home/cloudbase/devstack/accrc/invisible_to_admin/demo-pk.pem ']'
+ mv -f /home/cloudbase/devstack/accrc/invisible_to_admin/demo-pk.pem /home/cloudbase/devstack/accrc/invisible_to_admin/demo-pk.pem.old
+ '[' -e /home/cloudbase/devstack/accrc/invisible_to_admin/demo-cert.pem ']'
+ mv -f /home/cloudbase/devstack/accrc/invisible_to_admin/demo-cert.pem /home/cloudbase/devstack/accrc/invisible_to_admin/demo-cert.pem.old
+ nova --os-password Passw0rd --os-username demo --os-tenant-name invisible_to_admin x509-create-cert /home/cloudbase/devstack/accrc/invisible_to_admin/demo-pk.pem /home/cloudbase/devstack/accrc/invisible_to_admin/demo-cert.pem
+ cat
+ '[' -n yes ']'
+ echo 'export OS_PASSWORD="Passw0rd"'
+ '[' -n '' ']'
+ IFS=,
+ read user_id user_name project email enabled
+ IFS=,
+ read tenant_id tenant_name desc enabled
+ openstack user list --project 8a013c2d524f4385aafb383ed24a3c99 --long --quote none -f csv
+ grep ,True
+ IFS=,
+ read user_id user_name project email enabled
+ '[' all = one -a swiftusertest2 '!=' admin ']'
+ eval 'SPECIFIC_UPASSWORD=$swiftusertest2_password'
++ SPECIFIC_UPASSWORD=testing2
+ '[' -n testing2 ']'
+ USER_PASS=testing2
+ add_entry d19f4fd8dc854abbab4d78f055e74c40 swiftusertest2 8a013c2d524f4385aafb383ed24a3c99 swifttenanttest2 testing2
+ local user_id=d19f4fd8dc854abbab4d78f055e74c40
+ local user_name=swiftusertest2
+ local tenant_id=8a013c2d524f4385aafb383ed24a3c99
+ local tenant_name=swifttenanttest2
+ local user_passwd=testing2
++ openstack ec2 credentials list --user d19f4fd8dc854abbab4d78f055e74c40
++ grep ' 8a013c2d524f4385aafb383ed24a3c99 '
+ local line=
+ '[' -z '' ']'
+ openstack ec2 credentials create --user d19f4fd8dc854abbab4d78f055e74c40 --project 8a013c2d524f4385aafb383ed24a3c99
+-----------+----------------------------------+
| Field     | Value                            |
+-----------+----------------------------------+
| access    | eeb9eefa71e7492d9b7733f52ecb1421 |
| secret    | b25a552d68a649cd8152eed9450fd385 |
| tenant_id | 8a013c2d524f4385aafb383ed24a3c99 |
| trust_id  | None                             |
| user_id   | d19f4fd8dc854abbab4d78f055e74c40 |
+-----------+----------------------------------+
++ openstack ec2 credentials list --user d19f4fd8dc854abbab4d78f055e74c40
++ grep ' 8a013c2d524f4385aafb383ed24a3c99 '
+ line='| eeb9eefa71e7492d9b7733f52ecb1421 | b25a552d68a649cd8152eed9450fd385 | 8a013c2d524f4385aafb383ed24a3c99 | d19f4fd8dc854abbab4d78f055e74c40 |'
+ local ec2_access_key ec2_secret_key
+ read ec2_access_key ec2_secret_key
++ echo '|' eeb9eefa71e7492d9b7733f52ecb1421 '|' b25a552d68a649cd8152eed9450fd385 '|' 8a013c2d524f4385aafb383ed24a3c99 '|' d19f4fd8dc854abbab4d78f055e74c40 '|'
++ awk '{print $2 " " $4 }'
+ mkdir -p /home/cloudbase/devstack/accrc/swifttenanttest2
+ local rcfile=/home/cloudbase/devstack/accrc/swifttenanttest2/swiftusertest2
+ local ec2_cert=/home/cloudbase/devstack/accrc/swifttenanttest2/swiftusertest2-cert.pem
+ local ec2_private_key=/home/cloudbase/devstack/accrc/swifttenanttest2/swiftusertest2-pk.pem
+ '[' -e /home/cloudbase/devstack/accrc/swifttenanttest2/swiftusertest2-pk.pem ']'
+ mv -f /home/cloudbase/devstack/accrc/swifttenanttest2/swiftusertest2-pk.pem /home/cloudbase/devstack/accrc/swifttenanttest2/swiftusertest2-pk.pem.old
+ '[' -e /home/cloudbase/devstack/accrc/swifttenanttest2/swiftusertest2-cert.pem ']'
+ mv -f /home/cloudbase/devstack/accrc/swifttenanttest2/swiftusertest2-cert.pem /home/cloudbase/devstack/accrc/swifttenanttest2/swiftusertest2-cert.pem.old
+ nova --os-password testing2 --os-username swiftusertest2 --os-tenant-name swifttenanttest2 x509-create-cert /home/cloudbase/devstack/accrc/swifttenanttest2/swiftusertest2-pk.pem /home/cloudbase/devstack/accrc/swifttenanttest2/swiftusertest2-cert.pem
+ cat
+ '[' -n yes ']'
+ echo 'export OS_PASSWORD="testing2"'
+ '[' -n '' ']'
+ IFS=,
+ read user_id user_name project email enabled
+ IFS=,
+ read tenant_id tenant_name desc enabled
+ openstack user list --project c8a8f2c1f6ed4781a8bb278ddd58d962 --long --quote none -f csv
+ grep ,True
+ IFS=,
+ read user_id user_name project email enabled
+ '[' all = one -a admin '!=' admin ']'
+ eval 'SPECIFIC_UPASSWORD=$admin_password'
++ SPECIFIC_UPASSWORD=
+ '[' -n '' ']'
+ add_entry aeee7d926a3747c88a454c79ed8b306a admin c8a8f2c1f6ed4781a8bb278ddd58d962 admin Passw0rd
+ local user_id=aeee7d926a3747c88a454c79ed8b306a
+ local user_name=admin
+ local tenant_id=c8a8f2c1f6ed4781a8bb278ddd58d962
+ local tenant_name=admin
+ local user_passwd=Passw0rd
++ openstack ec2 credentials list --user aeee7d926a3747c88a454c79ed8b306a
++ grep ' c8a8f2c1f6ed4781a8bb278ddd58d962 '
+ local line=
+ '[' -z '' ']'
+ openstack ec2 credentials create --user aeee7d926a3747c88a454c79ed8b306a --project c8a8f2c1f6ed4781a8bb278ddd58d962
+-----------+----------------------------------+
| Field     | Value                            |
+-----------+----------------------------------+
| access    | 4e3a316009534cd4822ae907a8174f35 |
| secret    | e8644d9611f94ffc818c3f73667afb00 |
| tenant_id | c8a8f2c1f6ed4781a8bb278ddd58d962 |
| trust_id  | None                             |
| user_id   | aeee7d926a3747c88a454c79ed8b306a |
+-----------+----------------------------------+
++ openstack ec2 credentials list --user aeee7d926a3747c88a454c79ed8b306a
++ grep ' c8a8f2c1f6ed4781a8bb278ddd58d962 '
+ line='| 4e3a316009534cd4822ae907a8174f35 | e8644d9611f94ffc818c3f73667afb00 | c8a8f2c1f6ed4781a8bb278ddd58d962 | aeee7d926a3747c88a454c79ed8b306a |'
+ local ec2_access_key ec2_secret_key
+ read ec2_access_key ec2_secret_key
++ echo '|' 4e3a316009534cd4822ae907a8174f35 '|' e8644d9611f94ffc818c3f73667afb00 '|' c8a8f2c1f6ed4781a8bb278ddd58d962 '|' aeee7d926a3747c88a454c79ed8b306a '|'
++ awk '{print $2 " " $4 }'
+ mkdir -p /home/cloudbase/devstack/accrc/admin
+ local rcfile=/home/cloudbase/devstack/accrc/admin/admin
+ local ec2_cert=/home/cloudbase/devstack/accrc/admin/admin-cert.pem
+ local ec2_private_key=/home/cloudbase/devstack/accrc/admin/admin-pk.pem
+ '[' -e /home/cloudbase/devstack/accrc/admin/admin-pk.pem ']'
+ mv -f /home/cloudbase/devstack/accrc/admin/admin-pk.pem /home/cloudbase/devstack/accrc/admin/admin-pk.pem.old
+ '[' -e /home/cloudbase/devstack/accrc/admin/admin-cert.pem ']'
+ mv -f /home/cloudbase/devstack/accrc/admin/admin-cert.pem /home/cloudbase/devstack/accrc/admin/admin-cert.pem.old
+ nova --os-password Passw0rd --os-username admin --os-tenant-name admin x509-create-cert /home/cloudbase/devstack/accrc/admin/admin-pk.pem /home/cloudbase/devstack/accrc/admin/admin-cert.pem
+ cat
+ '[' -n yes ']'
+ echo 'export OS_PASSWORD="Passw0rd"'
+ '[' -n '' ']'
+ IFS=,
+ read user_id user_name project email enabled
+ IFS=,
+ read tenant_id tenant_name desc enabled
+ openstack user list --project e925366f53424cdeb40943a8495711df --long --quote none -f csv
+ grep ,True
+ IFS=,
+ read user_id user_name project email enabled
+ '[' all = one -a admin '!=' admin ']'
+ eval 'SPECIFIC_UPASSWORD=$admin_password'
++ SPECIFIC_UPASSWORD=
+ '[' -n '' ']'
+ add_entry aeee7d926a3747c88a454c79ed8b306a admin e925366f53424cdeb40943a8495711df demo Passw0rd
+ local user_id=aeee7d926a3747c88a454c79ed8b306a
+ local user_name=admin
+ local tenant_id=e925366f53424cdeb40943a8495711df
+ local tenant_name=demo
+ local user_passwd=Passw0rd
++ openstack ec2 credentials list --user aeee7d926a3747c88a454c79ed8b306a
++ grep ' e925366f53424cdeb40943a8495711df '
+ local line=
+ '[' -z '' ']'
+ openstack ec2 credentials create --user aeee7d926a3747c88a454c79ed8b306a --project e925366f53424cdeb40943a8495711df
+-----------+----------------------------------+
| Field     | Value                            |
+-----------+----------------------------------+
| access    | 0d470a4d4b9b43b69a21195207e8dfba |
| secret    | db326d8edd63436e8596a755e4a1e7f7 |
| tenant_id | e925366f53424cdeb40943a8495711df |
| trust_id  | None                             |
| user_id   | aeee7d926a3747c88a454c79ed8b306a |
+-----------+----------------------------------+
++ openstack ec2 credentials list --user aeee7d926a3747c88a454c79ed8b306a
++ grep ' e925366f53424cdeb40943a8495711df '
+ line='| 0d470a4d4b9b43b69a21195207e8dfba | db326d8edd63436e8596a755e4a1e7f7 | e925366f53424cdeb40943a8495711df | aeee7d926a3747c88a454c79ed8b306a |'
+ local ec2_access_key ec2_secret_key
+ read ec2_access_key ec2_secret_key
++ echo '|' 0d470a4d4b9b43b69a21195207e8dfba '|' db326d8edd63436e8596a755e4a1e7f7 '|' e925366f53424cdeb40943a8495711df '|' aeee7d926a3747c88a454c79ed8b306a '|'
++ awk '{print $2 " " $4 }'
+ mkdir -p /home/cloudbase/devstack/accrc/demo
+ local rcfile=/home/cloudbase/devstack/accrc/demo/admin
+ local ec2_cert=/home/cloudbase/devstack/accrc/demo/admin-cert.pem
+ local ec2_private_key=/home/cloudbase/devstack/accrc/demo/admin-pk.pem
+ '[' -e /home/cloudbase/devstack/accrc/demo/admin-pk.pem ']'
+ mv -f /home/cloudbase/devstack/accrc/demo/admin-pk.pem /home/cloudbase/devstack/accrc/demo/admin-pk.pem.old
+ '[' -e /home/cloudbase/devstack/accrc/demo/admin-cert.pem ']'
+ mv -f /home/cloudbase/devstack/accrc/demo/admin-cert.pem /home/cloudbase/devstack/accrc/demo/admin-cert.pem.old
+ nova --os-password Passw0rd --os-username admin --os-tenant-name demo x509-create-cert /home/cloudbase/devstack/accrc/demo/admin-pk.pem /home/cloudbase/devstack/accrc/demo/admin-cert.pem
+ cat
+ '[' -n yes ']'
+ echo 'export OS_PASSWORD="Passw0rd"'
+ '[' -n '' ']'
+ IFS=,
+ read user_id user_name project email enabled
+ '[' all = one -a demo '!=' admin ']'
+ eval 'SPECIFIC_UPASSWORD=$demo_password'
++ SPECIFIC_UPASSWORD=
+ '[' -n '' ']'
+ add_entry 02b7ace5c16240b9851a6bce8b1379c7 demo e925366f53424cdeb40943a8495711df demo Passw0rd
+ local user_id=02b7ace5c16240b9851a6bce8b1379c7
+ local user_name=demo
+ local tenant_id=e925366f53424cdeb40943a8495711df
+ local tenant_name=demo
+ local user_passwd=Passw0rd
++ openstack ec2 credentials list --user 02b7ace5c16240b9851a6bce8b1379c7
++ grep ' e925366f53424cdeb40943a8495711df '
+ local line=
+ '[' -z '' ']'
+ openstack ec2 credentials create --user 02b7ace5c16240b9851a6bce8b1379c7 --project e925366f53424cdeb40943a8495711df
+-----------+----------------------------------+
| Field     | Value                            |
+-----------+----------------------------------+
| access    | 5a43a7db50274af499552afdcc8333c0 |
| secret    | 4c9464316bc94ab28db6570544a2112b |
| tenant_id | e925366f53424cdeb40943a8495711df |
| trust_id  | None                             |
| user_id   | 02b7ace5c16240b9851a6bce8b1379c7 |
+-----------+----------------------------------+
++ openstack ec2 credentials list --user 02b7ace5c16240b9851a6bce8b1379c7
++ grep ' e925366f53424cdeb40943a8495711df '
+ line='| 5a43a7db50274af499552afdcc8333c0 | 4c9464316bc94ab28db6570544a2112b | e925366f53424cdeb40943a8495711df | 02b7ace5c16240b9851a6bce8b1379c7 |'
+ local ec2_access_key ec2_secret_key
+ read ec2_access_key ec2_secret_key
++ echo '|' 5a43a7db50274af499552afdcc8333c0 '|' 4c9464316bc94ab28db6570544a2112b '|' e925366f53424cdeb40943a8495711df '|' 02b7ace5c16240b9851a6bce8b1379c7 '|'
++ awk '{print $2 " " $4 }'
+ mkdir -p /home/cloudbase/devstack/accrc/demo
+ local rcfile=/home/cloudbase/devstack/accrc/demo/demo
+ local ec2_cert=/home/cloudbase/devstack/accrc/demo/demo-cert.pem
+ local ec2_private_key=/home/cloudbase/devstack/accrc/demo/demo-pk.pem
+ '[' -e /home/cloudbase/devstack/accrc/demo/demo-pk.pem ']'
+ mv -f /home/cloudbase/devstack/accrc/demo/demo-pk.pem /home/cloudbase/devstack/accrc/demo/demo-pk.pem.old
+ '[' -e /home/cloudbase/devstack/accrc/demo/demo-cert.pem ']'
+ mv -f /home/cloudbase/devstack/accrc/demo/demo-cert.pem /home/cloudbase/devstack/accrc/demo/demo-cert.pem.old
+ nova --os-password Passw0rd --os-username demo --os-tenant-name demo x509-create-cert /home/cloudbase/devstack/accrc/demo/demo-pk.pem /home/cloudbase/devstack/accrc/demo/demo-cert.pem
+ cat
+ '[' -n yes ']'
+ echo 'export OS_PASSWORD="Passw0rd"'
+ '[' -n '' ']'
+ IFS=,
+ read user_id user_name project email enabled
+ IFS=,
+ read tenant_id tenant_name desc enabled
+ openstack user list --project edc9fc591c9c4dd8b266572970c8f1cb --long --quote none -f csv
+ grep ,True
+ IFS=,
+ read user_id user_name project email enabled
+ '[' all = one -a swiftusertest1 '!=' admin ']'
+ eval 'SPECIFIC_UPASSWORD=$swiftusertest1_password'
++ SPECIFIC_UPASSWORD=testing
+ '[' -n testing ']'
+ USER_PASS=testing
+ add_entry a4b761ab10ca406499e6707a1b82c02b swiftusertest1 edc9fc591c9c4dd8b266572970c8f1cb swifttenanttest1 testing
+ local user_id=a4b761ab10ca406499e6707a1b82c02b
+ local user_name=swiftusertest1
+ local tenant_id=edc9fc591c9c4dd8b266572970c8f1cb
+ local tenant_name=swifttenanttest1
+ local user_passwd=testing
++ openstack ec2 credentials list --user a4b761ab10ca406499e6707a1b82c02b
++ grep ' edc9fc591c9c4dd8b266572970c8f1cb '
+ local line=
+ '[' -z '' ']'
+ openstack ec2 credentials create --user a4b761ab10ca406499e6707a1b82c02b --project edc9fc591c9c4dd8b266572970c8f1cb
+-----------+----------------------------------+
| Field     | Value                            |
+-----------+----------------------------------+
| access    | 5e42fdf4a77b4dd2abc4afc94623ee54 |
| secret    | b385b8e827f6494fa856f809fcde5e69 |
| tenant_id | edc9fc591c9c4dd8b266572970c8f1cb |
| trust_id  | None                             |
| user_id   | a4b761ab10ca406499e6707a1b82c02b |
+-----------+----------------------------------+
++ openstack ec2 credentials list --user a4b761ab10ca406499e6707a1b82c02b
++ grep ' edc9fc591c9c4dd8b266572970c8f1cb '
+ line='| 5e42fdf4a77b4dd2abc4afc94623ee54 | b385b8e827f6494fa856f809fcde5e69 | edc9fc591c9c4dd8b266572970c8f1cb | a4b761ab10ca406499e6707a1b82c02b |'
+ local ec2_access_key ec2_secret_key
+ read ec2_access_key ec2_secret_key
++ echo '|' 5e42fdf4a77b4dd2abc4afc94623ee54 '|' b385b8e827f6494fa856f809fcde5e69 '|' edc9fc591c9c4dd8b266572970c8f1cb '|' a4b761ab10ca406499e6707a1b82c02b '|'
++ awk '{print $2 " " $4 }'
+ mkdir -p /home/cloudbase/devstack/accrc/swifttenanttest1
+ local rcfile=/home/cloudbase/devstack/accrc/swifttenanttest1/swiftusertest1
+ local ec2_cert=/home/cloudbase/devstack/accrc/swifttenanttest1/swiftusertest1-cert.pem
+ local ec2_private_key=/home/cloudbase/devstack/accrc/swifttenanttest1/swiftusertest1-pk.pem
+ '[' -e /home/cloudbase/devstack/accrc/swifttenanttest1/swiftusertest1-pk.pem ']'
+ mv -f /home/cloudbase/devstack/accrc/swifttenanttest1/swiftusertest1-pk.pem /home/cloudbase/devstack/accrc/swifttenanttest1/swiftusertest1-pk.pem.old
+ '[' -e /home/cloudbase/devstack/accrc/swifttenanttest1/swiftusertest1-cert.pem ']'
+ mv -f /home/cloudbase/devstack/accrc/swifttenanttest1/swiftusertest1-cert.pem /home/cloudbase/devstack/accrc/swifttenanttest1/swiftusertest1-cert.pem.old
+ nova --os-password testing --os-username swiftusertest1 --os-tenant-name swifttenanttest1 x509-create-cert /home/cloudbase/devstack/accrc/swifttenanttest1/swiftusertest1-pk.pem /home/cloudbase/devstack/accrc/swifttenanttest1/swiftusertest1-cert.pem
+ cat
+ '[' -n yes ']'
+ echo 'export OS_PASSWORD="testing"'
+ '[' -n '' ']'
+ IFS=,
+ read user_id user_name project email enabled
+ '[' all = one -a swiftusertest3 '!=' admin ']'
+ eval 'SPECIFIC_UPASSWORD=$swiftusertest3_password'
++ SPECIFIC_UPASSWORD=testing3
+ '[' -n testing3 ']'
+ USER_PASS=testing3
+ add_entry ad4329a1a9ba428ba81f64376193cd7f swiftusertest3 edc9fc591c9c4dd8b266572970c8f1cb swifttenanttest1 testing3
+ local user_id=ad4329a1a9ba428ba81f64376193cd7f
+ local user_name=swiftusertest3
+ local tenant_id=edc9fc591c9c4dd8b266572970c8f1cb
+ local tenant_name=swifttenanttest1
+ local user_passwd=testing3
++ openstack ec2 credentials list --user ad4329a1a9ba428ba81f64376193cd7f
++ grep ' edc9fc591c9c4dd8b266572970c8f1cb '
+ local line=
+ '[' -z '' ']'
+ openstack ec2 credentials create --user ad4329a1a9ba428ba81f64376193cd7f --project edc9fc591c9c4dd8b266572970c8f1cb
+-----------+----------------------------------+
| Field     | Value                            |
+-----------+----------------------------------+
| access    | 82859bdd202445e68aa9608e47a5135e |
| secret    | 7ecdae74ddb14e45858b53c0b8a45b41 |
| tenant_id | edc9fc591c9c4dd8b266572970c8f1cb |
| trust_id  | None                             |
| user_id   | ad4329a1a9ba428ba81f64376193cd7f |
+-----------+----------------------------------+
++ openstack ec2 credentials list --user ad4329a1a9ba428ba81f64376193cd7f
++ grep ' edc9fc591c9c4dd8b266572970c8f1cb '
+ line='| 82859bdd202445e68aa9608e47a5135e | 7ecdae74ddb14e45858b53c0b8a45b41 | edc9fc591c9c4dd8b266572970c8f1cb | ad4329a1a9ba428ba81f64376193cd7f |'
+ local ec2_access_key ec2_secret_key
+ read ec2_access_key ec2_secret_key
++ echo '|' 82859bdd202445e68aa9608e47a5135e '|' 7ecdae74ddb14e45858b53c0b8a45b41 '|' edc9fc591c9c4dd8b266572970c8f1cb '|' ad4329a1a9ba428ba81f64376193cd7f '|'
++ awk '{print $2 " " $4 }'
+ mkdir -p /home/cloudbase/devstack/accrc/swifttenanttest1
+ local rcfile=/home/cloudbase/devstack/accrc/swifttenanttest1/swiftusertest3
+ local ec2_cert=/home/cloudbase/devstack/accrc/swifttenanttest1/swiftusertest3-cert.pem
+ local ec2_private_key=/home/cloudbase/devstack/accrc/swifttenanttest1/swiftusertest3-pk.pem
+ '[' -e /home/cloudbase/devstack/accrc/swifttenanttest1/swiftusertest3-pk.pem ']'
+ mv -f /home/cloudbase/devstack/accrc/swifttenanttest1/swiftusertest3-pk.pem /home/cloudbase/devstack/accrc/swifttenanttest1/swiftusertest3-pk.pem.old
+ '[' -e /home/cloudbase/devstack/accrc/swifttenanttest1/swiftusertest3-cert.pem ']'
+ mv -f /home/cloudbase/devstack/accrc/swifttenanttest1/swiftusertest3-cert.pem /home/cloudbase/devstack/accrc/swifttenanttest1/swiftusertest3-cert.pem.old
+ nova --os-password testing3 --os-username swiftusertest3 --os-tenant-name swifttenanttest1 x509-create-cert /home/cloudbase/devstack/accrc/swifttenanttest1/swiftusertest3-pk.pem /home/cloudbase/devstack/accrc/swifttenanttest1/swiftusertest3-cert.pem
+ cat
+ '[' -n yes ']'
+ echo 'export OS_PASSWORD="testing3"'
+ '[' -n '' ']'
+ IFS=,
+ read user_id user_name project email enabled
+ IFS=,
+ read tenant_id tenant_name desc enabled
+ is_service_enabled nova
++ set +o
++ grep xtrace
+ local 'xtrace=set -o xtrace'
+ set +o xtrace
+ return 0
+ is_baremetal
+ [[ g-api,g-reg,key,n-api,n-crt,n-obj,n-cond,n-sch,n-xvnc,n-cauth,c-sch,c-api,c-vol,h-eng,h-api,h-api-cfn,h-api-cw,rabbit,tempest,mysql,neutron,q-svc,q-agt,q-dhcp,q-l3,q-meta,q-lbaas,q-fwaas,q-metering,q-vpn,c-bak,s-proxy,s-object,s-container,s-account,heat,ceilometer-acentral,ceilometer-collector,ceilometer-api =~ baremetal ]]
+ return 1
++ date +%F-%H%M%S
+ CURRENT_RUN_TIME=2014-12-12-163439
+ echo '# 2014-12-12-163439'
+ for i in BASE_SQL_CONN ENABLED_SERVICES HOST_IP LOGFILE SERVICE_HOST SERVICE_PROTOCOL STACK_USER TLS_IP KEYSTONE_AUTH_PROTOCOL OS_CACERT
+ echo BASE_SQL_CONN=mysql://root:Passw0rd@127.0.0.1
+ for i in BASE_SQL_CONN ENABLED_SERVICES HOST_IP LOGFILE SERVICE_HOST SERVICE_PROTOCOL STACK_USER TLS_IP KEYSTONE_AUTH_PROTOCOL OS_CACERT
+ echo ENABLED_SERVICES=g-api,g-reg,key,n-api,n-crt,n-obj,n-cond,n-sch,n-xvnc,n-cauth,c-sch,c-api,c-vol,h-eng,h-api,h-api-cfn,h-api-cw,rabbit,tempest,mysql,neutron,q-svc,q-agt,q-dhcp,q-l3,q-meta,q-lbaas,q-fwaas,q-metering,q-vpn,c-bak,s-proxy,s-object,s-container,s-account,heat,ceilometer-acentral,ceilometer-collector,ceilometer-api
+ for i in BASE_SQL_CONN ENABLED_SERVICES HOST_IP LOGFILE SERVICE_HOST SERVICE_PROTOCOL STACK_USER TLS_IP KEYSTONE_AUTH_PROTOCOL OS_CACERT
+ echo HOST_IP=10.14.0.26
+ for i in BASE_SQL_CONN ENABLED_SERVICES HOST_IP LOGFILE SERVICE_HOST SERVICE_PROTOCOL STACK_USER TLS_IP KEYSTONE_AUTH_PROTOCOL OS_CACERT
+ echo LOGFILE=
+ for i in BASE_SQL_CONN ENABLED_SERVICES HOST_IP LOGFILE SERVICE_HOST SERVICE_PROTOCOL STACK_USER TLS_IP KEYSTONE_AUTH_PROTOCOL OS_CACERT
+ echo SERVICE_HOST=10.14.0.26
+ for i in BASE_SQL_CONN ENABLED_SERVICES HOST_IP LOGFILE SERVICE_HOST SERVICE_PROTOCOL STACK_USER TLS_IP KEYSTONE_AUTH_PROTOCOL OS_CACERT
+ echo SERVICE_PROTOCOL=http
+ for i in BASE_SQL_CONN ENABLED_SERVICES HOST_IP LOGFILE SERVICE_HOST SERVICE_PROTOCOL STACK_USER TLS_IP KEYSTONE_AUTH_PROTOCOL OS_CACERT
+ echo STACK_USER=cloudbase
+ for i in BASE_SQL_CONN ENABLED_SERVICES HOST_IP LOGFILE SERVICE_HOST SERVICE_PROTOCOL STACK_USER TLS_IP KEYSTONE_AUTH_PROTOCOL OS_CACERT
+ echo TLS_IP=
+ for i in BASE_SQL_CONN ENABLED_SERVICES HOST_IP LOGFILE SERVICE_HOST SERVICE_PROTOCOL STACK_USER TLS_IP KEYSTONE_AUTH_PROTOCOL OS_CACERT
+ echo KEYSTONE_AUTH_PROTOCOL=http
+ for i in BASE_SQL_CONN ENABLED_SERVICES HOST_IP LOGFILE SERVICE_HOST SERVICE_PROTOCOL STACK_USER TLS_IP KEYSTONE_AUTH_PROTOCOL OS_CACERT
+ echo OS_CACERT=
+ merge_config_group /home/cloudbase/devstack/local.conf extra
+ local localfile=/home/cloudbase/devstack/local.conf
+ shift
+ local matchgroups=extra
+ [[ -r /home/cloudbase/devstack/local.conf ]]
+ local configfile group
+ for group in '$matchgroups'
++ get_meta_section_files /home/cloudbase/devstack/local.conf extra
++ local file=/home/cloudbase/devstack/local.conf
++ local matchgroup=extra
++ [[ -r /home/cloudbase/devstack/local.conf ]]
++ awk -v matchgroup=extra '
        /^\[\[.+\|.*\]\]/ {
            gsub("[][]", "", $1);
            split($1, a, "|");
            if (a[1] == matchgroup)
                print a[2]
        }
    ' /home/cloudbase/devstack/local.conf
+ [[ -d /home/cloudbase/devstack/extras.d ]]
+ for i in '$TOP_DIR/extras.d/*.sh'
+ [[ -r /home/cloudbase/devstack/extras.d/40-dib.sh ]]
+ source /home/cloudbase/devstack/extras.d/40-dib.sh stack extra
++ is_service_enabled dib
+++ set +o
+++ grep xtrace
++ local 'xtrace=set -o xtrace'
++ set +o xtrace
++ return 1
+ for i in '$TOP_DIR/extras.d/*.sh'
+ [[ -r /home/cloudbase/devstack/extras.d/50-ironic.sh ]]
+ source /home/cloudbase/devstack/extras.d/50-ironic.sh stack extra
++ is_service_enabled ir-api ir-cond
+++ set +o
+++ grep xtrace
++ local 'xtrace=set -o xtrace'
++ set +o xtrace
++ return 1
+ for i in '$TOP_DIR/extras.d/*.sh'
+ [[ -r /home/cloudbase/devstack/extras.d/60-ceph.sh ]]
+ source /home/cloudbase/devstack/extras.d/60-ceph.sh stack extra
++ is_service_enabled ceph
+++ set +o
+++ grep xtrace
++ local 'xtrace=set -o xtrace'
++ set +o xtrace
++ return 1
+ for i in '$TOP_DIR/extras.d/*.sh'
+ [[ -r /home/cloudbase/devstack/extras.d/70-gantt.sh ]]
+ source /home/cloudbase/devstack/extras.d/70-gantt.sh stack extra
++ is_service_enabled n-sch
+++ set +o
+++ grep xtrace
++ local 'xtrace=set -o xtrace'
++ set +o xtrace
++ return 0
++ disable_service gantt
++ local tmpsvcs=,g-api,g-reg,key,n-api,n-crt,n-obj,n-cond,n-sch,n-xvnc,n-cauth,c-sch,c-api,c-vol,h-eng,h-api,h-api-cfn,h-api-cw,rabbit,tempest,mysql,neutron,q-svc,q-agt,q-dhcp,q-l3,q-meta,q-lbaas,q-fwaas,q-metering,q-vpn,c-bak,s-proxy,s-object,s-container,s-account,heat,ceilometer-acentral,ceilometer-collector,ceilometer-api,
++ local service
++ for service in '$@'
++ is_service_enabled gantt
+++ set +o
+++ grep xtrace
++ local 'xtrace=set -o xtrace'
++ set +o xtrace
++ return 1
+++ _cleanup_service_list ,g-api,g-reg,key,n-api,n-crt,n-obj,n-cond,n-sch,n-xvnc,n-cauth,c-sch,c-api,c-vol,h-eng,h-api,h-api-cfn,h-api-cw,rabbit,tempest,mysql,neutron,q-svc,q-agt,q-dhcp,q-l3,q-meta,q-lbaas,q-fwaas,q-metering,q-vpn,c-bak,s-proxy,s-object,s-container,s-account,heat,ceilometer-acentral,ceilometer-collector,ceilometer-api,
+++ echo ,g-api,g-reg,key,n-api,n-crt,n-obj,n-cond,n-sch,n-xvnc,n-cauth,c-sch,c-api,c-vol,h-eng,h-api,h-api-cfn,h-api-cw,rabbit,tempest,mysql,neutron,q-svc,q-agt,q-dhcp,q-l3,q-meta,q-lbaas,q-fwaas,q-metering,q-vpn,c-bak,s-proxy,s-object,s-container,s-account,heat,ceilometer-acentral,ceilometer-collector,ceilometer-api,
+++ sed -e '
        s/,,/,/g;
        s/^,//;
        s/,$//
    '
++ ENABLED_SERVICES=g-api,g-reg,key,n-api,n-crt,n-obj,n-cond,n-sch,n-xvnc,n-cauth,c-sch,c-api,c-vol,h-eng,h-api,h-api-cfn,h-api-cw,rabbit,tempest,mysql,neutron,q-svc,q-agt,q-dhcp,q-l3,q-meta,q-lbaas,q-fwaas,q-metering,q-vpn,c-bak,s-proxy,s-object,s-container,s-account,heat,ceilometer-acentral,ceilometer-collector,ceilometer-api
++ is_service_enabled gantt
+++ set +o
+++ grep xtrace
++ local 'xtrace=set -o xtrace'
++ set +o xtrace
++ return 1
+ for i in '$TOP_DIR/extras.d/*.sh'
+ [[ -r /home/cloudbase/devstack/extras.d/70-sahara.sh ]]
+ source /home/cloudbase/devstack/extras.d/70-sahara.sh stack extra
++ is_service_enabled sahara
+++ set +o
+++ grep xtrace
++ local 'xtrace=set -o xtrace'
++ set +o xtrace
++ return 1
+ for i in '$TOP_DIR/extras.d/*.sh'
+ [[ -r /home/cloudbase/devstack/extras.d/70-trove.sh ]]
+ source /home/cloudbase/devstack/extras.d/70-trove.sh stack extra
++ is_service_enabled trove
+++ set +o
+++ grep xtrace
++ local 'xtrace=set -o xtrace'
++ set +o xtrace
++ return 1
+ for i in '$TOP_DIR/extras.d/*.sh'
+ [[ -r /home/cloudbase/devstack/extras.d/70-zaqar.sh ]]
+ source /home/cloudbase/devstack/extras.d/70-zaqar.sh stack extra
++ is_service_enabled zaqar-server
+++ set +o
+++ grep xtrace
++ local 'xtrace=set -o xtrace'
++ set +o xtrace
++ return 1
+ for i in '$TOP_DIR/extras.d/*.sh'
+ [[ -r /home/cloudbase/devstack/extras.d/80-opendaylight.sh ]]
+ source /home/cloudbase/devstack/extras.d/80-opendaylight.sh stack extra
++ is_service_enabled odl-server odl-compute
+++ set +o
+++ grep xtrace
++ local 'xtrace=set -o xtrace'
++ set +o xtrace
++ return 1
++ is_service_enabled odl-server
+++ set +o
+++ grep xtrace
++ local 'xtrace=set -o xtrace'
++ set +o xtrace
++ return 1
++ is_service_enabled odl-compute
+++ set +o
+++ grep xtrace
++ local 'xtrace=set -o xtrace'
++ set +o xtrace
++ return 1
+ for i in '$TOP_DIR/extras.d/*.sh'
+ [[ -r /home/cloudbase/devstack/extras.d/80-tempest.sh ]]
+ source /home/cloudbase/devstack/extras.d/80-tempest.sh stack extra
++ is_service_enabled tempest
+++ set +o
+++ grep xtrace
++ local 'xtrace=set -o xtrace'
++ set +o xtrace
++ return 0
++ [[ stack == \s\o\u\r\c\e ]]
++ [[ stack == \s\t\a\c\k ]]
++ [[ extra == \i\n\s\t\a\l\l ]]
++ [[ stack == \s\t\a\c\k ]]
++ [[ extra == \p\o\s\t\-\c\o\n\f\i\g ]]
++ [[ stack == \s\t\a\c\k ]]
++ [[ extra == \e\x\t\r\a ]]
++ echo_summary 'Initializing Tempest'
++ [[ -t 3 ]]
++ echo -e Initializing Tempest
++ configure_tempest
++ setup_develop /opt/stack/tempest
++ local project_dir=/opt/stack/tempest
++ setup_package_with_req_sync /opt/stack/tempest -e
++ local project_dir=/opt/stack/tempest
++ local flags=-e
+++ cd /opt/stack/tempest
+++ git diff --exit-code
++ local update_requirements=
++ [[ '' != \c\h\a\n\g\e\d ]]
++ cd /opt/stack/requirements
++ python update.py /opt/stack/tempest
++ setup_package /opt/stack/tempest -e
++ local project_dir=/opt/stack/tempest
++ local flags=-e
++ pip_install -e /opt/stack/tempest
+++ set +o
+++ grep xtrace
++ local 'xtrace=set -o xtrace'
++ set +o xtrace
++ sudo PIP_DOWNLOAD_CACHE=/var/cache/pip http_proxy= https_proxy= no_proxy= /usr/local/bin/pip install -e /opt/stack/tempest
++ [[ False == \T\r\u\e ]]
++ [[ -e == \-\e ]]
++ safe_chown -R cloudbase /opt/stack/tempest/tempest.egg-info
++ _safe_permission_operation chown -R cloudbase /opt/stack/tempest/tempest.egg-info
+++ set +o
+++ grep xtrace
++ local 'xtrace=set -o xtrace'
++ set +o xtrace
++ sudo chown -R cloudbase /opt/stack/tempest/tempest.egg-info
++ '[' True = True ']'
++ [[ '' != \c\h\a\n\g\e\d ]]
++ cd /opt/stack/tempest
++ git reset --hard
++ local image_lines
++ local images
++ local num_images
++ local image_uuid
++ local image_uuid_alt
++ local password
++ local line
++ local flavors
++ local available_flavors
++ local flavors_ref
++ local flavor_lines
++ local public_network_id
++ local public_router_id
++ local tenant_networks_reachable
++ local boto_instance_type=m1.tiny
++ local ssh_connect_method=fixed
++ ifs=' 	
'
++ declare -a images
++ read -r IMAGE_NAME IMAGE_UUID
+++ glance image-list --status=active
+++ awk '-F|' '!/^(+--)|ID|aki|ari/ { print $3,$2 }'
++ '[' cirros-0 = cirros-0.3.2-x86_64-uec ']'
++ images+=($IMAGE_UUID)
++ read -r IMAGE_NAME IMAGE_UUID
++ '[' Fedora-x86_64-20-20140618-sda = cirros-0.3.2-x86_64-uec ']'
++ images+=($IMAGE_UUID)
++ read -r IMAGE_NAME IMAGE_UUID
++ case "${#images[*]}" in
++ '[' -z '' ']'
++ image_uuid=1842cda0-b14b-44ca-9abf-3e549f3abe2e
++ image_uuid_alt=9b2b82d5-84cb-4b92-8d3a-ce2779cf144e
++ [[ ! -d /opt/stack/tempest/etc ]]
++ sudo chown cloudbase /opt/stack/tempest/etc
++ cp /opt/stack/tempest/etc/tempest.conf.sample /opt/stack/tempest/etc/tempest.conf
++ chmod 644 /opt/stack/tempest/etc/tempest.conf
++ password=Passw0rd
++ ADMIN_USERNAME=admin
++ ADMIN_TENANT_NAME=admin
++ ADMIN_DOMAIN_NAME=Default
++ TEMPEST_USERNAME=demo
++ TEMPEST_TENANT_NAME=demo
++ ALT_USERNAME=alt_demo
++ ALT_TENANT_NAME=alt_demo
+++ openstack project list
+++ awk '/ admin / { print $2 }'
++ ADMIN_TENANT_ID=c8a8f2c1f6ed4781a8bb278ddd58d962
++ [[ -z '' ]]
+++ nova flavor-list
++ available_flavors='+----+-----------+-----------+------+-----------+------+-------+-------------+-----------+
| ID | Name      | Memory_MB | Disk | Ephemeral | Swap | VCPUs | RXTX_Factor | Is_Public |
+----+-----------+-----------+------+-----------+------+-------+-------------+-----------+
| 1  | m1.tiny   | 512       | 1    | 0         |      | 1     | 1.0         | True      |
| 2  | m1.small  | 2048      | 20   | 0         |      | 1     | 1.0         | True      |
| 3  | m1.medium | 4096      | 40   | 0         |      | 2     | 1.0         | True      |
| 4  | m1.large  | 8192      | 80   | 0         |      | 4     | 1.0         | True      |
| 5  | m1.xlarge | 16384     | 160  | 0         |      | 8     | 1.0         | True      |
+----+-----------+-----------+------+-----------+------+-------+-------------+-----------+'
++ [[ +----+-----------+-----------+------+-----------+------+-------+-------------+-----------+
| ID | Name      | Memory_MB | Disk | Ephemeral | Swap | VCPUs | RXTX_Factor | Is_Public |
+----+-----------+-----------+------+-----------+------+-------+-------------+-----------+
| 1  | m1.tiny   | 512       | 1    | 0         |      | 1     | 1.0         | True      |
| 2  | m1.small  | 2048      | 20   | 0         |      | 1     | 1.0         | True      |
| 3  | m1.medium | 4096      | 40   | 0         |      | 2     | 1.0         | True      |
| 4  | m1.large  | 8192      | 80   | 0         |      | 4     | 1.0         | True      |
| 5  | m1.xlarge | 16384     | 160  | 0         |      | 8     | 1.0         | True      |
+----+-----------+-----------+------+-----------+------+-------+-------------+-----------+ =~ m1\.nano ]]
++ is_arch ppc64
+++ uname -m
++ [[ x86_64 == \p\p\c\6\4 ]]
++ nova flavor-create m1.nano 42 64 0 1
++ flavor_ref=42
++ boto_instance_type=m1.nano
++ [[ +----+-----------+-----------+------+-----------+------+-------+-------------+-----------+
| ID | Name      | Memory_MB | Disk | Ephemeral | Swap | VCPUs | RXTX_Factor | Is_Public |
+----+-----------+-----------+------+-----------+------+-------+-------------+-----------+
| 1  | m1.tiny   | 512       | 1    | 0         |      | 1     | 1.0         | True      |
| 2  | m1.small  | 2048      | 20   | 0         |      | 1     | 1.0         | True      |
| 3  | m1.medium | 4096      | 40   | 0         |      | 2     | 1.0         | True      |
| 4  | m1.large  | 8192      | 80   | 0         |      | 4     | 1.0         | True      |
| 5  | m1.xlarge | 16384     | 160  | 0         |      | 8     | 1.0         | True      |
+----+-----------+-----------+------+-----------+------+-------+-------------+-----------+ =~ m1\.micro ]]
++ is_arch ppc64
+++ uname -m
++ [[ x86_64 == \p\p\c\6\4 ]]
++ nova flavor-create m1.micro 84 128 0 1
++ flavor_ref_alt=84
++ '[' True '!=' False ']'
++ tenant_networks_reachable=false
++ is_service_enabled n-net
+++ set +o
+++ grep xtrace
++ local 'xtrace=set -o xtrace'
++ set +o xtrace
++ return 1
++ ssh_connect_method=floating
++ ssh_connect_method=floating
++ '[' True = True ']'
+++ neutron net-list
+++ grep public
+++ awk '{print $2}'
++ public_network_id=b7d1f5c2-5e53-4435-9e9a-f492fe1b3ab2
++ '[' True == False ']'
++ iniset /opt/stack/tempest/etc/tempest.conf DEFAULT lock_path /opt/stack/data/tempest
+++ set +o
+++ grep xtrace
++ local 'xtrace=set -o xtrace'
++ set +o xtrace
++ mkdir -p /opt/stack/data/tempest
++ iniset /opt/stack/tempest/etc/tempest.conf DEFAULT use_stderr False
+++ set +o
+++ grep xtrace
++ local 'xtrace=set -o xtrace'
++ set +o xtrace
++ iniset /opt/stack/tempest/etc/tempest.conf DEFAULT log_file tempest.log
+++ set +o
+++ grep xtrace
++ local 'xtrace=set -o xtrace'
++ set +o xtrace
++ iniset /opt/stack/tempest/etc/tempest.conf DEFAULT debug True
+++ set +o
+++ grep xtrace
++ local 'xtrace=set -o xtrace'
++ set +o xtrace
++ iniset /opt/stack/tempest/etc/tempest.conf compute build_timeout 196
+++ set +o
+++ grep xtrace
++ local 'xtrace=set -o xtrace'
++ set +o xtrace
++ iniset /opt/stack/tempest/etc/tempest.conf volume build_timeout 196
+++ set +o
+++ grep xtrace
++ local 'xtrace=set -o xtrace'
++ set +o xtrace
++ iniset /opt/stack/tempest/etc/tempest.conf boto build_timeout 196
+++ set +o
+++ grep xtrace
++ local 'xtrace=set -o xtrace'
++ set +o xtrace
++ iniset /opt/stack/tempest/etc/tempest.conf boto http_socket_timeout 5
+++ set +o
+++ grep xtrace
++ local 'xtrace=set -o xtrace'
++ set +o xtrace
++ iniset /opt/stack/tempest/etc/tempest.conf identity uri http://10.14.0.26:5000/v2.0/
+++ set +o
+++ grep xtrace
++ local 'xtrace=set -o xtrace'
++ set +o xtrace
++ iniset /opt/stack/tempest/etc/tempest.conf identity uri_v3 http://10.14.0.26:5000/v3/
+++ set +o
+++ grep xtrace
++ local 'xtrace=set -o xtrace'
++ set +o xtrace
++ iniset /opt/stack/tempest/etc/tempest.conf identity username demo
+++ set +o
+++ grep xtrace
++ local 'xtrace=set -o xtrace'
++ set +o xtrace
++ iniset /opt/stack/tempest/etc/tempest.conf identity password Passw0rd
+++ set +o
+++ grep xtrace
++ local 'xtrace=set -o xtrace'
++ set +o xtrace
++ iniset /opt/stack/tempest/etc/tempest.conf identity tenant_name demo
+++ set +o
+++ grep xtrace
++ local 'xtrace=set -o xtrace'
++ set +o xtrace
++ iniset /opt/stack/tempest/etc/tempest.conf identity alt_username alt_demo
+++ set +o
+++ grep xtrace
++ local 'xtrace=set -o xtrace'
++ set +o xtrace
++ iniset /opt/stack/tempest/etc/tempest.conf identity alt_password Passw0rd
+++ set +o
+++ grep xtrace
++ local 'xtrace=set -o xtrace'
++ set +o xtrace
++ iniset /opt/stack/tempest/etc/tempest.conf identity alt_tenant_name alt_demo
+++ set +o
+++ grep xtrace
++ local 'xtrace=set -o xtrace'
++ set +o xtrace
++ iniset /opt/stack/tempest/etc/tempest.conf identity admin_username admin
+++ set +o
+++ grep xtrace
++ local 'xtrace=set -o xtrace'
++ set +o xtrace
++ iniset /opt/stack/tempest/etc/tempest.conf identity admin_password Passw0rd
+++ set +o
+++ grep xtrace
++ local 'xtrace=set -o xtrace'
++ set +o xtrace
++ iniset /opt/stack/tempest/etc/tempest.conf identity admin_tenant_name admin
+++ set +o
+++ grep xtrace
++ local 'xtrace=set -o xtrace'
++ set +o xtrace
++ iniset /opt/stack/tempest/etc/tempest.conf identity admin_tenant_id c8a8f2c1f6ed4781a8bb278ddd58d962
+++ set +o
+++ grep xtrace
++ local 'xtrace=set -o xtrace'
++ set +o xtrace
++ iniset /opt/stack/tempest/etc/tempest.conf identity admin_domain_name Default
+++ set +o
+++ grep xtrace
++ local 'xtrace=set -o xtrace'
++ set +o xtrace
++ iniset /opt/stack/tempest/etc/tempest.conf identity auth_version v2
+++ set +o
+++ grep xtrace
++ local 'xtrace=set -o xtrace'
++ set +o xtrace
++ iniset /opt/stack/tempest/etc/tempest.conf identity-feature-enabled xml_api True
+++ set +o
+++ grep xtrace
++ local 'xtrace=set -o xtrace'
++ set +o xtrace
++ [[ ! -z '' ]]
++ iniset /opt/stack/tempest/etc/tempest.conf compute allow_tenant_isolation True
+++ set +o
+++ grep xtrace
++ local 'xtrace=set -o xtrace'
++ set +o xtrace
++ iniset /opt/stack/tempest/etc/tempest.conf compute ssh_user cirros
+++ set +o
+++ grep xtrace
++ local 'xtrace=set -o xtrace'
++ set +o xtrace
++ iniset /opt/stack/tempest/etc/tempest.conf compute network_for_ssh private
+++ set +o
+++ grep xtrace
++ local 'xtrace=set -o xtrace'
++ set +o xtrace
++ iniset /opt/stack/tempest/etc/tempest.conf compute ip_version_for_ssh 4
+++ set +o
+++ grep xtrace
++ local 'xtrace=set -o xtrace'
++ set +o xtrace
++ iniset /opt/stack/tempest/etc/tempest.conf compute ssh_timeout 196
+++ set +o
+++ grep xtrace
++ local 'xtrace=set -o xtrace'
++ set +o xtrace
++ iniset /opt/stack/tempest/etc/tempest.conf compute image_ref 1842cda0-b14b-44ca-9abf-3e549f3abe2e
+++ set +o
+++ grep xtrace
++ local 'xtrace=set -o xtrace'
++ set +o xtrace
++ iniset /opt/stack/tempest/etc/tempest.conf compute image_ssh_user cirros
+++ set +o
+++ grep xtrace
++ local 'xtrace=set -o xtrace'
++ set +o xtrace
++ iniset /opt/stack/tempest/etc/tempest.conf compute image_ref_alt 9b2b82d5-84cb-4b92-8d3a-ce2779cf144e
+++ set +o
+++ grep xtrace
++ local 'xtrace=set -o xtrace'
++ set +o xtrace
++ iniset /opt/stack/tempest/etc/tempest.conf compute image_alt_ssh_user cirros
+++ set +o
+++ grep xtrace
++ local 'xtrace=set -o xtrace'
++ set +o xtrace
++ iniset /opt/stack/tempest/etc/tempest.conf compute flavor_ref 42
+++ set +o
+++ grep xtrace
++ local 'xtrace=set -o xtrace'
++ set +o xtrace
++ iniset /opt/stack/tempest/etc/tempest.conf compute flavor_ref_alt 84
+++ set +o
+++ grep xtrace
++ local 'xtrace=set -o xtrace'
++ set +o xtrace
++ iniset /opt/stack/tempest/etc/tempest.conf compute ssh_connect_method floating
+++ set +o
+++ grep xtrace
++ local 'xtrace=set -o xtrace'
++ set +o xtrace
++ iniset /opt/stack/tempest/etc/tempest.conf compute-feature-enabled resize True
+++ set +o
+++ grep xtrace
++ local 'xtrace=set -o xtrace'
++ set +o xtrace
++ iniset /opt/stack/tempest/etc/tempest.conf compute-feature-enabled live_migration False
+++ set +o
+++ grep xtrace
++ local 'xtrace=set -o xtrace'
++ set +o xtrace
++ iniset /opt/stack/tempest/etc/tempest.conf compute-feature-enabled change_password False
+++ set +o
+++ grep xtrace
++ local 'xtrace=set -o xtrace'
++ set +o xtrace
++ iniset /opt/stack/tempest/etc/tempest.conf compute-feature-enabled block_migration_for_live_migration False
+++ set +o
+++ grep xtrace
++ local 'xtrace=set -o xtrace'
++ set +o xtrace
++ iniset /opt/stack/tempest/etc/tempest.conf compute-feature-enabled api_extensions all
+++ set +o
+++ grep xtrace
++ local 'xtrace=set -o xtrace'
++ set +o xtrace
++ iniset /opt/stack/tempest/etc/tempest.conf compute-feature-enabled xml_api_v2 True
+++ set +o
+++ grep xtrace
++ local 'xtrace=set -o xtrace'
++ set +o xtrace
++ iniset /opt/stack/tempest/etc/tempest.conf compute-feature-disabled api_extensions
+++ set +o
+++ grep xtrace
++ local 'xtrace=set -o xtrace'
++ set +o xtrace
++ iniset /opt/stack/tempest/etc/tempest.conf compute-admin username admin
+++ set +o
+++ grep xtrace
++ local 'xtrace=set -o xtrace'
++ set +o xtrace
++ iniset /opt/stack/tempest/etc/tempest.conf compute-admin password Passw0rd
+++ set +o
+++ grep xtrace
++ local 'xtrace=set -o xtrace'
++ set +o xtrace
++ iniset /opt/stack/tempest/etc/tempest.conf compute-admin tenant_name admin
+++ set +o
+++ grep xtrace
++ local 'xtrace=set -o xtrace'
++ set +o xtrace
++ iniset /opt/stack/tempest/etc/tempest.conf network api_version 2.0
+++ set +o
+++ grep xtrace
++ local 'xtrace=set -o xtrace'
++ set +o xtrace
++ iniset /opt/stack/tempest/etc/tempest.conf network tenant_networks_reachable false
+++ set +o
+++ grep xtrace
++ local 'xtrace=set -o xtrace'
++ set +o xtrace
++ iniset /opt/stack/tempest/etc/tempest.conf network public_network_id b7d1f5c2-5e53-4435-9e9a-f492fe1b3ab2
+++ set +o
+++ grep xtrace
++ local 'xtrace=set -o xtrace'
++ set +o xtrace
++ iniset /opt/stack/tempest/etc/tempest.conf network public_router_id ''
+++ set +o
+++ grep xtrace
++ local 'xtrace=set -o xtrace'
++ set +o xtrace
++ iniset /opt/stack/tempest/etc/tempest.conf network default_network 10.0.0.0/24
+++ set +o
+++ grep xtrace
++ local 'xtrace=set -o xtrace'
++ set +o xtrace
++ iniset /opt/stack/tempest/etc/tempest.conf network-feature-enabled ipv6 True
+++ set +o
+++ grep xtrace
++ local 'xtrace=set -o xtrace'
++ set +o xtrace
++ iniset /opt/stack/tempest/etc/tempest.conf network-feature-enabled ipv6_subnet_attributes True
+++ set +o
+++ grep xtrace
++ local 'xtrace=set -o xtrace'
++ set +o xtrace
++ iniset /opt/stack/tempest/etc/tempest.conf network-feature-enabled api_extensions all
+++ set +o
+++ grep xtrace
++ local 'xtrace=set -o xtrace'
++ set +o xtrace
++ iniset /opt/stack/tempest/etc/tempest.conf network-feature-disabled api_extensions
+++ set +o
+++ grep xtrace
++ local 'xtrace=set -o xtrace'
++ set +o xtrace
++ iniset /opt/stack/tempest/etc/tempest.conf network-feature-enabled xml_api True
+++ set +o
+++ grep xtrace
++ local 'xtrace=set -o xtrace'
++ set +o xtrace
++ iniset /opt/stack/tempest/etc/tempest.conf boto ec2_url http://10.14.0.26:8773/services/Cloud
+++ set +o
+++ grep xtrace
++ local 'xtrace=set -o xtrace'
++ set +o xtrace
++ iniset /opt/stack/tempest/etc/tempest.conf boto s3_url http://10.14.0.26:3333
+++ set +o
+++ grep xtrace
++ local 'xtrace=set -o xtrace'
++ set +o xtrace
++ iniset /opt/stack/tempest/etc/tempest.conf boto s3_materials_path /home/cloudbase/devstack/files/images/s3-materials/cirros-0.3.2
+++ set +o
+++ grep xtrace
++ local 'xtrace=set -o xtrace'
++ set +o xtrace
++ iniset /opt/stack/tempest/etc/tempest.conf boto ari_manifest cirros-0.3.2-x86_64-initrd.manifest.xml
+++ set +o
+++ grep xtrace
++ local 'xtrace=set -o xtrace'
++ set +o xtrace
++ iniset /opt/stack/tempest/etc/tempest.conf boto ami_manifest cirros-0.3.2-x86_64-blank.img.manifest.xml
+++ set +o
+++ grep xtrace
++ local 'xtrace=set -o xtrace'
++ set +o xtrace
++ iniset /opt/stack/tempest/etc/tempest.conf boto aki_manifest cirros-0.3.2-x86_64-vmlinuz.manifest.xml
+++ set +o
+++ grep xtrace
++ local 'xtrace=set -o xtrace'
++ set +o xtrace
++ iniset /opt/stack/tempest/etc/tempest.conf boto instance_type m1.nano
+++ set +o
+++ grep xtrace
++ local 'xtrace=set -o xtrace'
++ set +o xtrace
++ iniset /opt/stack/tempest/etc/tempest.conf boto http_socket_timeout 30
+++ set +o
+++ grep xtrace
++ local 'xtrace=set -o xtrace'
++ set +o xtrace
++ iniset /opt/stack/tempest/etc/tempest.conf boto ssh_user cirros
+++ set +o
+++ grep xtrace
++ local 'xtrace=set -o xtrace'
++ set +o xtrace
++ is_service_enabled heat
+++ set +o
+++ grep xtrace
++ local 'xtrace=set -o xtrace'
++ set +o xtrace
++ return 0
++ [[ ! -z file:///home/cloudbase/devstack/Fedora-x86_64-20-20140618-sda.vhd ]]
+++ basename file:///home/cloudbase/devstack/Fedora-x86_64-20-20140618-sda.vhd .qcow2
++ iniset /opt/stack/tempest/etc/tempest.conf orchestration image_ref Fedora-x86_64-20-20140618-sda.vhd
+++ set +o
+++ grep xtrace
++ local 'xtrace=set -o xtrace'
++ set +o xtrace
+++ nova flavor-list
++ available_flavors='+----+-----------+-----------+------+-----------+------+-------+-------------+-----------+
| ID | Name      | Memory_MB | Disk | Ephemeral | Swap | VCPUs | RXTX_Factor | Is_Public |
+----+-----------+-----------+------+-----------+------+-------+-------------+-----------+
| 1  | m1.tiny   | 512       | 1    | 0         |      | 1     | 1.0         | True      |
| 2  | m1.small  | 2048      | 20   | 0         |      | 1     | 1.0         | True      |
| 3  | m1.medium | 4096      | 40   | 0         |      | 2     | 1.0         | True      |
| 4  | m1.large  | 8192      | 80   | 0         |      | 4     | 1.0         | True      |
| 42 | m1.nano   | 64        | 0    | 0         |      | 1     | 1.0         | True      |
| 5  | m1.xlarge | 16384     | 160  | 0         |      | 8     | 1.0         | True      |
| 84 | m1.micro  | 128       | 0    | 0         |      | 1     | 1.0         | True      |
+----+-----------+-----------+------+-----------+------+-------+-------------+-----------+'
++ [[ +----+-----------+-----------+------+-----------+------+-------+-------------+-----------+
| ID | Name      | Memory_MB | Disk | Ephemeral | Swap | VCPUs | RXTX_Factor | Is_Public |
+----+-----------+-----------+------+-----------+------+-------+-------------+-----------+
| 1  | m1.tiny   | 512       | 1    | 0         |      | 1     | 1.0         | True      |
| 2  | m1.small  | 2048      | 20   | 0         |      | 1     | 1.0         | True      |
| 3  | m1.medium | 4096      | 40   | 0         |      | 2     | 1.0         | True      |
| 4  | m1.large  | 8192      | 80   | 0         |      | 4     | 1.0         | True      |
| 42 | m1.nano   | 64        | 0    | 0         |      | 1     | 1.0         | True      |
| 5  | m1.xlarge | 16384     | 160  | 0         |      | 8     | 1.0         | True      |
| 84 | m1.micro  | 128       | 0    | 0         |      | 1     | 1.0         | True      |
+----+-----------+-----------+------+-----------+------+-------+-------------+-----------+ =~ m1\.heat ]]
++ nova flavor-create m1.heat 451 512 0 1
++ iniset /opt/stack/tempest/etc/tempest.conf orchestration instance_type m1.heat
+++ set +o
+++ grep xtrace
++ local 'xtrace=set -o xtrace'
++ set +o xtrace
++ iniset /opt/stack/tempest/etc/tempest.conf orchestration build_timeout 900
+++ set +o
+++ grep xtrace
++ local 'xtrace=set -o xtrace'
++ set +o xtrace
++ iniset /opt/stack/tempest/etc/tempest.conf scenario img_dir /home/cloudbase/devstack/files/images/cirros-0.3.2-x86_64-uec
+++ set +o
+++ grep xtrace
++ local 'xtrace=set -o xtrace'
++ set +o xtrace
++ iniset /opt/stack/tempest/etc/tempest.conf scenario ami_img_file cirros-0.3.2-x86_64-blank.img
+++ set +o
+++ grep xtrace
++ local 'xtrace=set -o xtrace'
++ set +o xtrace
++ iniset /opt/stack/tempest/etc/tempest.conf scenario ari_img_file cirros-0.3.2-x86_64-initrd
+++ set +o
+++ grep xtrace
++ local 'xtrace=set -o xtrace'
++ set +o xtrace
++ iniset /opt/stack/tempest/etc/tempest.conf scenario aki_img_file cirros-0.3.2-x86_64-vmlinuz
+++ set +o
+++ grep xtrace
++ local 'xtrace=set -o xtrace'
++ set +o xtrace
++ iniset /opt/stack/tempest/etc/tempest.conf scenario large_ops_number 0
+++ set +o
+++ grep xtrace
++ local 'xtrace=set -o xtrace'
++ set +o xtrace
++ iniset /opt/stack/tempest/etc/tempest.conf telemetry too_slow_to_test False
+++ set +o
+++ grep xtrace
++ local 'xtrace=set -o xtrace'
++ set +o xtrace
++ iniset /opt/stack/tempest/etc/tempest.conf object-storage-feature-enabled discoverable_apis all
+++ set +o
+++ grep xtrace
++ local 'xtrace=set -o xtrace'
++ set +o xtrace
++ iniset /opt/stack/tempest/etc/tempest.conf object-storage-feature-disabled discoverable_apis
+++ set +o
+++ grep xtrace
++ local 'xtrace=set -o xtrace'
++ set +o xtrace
++ iniset /opt/stack/tempest/etc/tempest.conf volume-feature-enabled api_extensions all
+++ set +o
+++ grep xtrace
++ local 'xtrace=set -o xtrace'
++ set +o xtrace
++ iniset /opt/stack/tempest/etc/tempest.conf volume-feature-disabled api_extensions
+++ set +o
+++ grep xtrace
++ local 'xtrace=set -o xtrace'
++ set +o xtrace
++ is_service_enabled c-bak
+++ set +o
+++ grep xtrace
++ local 'xtrace=set -o xtrace'
++ set +o xtrace
++ return 0
+++ trueorfalse False False
++++ set +o
++++ grep xtrace
+++ local 'xtrace=set -o xtrace'
+++ set +o xtrace
++ CINDER_MULTI_LVM_BACKEND=False
++ '[' False == True ']'
++ '[' default '!=' default ']'
++ iniset /opt/stack/tempest/etc/tempest.conf dashboard dashboard_url http://10.14.0.26/
+++ set +o
+++ grep xtrace
++ local 'xtrace=set -o xtrace'
++ set +o xtrace
++ iniset /opt/stack/tempest/etc/tempest.conf dashboard login_url http://10.14.0.26/auth/login/
+++ set +o
+++ grep xtrace
++ local 'xtrace=set -o xtrace'
++ set +o xtrace
++ iniset /opt/stack/tempest/etc/tempest.conf cli cli_dir /usr/local/bin
+++ set +o
+++ grep xtrace
++ local 'xtrace=set -o xtrace'
++ set +o xtrace
++ '[' libvirt = ironic ']'
++ for service in '${TEMPEST_SERVICES//,/ }'
++ is_service_enabled horizon
+++ set +o
+++ grep xtrace
++ local 'xtrace=set -o xtrace'
++ set +o xtrace
++ return 1
++ iniset /opt/stack/tempest/etc/tempest.conf service_available horizon False
+++ set +o
+++ grep xtrace
++ local 'xtrace=set -o xtrace'
++ set +o xtrace
++ for service in '${TEMPEST_SERVICES//,/ }'
++ is_service_enabled glance
+++ set +o
+++ grep xtrace
++ local 'xtrace=set -o xtrace'
++ set +o xtrace
++ return 0
++ iniset /opt/stack/tempest/etc/tempest.conf service_available glance True
+++ set +o
+++ grep xtrace
++ local 'xtrace=set -o xtrace'
++ set +o xtrace
++ for service in '${TEMPEST_SERVICES//,/ }'
++ is_service_enabled nova
+++ set +o
+++ grep xtrace
++ local 'xtrace=set -o xtrace'
++ set +o xtrace
++ return 0
++ iniset /opt/stack/tempest/etc/tempest.conf service_available nova True
+++ set +o
+++ grep xtrace
++ local 'xtrace=set -o xtrace'
++ set +o xtrace
++ for service in '${TEMPEST_SERVICES//,/ }'
++ is_service_enabled cinder
+++ set +o
+++ grep xtrace
++ local 'xtrace=set -o xtrace'
++ set +o xtrace
++ return 0
++ iniset /opt/stack/tempest/etc/tempest.conf service_available cinder True
+++ set +o
+++ grep xtrace
++ local 'xtrace=set -o xtrace'
++ set +o xtrace
++ for service in '${TEMPEST_SERVICES//,/ }'
++ is_service_enabled swift
+++ set +o
+++ grep xtrace
++ local 'xtrace=set -o xtrace'
++ set +o xtrace
++ return 0
++ iniset /opt/stack/tempest/etc/tempest.conf service_available swift True
+++ set +o
+++ grep xtrace
++ local 'xtrace=set -o xtrace'
++ set +o xtrace
++ for service in '${TEMPEST_SERVICES//,/ }'
++ is_service_enabled ceilometer
+++ set +o
+++ grep xtrace
++ local 'xtrace=set -o xtrace'
++ set +o xtrace
++ return 0
++ iniset /opt/stack/tempest/etc/tempest.conf service_available ceilometer True
+++ set +o
+++ grep xtrace
++ local 'xtrace=set -o xtrace'
++ set +o xtrace
++ for service in '${TEMPEST_SERVICES//,/ }'
++ is_service_enabled heat
+++ set +o
+++ grep xtrace
++ local 'xtrace=set -o xtrace'
++ set +o xtrace
++ return 0
++ iniset /opt/stack/tempest/etc/tempest.conf service_available heat True
+++ set +o
+++ grep xtrace
++ local 'xtrace=set -o xtrace'
++ set +o xtrace
++ for service in '${TEMPEST_SERVICES//,/ }'
++ is_service_enabled neutron
+++ set +o
+++ grep xtrace
++ local 'xtrace=set -o xtrace'
++ set +o xtrace
++ return 0
++ iniset /opt/stack/tempest/etc/tempest.conf service_available neutron True
+++ set +o
+++ grep xtrace
++ local 'xtrace=set -o xtrace'
++ set +o xtrace
++ IFS=' 	
'
++ init_tempest
++ local base_image_name=cirros-0.3.2-x86_64
++ local image_dir=/home/cloudbase/devstack/files/images/cirros-0.3.2-x86_64-uec
++ local kernel=/home/cloudbase/devstack/files/images/cirros-0.3.2-x86_64-uec/cirros-0.3.2-x86_64-vmlinuz
++ local ramdisk=/home/cloudbase/devstack/files/images/cirros-0.3.2-x86_64-uec/cirros-0.3.2-x86_64-initrd
++ local disk_image=/home/cloudbase/devstack/files/images/cirros-0.3.2-x86_64-uec/cirros-0.3.2-x86_64-blank.img
++ '[' -f /home/cloudbase/devstack/files/images/cirros-0.3.2-x86_64-uec/cirros-0.3.2-x86_64-vmlinuz -a -f /home/cloudbase/devstack/files/images/cirros-0.3.2-x86_64-uec/cirros-0.3.2-x86_64-initrd -a -f /home/cloudbase/devstack/files/images/cirros-0.3.2-x86_64-uec/cirros-0.3.2-x86_64-blank.img -a libvirt '!=' openvz -a '(' kvm '!=' lxc -o libvirt '!=' libvirt ')' ']'
++ echo 'Prepare aki/ari/ami Images'
++ mkdir -p /home/cloudbase/devstack/files/images/s3-materials/cirros-0.3.2
++ cat
++ [[ stack == \u\n\s\t\a\c\k ]]
++ [[ stack == \c\l\e\a\n ]]
+ merge_config_group /home/cloudbase/devstack/local.conf post-extra
+ local localfile=/home/cloudbase/devstack/local.conf
+ shift
+ local matchgroups=post-extra
+ [[ -r /home/cloudbase/devstack/local.conf ]]
+ local configfile group
+ for group in '$matchgroups'
++ get_meta_section_files /home/cloudbase/devstack/local.conf post-extra
++ local file=/home/cloudbase/devstack/local.conf
++ local matchgroup=post-extra
++ [[ -r /home/cloudbase/devstack/local.conf ]]
++ awk -v matchgroup=post-extra '
        /^\[\[.+\|.*\]\]/ {
            gsub("[][]", "", $1);
            split($1, a, "|");
            if (a[1] == matchgroup)
                print a[2]
        }
    ' /home/cloudbase/devstack/local.conf
+ [[ -x /home/cloudbase/devstack/local.sh ]]
+ echo 'Running user script /home/cloudbase/devstack/local.sh'
+ /home/cloudbase/devstack/local.sh
+ service_check
+ local service
+ local failures
+ SCREEN_NAME=stack
+ SERVICE_DIR=/opt/stack/status
+ [[ ! -d /opt/stack/status/stack ]]
++ ls '/opt/stack/status/stack/*.failure'
++ /bin/true
+ failures=
+ '[' -n '' ']'
+ set +o xtrace
